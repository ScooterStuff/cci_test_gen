[
  {
    "id": "essentials_Essentials-250-Param-0",
    "old_comment_raw": "@param userName the name of the user",
    "new_code_raw": "\tpublic User getUser(String userId) {\n\t\t\n\t\tif (getUsers().containsKey(userId.toLowerCase())) {\n\t\t\treturn getUsers().get(userId.toLowerCase());\n\t\t}\n\t\t\n\t\t// Legacy name matching\n\t\tif (userId.length() < 36) {\n\n\t\t\t// Search for a LastName match\n\t\t\tfor (User user : getUserList()) {\n\t\t\t\t\n\t\t\t\tif (user.getLastName().equalsIgnoreCase(userId))\n\t\t\t\t\treturn user;\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\n\t\t// No user account found so create a new one.\n\t\tUser newUser = createUser(userId);\n\t\t\n\t\treturn newUser;\n\t}\n"
  },
  {
    "id": "apache_ignite-4949-Param-10",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    @Override protected void clearIndex(CacheObject val) {\n        // No-op.\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-605-Param-0",
    "old_comment_raw": "@param createDate",
    "new_code_raw": "    public int delete(Date now) {\n        if (null != now) {\n            QueryHandler queryHandler = getQueryHandler(\"delete from SysEmailToken bean\");\n            queryHandler.condition(\"bean.expiryDate is not null\");\n            queryHandler.condition(\"bean.expiryDate <= :expiryDate\").setParameter(\"expiryDate\", now);\n            return delete(queryHandler);\n        }\n        return 0;\n    }\n"
  },
  {
    "id": "apache_ignite-4967-Param-0",
    "old_comment_raw": "@param key Key to add.",
    "new_code_raw": "    private boolean addLocalKey(KeyCacheObject key, long topVer, Collection<KeyCacheObject> distributedKeys)\n        throws IgniteCheckedException {\n        GridDistributedCacheEntry entry = cctx.colocated().entryExx(key, topVer, false);\n\n        assert !entry.detached();\n\n        if (!cctx.isAll(entry, filter)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Entry being locked did not pass filter (will not lock): \" + entry);\n\n            onComplete(false, false);\n\n            return false;\n        }\n\n        GridCacheMvccCandidate cand = addEntry(entry);\n\n        if (cand != null && !cand.reentry())\n            distributedKeys.add(key);\n\n        return inTx() && cand == null;\n    }\n"
  },
  {
    "id": "apache_ignite-12330-Param-3",
    "old_comment_raw": "@param metaStore Store.",
    "new_code_raw": "    protected ReuseList createReuseList(int cacheId, PageMemory pageMem, long[] rootIds, boolean initNew)\n        throws IgniteCheckedException {\n        return null;\n    }\n"
  },
  {
    "id": "fabric8io_kubernetes_client-4-Param-1",
    "old_comment_raw": "@param apiGroupName the API Group name like apps.openshift.io or build.openshift.io",
    "new_code_raw": "  public static ConfigAndApiGroupsInfo withApiGroup(OpenShiftClient openShiftClient, String apiGroupName, String apiVersion, OpenShiftConfig config) {\n    String oapiVersion = config.getOapiVersion();\n    if (config.isOpenShiftAPIGroups(openShiftClient)) {\n      String apiGroupUrl = URLUtils.join(config.getMasterUrl(), \"apis\", apiGroupName, oapiVersion);\n      String apiGroupVersion = URLUtils.join(apiGroupName, oapiVersion);\n      return new ConfigAndApiGroupsInfo(new OpenShiftConfig(config, apiGroupUrl), apiGroupName, apiGroupVersion);\n    } else {\n      if (apiVersion == null) {\n        apiVersion = oapiVersion;\n      }\n      return new ConfigAndApiGroupsInfo(config, apiGroupName, apiVersion);\n    }\n  }\n"
  },
  {
    "id": "essentials_Essentials-251-Param-0",
    "old_comment_raw": "@param userName",
    "new_code_raw": "\tpublic boolean isUserDeclared(String userId) {\n\n\t\treturn getUsers().containsKey(userId.toLowerCase());\n\t}\n"
  },
  {
    "id": "apache_ignite-12020-Param-2",
    "old_comment_raw": "@param cnt Number of popular numbers to return.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite ignite, Timer timer, final int cnt) {\n        TimerTask task = new TimerTask() {\n            private CacheQuery<List<?>> qry;\n\n            @Override public void run() {\n                // Get reference to cache.\n                GridCache<Integer, Long> cache = ignite.cache(CACHE_NAME);\n\n                if (qry == null)\n                    qry = cache.queries().\n                        createSqlFieldsQuery(\"select _key, _val from Long order by _val desc limit \" + cnt);\n\n                try {\n                    List<List<?>> results = new ArrayList<>(qry.execute().get());\n\n                    Collections.sort(results, new Comparator<List<?>>() {\n                        @Override public int compare(List<?> r1, List<?> r2) {\n                            long cnt1 = (Long)r1.get(1);\n                            long cnt2 = (Long)r2.get(1);\n\n                            return cnt1 < cnt2 ? 1 : cnt1 > cnt2 ? -1 : 0;\n                        }\n                    });\n\n                    for (int i = 0; i < cnt && i < results.size(); i++) {\n                        List<?> res = results.get(i);\n\n                        System.out.println(res.get(0) + \"=\" + res.get(1));\n                    }\n\n                    System.out.println(\"----------------\");\n                }\n                catch (IgniteCheckedException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 3000, 3000);\n\n        return task;\n    }\n"
  },
  {
    "id": "apache_ignite-13601-Param-0",
    "old_comment_raw": "@param schema Schema.",
    "new_code_raw": "    public String space(String schemaName) {\n        assert schemaName != null;\n\n        Schema schema = schemas.get(schemaName);\n\n        // For the compatibility with conversion from \"\"\"\" to \"\" inside h2 lib\n        if (schema == null) {\n            assert schemaName.isEmpty() || schemaName.charAt(0) != ESC_CH;\n\n            schema = schemas.get(escapeName(schemaName, true));\n        }\n\n        return schema.spaceName;\n    }\n"
  },
  {
    "id": "apache_ignite-5771-Param-0",
    "old_comment_raw": "@param ctx Cache context.",
    "new_code_raw": "    public static Collection<ClusterNode> allNodes(GridCacheContext ctx, AffinityTopologyVersion topOrder) {\n        return ctx.discovery().cacheNodes(ctx.namex(), topOrder);\n    }\n"
  },
  {
    "id": "eclipse_elk-51-Associations-Param0",
    "old_comment_raw": "@param kedge the  KEdge check for connected elements",
    "new_code_raw": "    public static Iterator<ElkGraphElement> getConnectedElements(final ElkEdge edge, final boolean addPorts) {\n        final SelectionIterator sourceSideIt = new DefaultSelectionIterator(edge, addPorts, false);\n        final SelectionIterator targetSideIt = new DefaultSelectionIterator(edge, addPorts, true);\n\n        return getConnectedElements(edge, sourceSideIt, targetSideIt);\n    }\n\n"
  },
  {
    "id": "apache_ignite-12330-Param-1",
    "old_comment_raw": "@param pageMem Page memory.",
    "new_code_raw": "    protected ReuseList createReuseList(int cacheId, PageMemory pageMem, long[] rootIds, boolean initNew)\n        throws IgniteCheckedException {\n        return null;\n    }\n"
  },
  {
    "id": "apache_wss4j-33-Associations-Param0",
    "old_comment_raw": "@param wsResultVector The result vector to fetch an action from",
    "new_code_raw": "    public static WSSecurityEngineResult fetchActionResult(List resultList, int action) {\n\n        for (int i = 0; i < resultList.size(); i++) {\n            //\n            // Check the result of every action whether it matches the given action\n            //\n            WSSecurityEngineResult result = \n                (WSSecurityEngineResult) resultList.get(i);\n            int resultAction = \n                ((java.lang.Integer)result.get(WSSecurityEngineResult.TAG_ACTION)).intValue();\n            if (resultAction == action) {\n                return result;\n            }\n        }\n\n        return null;\n    }\n\n"
  },
  {
    "id": "apache_ignite-5772-Param-0",
    "old_comment_raw": "@param ctx Shared cache context.",
    "new_code_raw": "    public static Collection<ClusterNode> allNodes(GridCacheSharedContext ctx, AffinityTopologyVersion topOrder) {\n        return ctx.discovery().cacheNodes(topOrder);\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-503-Param-1",
    "old_comment_raw": "@param refresh",
    "new_code_raw": "    public String check(Long[] ids, String _csrf, HttpServletRequest request, HttpSession session, ModelMap model) {\n        if (ControllerUtils.verifyNotEquals(\"_csrf\", ControllerUtils.getAdminToken(request), _csrf, model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        if (CommonUtils.notEmpty(ids)) {\n            SysSite site = getSite(request);\n            Long userId = ControllerUtils.getAdminFromSession(session).getId();\n            List<CmsContent> entityList = service.check(site.getId(), userId, ids);\n            Set<Integer> categoryIdSet = new HashSet<>();\n            for (CmsContent entity : entityList) {\n                if (null != entity && site.getId() == entity.getSiteId()) {\n                    if (CommonUtils.notEmpty(entity.getParentId())) {\n                        publish(new Long[] { entity.getParentId() }, _csrf, request, session, model);\n                    }\n                    publish(new Long[] { entity.getId() }, _csrf, request, session, model);\n                    categoryIdSet.add(entity.getCategoryId());\n                }\n            }\n            for (CmsCategory category : categoryService.getEntitys(categoryIdSet.toArray(new Integer[categoryIdSet.size()]))) {\n                templateComponent.createCategoryFile(site, category, null, null);\n            }\n            logOperateService.save(new LogOperate(site.getId(), userId, LogLoginService.CHANNEL_WEB_MANAGER, \"check.content\",\n                    RequestUtils.getIpAddress(request), CommonUtils.getDate(), StringUtils.join(ids, ',')));\n        }\n        return CommonConstants.TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-797-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "  public Long incrBy(final byte[] key, final long increment) {\n    checkIsInMultiOrPipeline();\n    client.incrBy(key, increment);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "sanluan_PublicCMS-590-Param-2",
    "old_comment_raw": "@param id",
    "new_code_raw": "    public boolean virify(String name, String domain, String oldName, ModelMap model) {\n        if (CommonUtils.notEmpty(name)) {\n            if (CommonUtils.notEmpty(oldName) && !name.equals(oldName)\n                    && ControllerUtils.verifyHasExist(\"domain\", service.getEntity(name), model)\n                    || CommonUtils.empty(oldName) && ControllerUtils.verifyHasExist(\"domain\", service.getEntity(name), model)) {\n                return false;\n            }\n        }\n        if (CommonUtils.notEmpty(domain) && ControllerUtils.verifyHasExist(\"domain\", service.getEntity(domain), model)) {\n            return false;\n        }\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-1555-Param-4",
    "old_comment_raw": "@param pendingParts per tier pending partitions map.",
    "new_code_raw": "        boolean assign(int part, int tier, ClusterNode node, boolean force, Map<Integer, Queue<Integer>> pendingParts) {\n            UUID nodeId = node.id();\n\n            if (!fullMap.get(nodeId).contains(part)) {\n                tierMaps[tier].get(nodeId).add(part);\n\n                fullMap.get(nodeId).add(part);\n\n                List<ClusterNode> assignment = assignments.get(part);\n\n                if (assignment.size() <= tier)\n                    assignment.add(node);\n                else {\n                    ClusterNode oldNode = assignment.set(tier, node);\n\n                    if (oldNode != null) {\n                        UUID oldNodeId = oldNode.id();\n\n                        tierMaps[tier].get(oldNodeId).remove(part);\n                        fullMap.get(oldNodeId).remove(part);\n                    }\n                }\n\n                return true;\n            }\n            else if (force) {\n                assert !tierMaps[tier].get(nodeId).contains(part);\n\n                // Check previous tiers first.\n                for (int t = 0; t < tier; t++) {\n                    if (tierMaps[t].get(nodeId).contains(part))\n                        return false;\n                }\n\n                // Partition is on some lower tier, switch it.\n                for (int t = tier + 1; t < tierMaps.length; t++) {\n                    if (tierMaps[t].get(nodeId).contains(part)) {\n                        ClusterNode oldNode = assignments.get(part).get(tier);\n\n                        // Move partition from level t to tier.\n                        assignments.get(part).set(tier, node);\n                        assignments.get(part).set(t, null);\n\n                        if (oldNode != null) {\n                            tierMaps[tier].get(oldNode.id()).remove(part);\n                            fullMap.get(oldNode.id()).remove(part);\n                        }\n\n                        tierMaps[tier].get(nodeId).add(part);\n                        tierMaps[t].get(nodeId).remove(part);\n\n                        Queue<Integer> pending = pendingParts.get(t);\n\n                        if (pending == null) {\n                            pending = new LinkedList<>();\n\n                            pendingParts.put(t, pending);\n                        }\n\n                        pending.add(part);\n\n                        return true;\n                    }\n                }\n\n                throw new IllegalStateException(\"Unable to assign partition to node while force is true.\");\n            }\n\n            // !force.\n            return false;\n        }\n"
  },
  {
    "id": "apache_ignite-13611-Param-1",
    "old_comment_raw": "@param cls Source type class.",
    "new_code_raw": "    private static ClassProperty buildClassProperty(Class<?> keyCls, Class<?> valCls, String pathStr, Class<?> resType)\n        throws IgniteCheckedException {\n        ClassProperty res = buildClassProperty(true, keyCls, pathStr, resType);\n\n        if (res == null) // We check key before value consistently with PortableProperty.\n            res = buildClassProperty(false, valCls, pathStr, resType);\n\n        if (res == null)\n            throw new IgniteCheckedException(\"Failed to initialize property '\" + pathStr + \"' for \" +\n                \"key class '\" + keyCls + \"' and value class '\" + valCls + \"'. \" +\n                \"Make sure that one of these classes contains respective getter method or field.\");\n\n        return res;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-189-Param-1",
    "old_comment_raw": "@param numRows number of training rows",
    "new_code_raw": "  private static long computeTrainSamplesPerIteration(final long train_samples_per_iteration, final long numRows, final boolean replicate_training_data, final boolean single_node_mode) {\n    long tspi = train_samples_per_iteration;\n    assert(tspi == 0 || tspi == -1 || tspi >= 1);\n    if (tspi == 0 || (!replicate_training_data && (tspi == -1 || tspi > numRows)) || (replicate_training_data && single_node_mode))\n      Log.info(\"Setting train_samples_per_iteration (\" + tspi + \") to one epoch: #rows (\" + (tspi=numRows) + \").\");\n    else if (tspi == -1 || tspi > H2O.CLOUD.size()*numRows)\n      Log.info(\"Setting train_samples_per_iteration (\" + tspi + \") to the largest possible number: #nodes x #rows (\" + (tspi=H2O.CLOUD.size()*numRows) + \").\");\n    assert(tspi != 0 && tspi != -1 && tspi >= 1);\n    return tspi;\n  }\n"
  },
  {
    "id": "zxing_zxing-597-Param-0",
    "old_comment_raw": "@param luminanceBuckets an array of counts of luminance values",
    "new_code_raw": "  public static int estimate(int[] histogram) {\n\n    int numBuckets = histogram.length;\n\n    // Find tallest peak in histogram\n    int firstPeak = 0;\n    int firstPeakSize = 0;\n    for (int i = 0; i < numBuckets; i++) {\n      if (histogram[i] > firstPeakSize) {\n        firstPeak = i;\n        firstPeakSize = histogram[i];\n      }\n    }\n\n    // Find second-tallest peak -- well, another peak that is tall and not\n    // so close to the first one\n    int secondPeak = 0;\n    int secondPeakScore = 0;\n    for (int i = 0; i < numBuckets; i++) {\n      int distanceToBiggest = i - firstPeak;\n      // Encourage more distant second peaks by multiplying by square of distance\n      int score = histogram[i] * distanceToBiggest * distanceToBiggest;\n      if (score > secondPeakScore) {\n        secondPeak = i;\n        secondPeakScore = score;\n      }\n    }\n\n    // Put firstPeak first\n    if (firstPeak > secondPeak) {\n      int temp = firstPeak;\n      firstPeak = secondPeak;\n      secondPeak = temp;\n    }\n\n    // Find a valley between them that is low and closer to the white peak\n    int bestValley = secondPeak;\n    int bestValleyScore = Integer.MAX_VALUE;\n    for (int i = secondPeak; i > firstPeak; i--) {\n      int distance = secondPeak - i + 3;\n      int score = distance * histogram[i];\n      if (score < bestValleyScore) {\n        bestValley = i;\n        bestValleyScore = score;\n      }\n    }\n\n    return bestValley;\n  }\n"
  },
  {
    "id": "keycloak_keycloak-249-Param-0",
    "old_comment_raw": "@param app",
    "new_code_raw": "    public static ApplicationRepresentation exportApplication(ClientModel app) {\n        ApplicationRepresentation appRep = ModelToRepresentation.toRepresentation(app);\n\n        appRep.setSecret(app.getSecret());\n        return appRep;\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-601-Param-1",
    "old_comment_raw": "@param userId",
    "new_code_raw": "    public List<CmsContent> check(short siteId, SysUser user, Serializable[] ids) {\n        List<CmsContent> entityList = new ArrayList<>();\n        for (CmsContent entity : getEntitys(ids)) {\n            if (null != entity && siteId == entity.getSiteId() && STATUS_PEND == entity.getStatus()\n                    && (user.isOwnsAllContent() || entity.getUserId() == user.getId())) {\n                entity.setStatus(STATUS_NORMAL);\n                entity.setCheckUserId(user.getId());\n                entity.setCheckDate(CommonUtils.getDate());\n                entityList.add(entity);\n            }\n        }\n        return entityList;\n    }\n"
  },
  {
    "id": "apache_ignite-8262-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    public boolean update(KeyCacheObject key, int partId, CacheObject val, GridCacheVersion ver, long expirationTime, boolean rmv)\n        throws IgniteCheckedException {\n        assert desc != null;\n\n        GridH2Row row = desc.createRow(key, partId, val, ver, expirationTime);\n\n        return doUpdate(row, rmv);\n    }\n"
  },
  {
    "id": "apache_ignite-11585-Param-1",
    "old_comment_raw": "@param localCombiner If we have mapper with combiner.",
    "new_code_raw": "    private GridHadoopTaskInput createInput(GridHadoopTaskInfo info, boolean locCombiner) throws GridException {\n        switch (info.type()) {\n            case SETUP:\n            case MAP:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case COMBINE:\n                if (locCombiner) {\n                    assert local != null;\n\n                    return local.input((Comparator<Object>)job.combineGroupComparator());\n                }\n\n            default:\n                return createInput(info);\n        }\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-283-Param-0",
    "old_comment_raw": "@param itemName",
    "new_code_raw": "\tprivate ExecBindingProvider findFirstMatchingBindingProvider(String itemName, Command command) {\n\t\t\n\t\tExecBindingProvider firstMatchingProvider = null;\n\t\t\n\t\tfor (ExecBindingProvider provider : this.providers) {\n\t\t\t\n\t\t\tString commandLine = provider.getCommandLine(itemName, command);\n\t\t\t\n\t\t\tif (commandLine != null) {\n\t\t\t\tfirstMatchingProvider = provider;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t// we didn't find an exact match. probably one configured a fallback\n\t\t// command?\n\t\tif (firstMatchingProvider == null) {\n\t\t\tfor (ExecBindingProvider provider : this.providers) {\n\t\t\t\t\n\t\t\t\tString commandLine = provider.getCommandLine(itemName, WILDCARD_COMMAND_KEY);\n\t\t\t\tif (commandLine != null) {\n\t\t\t\t\tfirstMatchingProvider = provider;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn firstMatchingProvider;\n\t}\n"
  },
  {
    "id": "xetorthio_jedis-801-Param-1",
    "old_comment_raw": "@param score",
    "new_code_raw": "  public Double zincrby(final byte[] key, final double increment, final byte[] member) {\n    checkIsInMultiOrPipeline();\n    client.zincrby(key, increment, member);\n    String newscore = client.getBulkReply();\n    return Double.valueOf(newscore);\n  }\n"
  },
  {
    "id": "apache_ignite-2016-Param-0",
    "old_comment_raw": "@param parentId Parent ID.",
    "new_code_raw": "    @Nullable private IgniteUuid softDeleteNonTx(@Nullable IgniteUuid parentId, @Nullable String name, IgniteUuid id)\n        throws GridException {\n        assert validTxState(true);\n\n        IgniteUuid resId;\n\n        if (parentId == null) {\n            // Handle special case when we deleting root directory.\n            assert ROOT_ID.equals(id);\n\n            GridGgfsFileInfo rootInfo = id2InfoPrj.get(ROOT_ID);\n\n            if (rootInfo == null)\n                return null; // Root was never created.\n\n            // Ensure trash directory existence.\n            if (id2InfoPrj.get(TRASH_ID) == null)\n                id2InfoPrj.put(TRASH_ID, new GridGgfsFileInfo(TRASH_ID));\n\n            Map<String, GridGgfsListingEntry> rootListing = rootInfo.listing();\n\n            if (!rootListing.isEmpty()) {\n                IgniteUuid[] lockIds = new IgniteUuid[rootInfo.listing().size()];\n\n                int i = 0;\n\n                for (GridGgfsListingEntry entry : rootInfo.listing().values())\n                    lockIds[i++] = entry.fileId();\n\n                // Lock children IDs in correct order.\n                lockIds(lockIds);\n\n                // Construct new info and move locked entries from root to it.\n                Map<String, GridGgfsListingEntry> transferListing = new HashMap<>();\n\n                transferListing.putAll(rootListing);\n\n                GridGgfsFileInfo newInfo = new GridGgfsFileInfo(transferListing);\n\n                id2InfoPrj.put(newInfo.id(), newInfo);\n\n                // Add new info to trash listing.\n                id2InfoPrj.transform(TRASH_ID, new UpdateListing(newInfo.id().toString(),\n                    new GridGgfsListingEntry(newInfo), false));\n\n                // Remove listing entries from root.\n                for (Map.Entry<String, GridGgfsListingEntry> entry : transferListing.entrySet())\n                    id2InfoPrj.transform(ROOT_ID, new UpdateListing(entry.getKey(), entry.getValue(), true));\n\n                resId = newInfo.id();\n            }\n            else\n                resId = null;\n        }\n        else {\n            // Ensure trash directory existence.\n            if (id2InfoPrj.get(TRASH_ID) == null)\n                id2InfoPrj.put(TRASH_ID, new GridGgfsFileInfo(TRASH_ID));\n\n            moveNonTx(id, name, parentId, id.toString(), TRASH_ID);\n\n            resId = id;\n        }\n\n        return resId;\n    }\n"
  },
  {
    "id": "eclipse_rt.equinox.framework-57-Associations-Param0",
    "old_comment_raw": "@param target the target name to write.",
    "new_code_raw": "\tpublic ManagedOutputStream getOutputStream(String managedFile) throws IOException {\n\t\tif (useReliableFiles) {\n\t\t\tReliableFileOutputStream out = new ReliableFileOutputStream(new File(getBase(), managedFile));\n\t\t\treturn new ManagedOutputStream(out, this, managedFile, null);\n\t\t}\n\t\tFile tmpFile = createTempFile(managedFile);\n\t\treturn new ManagedOutputStream(new FileOutputStream(tmpFile), this, managedFile, tmpFile);\n\t}\n\n"
  },
  {
    "id": "apache_ignite-13278-Param-2",
    "old_comment_raw": "@param n Node from which affinity is requested.",
    "new_code_raw": "    private AffinityInfo affinityInfoFromNode(@Nullable String cacheName, long topVer, ClusterNode n)\n        throws IgniteCheckedException {\n        GridTuple3<GridAffinityMessage, GridAffinityMessage, GridAffinityAssignment> t = ctx.closure()\n            .callAsyncNoFailover(BALANCE, affinityJob(cacheName, topVer), F.asList(n), true/*system pool*/).get();\n\n        CacheAffinityFunction f = (CacheAffinityFunction)unmarshall(ctx, n.id(), t.get1());\n        CacheAffinityKeyMapper m = (CacheAffinityKeyMapper)unmarshall(ctx, n.id(), t.get2());\n\n        assert m != null;\n\n        // Bring to initial state.\n        f.reset();\n        m.reset();\n\n        return new AffinityInfo(f, m, t.get3(), ctx.cacheObjects().contextForCache(n, cacheName));\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-757-Param-1",
    "old_comment_raw": "@param resId",
    "new_code_raw": "    public StyledText foreground(final CharSequence text, final int color) {\n        return append(text, new ForegroundColorSpan(color));\n    }\n"
  },
  {
    "id": "apache_ignite-314-Param-1",
    "old_comment_raw": "@param p Partition.",
    "new_code_raw": "        private boolean preloadEntry(GridNode pick, int p, GridCacheEntryInfo<K, V> entry, long topVer)\n            throws GridException, GridInterruptedException {\n            try {\n                GridCacheEntryEx<K, V> cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isGgfsDataCache() &&\n                        cctx.dht().ggfsDataSpaceUsed() > cctx.dht().ggfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload GGFS data cache (GGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            entry.valueBytes(),\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isDrEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (GridUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (GridInterruptedException e) {\n                throw e;\n            }\n            catch (GridException e) {\n                throw new GridException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "openhab_openhab1_addons-966-Param-1",
    "old_comment_raw": "@param itemName",
    "new_code_raw": "\tpublic Iterable<Rule> getRules(TriggerTypes triggerType, Item item, Command command) {\n\t\treturn internalGetRules(triggerType, item, command, null);\n\t}\n"
  },
  {
    "id": "apache_ignite-5661-Param-0",
    "old_comment_raw": "@param keys Keys to lock.",
    "new_code_raw": "    private List<GridDhtCacheEntry> lockEntries(List<KeyCacheObject> keys, AffinityTopologyVersion topVer)\n        throws GridDhtInvalidPartitionException {\n        if (keys.size() == 1) {\n            KeyCacheObject key = keys.get(0);\n\n            while (true) {\n                try {\n                    GridDhtCacheEntry entry = entryExx(key, topVer);\n\n                    UNSAFE.monitorEnter(entry);\n\n                    if (entry.obsolete())\n                        UNSAFE.monitorExit(entry);\n                    else\n                        return Collections.singletonList(entry);\n                }\n                catch (GridDhtInvalidPartitionException e) {\n                    // Ignore invalid partition exception in CLOCK ordering mode.\n                    if (ctx.config().getAtomicWriteOrderMode() == CLOCK)\n                        return Collections.singletonList(null);\n                    else\n                        throw e;\n                }\n            }\n        }\n        else {\n            List<GridDhtCacheEntry> locked = new ArrayList<>(keys.size());\n\n            while (true) {\n                for (KeyCacheObject key : keys) {\n                    try {\n                        GridDhtCacheEntry entry = entryExx(key, topVer);\n\n                        locked.add(entry);\n                    }\n                    catch (GridDhtInvalidPartitionException e) {\n                        // Ignore invalid partition exception in CLOCK ordering mode.\n                        if (ctx.config().getAtomicWriteOrderMode() == CLOCK)\n                            locked.add(null);\n                        else\n                            throw e;\n                    }\n                }\n\n                boolean retry = false;\n\n                for (int i = 0; i < locked.size(); i++) {\n                    GridCacheMapEntry entry = locked.get(i);\n\n                    if (entry == null)\n                        continue;\n\n                    UNSAFE.monitorEnter(entry);\n\n                    if (entry.obsolete()) {\n                        // Unlock all locked.\n                        for (int j = 0; j <= i; j++) {\n                            if (locked.get(j) != null)\n                                UNSAFE.monitorExit(locked.get(j));\n                        }\n\n                        // Clear entries.\n                        locked.clear();\n\n                        // Retry.\n                        retry = true;\n\n                        break;\n                    }\n                }\n\n                if (!retry)\n                    return locked;\n            }\n        }\n    }\n"
  },
  {
    "id": "voldemort_voldemort-729-Param-1",
    "old_comment_raw": "@param donorNodeId Donor node id",
    "new_code_raw": "    private Node getNodeIfPresent(int proxyNodeId) {\n        try {\n            return metadata.getCluster().getNodeById(proxyNodeId);\n        } catch(Exception e) {\n            throw new VoldemortException(\"Failed to get proxyNode \" + proxyNodeId\n                                         + \" from current cluster \" + metadata.getCluster()\n                                         + \" at node \" + metadata.getNodeId(), e);\n        }\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-222-Param-2",
    "old_comment_raw": "@param timeout the socket timeout to wait for data",
    "new_code_raw": "\tpublic static String executeUrl(String httpMethod, String url, int timeout, String proxyHost, Integer proxyPort, String proxyUser, String proxyPassword) {\n\t\t\n\t\tHttpClient client = new HttpClient();\n\n\t\t// only configure a proxy if a host is provided\n\t\tif (StringUtils.isNotBlank(proxyHost)) {\n\t\t\tclient.getHostConfiguration().setProxy(proxyHost, proxyPort);\n\t\t\tif (StringUtils.isNotBlank(proxyUser)) {\n\t\t\t\tclient.getState().setProxyCredentials(AuthScope.ANY,\n\t\t\t\t\tnew UsernamePasswordCredentials(proxyUser, proxyPassword));\n\t\t\t}\n\t\t}\n\t\t  \n\t\tHttpMethod method = HttpUtil.createHttpMethod(httpMethod, url);\n\n\t\tmethod.getParams().setSoTimeout(timeout);\n\t\tmethod.getParams().setParameter(HttpMethodParams.RETRY_HANDLER,\n\t\t\t\tnew DefaultHttpMethodRetryHandler(3, false));\n\n\t\tCredentials credentials = extractCredentials(url);\n\t\tif (credentials != null) {\n\t\t\tclient.getParams().setAuthenticationPreemptive(true); \n\t\t\tclient.getState().setCredentials(AuthScope.ANY, credentials);\t\t\t\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\ttry {\n\t\t\t\tlogger.debug(\"About to execute '\" + method.getURI().toString() + \"'\");\n\t\t\t} catch (URIException e) {\n\t\t\t\tlogger.debug(e.getLocalizedMessage());\n\t\t\t}\n\t\t}\n\n\t\ttry {\n\n\t\t\tint statusCode = client.executeMethod(method);\n\n\t\t\tif (statusCode != HttpStatus.SC_OK) {\n\t\t\t\tlogger.warn(\"Method failed: \" + method.getStatusLine());\n\t\t\t}\n\n\t\t\tString responseBody = IOUtils.toString(method.getResponseBodyAsStream());\n\n\t\t\tif (!responseBody.isEmpty()) {\n\t\t\t\tlogger.debug(responseBody);\n\t\t\t}\n\t\t\t\n\t\t\treturn responseBody;\n\t\t}\n\t\tcatch (HttpException he) {\n\t\t\tlogger.error(\"Fatal protocol violation: \", he);\n\t\t}\n\t\tcatch (IOException e) {\n\t\t\tlogger.error(\"Fatal transport error: {}\", e.toString());\n\t\t}\n\t\tfinally {\n\t\t\tmethod.releaseConnection();\n\t\t}\n\t\t\n\t\treturn null;\n\t}\n"
  },
  {
    "id": "essentials_Essentials-233-Param-0",
    "old_comment_raw": "@param userName",
    "new_code_raw": "\tpublic boolean removeUser(String userId) {\n\n\t\t//OVERLOADED CODE\n\t\tif (overloadedUsers.containsKey(userId.toLowerCase())) {\n\t\t\toverloadedUsers.remove(userId.toLowerCase());\n\t\t\treturn true;\n\t\t}\n\t\t//END CODE\n\t\tif (getUsers().containsKey(userId.toLowerCase())) {\n\t\t\tgetUsers().remove(userId.toLowerCase());\n\t\t\tsetUsersChanged(true);\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n"
  },
  {
    "id": "apache_ignite-12179-Param-0",
    "old_comment_raw": "@param ignite Ignite.",
    "new_code_raw": "    public static VisorCacheMetrics from(IgniteEx ignite, String cacheName) {\n        VisorCacheMetrics cm = new VisorCacheMetrics();\n\n        GridCacheProcessor cacheProcessor = ignite.context().cache();\n\n        IgniteCache<Object, Object> c = cacheProcessor.jcache(cacheName);\n\n        cm.name = cacheName;\n        cm.mode = cacheProcessor.cacheMode(cacheName);\n        cm.sys = cacheProcessor.systemCache(cacheName);\n\n        CacheMetrics m = c.metrics();\n\n        cm.size = m.getSize();\n        cm.keySize = m.getKeySize();\n\n        cm.reads = m.getCacheGets();\n        cm.writes = m.getCachePuts() + m.getCacheRemovals();\n        cm.hits = m.getCacheHits();\n        cm.misses = m.getCacheMisses();\n\n        cm.txCommits = m.getCacheTxCommits();\n        cm.txRollbacks = m.getCacheTxRollbacks();\n\n        cm.avgTxCommitTime = m.getAverageTxCommitTime();\n        cm.avgTxRollbackTime = m.getAverageTxRollbackTime();\n\n        cm.puts = m.getCachePuts();\n        cm.removals = m.getCacheRemovals();\n        cm.evictions = m.getCacheEvictions();\n\n        cm.avgReadTime = m.getAverageGetTime();\n        cm.avgPutTime = m.getAveragePutTime();\n        cm.avgRemovalTime = m.getAverageRemoveTime();\n\n        cm.readsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageGetTime());\n        cm.writesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAveragePutTime());\n        cm.hitsPerSec = -1;\n        cm.missesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageRemoveTime());\n        cm.commitsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxCommitTime());\n        cm.rollbacksPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxRollbackTime());\n\n        cm.qryMetrics = VisorCacheQueryMetrics.from(c.queryMetrics());\n\n        cm.dhtEvictQueueCurrSize = m.getDhtEvictQueueCurrentSize();\n        cm.txThreadMapSize = m.getTxThreadMapSize();\n        cm.txXidMapSize = m.getTxXidMapSize();\n        cm.txCommitQueueSize = m.getTxCommitQueueSize();\n        cm.txPrepareQueueSize = m.getTxPrepareQueueSize();\n        cm.txStartVerCountsSize = m.getTxStartVersionCountsSize();\n        cm.txCommittedVersionsSize = m.getTxCommittedVersionsSize();\n        cm.txRolledbackVersionsSize = m.getTxRolledbackVersionsSize();\n        cm.txDhtThreadMapSize = m.getTxDhtThreadMapSize();\n        cm.txDhtXidMapSize = m.getTxDhtXidMapSize();\n        cm.txDhtCommitQueueSize = m.getTxDhtCommitQueueSize();\n        cm.txDhtPrepareQueueSize = m.getTxDhtPrepareQueueSize();\n        cm.txDhtStartVerCountsSize = m.getTxDhtStartVersionCountsSize();\n        cm.txDhtCommittedVersionsSize = m.getTxDhtCommittedVersionsSize();\n        cm.txDhtRolledbackVersionsSize = m.getTxDhtRolledbackVersionsSize();\n\n        return cm;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-386-Param-0",
    "old_comment_raw": "@param train_samples_per_iteration user-given train_samples_per_iteration size",
    "new_code_raw": "  private static long computeTrainSamplesPerIteration(final DeepLearning mp, final long numRows, long model_size) {\n    long tspi = mp.train_samples_per_iteration;\n    assert(tspi == 0 || tspi == -1 || tspi == -2 || tspi >= 1);\n    if (tspi == 0 || (!mp.replicate_training_data && tspi == -1) ) {\n      tspi = numRows;\n      if (!mp.quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to one epoch: #rows (\" + tspi + \").\");\n    }\n    else if (tspi == -1) {\n      tspi = (mp.single_node_mode ? 1 : H2O.CLOUD.size()) * numRows;\n      if (!mp.quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to #nodes x #rows (\" + tspi + \").\");\n    } else if (tspi == -2) {\n      // automatic tuning based on CPU speed, network speed and model size\n\n      // measure cpu speed\n      double total_gflops = 0;\n      for (H2ONode h2o : H2O.CLOUD._memary) {\n        HeartBeat hb = h2o._heartbeat;\n        total_gflops += hb._gflops;\n      }\n      if (mp.single_node_mode) total_gflops /= H2O.CLOUD.size();\n      if (total_gflops == 0) {\n        total_gflops = Linpack.run(H2O.SELF._heartbeat._cpus_allowed) * (mp.single_node_mode ? 1 : H2O.CLOUD.size());\n      }\n\n      int[] msg_sizes = new int[]{ (int)(model_size*4) == (model_size*4) ? (int)(model_size*4) : Integer.MAX_VALUE };\n      double[] microseconds_collective = new double[msg_sizes.length];\n      NetworkTest.NetworkTester nt = new NetworkTest.NetworkTester(msg_sizes,null,microseconds_collective,model_size>1e6 ? 1 : 5 /*repeats*/,false,true /*only collectives*/);\n      nt.compute2();\n\n      //length of the network traffic queue based on log-tree rollup (2 log(nodes))\n      int network_queue_length = mp.single_node_mode || H2O.CLOUD.size() == 1? 1 : 2*(int)Math.floor(Math.log(H2O.CLOUD.size())/Math.log(2));\n\n      // heuristics\n      double flops_overhead_per_row = 30;\n      if (mp.activation == Activation.Maxout || mp.activation == Activation.MaxoutWithDropout) {\n        flops_overhead_per_row *= 8;\n      } else if (mp.activation == Activation.Tanh || mp.activation == Activation.TanhWithDropout) {\n        flops_overhead_per_row *= 5;\n      }\n\n      // target fraction of comm vs cpu time: 5%\n      double fraction = mp.single_node_mode || H2O.CLOUD.size() == 1 ? 1e-3 : 0.05; //one single node mode, there's no model averaging effect, so less need to shorten the M/R iteration\n\n      // estimate the time for communication (network) and training (compute)\n      double time_comm_us = (H2O.CLOUD.size() == 1 ? 1e4 /* add 10ms for single-node */ : 0) + network_queue_length * microseconds_collective[0];\n      double time_per_row_us  = flops_overhead_per_row * model_size / (total_gflops * 1e9) / H2O.SELF._heartbeat._cpus_allowed * 1e6;\n\n      // compute the optimal number of training rows per iteration\n      // fraction := time_comm_us / (time_comm_us + tspi * time_per_row_us)  ==>  tspi = (time_comm_us/fraction - time_comm_us)/time_per_row_us\n      tspi = (long)((time_comm_us / fraction - time_comm_us)/ time_per_row_us);\n\n      tspi = Math.max(1, tspi); //at least 1 point\n      tspi = Math.min(tspi, (mp.single_node_mode ? 1 : H2O.CLOUD.size()) * numRows * 10); //not more than 10x of what train_samples_per_iteration=-1 would do\n\n      // If the number is close to a multiple of epochs, use that -> prettier scoring\n      if (tspi > numRows && Math.abs(tspi % numRows)/(double)numRows < 0.2)  tspi = tspi - tspi % numRows;\n      tspi = Math.min(tspi, (long)(mp.epochs * numRows)); //limit to number of epochs desired\n\n      if (!mp.quiet_mode) {\n        Log.info(\"Auto-tuning parameter 'train_samples_per_iteration':\");\n        Log.info(\"Estimated compute power : \" + (int)total_gflops + \" GFlops\");\n        Log.info(\"Estimated time for comm : \" + PrettyPrint.usecs((long)time_comm_us));\n        Log.info(\"Estimated time per row  : \" + ((long)time_per_row_us > 0 ? PrettyPrint.usecs((long)time_per_row_us) : time_per_row_us + \" usecs\"));\n        Log.info(\"Estimated training speed: \" + (int)(1e6/time_per_row_us) + \" rows/sec\");\n        Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to auto-tuned value: \" + tspi);\n      }\n\n    } else {\n      // limit user-given value to number of epochs desired\n      tspi = Math.min(tspi, (long)(mp.epochs * numRows));\n    }\n    assert(tspi != 0 && tspi != -1 && tspi != -2 && tspi >= 1);\n    return tspi;\n  }\n"
  },
  {
    "id": "fabric8io_kubernetes_client-26-Param-1",
    "old_comment_raw": "@param apiGroupName the API Group name like apps.openshift.io or build.openshift.io",
    "new_code_raw": "  public static OpenShiftConfig withApiGroup(OkHttpClient httpClient, String apiGroupName, OpenShiftConfig config) {\n    OpenShiftClient openShiftClient = new DefaultOpenShiftClient(httpClient, config);\n    return withApiGroup(openShiftClient, apiGroupName, config);\n  }\n"
  },
  {
    "id": "apache_ignite-11619-Param-0",
    "old_comment_raw": "@param grid Grid.",
    "new_code_raw": "    public static boolean hasStreamer(Ignite ignite, String name) {\n        if (ignite.configuration().getStreamerConfiguration() != null) {\n            for (GridStreamerConfiguration cfg : ignite.configuration().getStreamerConfiguration()) {\n                if (name.equals(cfg.getName()))\n                    return true;\n            }\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-5065-Param-2",
    "old_comment_raw": "@param dhtNodeId DHT node ID.",
    "new_code_raw": "    @Nullable private GridCacheMvccCandidate addEntry(long topVer, GridNearCacheEntry entry, UUID dhtNodeId)\n        throws GridCacheEntryRemovedException {\n        // Check if lock acquisition is timed out.\n        if (timedOut)\n            return null;\n\n        // Add local lock first, as it may throw GridCacheEntryRemovedException.\n        GridCacheMvccCandidate c = entry.addNearLocal(\n            dhtNodeId,\n            threadId,\n            lockVer,\n            timeout,\n            !inTx(),\n            inTx(),\n            implicitSingleTx()\n        );\n\n        if (inTx()) {\n            IgniteTxEntry txEntry = tx.entry(entry.txKey());\n\n            txEntry.cached(entry, null);\n        }\n\n        if (c != null)\n            c.topologyVersion(topVer);\n\n        synchronized (mux) {\n            entries.add(entry);\n        }\n\n        if (c == null && timeout < 0) {\n            if (log.isDebugEnabled())\n                log.debug(\"Failed to acquire lock with negative timeout: \" + entry);\n\n            onFailed(false);\n\n            return null;\n        }\n\n        // Double check if lock acquisition has already timed out.\n        if (timedOut) {\n            entry.removeLock(lockVer);\n\n            return null;\n        }\n\n        return c;\n    }\n"
  },
  {
    "id": "apache_ignite-13300-Param-0",
    "old_comment_raw": "@param cls Map class.",
    "new_code_raw": "    private Map readMap0(@Nullable BinaryMapFactory factory) throws BinaryObjectException {\n        switch (checkFlag(MAP)) {\n            case NORMAL:\n                return (Map)PortableUtils.doReadMap(in, ctx, ldr, this, true, factory);\n\n            case HANDLE: {\n                int handlePos = PortableUtils.positionForHandle(in) - in.readInt();\n\n                Object obj = getHandle(handlePos);\n\n                if (obj == null) {\n                    int retPos = in.position();\n\n                    streamPosition(handlePos);\n\n                    obj = readMap0(factory);\n\n                    streamPosition(retPos);\n                }\n\n                return (Map)obj;\n            }\n\n            default:\n                return null;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-7897-Param-1",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "    public boolean onUnswap(KeyCacheObject key, CacheObject val) throws IgniteCheckedException {\n        assert val != null : \"Key=\" + key;\n\n        return onSwapUnswap(key, val);\n    }\n"
  },
  {
    "id": "voldemort_voldemort-69-Associations-Param0",
    "old_comment_raw": "@param storeName List of all read-only stores",
    "new_code_raw": "    public long getROGlobalMaxVersion(String storeName) {\n        long maxVersionId = 0L;\n        for(Node node: currentCluster.getNodes()) {\n            long currentNodeVersion = getROMaxVersion(node.getId(), storeName);\n            if(currentNodeVersion > maxVersionId) {\n                maxVersionId = currentNodeVersion;\n            }\n        }\n        return maxVersionId;\n    }\n\n"
  },
  {
    "id": "apache_ignite-6299-Param-1",
    "old_comment_raw": "@param ccfg Cache configuration.",
    "new_code_raw": "    public VisorCacheConfiguration from(Ignite ignite, CacheConfiguration ccfg) {\n        name = ccfg.getName();\n        mode = ccfg.getCacheMode();\n        atomicityMode = ccfg.getAtomicityMode();\n        atomicWriteOrderMode = ccfg.getAtomicWriteOrderMode();\n        eagerTtl = ccfg.isEagerTtl();\n        writeSynchronizationMode = ccfg.getWriteSynchronizationMode();\n        swapEnabled = ccfg.isSwapEnabled();\n        invalidate = ccfg.isInvalidate();\n        startSize = ccfg.getStartSize();\n        tmLookupClsName = ccfg.getTransactionManagerLookupClassName();\n        offHeapMaxMemory = ccfg.getOffHeapMaxMemory();\n        maxConcurrentAsyncOps = ccfg.getMaxConcurrentAsyncOperations();\n        memoryMode = ccfg.getMemoryMode();\n        interceptor = compactClass(ccfg.getInterceptor());\n        typeMeta = VisorCacheTypeMetadata.list(ccfg.getTypeMetadata());\n        statisticsEnabled = ccfg.isStatisticsEnabled();\n        mgmtEnabled = ccfg.isManagementEnabled();\n        ldrFactory = compactClass(ccfg.getCacheLoaderFactory());\n        writerFactory = compactClass(ccfg.getCacheWriterFactory());\n        expiryPlcFactory = compactClass(ccfg.getExpiryPolicyFactory());\n\n        affinityCfg = VisorCacheAffinityConfiguration.from(ccfg);\n        rebalanceCfg = VisorCacheRebalanceConfiguration.from(ccfg);\n        evictCfg = VisorCacheEvictionConfiguration.from(ccfg);\n        nearCfg = VisorCacheNearConfiguration.from(ccfg);\n        dfltCfg = VisorCacheDefaultConfiguration.from(ccfg);\n        storeCfg = VisorCacheStoreConfiguration.from(ignite, ccfg);\n        qryCfg = VisorCacheQueryConfiguration.from(ccfg);\n\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-13611-Param-2",
    "old_comment_raw": "@param pathStr String representing path to the property. May contains dots '.' to identify nested fields.",
    "new_code_raw": "    private static ClassProperty buildClassProperty(Class<?> keyCls, Class<?> valCls, String pathStr, Class<?> resType)\n        throws IgniteCheckedException {\n        ClassProperty res = buildClassProperty(true, keyCls, pathStr, resType);\n\n        if (res == null) // We check key before value consistently with PortableProperty.\n            res = buildClassProperty(false, valCls, pathStr, resType);\n\n        if (res == null)\n            throw new IgniteCheckedException(\"Failed to initialize property '\" + pathStr + \"' for \" +\n                \"key class '\" + keyCls + \"' and value class '\" + valCls + \"'. \" +\n                \"Make sure that one of these classes contains respective getter method or field.\");\n\n        return res;\n    }\n"
  },
  {
    "id": "SpigotMC_BungeeCord-32-Param-1",
    "old_comment_raw": "@param commandLine the complete command line including command name and arguments",
    "new_code_raw": "    public boolean dispatchCommand(CommandSender sender, String commandLine, List<String> tabResults)\n    {\n        String[] split = argsSplit.split( commandLine );\n        // Check for chat that only contains \" \"\n        if ( split.length == 0 )\n        {\n            return false;\n        }\n\n        String commandName = split[0].toLowerCase();\n        if ( proxy.getDisabledCommands().contains( commandName ) )\n        {\n            return false;\n        }\n        Command command = commandMap.get( commandName );\n        if ( command == null )\n        {\n            return false;\n        }\n\n        String permission = command.getPermission();\n        if ( permission != null && !permission.isEmpty() && !sender.hasPermission( permission ) )\n        {\n            sender.sendMessage( proxy.getTranslation( \"no_permission\" ) );\n            return true;\n        }\n\n        String[] args = Arrays.copyOfRange( split, 1, split.length );\n        try\n        {\n            if ( tabResults == null )\n            {\n                command.execute( sender, args );\n            } else if ( command instanceof TabExecutor )\n            {\n                tabResults.addAll( ( (TabExecutor) command ).onTabComplete( sender, args ) );\n            }\n        } catch ( Exception ex )\n        {\n            sender.sendMessage( ChatColor.RED + \"An internal error occurred whilst executing this command, please check the console log for details.\" );\n            ProxyServer.getInstance().getLogger().log( Level.WARNING, \"Error in dispatching command\", ex );\n        }\n        return true;\n    }\n"
  },
  {
    "id": "apache_wss4j-34-Associations-Param0",
    "old_comment_raw": "@param wsResultVector The result vector to fetch an action from",
    "new_code_raw": "    public static List fetchAllActionResults(\n        List resultList,\n        int action, \n        List actionResultList\n    ) {\n        for (int i = 0; i < resultList.size(); i++) {\n            //\n            // Check the result of every action whether it matches the given action\n            //\n            WSSecurityEngineResult result = \n                (WSSecurityEngineResult) resultList.get(i);\n            int resultAction = \n                ((java.lang.Integer)result.get(WSSecurityEngineResult.TAG_ACTION)).intValue();\n            if (resultAction == action) {\n                actionResultList.add(result);\n            }\n        }\n        return actionResultList;\n    }\n\n"
  },
  {
    "id": "mitreid_connect_OpenID_Connect_Java_Spring_Server-62-Param-0",
    "old_comment_raw": "@param authentication the authentication of the current user, to be retrieved when the code is consumed",
    "new_code_raw": "\tpublic String createAuthorizationCode(OAuth2Authentication authentication) {\n\t\tString code = generator.generate();\n\t\t\n\t\tAuthorizationCodeEntity entity = new AuthorizationCodeEntity(code, authentication);\n\t\trepository.save(entity);\n\t\t\n\t\treturn code;\n\t}\n"
  },
  {
    "id": "pubnub_java-68-Param-0",
    "old_comment_raw": "@param sUrl , input string",
    "new_code_raw": "    public static String urlDecode(String stringToEncode) {\n        try {\n            return URLDecoder.decode(stringToEncode, \"UTF-8\");\n        } catch (UnsupportedEncodingException e) {\n            return null;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5200-Param-2",
    "old_comment_raw": "@param entry Preloaded entry.",
    "new_code_raw": "        private boolean preloadEntry(ClusterNode pick, int p, GridCacheEntryInfo<K, V> entry, AffinityTopologyVersion topVer)\n            throws IgniteCheckedException {\n            try {\n                GridCacheEntryEx<K, V> cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isIgfsDataCache() &&\n                        cctx.dht().igfsDataSpaceUsed() > cctx.dht().igfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload IGFS data cache (IGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            entry.valueBytes(),\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isDrEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (IgniteUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false, null, null, null);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (IgniteInterruptedCheckedException e) {\n                throw e;\n            }\n            catch (IgniteCheckedException e) {\n                throw new IgniteCheckedException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "apache_ignite-12255-Param-0",
    "old_comment_raw": "@param size Size.",
    "new_code_raw": "    public IgniteConfiguration setRebalanceThreadPoolSize(int rebalanceThreadPoolSize) {\n        this.rebalanceThreadPoolSize = rebalanceThreadPoolSize;\n\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-5660-Param-1",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    private GridDhtLocalPartition localPartition(int p, AffinityTopologyVersion topVer, boolean create, boolean updateSeq) {\n        while (true) {\n            boolean belongs = cctx.affinity().localNode(p, topVer);\n\n            GridDhtLocalPartition loc = locParts.get(p);\n\n            if (loc != null && loc.state() == EVICTED) {\n                locParts.remove(p, loc);\n\n                if (!create)\n                    return null;\n\n                if (!belongs)\n                    throw new GridDhtInvalidPartitionException(p, \"Adding entry to evicted partition [part=\" + p +\n                        \", topVer=\" + topVer + \", this.topVer=\" + this.topVer + ']');\n\n                continue;\n            }\n\n            if (loc == null && create) {\n                if (!belongs)\n                    throw new GridDhtInvalidPartitionException(p, \"Creating partition which does not belong [part=\" +\n                        p + \", topVer=\" + topVer + \", this.topVer=\" + this.topVer + ']');\n\n                lock.writeLock().lock();\n\n                try {\n                    GridDhtLocalPartition old = locParts.putIfAbsent(p,\n                        loc = new GridDhtLocalPartition(cctx, p));\n\n                    if (old != null)\n                        loc = old;\n                    else {\n                        if (updateSeq)\n                            this.updateSeq.incrementAndGet();\n\n                        if (log.isDebugEnabled())\n                            log.debug(\"Created local partition: \" + loc);\n                    }\n                }\n                finally {\n                    lock.writeLock().unlock();\n                }\n            }\n\n            return loc;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-13275-Param-1",
    "old_comment_raw": "@param cacheName Cache name.",
    "new_code_raw": "    public static VisorCache from(Ignite ignite, GridCache c, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<GridCacheEntryEx> set = ca.map().entries0();\n\n        long memSz = 0;\n\n        Iterator<GridCacheEntryEx> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name = cacheName;\n        cache.mode = mode;\n        cache.memorySize = memSz;\n        cache.size = size;\n        cache.nearSize = near;\n        cache.dhtSize = size - near;\n        cache.primarySize = ca.primarySize();\n        cache.offHeapAllocatedSize = ca.offHeapAllocatedSize();\n        cache.offHeapEntriesCnt = ca.offHeapEntriesCount();\n        cache.swapSize = swapSize;\n        cache.swapKeys = swapKeys;\n        cache.partitions = ca.affinity().partitions();\n        cache.primaryPartitions = pps;\n        cache.backupPartitions = bps;\n        cache.metrics = VisorCacheMetrics.from(ca);\n        cache.partitionsMap = partsMap;\n\n        return cache;\n    }\n"
  },
  {
    "id": "gephi_gephi-111-Param-2",
    "old_comment_raw": "@param pX",
    "new_code_raw": "    private String createImageFile(TempDir tempDir, double[] pVals, String pName, String pX, String pY) throws IOException {\n        XYSeries series = new XYSeries(pName);\n        for (int i = 0; i < mN; i++) {\n            series.add(i, pVals[i]);\n        }\n        XYSeriesCollection dataSet = new XYSeriesCollection();\n        dataSet.addSeries(series);\n\n        JFreeChart chart = ChartFactory.createXYLineChart(\n                pName,\n                pX,\n                pY,\n                dataSet,\n                PlotOrientation.VERTICAL,\n                true,\n                false,\n                false);\n        XYPlot plot = (XYPlot) chart.getPlot();\n        XYLineAndShapeRenderer renderer = new XYLineAndShapeRenderer();\n        renderer.setSeriesLinesVisible(0, false);\n        renderer.setSeriesShapesVisible(0, true);\n        renderer.setSeriesShape(0, new java.awt.geom.Ellipse2D.Double(0, 0, 1, 1));\n        plot.setBackgroundPaint(java.awt.Color.WHITE);\n        plot.setDomainGridlinePaint(java.awt.Color.GRAY);\n        plot.setRangeGridlinePaint(java.awt.Color.GRAY);\n        plot.setRenderer(renderer);\n\n        String imageFile = \"\";\n\n        ChartRenderingInfo info = new ChartRenderingInfo(new StandardEntityCollection());\n        String fileName = pY + \".png\";\n        File file1 = tempDir.createFile(fileName);\n        imageFile = \"<IMG SRC=\\\"file:\" + file1.getAbsolutePath() + \"\\\" \" + \"WIDTH=\\\"600\\\" HEIGHT=\\\"400\\\" BORDER=\\\"0\\\" USEMAP=\\\"#chart\\\"></IMG>\";\n\n        ChartUtilities.saveChartAsPNG(file1, chart, 600, 400, info);\n\n        return imageFile;\n    }\n"
  },
  {
    "id": "apache_ignite-13598-Param-0",
    "old_comment_raw": "@param prj Projection to guard.",
    "new_code_raw": "    @Nullable public CacheOperationContext enter(@Nullable CacheOperationContext opCtx) {\n        try {\n            GridCacheAdapter<K, V> cache = ctx.cache();\n\n            GridCachePreloader<K, V> preldr = cache != null ? cache.preloader() : null;\n\n            if (preldr == null)\n                throw new IllegalStateException(\"Grid is in invalid state to perform this operation. \" +\n                    \"It either not started yet or has already being or have stopped [gridName=\" + ctx.gridName() + ']');\n\n            preldr.startFuture().get();\n        }\n        catch (IgniteCheckedException e) {\n            throw new IgniteException(\"Failed to wait for cache preloader start [cacheName=\" +\n                ctx.name() + \"]\", e);\n        }\n\n        onEnter();\n\n        rwLock.readLock();\n\n        if (stopped) {\n            rwLock.readUnlock();\n\n            throw new IllegalStateException(\"Cache has been stopped: \" + ctx.name());\n        }\n\n        // Must unlock in case of unexpected errors to avoid\n        // deadlocks during kernal stop.\n        try {\n            return setOperationContextPerCall(opCtx);\n        }\n        catch (RuntimeException e) {\n            rwLock.readUnlock();\n\n            throw e;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-2133-Param-0",
    "old_comment_raw": "@param dep Deployment.",
    "new_code_raw": "    @Nullable private ClusterNode cacheAffinityNode(GridDeployment dep, ComputeJob job, Collection<ClusterNode> nodes)\n        throws GridException {\n        assert dep != null;\n        assert job != null;\n        assert nodes != null;\n\n        if (log.isDebugEnabled())\n            log.debug(\"Looking for cache affinity node [job=\" + job + \"]\");\n\n        Object key = dep.annotatedValue(job, GridCacheAffinityKeyMapped.class);\n\n        if (key == null)\n            return null;\n\n        String cacheName = (String)dep.annotatedValue(job, GridCacheName.class);\n\n        if (log.isDebugEnabled())\n            log.debug(\"Affinity properties [key=\" + key + \", cacheName=\" + cacheName + \"]\");\n\n        try {\n            ClusterNode node = ctx.affinity().mapKeyToNode(cacheName, key);\n\n            if (node == null)\n                throw new GridException(\"Failed to map key to node (is cache with given name started?) [gridName=\" +\n                    ctx.gridName() + \", key=\" + key + \", cacheName=\" + cacheName +\n                    \", nodes=\" + U.toShortString(nodes) + ']');\n\n            if (!nodes.contains(node))\n                throw new GridException(\"Failed to map key to node (projection nodes do not contain affinity node) \" +\n                    \"[gridName=\" + ctx.gridName() + \", key=\" + key + \", cacheName=\" + cacheName +\n                    \", nodes=\" + U.toShortString(nodes) + \", node=\" + U.toShortString(node) + ']');\n\n            return node;\n        }\n        catch (GridException e) {\n            throw new GridException(\"Failed to map affinity key to node for job [gridName=\" + ctx.gridName() +\n                \", job=\" + job + ']', e);\n        }\n    }\n"
  },
  {
    "id": "apache_curator-274-Param-1",
    "old_comment_raw": "@param child the child",
    "new_code_raw": "    public static String makePath(String parent, String... children)\n    {\n        StringBuilder path = new StringBuilder();\n\n        // Add parent piece, with no trailing slash.\n        if ( (parent != null) && (parent.length() > 0) )\n        {\n            if ( !parent.startsWith(PATH_SEPARATOR) )\n            {\n                path.append(PATH_SEPARATOR);\n            }\n            if ( parent.endsWith(PATH_SEPARATOR) )\n            {\n                path.append(parent.substring(0, parent.length() - 1));\n            }\n            else\n            {\n                path.append(parent);\n            }\n        }\n\n        if (children == null || children.length == 0)\n        {\n            // Special case, empty parent and child\n            if ( path.length() == 0 )\n            {\n                return PATH_SEPARATOR;\n            }\n            return path.toString();\n        }\n\n        for (String child : children)\n        {\n            if ( (child == null) || (child.length() == 0) || (child.equals(PATH_SEPARATOR)) )\n            {\n                // Special case, empty parent and child\n                if ( path.length() == 0 )\n                {\n                    path.append(PATH_SEPARATOR);\n                }\n\n                continue;\n            }\n\n            // Now add the separator between parent and child.\n            path.append(PATH_SEPARATOR);\n\n            if ( child.startsWith(PATH_SEPARATOR) )\n            {\n                child = child.substring(1);\n            }\n\n            if ( child.endsWith(PATH_SEPARATOR) )\n            {\n                child = child.substring(0, child.length() - 1);\n            }\n\n            // Finally, add the child.\n            path.append(child);\n        }\n\n        return path.toString();\n    }\n"
  },
  {
    "id": "apache_ignite-10461-Param-0",
    "old_comment_raw": "@param ldr Class loader.",
    "new_code_raw": "    private boolean undeploy(ClassLoader ldr, GridCacheEntryEx e, GridCacheAdapter cache) {\n        KeyCacheObject key = e.key();\n\n        GridCacheEntryEx entry = cache.peekEx(key);\n\n        if (entry == null)\n            return false;\n\n        Object key0;\n        Object val0;\n\n        try {\n            CacheObject v = entry.peek(GridCachePeekMode.GLOBAL, CU.empty0());\n\n            key0 = key.value(cache.context().cacheObjectContext(), false);\n\n            assert key0 != null : \"Key cannot be null for cache entry: \" + e;\n\n            val0 = CU.value(v, cache.context(), false);\n        }\n        catch (GridCacheEntryRemovedException ignore) {\n            return false;\n        }\n        catch (IgniteException ignore) {\n            // Peek can throw runtime exception if unmarshalling failed.\n            return true;\n        }\n\n        ClassLoader keyLdr = U.detectObjectClassLoader(key0);\n        ClassLoader valLdr = U.detectObjectClassLoader(val0);\n\n        boolean res = F.eq(ldr, keyLdr) || F.eq(ldr, valLdr);\n\n        if (log.isDebugEnabled())\n            log.debug(\"Finished examining entry [entryCls=\" + e.getClass() +\n                \", key=\" + key0 + \", keyCls=\" + key0.getClass() +\n                \", valCls=\" + (val0 != null ? val0.getClass() : \"null\") +\n                \", keyLdr=\" + keyLdr + \", valLdr=\" + valLdr + \", res=\" + res + ']');\n\n        return res;\n    }\n"
  },
  {
    "id": "nuxeo_nuxeo-29-Associations-Param1",
    "old_comment_raw": "@param searchedEntryName The content to be checked",
    "new_code_raw": "    public static boolean hasEntry(File file, String entryName)\n            throws IOException {\n        List<String> elements = getEntryNames(file);\n        return elements.contains(entryName);\n    }\n\n"
  },
  {
    "id": "sanluan_PublicCMS-137-Param-0",
    "old_comment_raw": "@param site",
    "new_code_raw": "    public List<ConfigInfo> getConfigList(SysSite site, Locale locale, boolean showAll) {\n        List<ConfigInfo> configList = new ArrayList<>();\n        List<String> configCodeList = new ArrayList<>();\n        if (CommonUtils.notEmpty(configPluginList)) {\n            for (Config config : configPluginList) {\n                String code = config.getCode(site, showAll);\n                if (CommonUtils.notEmpty(code) && !configCodeList.contains(code)) {\n                    configList.add(new ConfigInfo(code, config.getCodeDescription(locale)));\n                    configCodeList.add(code);\n                }\n            }\n        }\n        for (Entry<String, SysConfig> entry : getMap(site).entrySet()) {\n            if (!configCodeList.contains(entry.getKey())) {\n                ConfigInfo configInfo = new ConfigInfo(entry.getKey(), entry.getValue().getDescription());\n                configInfo.setCustomed(true);\n                configList.add(configInfo);\n                configCodeList.add(entry.getKey());\n            }\n        }\n        return configList;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1323-Param-1",
    "old_comment_raw": "@param idpInitiatedURI",
    "new_code_raw": "    public SAMLDocumentHolder idpInitiatedLogin(UserRepresentation user, Binding expectedResponseBinding, boolean consentRequired, boolean consent) {\n        return getSamlResponse(expectedResponseBinding, (client, context, strategy) -> {\n            HttpGet get = new HttpGet(samlEndpoint);\n            CloseableHttpResponse response = client.execute(get);\n            assertThat(response, statusCodeIsHC(Response.Status.OK));\n\n            String loginPageText = EntityUtils.toString(response.getEntity(), \"UTF-8\");\n            response.close();\n\n            assertThat(loginPageText, containsString(\"login\"));\n\n            HttpUriRequest loginRequest = handleLoginPage(user, loginPageText);\n\n            if (consentRequired) {\n                // Client requires consent\n                response = client.execute(loginRequest, context);\n                String consentPageText = EntityUtils.toString(response.getEntity(), \"UTF-8\");\n                loginRequest = handleConsentPage(consentPageText, consent);\n            }\n\n            strategy.setRedirectable(false);\n            return client.execute(loginRequest, context);\n        });\n    }\n"
  },
  {
    "id": "apache_ignite-2312-Param-0",
    "old_comment_raw": "@param path Path.",
    "new_code_raw": "    private static boolean startsWith(IgniteFsPath path, IgniteFsPath prefix) {\n        List<String> p1Comps = path.components();\n        List<String> p2Comps = prefix.components();\n\n        if (p2Comps.size() > p1Comps.size())\n            return false;\n\n        for (int i = 0; i < p1Comps.size(); i++) {\n            if (i >= p2Comps.size() || p2Comps.get(i) == null)\n                // All prefix components already matched.\n                return true;\n\n            if (!p1Comps.get(i).equals(p2Comps.get(i)))\n                return false;\n        }\n\n        // Path and prefix components had same length and all of them matched.\n        return true;\n    }\n"
  },
  {
    "id": "eclipse_elk-140-Associations-Param1",
    "old_comment_raw": "@param nt2 another node type",
    "new_code_raw": "    public float getHorizontalSpacing(final NodeType t1, final NodeType t2) {\n        return nodeTypeSpacings[t1.ordinal()][t2.ordinal()];\n    }\n\n"
  },
  {
    "id": "apache_shiro-860-Param-0",
    "old_comment_raw": "@param key the key of the element to return.",
    "new_code_raw": "    public V get(K key) throws CacheException {\n        try {\n            if (log.isTraceEnabled()) {\n                log.trace(\"Getting object from cache [\" + cache.getName() + \"] for key [\" + key + \"]\");\n            }\n            if (key == null) {\n                return null;\n            } else {\n                Element element = cache.get(key);\n                if (element == null) {\n                    if (log.isTraceEnabled()) {\n                        log.trace(\"Element for [\" + key + \"] is null.\");\n                    }\n                    return null;\n                } else {\n                    //noinspection unchecked\n                    return (V) element.getObjectValue();\n                }\n            }\n        } catch (Throwable t) {\n            throw new CacheException(t);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-12293-Param-0",
    "old_comment_raw": "@param delete If lock ID is required for file deletion.",
    "new_code_raw": "    private IgniteUuid createFileLockId(boolean del) {\n        if (del)\n            return IgfsUtils.DELETE_LOCK_ID;\n\n        return IgniteUuid.fromUuid(locNode.id());\n    }\n"
  },
  {
    "id": "Netflix_Hystrix-1-Param-0",
    "old_comment_raw": "@param metricsPublisher Implementation of  HystrixMetricsPublisher to use.  See  HystrixMetricsPublisher class header JavaDocs for precedence of how this is retrieved.",
    "new_code_raw": "    public static HystrixMetricsPublisherThreadPool createOrRetrievePublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) {\n        // attempt to retrieve from cache first\n        HystrixMetricsPublisherThreadPool publisher = threadPoolPublishers.get(threadPoolKey.name());\n        if (publisher != null) {\n            return publisher;\n        }\n        // it doesn't exist so we need to create it\n        publisher = HystrixPlugins.getInstance().getMetricsPublisher().getMetricsPublisherForThreadPool(threadPoolKey, metrics, properties);\n        // attempt to store it (race other threads)\n        HystrixMetricsPublisherThreadPool existing = threadPoolPublishers.putIfAbsent(threadPoolKey.name(), publisher);\n        if (existing == null) {\n            // we won the thread-race to store the instance we created so initialize it\n            publisher.initialize();\n            // done registering, return instance that got cached\n            return publisher;\n        } else {\n            // we lost so return 'existing' and let the one we created be garbage collected\n            // without calling initialize() on it\n            return existing;\n        }\n    }\n"
  },
  {
    "id": "xianrendzw_EasyReport-15-Param-0",
    "old_comment_raw": "@param dataSet",
    "new_code_raw": "\tpublic static ReportTable generate(Queryer queryer, ReportParameter parameter) {\n\t\treturn generate(getDataSet(queryer, parameter), parameter);\n\t}\n"
  },
  {
    "id": "apache_ignite-2226-Param-1",
    "old_comment_raw": "@param uri GAR file deployment URI.",
    "new_code_raw": "    private static GridUriDeploymentFileProcessorResult processNoDescriptorFile(File file, String uri, IgniteLogger log)\n        throws GridSpiException {\n        ClassLoader clsLdr = GridUriDeploymentClassLoaderFactory.create(U.gridClassLoader(), file, log);\n\n        Set<Class<? extends ComputeTask<?, ?>>> clss = GridUriDeploymentDiscovery.getClasses(clsLdr, file);\n\n        GridUriDeploymentFileProcessorResult res = new GridUriDeploymentFileProcessorResult();\n\n        res.setFile(file);\n        res.setClassLoader(clsLdr);\n\n        if (clss != null) {\n            List<Class<? extends ComputeTask<?, ?>>> validTasks =\n                new ArrayList<>(clss.size());\n\n            for (Class<? extends ComputeTask<?, ?>> cls : clss) {\n                if (isAllowedTaskClass(cls)) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Found grid deployment task: \" + cls.getName());\n\n                    validTasks.add(cls);\n                }\n            }\n\n            if (!validTasks.isEmpty())\n                res.setTaskClasses(validTasks);\n            else if (log.isDebugEnabled())\n                log.debug(\"No tasks loaded from file [file=\" + file.getAbsolutePath() +\n                    \", uri=\" + U.hidePassword(uri) + ']');\n        }\n\n        return res;\n    }\n"
  },
  {
    "id": "apache_ignite-13261-Param-0",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "    public CacheObject applyEntryProcessors(CacheObject cacheVal) {\n        Object key = CU.value(this.key, ctx, false);\n        Object val = CU.value(cacheVal, ctx, false);\n\n        for (T2<EntryProcessor<Object, Object, Object>, Object[]> t : entryProcessors()) {\n            try {\n                CacheInvokeEntry<Object, Object> invokeEntry = new CacheInvokeEntry<>(ctx, key, val);\n\n                EntryProcessor processor = t.get1();\n\n                processor.process(invokeEntry, t.get2());\n\n                val = invokeEntry.getValue();\n            }\n            catch (Exception ignore) {\n                // No-op.\n            }\n        }\n\n        return ctx.toCacheObject(val);\n// TODO IGNITE-51\n//        if (ctx.portableEnabled())\n//            val = (V)ctx.marshalToPortable(val);\n//\n//        return val;\n    }\n"
  },
  {
    "id": "apache_ignite-2040-Param-0",
    "old_comment_raw": "@param e Event",
    "new_code_raw": "        private boolean filterByTaskSessionId(GridEvent e, IgniteUuid taskSessionId) {\n            if (e.getClass().equals(GridTaskEvent.class)) {\n                GridTaskEvent te = (GridTaskEvent)e;\n\n                return te.taskSessionId().equals(taskSessionId);\n            }\n\n            if (e.getClass().equals(GridJobEvent.class)) {\n                GridJobEvent je = (GridJobEvent)e;\n\n                return je.taskSessionId().equals(taskSessionId);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "google_tink-273-Param-1",
    "old_comment_raw": "@param additionalData additional data",
    "new_code_raw": "  private byte[] decrypt(ByteBuffer ciphertext, final byte[] associatedData)\n      throws GeneralSecurityException {\n    if (ciphertext.remaining() < snuffle.nonceSizeInBytes() + MAC_TAG_SIZE_IN_BYTES) {\n      throw new GeneralSecurityException(\"ciphertext too short\");\n    }\n    int firstPosition = ciphertext.position();\n    byte[] tag = new byte[MAC_TAG_SIZE_IN_BYTES];\n    ciphertext.position(ciphertext.limit() - MAC_TAG_SIZE_IN_BYTES);\n    ciphertext.get(tag);\n    // rewind to read ciphertext and compute tag.\n    ciphertext.position(firstPosition);\n    ciphertext.limit(ciphertext.limit() - MAC_TAG_SIZE_IN_BYTES);\n    byte[] nonce = new byte[snuffle.nonceSizeInBytes()];\n    ciphertext.get(nonce);\n    byte[] aad = associatedData;\n    if (aad == null) {\n      aad = new byte[0];\n    }\n    try {\n      Poly1305.verifyMac(getMacKey(nonce), macDataRfc7539(aad, ciphertext), tag);\n    } catch (GeneralSecurityException ex) {\n      throw new AEADBadTagException(ex.toString());\n    }\n\n    // rewind to decrypt the ciphertext.\n    ciphertext.position(firstPosition);\n    return snuffle.decrypt(ciphertext);\n  }\n"
  },
  {
    "id": "apache_ignite-5019-Param-0",
    "old_comment_raw": "@param primary If  true includes primary entries.",
    "new_code_raw": "    public int swapEntriesCount(boolean primary, boolean backup, AffinityTopologyVersion topVer) throws IgniteCheckedException {\n        assert primary || backup;\n\n        if (!swapEnabled)\n            return 0;\n\n        if (!(primary && backup)) {\n            Set<Integer> parts = primary ? cctx.affinity().primaryPartitions(cctx.localNodeId(), topVer) :\n                cctx.affinity().backupPartitions(cctx.localNodeId(), topVer);\n\n            return (int)swapMgr.swapKeys(spaceName, parts);\n        }\n        else\n            return (int)swapMgr.swapKeys(spaceName);\n    }\n"
  },
  {
    "id": "apache_ignite-13182-Param-0",
    "old_comment_raw": "@param info Task info.",
    "new_code_raw": "    private GridHadoopTaskOutput createOutput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case REDUCE:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case MAP:\n                if (locCombiner) {\n                    assert local == null;\n\n                    local = get(job.info(), SHUFFLE_COMBINER_NO_SORTING, false) ?\n                        new GridHadoopHashMultimap(job, mem, get(job.info(), COMBINER_HASHMAP_SIZE, 8 * 1024)):\n                        new GridHadoopSkipList(job, mem, ctx.sortComparator()); // TODO replace with red-black tree\n\n                    return local.startAdding(ctx);\n                }\n\n            default:\n                return createOutput(ctx);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-8330-Param-0",
    "old_comment_raw": "@param authority Authority.",
    "new_code_raw": "    private static Configuration configuration(String authority, boolean tcp) {\n        Configuration cfg = new Configuration();\n\n        cfg.set(\"fs.defaultFS\", \"igfs://\" + authority + \"/\");\n        cfg.set(\"fs.igfs.impl\", org.apache.ignite.hadoop.fs.v1.IgniteHadoopFileSystem.class.getName());\n        cfg.set(\"fs.AbstractFileSystem.igfs.impl\",\n            IgniteHadoopFileSystem.class.getName());\n\n        cfg.setBoolean(\"fs.igfs.impl.disable.cache\", true);\n\n        if (tcp)\n            cfg.setBoolean(String.format(PARAM_IGFS_ENDPOINT_NO_EMBED, authority), true);\n        else\n            cfg.setBoolean(String.format(PARAM_IGFS_ENDPOINT_NO_LOCAL_TCP, authority), true);\n\n        cfg.setBoolean(String.format(PARAM_IGFS_ENDPOINT_NO_LOCAL_SHMEM, authority), true);\n\n        return cfg;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-381-Param-1",
    "old_comment_raw": "@param mini_batch number of training rows to be processed per iteration",
    "new_code_raw": "  private static float computeRowUsageFraction(final long numRows, long train_samples_per_iteration, boolean replicate_training_data) {\n    float rowUsageFraction = (float)train_samples_per_iteration / numRows;\n    if (replicate_training_data) rowUsageFraction /= H2O.CLOUD.size();\n    assert(rowUsageFraction > 0 && rowUsageFraction <= 1.);\n    return rowUsageFraction;\n  }\n"
  },
  {
    "id": "apache_ignite-3063-Param-0",
    "old_comment_raw": "@param ccfg Cache configuration.",
    "new_code_raw": "    public static VisorCacheAffinityConfiguration from(CacheConfiguration ccfg) {\n        GridCacheAffinityFunction aff = ccfg.getAffinity();\n\n        Integer dfltReplicas = null;\n        Boolean excludeNeighbors = null;\n\n        if (aff instanceof GridCacheConsistentHashAffinityFunction) {\n            GridCacheConsistentHashAffinityFunction hashAffFunc = (GridCacheConsistentHashAffinityFunction)aff;\n\n            dfltReplicas = hashAffFunc.getDefaultReplicas();\n            excludeNeighbors = hashAffFunc.isExcludeNeighbors();\n        }\n\n        VisorCacheAffinityConfiguration cfg = new VisorCacheAffinityConfiguration();\n\n        cfg.function(compactClass(aff));\n        cfg.mapper(compactClass(ccfg.getAffinityMapper()));\n        cfg.partitionedBackups(ccfg.getBackups());\n        cfg.defaultReplicas(dfltReplicas);\n        cfg.excludeNeighbors(excludeNeighbors);\n\n        return cfg;\n    }\n"
  },
  {
    "id": "xianrendzw_EasyReport-14-Param-0",
    "old_comment_raw": "@param ds",
    "new_code_raw": "\tpublic static ReportDataSet getDataSet(Queryer queryer, ReportParameter parameter) {\n\t\treturn new DataExecutor(queryer, parameter).execute();\n\t}\n"
  },
  {
    "id": "sanluan_PublicCMS-57-Param-4",
    "old_comment_raw": "@param model",
    "new_code_raw": "    public String delete(String id, String _csrf, HttpServletRequest request, HttpSession session, ModelMap model) {\n        SysSite site = getSite(request);\n        if (ControllerUtils.verifyCustom(\"noright\", !siteComponent.isMaster(site.getId()), model)\n                || ControllerUtils.verifyNotEquals(\"_csrf\", ControllerUtils.getAdminToken(request), _csrf, model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        SysModule entity = service.getEntity(id);\n        if (null != entity) {\n            service.delete(id);\n            @SuppressWarnings(\"unchecked\")\n            List<SysRoleModule> roleModuleList = (List<SysRoleModule>) roleModuleService.getPage(null, id, null, null).getList();\n            roleModuleService.deleteByModuleId(id);\n            dealRoleAuthorized(roleModuleList);\n            logOperateService.save(new LogOperate(getSite(request).getId(), ControllerUtils.getAdminFromSession(session).getId(),\n                    LogLoginService.CHANNEL_WEB_MANAGER, \"delete.module\", RequestUtils.getIpAddress(request),\n                    CommonUtils.getDate(), JsonUtils.getString(entity)));\n        }\n        return CommonConstants.TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "JSQLParser_JSqlParser-32-Param-0",
    "old_comment_raw": "@param select",
    "new_code_raw": "    public List<String> getTableList(Statement statement) {\n        init();\n        statement.accept(this);\n        return tables;\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-531-Param-2",
    "old_comment_raw": "@param pageSize",
    "new_code_raw": "    public PageHandler getPage(String hql, Map<String, Object> parameters, Integer pageIndex, Integer pageSize) {\n        return dao.getPage(hql, parameters, pageIndex, pageSize);\n    }\n"
  },
  {
    "id": "apache_ignite-12346-Param-2",
    "old_comment_raw": "@param rootIds Root page IDs.",
    "new_code_raw": "    protected ReuseList createReuseList(int cacheId, PageMemory pageMem, long rootId, boolean initNew)\n        throws IgniteCheckedException {\n        return null;\n    }\n"
  },
  {
    "id": "apache_ignite-7412-Param-1",
    "old_comment_raw": "@param writer Writer.",
    "new_code_raw": "    private boolean writeHeader(Object obj, BinaryWriterExImpl writer) {\n        if (writer.tryWriteAsHandle(obj))\n            return false;\n\n        PortableUtils.writeHeader(\n            writer,\n            userType,\n            registered ? typeId : GridPortableMarshaller.UNREGISTERED_TYPE_ID,\n            obj instanceof CacheObjectImpl ? 0 : obj.hashCode(),\n            registered ? null : cls.getName()\n        );\n\n        return true;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1294-Param-0",
    "old_comment_raw": "@param authSession for current request",
    "new_code_raw": "    protected Response handleBrowserAuthenticationRequest(ClientSessionModel clientSession, LoginProtocol protocol, boolean isPassive, boolean redirectToAuthentication) {\n        AuthenticationFlowModel flow = getAuthenticationFlow();\n        String flowId = flow.getId();\n        AuthenticationProcessor processor = createProcessor(clientSession, flowId, LoginActionsService.AUTHENTICATE_PATH);\n        event.detail(Details.CODE_ID, clientSession.getId());\n        if (isPassive) {\n            // OIDC prompt == NONE or SAML 2 IsPassive flag\n            // This means that client is just checking if the user is already completely logged in.\n            // We cancel login if any authentication action or required action is required\n            try {\n                if (processor.authenticateOnly() == null) {\n                    processor.attachSession();\n                } else {\n                    Response response = protocol.sendError(clientSession, Error.PASSIVE_LOGIN_REQUIRED);\n                    session.sessions().removeClientSession(realm, clientSession);\n                    return response;\n                }\n                if (processor.isActionRequired()) {\n                    Response response = protocol.sendError(clientSession, Error.PASSIVE_INTERACTION_REQUIRED);\n                    session.sessions().removeClientSession(realm, clientSession);\n                    return response;\n\n                }\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n            return processor.finishAuthentication(protocol);\n        } else {\n            try {\n                RestartLoginCookie.setRestartCookie(session, realm, clientConnection, uriInfo, clientSession);\n                if (redirectToAuthentication) {\n                    return processor.redirectToFlow();\n                }\n                return processor.authenticate();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-8524-Param-0",
    "old_comment_raw": "@param err Creation error.",
    "new_code_raw": "    private IgniteCheckedException componentException(Throwable err) {\n        return new IgniteCheckedException(\"Failed to create Ignite component (consider adding \" + module +\n            \" module to classpath) [component=\" + this + \", cls=\" + clsName + ']', err);\n    }\n"
  },
  {
    "id": "apache_ignite-12180-Param-0",
    "old_comment_raw": "@param url XML file URL.",
    "new_code_raw": "    private ApplicationContext initContext(Resource res) throws IgniteCheckedException {\n        GenericApplicationContext springCtx;\n\n        try {\n            springCtx = new GenericApplicationContext();\n\n            XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(springCtx);\n\n            reader.setValidationMode(XmlBeanDefinitionReader.VALIDATION_NONE);\n\n            reader.loadBeanDefinitions(res);\n\n            springCtx.refresh();\n        }\n        catch (BeansException e) {\n            if (X.hasCause(e, ClassNotFoundException.class))\n                throw new IgniteCheckedException(\"Failed to instantiate Spring XML application context \" +\n                    \"(make sure all classes used in Spring configuration are present at CLASSPATH) \" +\n                    \"[resource=\" + res + ']', e);\n            else\n                throw new IgniteCheckedException(\"Failed to instantiate Spring XML application context [resource=\" +\n                    res + \", err=\" + e.getMessage() + ']', e);\n        }\n\n        return springCtx;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-132-Param-0",
    "old_comment_raw": "@param fr Input frame",
    "new_code_raw": "  public static Frame shuffleAndBalance(final Frame fr, long seed, final boolean local, final boolean shuffle) {\n    int cores = 0;\n    for( H2ONode node : H2O.CLOUD._memary ) {\n      if (local) cores = Math.max(cores, node._heartbeat._num_cpus);\n      else cores += node._heartbeat._num_cpus;\n    }\n    final int splits = 4*cores;\n\n    // rebalance only if the number of chunks is less than the number of cores\n    if( (fr.vecs()[0].nChunks() < cores || shuffle) && fr.numRows() > splits) {\n      Vec[] vecs = fr.vecs().clone();\n      Log.info(\"Load balancing dataset, splitting it into up to \" + splits + \" chunks.\");\n      long[] idx = null;\n      if (shuffle) {\n        idx = new long[splits];\n        for (int r=0; r<idx.length; ++r) idx[r] = r;\n        Utils.shuffleArray(idx, seed);\n      }\n      Key keys[] = new Vec.VectorGroup().addVecs(vecs.length);\n      final long rows_per_new_chunk = (long)(Math.ceil((double)fr.numRows()/splits));\n      //loop over cols (same indexing for each column)\n      Futures fs = new Futures();\n      for(int col=0; col<vecs.length; col++) {\n        AppendableVec vec = new AppendableVec(keys[col]);\n        // create outgoing chunks for this col\n        NewChunk[] outCkg = new NewChunk[splits];\n        for(int i=0; i<splits; ++i)\n          outCkg[i] = new NewChunk(vec, i);\n        //loop over all incoming chunks\n        for( int ckg = 0; ckg < vecs[col].nChunks(); ckg++ ) {\n          final Chunk inCkg = vecs[col].chunkForChunkIdx(ckg);\n          // loop over local rows of incoming chunks (fast path)\n          for (int row = 0; row < inCkg._len; ++row) {\n            int outCkgIdx = (int)((inCkg._start + row) / rows_per_new_chunk); // destination chunk idx\n            if (shuffle) outCkgIdx = (int)(idx[outCkgIdx]); //shuffle: choose a different output chunk\n            assert(outCkgIdx >= 0 && outCkgIdx < splits);\n            outCkg[outCkgIdx].addNum(inCkg.at0(row));\n          }\n        }\n        for(int i=0; i<outCkg.length; ++i)\n          outCkg[i].close(i, fs);\n        Vec t = vec.close(fs);\n        t._domain = vecs[col]._domain;\n        vecs[col] = t;\n      }\n      fs.blockForPending();\n      Log.info(\"Load balancing done.\");\n      return new Frame(fr.names(), vecs);\n    }\n    return fr;\n  }\n"
  },
  {
    "id": "stephanenicolas_robospice-41-Param-1",
    "old_comment_raw": "@param contentRequest the request that we wish to remove notification for.",
    "new_code_raw": "    private boolean match( CachedSpiceRequest< ? > cachedSpiceRequest, SpiceRequest< ? > spiceRequest ) {\n        if ( spiceRequest instanceof CachedSpiceRequest ) {\n            return spiceRequest == cachedSpiceRequest;\n        } else {\n            return cachedSpiceRequest.getSpiceRequest() == spiceRequest;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5030-Param-2",
    "old_comment_raw": "@param fastMap Flag indicating whether mapping is performed for fast-circuit update.",
    "new_code_raw": "    private Collection<ClusterNode> mapKey(K key, AffinityTopologyVersion topVer, boolean fastMap) {\n        GridCacheAffinityManager<K, V> affMgr = cctx.affinity();\n\n        // If we can send updates in parallel - do it.\n        return fastMap ?\n            cctx.topology().nodes(affMgr.partition(key), topVer) :\n            Collections.singletonList(affMgr.primary(key, topVer));\n    }\n"
  },
  {
    "id": "apache_ignite-13180-Param-0",
    "old_comment_raw": "@param taskInfo Task info.",
    "new_code_raw": "    public GridHadoopTaskInput input(GridHadoopTaskContext taskCtx) throws GridException {\n        switch (taskCtx.taskInfo().type()) {\n            case COMBINE:\n                return combinerMap.input(taskCtx, (Comparator<Object>) taskCtx.combineGroupComparator());\n\n            case REDUCE:\n                int reducer = taskCtx.taskInfo().taskNumber();\n\n                GridHadoopMultimap m = maps.get(reducer);\n\n                if (m != null)\n                    return m.input(taskCtx, (Comparator<Object>)taskCtx.reduceGroupComparator());\n\n                return new GridHadoopTaskInput() { // Empty input.\n                    @Override public boolean next() {\n                        return false;\n                    }\n\n                    @Override public Object key() {\n                        throw new IllegalStateException();\n                    }\n\n                    @Override public Iterator<?> values() {\n                        throw new IllegalStateException();\n                    }\n\n                    @Override public void close() {\n                        // No-op.\n                    }\n                };\n\n            default:\n                throw new IllegalStateException(\"Illegal type: \" + taskCtx.taskInfo().type());\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-3715-Param-2",
    "old_comment_raw": "@param status Finalization status.",
    "new_code_raw": "    private boolean salvageTx(IgniteInternalTx<K, V> tx, boolean warn, IgniteInternalTx.FinalizationStatus status) {\n        assert tx != null;\n\n        IgniteTxState state = tx.state();\n\n        if (state == ACTIVE || state == PREPARING || state == PREPARED) {\n            try {\n                if (!tx.markFinalizing(status)) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Will not try to commit invalidate transaction (could not mark finalized): \" + tx);\n\n                    return false;\n                }\n\n                tx.systemInvalidate(true);\n\n                tx.prepare();\n\n                if (tx.state() == PREPARING) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Ignoring transaction in PREPARING state as it is currently handled \" +\n                            \"by another thread: \" + tx);\n\n                    return false;\n                }\n\n                if (tx instanceof IgniteTxRemoteEx) {\n                    IgniteTxRemoteEx<K, V> rmtTx = (IgniteTxRemoteEx<K, V>)tx;\n\n                    rmtTx.doneRemote(tx.xidVersion(), Collections.<GridCacheVersion>emptyList(),\n                        Collections.<GridCacheVersion>emptyList(), Collections.<GridCacheVersion>emptyList());\n                }\n\n                tx.commit();\n\n                if (warn) {\n                    // This print out cannot print any peer-deployed entity either\n                    // directly or indirectly.\n                    U.warn(log, \"Invalidated transaction because originating node either \" +\n                        \"crashed or left grid: \" + CU.txString(tx));\n                }\n            }\n            catch (IgniteTxOptimisticCheckedException ignore) {\n                if (log.isDebugEnabled())\n                    log.debug(\"Optimistic failure while invalidating transaction (will rollback): \" +\n                        tx.xidVersion());\n\n                try {\n                    tx.rollback();\n                }\n                catch (IgniteCheckedException e) {\n                    U.error(log, \"Failed to rollback transaction: \" + tx.xidVersion(), e);\n                }\n            }\n            catch (IgniteCheckedException e) {\n                U.error(log, \"Failed to invalidate transaction: \" + tx, e);\n            }\n        }\n        else if (state == MARKED_ROLLBACK) {\n            try {\n                tx.rollback();\n            }\n            catch (IgniteCheckedException e) {\n                U.error(log, \"Failed to rollback transaction: \" + tx.xidVersion(), e);\n            }\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "guoguibing_librec-228-Param-2",
    "old_comment_raw": "@param nd indices of other dimensions",
    "new_code_raw": "\tpublic SparseMatrix slice(int rowDim, int colDim, int... otherKeys) {\n\n\t\tif (otherKeys.length != numDimensions - 2)\n\t\t\tthrow new Error(\"The input dimensions do not match the tensor specification!\");\n\n\t\t// find an indexed array to search \n\t\tint d = -1;\n\t\tboolean cond1 = indexedDimensions.size() == 0;\n\t\tboolean cond2 = (indexedDimensions.contains(rowDim) || indexedDimensions.contains(colDim))\n\t\t\t\t&& indexedDimensions.size() == 1;\n\t\tboolean cond3 = indexedDimensions.contains(rowDim) && indexedDimensions.contains(colDim)\n\t\t\t\t&& indexedDimensions.size() == 2;\n\t\tif (cond1 || cond2 || cond3) {\n\t\t\tfor (d = 0; d < numDimensions; d++) {\n\t\t\t\tif (d != rowDim && d != colDim)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbuildIndex(d);\n\t\t} else {\n\t\t\tfor (int dd : indexedDimensions) {\n\t\t\t\tif (dd != rowDim && dd != colDim) {\n\t\t\t\t\td = dd;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// get search key\n\t\tint key = -1;\n\t\tfor (int dim = 0, i = 0; dim < numDimensions; dim++) {\n\t\t\tif (dim == rowDim || dim == colDim)\n\t\t\t\tcontinue;\n\n\t\t\tif (dim == d) {\n\t\t\t\tkey = otherKeys[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ti++;\n\t\t}\n\n\t\t// all relevant positions\n\t\tCollection<Integer> indices = keyIndices[d].get(key);\n\t\tif (indices == null || indices.size() == 0)\n\t\t\treturn null;\n\n\t\tTable<Integer, Integer, Double> dataTable = HashBasedTable.create();\n\t\tMultimap<Integer, Integer> colMap = HashMultimap.create();\n\n\t\t// for each possible position\n\t\tfor (int index : indices) {\n\t\t\tboolean found = true;\n\t\t\tfor (int dd = 0, j = 0; dd < numDimensions; dd++) {\n\n\t\t\t\tif (dd == rowDim || dd == colDim)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (otherKeys[j++] != key(dd, index)) {\n\t\t\t\t\tfound = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (found) {\n\t\t\t\tint row = ndKeys[rowDim].get(index);\n\t\t\t\tint col = ndKeys[colDim].get(index);\n\t\t\t\tdouble val = values.get(index);\n\n\t\t\t\tdataTable.put(row, col, val);\n\t\t\t\tcolMap.put(col, row);\n\t\t\t}\n\t\t}\n\n\t\treturn new SparseMatrix(dimensions[rowDim], dimensions[colDim], dataTable, colMap);\n\t}\n"
  },
  {
    "id": "pockethub_PocketHub-726-Param-0",
    "old_comment_raw": "@param event",
    "new_code_raw": "    public static boolean isValid(final GitHubEvent event) {\n        if (event == null || event.payload() == null)\n            return false;\n\n        final GitHubEventType type = event.type();\n\n        return CommitCommentEvent.equals(type) //\n                || (CreateEvent.equals(type) //\n                && ((CreatePayload) event.payload()).refType() != null) //\n                || DeleteEvent.equals(type) //\n                || DownloadEvent.equals(type) //\n                || FollowEvent.equals(type) //\n                || ForkEvent.equals(type) //\n                || (GistEvent.equals(type)\n                && ((GistPayload) event.payload()).gist() != null)\n                || GollumEvent.equals(type) //\n                || (IssueCommentEvent.equals(type) //\n                && ((IssueCommentPayload) event.payload()).issue() != null) //\n                || (IssuesEvent.equals(type) //\n                && ((IssuesPayload) event.payload()).issue() != null) //\n                || MemberEvent.equals(type) //\n                || PublicEvent.equals(type) //\n                || PullRequestEvent.equals(type) //\n                || PullRequestReviewCommentEvent.equals(type) //\n                || PushEvent.equals(type) //\n                || TeamAddEvent.equals(type) //\n                || WatchEvent.equals(type);\n    }\n"
  },
  {
    "id": "CalebFenton_simplify-17-Param-0",
    "old_comment_raw": "@param methodDescriptor",
    "new_code_raw": "    public List<BuilderTryBlock> getTryBlocks(String methodSignature) {\n        dexifyClassIfNecessary(methodSignature);\n\n        return methodSignatureToTryBlocks.get(methodSignature);\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-704-Param-0",
    "old_comment_raw": "@param repo",
    "new_code_raw": "    public Commit refreshCommit(final Repository repo, final String id) throws IOException {\n        Commit commit = ServiceGenerator.createService(context, RepositoryCommitService.class)\n                .getCommit(repo.owner().login(), repo.name(), id)\n                .toBlocking()\n                .first();\n\n        return addCommit(repo, commit);\n    }\n"
  },
  {
    "id": "alibaba_Sentinel-62-Param-0",
    "old_comment_raw": "@param time a valid timestamp in milliseconds",
    "new_code_raw": "    public T getWindowValue(long timeMillis) {\n        if (timeMillis < 0) {\n            return null;\n        }\n        int idx = calculateTimeIdx(timeMillis);\n\n        WindowWrap<T> bucket = array.get(idx);\n\n        if (bucket == null || !bucket.isTimeInWindow(timeMillis)) {\n            return null;\n        }\n\n        return bucket.value();\n    }\n"
  },
  {
    "id": "apache_ignite-1591-Param-0",
    "old_comment_raw": "@param cacheName Name of cache on which affinity is requested.",
    "new_code_raw": "    private AffinityInfo affinityInfoFromNode(@Nullable String cacheName, long topVer, ClusterNode n)\n        throws GridException {\n        GridTuple3<GridAffinityMessage, GridAffinityMessage, GridAffinityAssignment> t = ctx.closure()\n            .callAsyncNoFailover(BALANCE, affinityJob(cacheName, topVer), F.asList(n), true/*system pool*/).get();\n\n        GridCacheAffinityFunction f = (GridCacheAffinityFunction)unmarshall(ctx, n.id(), t.get1());\n        GridCacheAffinityKeyMapper m = (GridCacheAffinityKeyMapper)unmarshall(ctx, n.id(), t.get2());\n\n        assert m != null;\n\n        // Bring to initial state.\n        f.reset();\n        m.reset();\n\n        Boolean portableEnabled = U.portableEnabled(n, cacheName);\n\n        return new AffinityInfo(f, m, t.get3(), portableEnabled != null && portableEnabled);\n    }\n"
  },
  {
    "id": "json_path_JsonPath-197-Param-0",
    "old_comment_raw": "@param path path to evaluate in criteria",
    "new_code_raw": "    public static Criteria create(String left, String operator, String right) {\n        Object leftPrepared = left;\n        Object rightPrepared = right;\n        Path leftPath = null;\n        Path rightPath = null;\n\n        if(isPath(left)){\n            leftPath = PathCompiler.compile(left);\n            if(!leftPath.isDefinite()){\n                throw new InvalidPathException(\"the predicate path: \" + left + \" is not definite\");\n            }\n            leftPrepared = leftPath;\n        } else if(isString(left)) {\n            leftPrepared = left.substring(1, left.length() - 1);\n        }\n\n        if(isPath(right)){\n            rightPath = PathCompiler.compile(right);\n            if(!rightPath.isDefinite()){\n                throw new InvalidPathException(\"the predicate path: \" + right + \" is not definite\");\n            }\n            rightPrepared = rightPath;\n        } else if(isString(right)) {\n            rightPrepared = right.substring(1, right.length() - 1);\n        }\n\n        if(leftPath != null && operator.isEmpty()){\n            return Criteria.where(leftPath).exists(true);\n        } else {\n            return new Criteria(leftPrepared, CriteriaType.parse(operator), rightPrepared);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-12125-Param-1",
    "old_comment_raw": "@param addr Address to send message to.",
    "new_code_raw": "    @Nullable private Integer sendMessageDirectly(TcpDiscoveryAbstractMessage msg, InetSocketAddress addr)\n        throws IgniteSpiException {\n        assert msg != null;\n        assert addr != null;\n\n        Collection<Throwable> errs = null;\n\n        Socket sock = null;\n\n        long ackTimeout0 = ackTimeout;\n\n        int connectAttempts = 1;\n\n        boolean joinReqSent = false;\n\n        UUID locNodeId = ignite.configuration().getNodeId();\n\n        for (int i = 0; i < reconCnt; i++) {\n            // Need to set to false on each new iteration,\n            // since remote node may leave in the middle of the first iteration.\n            joinReqSent = false;\n\n            boolean openSock = false;\n\n            try {\n                long tstamp = U.currentTimeMillis();\n\n                sock = openSocket(addr);\n\n                openSock = true;\n\n                // Handshake.\n                writeToSocket(sock, new TcpDiscoveryHandshakeRequest(locNodeId));\n\n                TcpDiscoveryHandshakeResponse res = readMessage(sock, null, ackTimeout0);\n\n                if (locNodeId.equals(res.creatorNodeId())) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Handshake response from local node: \" + res);\n\n                    break;\n                }\n\n                stats.onClientSocketInitialized(U.currentTimeMillis() - tstamp);\n\n                // Send message.\n                tstamp = U.currentTimeMillis();\n\n                writeToSocket(sock, msg);\n\n                stats.onMessageSent(msg, U.currentTimeMillis() - tstamp);\n\n                if (debugMode)\n                    debugLog(\"Message has been sent directly to address [msg=\" + msg + \", addr=\" + addr +\n                        \", rmtNodeId=\" + res.creatorNodeId() + ']');\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Message has been sent directly to address [msg=\" + msg + \", addr=\" + addr +\n                        \", rmtNodeId=\" + res.creatorNodeId() + ']');\n\n                // Connection has been established, but\n                // join request may not be unmarshalled on remote host.\n                // E.g. due to class not found issue.\n                joinReqSent = msg instanceof TcpDiscoveryJoinRequestMessage;\n\n                return readReceipt(sock, ackTimeout0);\n            }\n            catch (ClassCastException e) {\n                // This issue is rarely reproducible on AmazonEC2, but never\n                // on dedicated machines.\n                if (log.isDebugEnabled())\n                    U.error(log, \"Class cast exception on direct send: \" + addr, e);\n\n                if (errs == null)\n                    errs = new ArrayList<>();\n\n                errs.add(e);\n            }\n            catch (IOException | IgniteCheckedException e) {\n                if (log.isDebugEnabled())\n                    log.error(\"Exception on direct send: \" + e.getMessage(), e);\n\n                if (errs == null)\n                    errs = new ArrayList<>();\n\n                errs.add(e);\n\n                if (!openSock) {\n                    // Reconnect for the second time, if connection is not established.\n                    if (connectAttempts < 2) {\n                        connectAttempts++;\n\n                        continue;\n                    }\n\n                    break; // Don't retry if we can not establish connection.\n                }\n\n                if (e instanceof SocketTimeoutException || X.hasCause(e, SocketTimeoutException.class)) {\n                    ackTimeout0 *= 2;\n\n                    if (!checkAckTimeout(ackTimeout0))\n                        break;\n                }\n            }\n            finally {\n                U.closeQuiet(sock);\n            }\n        }\n\n        if (joinReqSent) {\n            if (log.isDebugEnabled())\n                log.debug(\"Join request has been sent, but receipt has not been read (returning RES_WAIT).\");\n\n            // Topology will not include this node,\n            // however, warning on timed out join will be output.\n            return RES_OK;\n        }\n\n        throw new IgniteSpiException(\n            \"Failed to send message to address [addr=\" + addr + \", msg=\" + msg + ']',\n            U.exceptionWithSuppressed(\"Failed to send message to address \" +\n                \"[addr=\" + addr + \", msg=\" + msg + ']', errs));\n    }\n"
  },
  {
    "id": "apache_commons-proxy-0-Associations-Param1",
    "old_comment_raw": "@param proxyInterfaces the proxy interfaces",
    "new_code_raw": "    public static Object createNullObject( ProxyFactory proxyFactory, Class... proxyClasses )\n    {\n        return proxyFactory.createInvocationHandlerProxy( new NullInvocationHandler(), proxyClasses );\n    }\n\n"
  },
  {
    "id": "apache_ignite-5647-Param-1",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    private AffinityInfo affinityInfoFromNode(@Nullable String cacheName, AffinityTopologyVersion topVer, ClusterNode n)\n        throws IgniteCheckedException {\n        GridTuple3<GridAffinityMessage, GridAffinityMessage, GridAffinityAssignment> t = ctx.closure()\n            .callAsyncNoFailover(BALANCE, affinityJob(cacheName, topVer), F.asList(n), true/*system pool*/).get();\n\n        CacheAffinityFunction f = (CacheAffinityFunction)unmarshall(ctx, n.id(), t.get1());\n        CacheAffinityKeyMapper m = (CacheAffinityKeyMapper)unmarshall(ctx, n.id(), t.get2());\n\n        assert m != null;\n\n        // Bring to initial state.\n        f.reset();\n        m.reset();\n\n        return new AffinityInfo(f, m, t.get3(), ctx.cacheObjects().contextForCache(n, cacheName));\n    }\n"
  },
  {
    "id": "guoguibing_librec-219-Param-0",
    "old_comment_raw": "@param rels the indexes of the relevant columns in the data file",
    "new_code_raw": "\tpublic SparseMat readData(int[] cols) throws Exception {\n\n\t\tTable<String, String, Double> dataTable = HashBasedTable.create();\n\t\tBufferedReader br = FileIO.getReader(dataPath);\n\t\tString line = null;\n\t\twhile ((line = br.readLine()) != null) {\n\t\t\tString[] data = line.split(\"[ \\t,]\");\n\n\t\t\tString user = data[cols[0]];\n\t\t\tString item = data[cols[1]];\n\t\t\tDouble rate = Double.valueOf(data[cols[2]]);\n\n\t\t\t/*if (cols.length >= 4) {\n\t\t\t\tdouble weight = Double.parseDouble(data[cols[3]]);\n\t\t\t\tif (rate == 0 && weight < 1)\n\t\t\t\t\tcontinue;\n\t\t\t}*/\n\n\t\t\tscaleDist.add(rate);\n\t\t\tdataTable.put(user, item, rate);\n\n\t\t\t// inner id starting from 0\n\t\t\tif (!userIds.containsKey(user))\n\t\t\t\tuserIds.put(user, userIds.size());\n\n\t\t\tif (!itemIds.containsKey(item))\n\t\t\t\titemIds.put(item, itemIds.size());\n\t\t}\n\t\tbr.close();\n\n\t\tnumRates = scaleDist.size();\n\t\tscales = new ArrayList<>(scaleDist.elementSet());\n\t\tCollections.sort(scales);\n\n\t\t// if min-rate = 0.0, shift upper a scale\n\t\tdouble minRate = scales.get(0).doubleValue();\n\t\tdouble epsilon = minRate == 0.0 ? scales.get(1).doubleValue() - minRate : 0;\n\t\tif (epsilon > 0) {\n\t\t\tfor (int i = 0, im = scales.size(); i < im; i++) {\n\t\t\t\tdouble val = scales.get(i);\n\t\t\t\tscales.set(i, val + epsilon);\n\t\t\t}\n\t\t}\n\n\t\tint numRows = numUsers(), numCols = numItems();\n\t\tif (isItemAsUser) {\n\t\t\tLogs.debug(\"User amount: {}, scales: {{}}\", numRows, Strings.toString(scales, \", \"));\n\t\t} else {\n\t\t\tLogs.debug(\"User amount: {}, item amount: {}\", numRows, numCols);\n\t\t\tLogs.debug(\"Rating amount: {}, scales: {{}}\", numRates, Strings.toString(scales, \", \"));\n\t\t}\n\n\t\t// build rating matrix\n\t\tint[][] nz = new int[numRows][];\n\n\t\tfor (int uid = 0; uid < nz.length; uid++) {\n\t\t\tString user = getUserId(uid);\n\n\t\t\tnz[uid] = new int[dataTable.row(user).size()];\n\n\t\t\tList<Integer> items = new ArrayList<>();\n\t\t\tfor (String item : dataTable.row(user).keySet())\n\t\t\t\titems.add(getItemId(item));\n\t\t\tCollections.sort(items);\n\n\t\t\tfor (int c = 0, cm = items.size(); c < cm; c++)\n\t\t\t\tnz[uid][c] = items.get(c);\n\t\t}\n\n\t\trateMatrix = new SparseMat(numRows, numCols, nz);\n\t\tfor (int i = 0; i < numRows; i++) {\n\t\t\tString user = getUserId(i);\n\n\t\t\tMap<String, Double> itemRates = dataTable.row(user);\n\t\t\tfor (Entry<String, Double> en : itemRates.entrySet()) {\n\t\t\t\tint j = getItemId(en.getKey());\n\t\t\t\tdouble rate = en.getValue();\n\t\t\t\trateMatrix.set(i, j, rate + epsilon);\n\t\t\t}\n\t\t}\n\n\t\t// release memory of data table\n\t\tdataTable = null;\n\n\t\treturn rateMatrix;\n\t}\n"
  },
  {
    "id": "guoguibing_librec-233-Param-0",
    "old_comment_raw": "@param userDim dimension of users",
    "new_code_raw": "\tpublic SparseMatrix rateMatrix() {\n\n\t\tTable<Integer, Integer, Double> dataTable = HashBasedTable.create();\n\t\tMultimap<Integer, Integer> colMap = HashMultimap.create();\n\n\t\tfor (TensorEntry te : this) {\n\t\t\tint u = te.key(userDimension);\n\t\t\tint i = te.key(itemDimension);\n\n\t\t\tdataTable.put(u, i, te.get());\n\t\t\tcolMap.put(i, u);\n\t\t}\n\n\t\treturn new SparseMatrix(dimensions[userDimension], dimensions[itemDimension], dataTable, colMap);\n\t}\n"
  },
  {
    "id": "json_path_JsonPath-232-Param-0",
    "old_comment_raw": "@param criteriaList list of criteria",
    "new_code_raw": "    public static Filter filter(Predicate criteria) {\n        return new SingleFilter(criteria);\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-55-Param-0",
    "old_comment_raw": "@param setpoint the setpoint to set.",
    "new_code_raw": "\tpublic SerialMessage setMessage(int scale, BigDecimal setpoint) {\n\t\tfor (SetpointType setpointType : this.setpointTypes) {\n\t\t\treturn setMessage(scale, setpointType, setpoint);\n\t\t}\n\t\t\n\t\t// in case there are no supported setpoint types, get them.\n\t\treturn this.getSupportedMessage();\n\t}\n"
  },
  {
    "id": "eclipse_milo-7-Associations-Param0",
    "old_comment_raw": "@param algorithm the algorithm to use when determined the nonce length.",
    "new_code_raw": "    public static ByteString generateNonce(SecurityPolicy securityPolicy) {\n        return generateNonce(getNonceLength(securityPolicy));\n    }\n\n"
  },
  {
    "id": "haifengl_smile-109-Param-1",
    "old_comment_raw": "@param v on input, it is the non-zero initial guess of the eigen vector. On output, it is the eigen vector corresponding largest eigen value.",
    "new_code_raw": "    public static double eigen(Matrix A, double[] v, double p, double tol) {\n        return eigen(A, v, p, tol, Math.max(20, 2 * A.nrows()));\n    }\n"
  },
  {
    "id": "LMAX-Exchange_disruptor-20-Associations-Param0",
    "old_comment_raw": "@param sequenceBatch to be updated for the batch range.",
    "new_code_raw": "    public BatchDescriptor next(final BatchDescriptor batchDescriptor)\n    {\n        if (null == gatingSequences)\n        {\n            throw new NullPointerException(\"gatingSequences must be set before claiming sequences\");\n        }\n\n        final long sequence = claimStrategy.incrementAndGet(batchDescriptor.getSize(), gatingSequences);\n        batchDescriptor.setEnd(sequence);\n        return batchDescriptor;\n    }\n\n"
  },
  {
    "id": "zxing_zxing-311-Param-1",
    "old_comment_raw": "@param codeIndex The current index into the codeword array.",
    "new_code_raw": "  private static int textCompaction(int[] codewords, int codeIndex, StringBuilder result) {\n    // 2 character per codeword\n    int[] textCompactionData = new int[codewords[0] << 1];\n    // Used to hold the byte compaction value if there is a mode shift\n    int[] byteCompactionData = new int[codewords[0] << 1];\n\n    int index = 0;\n    boolean end = false;\n    while ((codeIndex < codewords[0]) && !end) {\n      int code = codewords[codeIndex++];\n      if (code < TEXT_COMPACTION_MODE_LATCH) {\n        textCompactionData[index] = code / 30;\n        textCompactionData[index + 1] = code % 30;\n        index += 2;\n      } else {\n        switch (code) {\n          case TEXT_COMPACTION_MODE_LATCH:\n            codeIndex--;\n            end = true;\n            break;\n          case BYTE_COMPACTION_MODE_LATCH:\n            codeIndex--;\n            end = true;\n            break;\n          case NUMERIC_COMPACTION_MODE_LATCH:\n            codeIndex--;\n            end = true;\n            break;\n          case MODE_SHIFT_TO_BYTE_COMPACTION_MODE:\n            // The Mode Shift codeword 913 shall cause a temporary\n            // switch from Text Compaction mode to Byte Compaction mode.\n            // This switch shall be in effect for only the next codeword,\n            // after which the mode shall revert to the prevailing sub-mode\n            // of the Text Compaction mode. Codeword 913 is only available\n            // in Text Compaction mode; its use is described in 5.4.2.4.\n            textCompactionData[index] = MODE_SHIFT_TO_BYTE_COMPACTION_MODE;\n            code = codewords[codeIndex++];\n            byteCompactionData[index] = code; //Integer.toHexString(code);\n            index++;\n            break;\n          case BYTE_COMPACTION_MODE_LATCH_6:\n            codeIndex--;\n            end = true;\n            break;\n        }\n      }\n    }\n    decodeTextCompaction(textCompactionData, byteCompactionData, index, result);\n    return codeIndex;\n  }\n"
  },
  {
    "id": "svn2github_stripesframework-10-Associations-Param0",
    "old_comment_raw": "@param urlBinding the url to find the bound bean type",
    "new_code_raw": "    public Class<? extends ActionBean> getActionBeanType(String path) {\n        return this.formBeans.get(getUrlBindingFromPath(path));\n    }\n\n"
  },
  {
    "id": "apache_ignite-2214-Param-1",
    "old_comment_raw": "@param log Log.",
    "new_code_raw": "    private static GridIpcEndpoint connectSharedMemoryEndpoint(int port, IgniteLogger log) throws GridException {\n        return new GridIpcSharedMemoryClientEndpoint(port, log);\n    }\n"
  },
  {
    "id": "apache_ignite-13178-Param-0",
    "old_comment_raw": "@param info Task info.",
    "new_code_raw": "    private GridHadoopTaskInput createInput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case MAP:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case COMBINE:\n                if (locCombiner) {\n                    assert local != null;\n\n                    return local.input((Comparator<Object>)job.combineGroupComparator());\n                }\n\n            default:\n                return createInput(ctx);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-2303-Param-1",
    "old_comment_raw": "@param skipTx Whether to skip existing transaction.",
    "new_code_raw": "    private List<IgniteUuid> fileIds(IgniteFsPath path, boolean skipTx) throws GridException {\n        assert path != null;\n\n        // Path components.\n        Collection<String> components = path.components();\n\n        // Collection of file IDs for components of specified path.\n        List<IgniteUuid> ids = new ArrayList<>(components.size() + 1);\n\n        ids.add(ROOT_ID); // Always add root ID.\n\n        IgniteUuid fileId = ROOT_ID;\n\n        for (String s : components) {\n            assert !s.isEmpty();\n\n            if (fileId != null)\n                fileId = fileId(fileId, s, skipTx);\n\n            ids.add(fileId);\n        }\n\n        return ids;\n    }\n"
  },
  {
    "id": "apache_ignite-11534-Param-1",
    "old_comment_raw": "@param out Output character stream.",
    "new_code_raw": "    public static int copy(InputStream in, OutputStream out) throws IOException {\n        assert in != null;\n        assert out != null;\n\n        byte[] buf = new byte[BUF_SIZE];\n\n        int cnt = 0;\n\n        for (int n; (n = in.read(buf)) > 0;) {\n            out.write(buf, 0, n);\n\n            cnt += n;\n        }\n\n        return cnt;\n    }\n"
  },
  {
    "id": "todoroo_astrid-732-Param-0",
    "old_comment_raw": "@param taskId",
    "new_code_raw": "    protected String getTagsAsString(long taskId, String separator, boolean includeEmergent) {\n        StringBuilder tagBuilder = new StringBuilder();\n        TodorooCursor<Metadata> tags = getTags(taskId, includeEmergent);\n        try {\n            int length = tags.getCount();\n            Metadata metadata = new Metadata();\n            for (int i = 0; i < length; i++) {\n                tags.moveToNext();\n                metadata.readFromCursor(tags);\n                tagBuilder.append(metadata.getValue(TAG));\n                if (i < length - 1)\n                    tagBuilder.append(separator);\n            }\n        } finally {\n            tags.close();\n        }\n        return tagBuilder.toString();\n    }\n"
  },
  {
    "id": "apache_ignite-13222-Param-1",
    "old_comment_raw": "@param type Type description.",
    "new_code_raw": "    protected int fillKeyParameters(PreparedStatement stmt, EntryMapping m, Object key) throws CacheException {\n        return fillKeyParameters(stmt, 1, m, key);\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-721-Param-0",
    "old_comment_raw": "@param event",
    "new_code_raw": "    public UserPair getUsers(final GitHubEvent event) {\n        if (event == null || event.payload() == null)\n            return null;\n\n        GitHubEventType type = event.type();\n        if (GitHubEventType.FollowEvent.equals(type)) {\n            User from = event.actor();\n            User to = ((FollowPayload) event.payload()).target();\n            if (from != null && to != null)\n                return new UserPair(from, to);\n        }\n\n        return null;\n    }\n"
  },
  {
    "id": "keyboardsurfer_Crouton-31-Param-0",
    "old_comment_raw": "@param duration The durationInMilliseconds the crouton will be displayed  Crouton in milliseconds.",
    "new_code_raw": "\t\tpublic Builder setDuration(int durationInMilliseconds) {\n\t\t\tthis.durationInMilliseconds = durationInMilliseconds;\n\n\t\t\treturn this;\n\t\t}\n"
  },
  {
    "id": "apache_ignite-4954-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    protected boolean owns(KeyCacheObject key) {\n        assert key != null;\n\n        // Avoid hash code and remainder calculation in case there is no actual split.\n        return totalCnt == 1 || key.hashCode() % totalCnt == id;\n    }\n"
  },
  {
    "id": "apache_ignite-13313-Param-2",
    "old_comment_raw": "@param expFwdId Expected forward page ID.",
    "new_code_raw": "    private boolean findDown(final Get g, final long pageId, final long fwdId, final int lvl)\n        throws IgniteCheckedException {\n        Page page = page(pageId);\n\n        if (page == null)\n            return true; // Page was removed, retry.\n\n        try {\n            for (;;) {\n                // Init args.\n                g.pageId = pageId;\n                g.fwdId = fwdId;\n\n                int res = readPage(page, search, g, lvl, Get.RETRY);\n\n                switch (res) {\n                    case Get.RETRY:\n                        return true;\n\n                    case Get.GO_DOWN:\n                        assert g.pageId != pageId;\n                        assert g.fwdId != fwdId || fwdId == 0;\n\n                        // Go down recursively.\n                        if (findDown(g, g.pageId, g.fwdId, lvl - 1)) {\n                            checkInterrupted();\n\n                            continue; // The child page got splitted, need to reread our page.\n                        }\n\n                        return false;\n\n                    case Get.FOUND:\n                        return false; // We are done.\n\n                    case Get.NOT_FOUND:\n                        g.row = null; // Mark not found result.\n\n                        return false;\n\n                    default:\n                        assert false: res;\n                }\n            }\n        }\n        finally {\n            if (g.canRelease(page, lvl))\n                page.close();\n        }\n    }\n"
  },
  {
    "id": "bauerca_drag_sort_listview-16-Param-2",
    "old_comment_raw": "@param height Height of item at position. If -1, this function calculates this height.",
    "new_code_raw": "    private int getShuffleEdge(int position, int top) {\n\n        final int numHeaders = getHeaderViewsCount();\n        final int numFooters = getFooterViewsCount();\n\n        // shuffle edges are defined between items that can be\n        // dragged; there are N-1 of them if there are N draggable\n        // items.\n\n        if (position <= numHeaders || (position >= getCount() - numFooters)) {\n            return top;\n        }\n\n        int divHeight = getDividerHeight();\n\n        int edge;\n\n        int maxBlankHeight = mFloatViewHeight - mItemHeightCollapsed;\n        int childHeight = getChildHeight(position);\n        int itemHeight = getItemHeight(position);\n\n        // first calculate top of item given that floating View is\n        // centered over src position\n        int otop = top;\n        if (mSecondExpPos <= mSrcPos) {\n            // items are expanded on and/or above the source position\n\n            if (position == mSecondExpPos && mFirstExpPos != mSecondExpPos) {\n                if (position == mSrcPos) {\n                    otop = top + itemHeight - mFloatViewHeight;\n                } else {\n                    int blankHeight = itemHeight - childHeight;\n                    otop = top + blankHeight - maxBlankHeight;\n                }\n            } else if (position > mSecondExpPos && position <= mSrcPos) {\n                otop = top - maxBlankHeight;\n            }\n\n        } else {\n            // items are expanded on and/or below the source position\n\n            if (position > mSrcPos && position <= mFirstExpPos) {\n                otop = top + maxBlankHeight;\n            } else if (position == mSecondExpPos && mFirstExpPos != mSecondExpPos) {\n                int blankHeight = itemHeight - childHeight;\n                otop = top + blankHeight;\n            }\n        }\n\n        // otop is set\n        if (position <= mSrcPos) {\n            edge = otop + (mFloatViewHeight - divHeight - getChildHeight(position - 1)) / 2;\n        } else {\n            edge = otop + (childHeight - divHeight - mFloatViewHeight) / 2;\n        }\n\n        return edge;\n    }\n"
  },
  {
    "id": "CalebFenton_simplify-0-Associations-Param0",
    "old_comment_raw": "@param methodDescriptor",
    "new_code_raw": "    public BuilderMethod getMethod(String methodSignature) {\n        dexifyClassIfNecessary(methodSignature);\n\n        return methodSignatureToMethod.get(methodSignature);\n    }\n\n"
  },
  {
    "id": "apache_ignite-1792-Param-0",
    "old_comment_raw": "@param c Grid configuration.",
    "new_code_raw": "    public static VisorEmailConfiguration from(IgniteConfiguration c) {\n        VisorEmailConfiguration cfg = new VisorEmailConfiguration();\n\n        cfg.smtpHost(getProperty(GG_SMTP_HOST, c.getSmtpHost()));\n        cfg.smtpPort(intValue(GG_SMTP_PORT, c.getSmtpPort()));\n        cfg.smtpUsername(getProperty(GG_SMTP_USERNAME, c.getSmtpUsername()));\n        cfg.adminEmails(getProperty(GG_ADMIN_EMAILS, compactArray(c.getAdminEmails())));\n        cfg.smtpFromEmail(getProperty(GG_SMTP_FROM, c.getSmtpFromEmail()));\n        cfg.smtpSsl(boolValue(GG_SMTP_SSL, c.isSmtpSsl()));\n        cfg.smtpStartTls(boolValue(GG_SMTP_STARTTLS, c.isSmtpStartTls()));\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_ignite-11586-Param-1",
    "old_comment_raw": "@param localCombiner If we have mapper with combiner.",
    "new_code_raw": "    private GridHadoopTaskOutput createOutput(GridHadoopTaskInfo info, boolean locCombiner) throws GridException {\n        switch (info.type()) {\n            case SETUP:\n            case REDUCE:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case MAP:\n                if (locCombiner) {\n                    assert local == null;\n\n                    local = get(job.info(), SHUFFLE_COMBINER_NO_SORTING, false) ?\n                        new GridHadoopHashMultimap(job, mem, get(job.info(), COMBINER_HASHMAP_SIZE, 8 * 1024)):\n                        new GridHadoopSkipList(job, mem, job.sortComparator()); // TODO replace with red-black tree\n\n                    return local.startAdding();\n                }\n\n            default:\n                return createOutput(info);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-3207-Param-1",
    "old_comment_raw": "@param metrics Metrics.",
    "new_code_raw": "    private static byte[] serializeMetrics(UUID nodeId, ClusterNodeMetricsMBean metrics) {\n        assert nodeId != null;\n        assert metrics != null;\n\n        byte[] buf = new byte[16 + DiscoveryMetricsHelper.METRICS_SIZE];\n\n        U.longToBytes(nodeId.getMostSignificantBits(), buf, 0);\n        U.longToBytes(nodeId.getLeastSignificantBits(), buf, 8);\n\n        serialize(buf, 16, metrics);\n\n        return buf;\n    }\n"
  },
  {
    "id": "bytedeco_javacv-10-Param-0",
    "old_comment_raw": "@param image1",
    "new_code_raw": "    public static BufferedImage deepCopy(BufferedImage source) {\n        return Java2DFrameConverter.cloneBufferedImage(source);\n    }\n"
  },
  {
    "id": "zxing_zxing-312-Param-0",
    "old_comment_raw": "@param mode The byte compaction mode i.e. 901 or 924",
    "new_code_raw": "  private static int byteCompaction(int mode, int[] codewords, int codeIndex, StringBuilder result) {\n    if (mode == BYTE_COMPACTION_MODE_LATCH) {\n      // Total number of Byte Compaction characters to be encoded\n      // is not a multiple of 6\n      int count = 0;\n      long value = 0;\n      char[] decodedData = new char[6];\n      int[] byteCompactedCodewords = new int[6];\n      boolean end = false;\n      while ((codeIndex < codewords[0]) && !end) {\n        int code = codewords[codeIndex++];\n        if (code < TEXT_COMPACTION_MODE_LATCH) {\n          byteCompactedCodewords[count] = code;\n          count++;\n          // Base 900\n          value = 900 * value + code;\n        } else {\n          if (code == TEXT_COMPACTION_MODE_LATCH ||\n              code == BYTE_COMPACTION_MODE_LATCH ||\n              code == NUMERIC_COMPACTION_MODE_LATCH ||\n              code == BYTE_COMPACTION_MODE_LATCH_6 ||\n              code == BEGIN_MACRO_PDF417_CONTROL_BLOCK ||\n              code == BEGIN_MACRO_PDF417_OPTIONAL_FIELD ||\n              code == MACRO_PDF417_TERMINATOR) {\n            codeIndex--;\n            end = true;\n          }\n        }\n        if ((count % 5 == 0) && (count > 0)) {\n          // Decode every 5 codewords\n          // Convert to Base 256\n          for (int j = 0; j < 6; ++j) {\n            decodedData[5 - j] = (char) (value % 256);\n            value >>= 8;\n          }\n          result.append(decodedData);\n          count = 0;\n        }\n      }\n      // If Byte Compaction mode is invoked with codeword 901,\n      // the final group of codewords is interpreted directly\n      // as one byte per codeword, without compaction.\n      for (int i = (count / 5) * 5; i < count; i++) {\n        result.append((char) byteCompactedCodewords[i]);\n      }\n\n    } else if (mode == BYTE_COMPACTION_MODE_LATCH_6) {\n      // Total number of Byte Compaction characters to be encoded\n      // is an integer multiple of 6\n      int count = 0;\n      long value = 0;\n      boolean end = false;\n      while (codeIndex < codewords[0] && !end) {\n        int code = codewords[codeIndex++];\n        if (code < TEXT_COMPACTION_MODE_LATCH) {\n          count++;\n          // Base 900\n          value = 900 * value + code;\n        } else {\n          if (code == TEXT_COMPACTION_MODE_LATCH ||\n              code == BYTE_COMPACTION_MODE_LATCH ||\n              code == NUMERIC_COMPACTION_MODE_LATCH ||\n              code == BYTE_COMPACTION_MODE_LATCH_6 ||\n              code == BEGIN_MACRO_PDF417_CONTROL_BLOCK ||\n              code == BEGIN_MACRO_PDF417_OPTIONAL_FIELD ||\n              code == MACRO_PDF417_TERMINATOR) {\n            codeIndex--;\n            end = true;\n          }\n        }\n        if ((count % 5 == 0) && (count > 0)) {\n          // Decode every 5 codewords\n          // Convert to Base 256\n          char[] decodedData = new char[6];\n          for (int j = 0; j < 6; ++j) {\n            decodedData[5 - j] = (char) (value & 0xFF);\n            value >>= 8;\n          }\n          result.append(decodedData);\n        }\n      }\n    }\n    return codeIndex;\n  }\n"
  },
  {
    "id": "openhab_openhab1_addons-970-Param-0",
    "old_comment_raw": "@param name item name",
    "new_code_raw": "\tprivate AbstractNikobusItemConfig parseItem(Item item, String config) throws BindingConfigParseException {\n\n\t\tif (config == null || config.trim().length() == 0) {\n\t\t\tthrow new BindingConfigParseException(\"Invalid config for item \" + item.getName());\n\t\t}\n\n\t\tif (config.matches(BUTTON_CONFIG_PATTERN)) {\n\t\t\treturn new Button(item.getName(), config);\n\t\t}\n\n\t\tif (config.matches(MODULE_CHANNEL_PATTERN)) {\n\t\t\tString address = config.split(\":\")[0];\n\t\t\tint channelNum = Integer.parseInt(config.split(\":\")[1]);\n\t\t\tint group = channelNum > 6 ? 2 : 1;\n\t\t\tString moduleKey = address + \"-\" + group;\n\t\t\tNikobusModule module = getModule(moduleKey);\n\t\t\tif (module == null) {\n\t\t\t\tlog.trace(\"Creating channel group {}\", moduleKey);\n\t\t\t\tmodule = new ModuleChannelGroup(address, group);\n\t\t\t\tallModules.add(module);\n\t\t\t\tmodules.put(moduleKey, module);\n\t\t\t}\n\t\t\treturn ((ModuleChannelGroup) module).addChannel(item.getName(), channelNum, item.getAcceptedCommandTypes());\n\t\t}\n\n\t\tthrow new BindingConfigParseException(\"Could not determine item type from config: \" + config);\n\t}\n"
  },
  {
    "id": "apache_ignite-2324-Param-0",
    "old_comment_raw": "@param path GGFS path.",
    "new_code_raw": "    private Path convert(IgniteFsPath path) {\n        URI uri = fileSys.getUri();\n\n        return new Path(uri.getScheme(), uri.getAuthority(), path.toString());\n    }\n"
  },
  {
    "id": "apache_ignite-13260-Param-0",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "    public CacheObject applyEntryProcessors(CacheObject cacheVal) {\n        Object key = CU.value(this.key, ctx);\n        Object val = CU.value(cacheVal, ctx);\n\n        for (T2<EntryProcessor<Object, Object, Object>, Object[]> t : entryProcessors()) {\n            try {\n                CacheInvokeEntry<Object, Object> invokeEntry = new CacheInvokeEntry<>(ctx, key, val);\n\n                EntryProcessor processor = t.get1();\n\n                processor.process(invokeEntry, t.get2());\n\n                val = invokeEntry.getValue();\n            }\n            catch (Exception ignore) {\n                // No-op.\n            }\n        }\n\n        return ctx.toCacheObject(val);\n// TODO IGNITE-51\n//        if (ctx.portableEnabled())\n//            val = (V)ctx.marshalToPortable(val);\n//\n//        return val;\n    }\n"
  },
  {
    "id": "apache_ignite-7964-Param-2",
    "old_comment_raw": "@param expirationTime Expiration time.",
    "new_code_raw": "    public boolean update(KeyCacheObject key, CacheObject val, GridCacheVersion ver, long expirationTime, boolean rmv)\n        throws IgniteCheckedException {\n        assert desc != null;\n\n        GridH2Row row = desc.createRow(key, val, ver, expirationTime);\n\n        return doUpdate(row, rmv);\n    }\n"
  },
  {
    "id": "androidannotations_androidannotations-10-Param-1",
    "old_comment_raw": "@param t2 the second type",
    "new_code_raw": "\tpublic boolean isSubtype(TypeMirror potentialSubtype, TypeMirror potentialSupertype) {\n\n\t\tif (processingEnv.getTypeUtils().isSubtype(potentialSubtype, potentialSupertype)) {\n\t\t\treturn true;\n\t\t} else {\n\n\t\t\tif (potentialSubtype instanceof DeclaredType) {\n\n\t\t\t\tDeclaredType potentialDeclaredSubtype = (DeclaredType) potentialSubtype;\n\n\t\t\t\tElement potentialSubElement = potentialDeclaredSubtype.asElement();\n\t\t\t\tif (potentialSubElement instanceof TypeElement) {\n\t\t\t\t\tTypeElement potentialSubDeclaredElement = (TypeElement) potentialSubElement;\n\n\t\t\t\t\tTypeMirror superclassTypeMirror = potentialSubDeclaredElement.getSuperclass();\n\n\t\t\t\t\tif (isRootObjectClass(superclassTypeMirror)) {\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (superclassTypeMirror instanceof ErrorType) {\n\n\t\t\t\t\t\t\tErrorType errorType = (ErrorType) superclassTypeMirror;\n\n\t\t\t\t\t\t\tElement errorElement = errorType.asElement();\n\n\t\t\t\t\t\t\tString errorElementSimpleName = errorElement.getSimpleName().toString();\n\t\t\t\t\t\t\tif (errorElementSimpleName.endsWith(GENERATION_SUFFIX)) {\n\t\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tprocessingEnv.getMessager().printMessage(Kind.NOTE, String.format(\"The supertype %s of the potential subElement %s of potential supertype %s is an ErrorType that doesn't end with %s\", errorElement, potentialSubElement, potentialSupertype, GENERATION_SUFFIX));\n\t\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\treturn isSubtype(superclassTypeMirror, potentialSupertype);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tprocessingEnv.getMessager().printMessage(Kind.NOTE, String.format(\"The potential subElement %s of potential supertype %s is not a TypeElement but a %s\", potentialSubElement, potentialSupertype, potentialSubElement.getClass()));\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\n\t\t\t} else {\n\t\t\t\tprocessingEnv.getMessager().printMessage(Kind.NOTE, String.format(\"The potential subtype %s of potential supertype %s is not a DeclaredType but a %s\", potentialSubtype, potentialSupertype, potentialSubtype.getClass()));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n"
  },
  {
    "id": "pockethub_PocketHub-359-Param-0",
    "old_comment_raw": "@param repository",
    "new_code_raw": "    public Issue refreshIssue(Repository repository, int number) throws IOException {\n        Issue issue = service.getIssue(repository.owner().login(), repository.name(), number)\n                .toBlocking()\n                .first();\n        return addIssue(repository, issue);\n    }\n"
  },
  {
    "id": "mybatis_generator-158-Param-0",
    "old_comment_raw": "@param aObject the a object",
    "new_code_raw": "    public static int hash(int seed, Object o) {\n        int result = seed;\n        if (o == null) {\n            result = hash(result, 0);\n        } else if (!isArray(o)) {\n            result = hash(result, o.hashCode());\n        } else {\n            int length = Array.getLength(o);\n            for (int idx = 0; idx < length; ++idx) {\n                Object item = Array.get(o, idx);\n                // recursive call!\n                result = hash(result, item);\n            }\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-4857-Param-1",
    "old_comment_raw": "@param threadId Thread id. If -1, all threads will be checked.",
    "new_code_raw": "    public boolean isLockedByThread(KeyCacheObject key, long threadId) {\n        if (threadId < 0) {\n            for (GridCacheExplicitLockSpan span : pendingExplicit.values()) {\n                GridCacheMvccCandidate cand = span.candidate(key, null);\n\n                if (cand != null && cand.owner())\n                    return true;\n            }\n        }\n        else {\n            GridCacheExplicitLockSpan span = pendingExplicit.get(threadId);\n\n            if (span != null) {\n                GridCacheMvccCandidate cand = span.candidate(key, null);\n\n                return cand != null && cand.owner();\n            }\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1328-Param-1",
    "old_comment_raw": "@param milis miliseconds entered in a positive value",
    "new_code_raw": "    public static XMLGregorianCalendar subtract(XMLGregorianCalendar value, long millis) {\n        return add(value, - millis);\n    }\n"
  },
  {
    "id": "apache_ignite-4116-Param-0",
    "old_comment_raw": "@param e Entry to verify.",
    "new_code_raw": "    boolean isAll(CacheEntry<K, V> e, boolean noNulls) {\n        CacheFlag[] f = cctx.forceLocalRead();\n\n        try {\n            return F.isAll(e, entryFilter(noNulls));\n        }\n        finally {\n            cctx.forceFlags(f);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-249-Associations-Param0",
    "old_comment_raw": "@param buf String buffer.",
    "new_code_raw": "    private StringBuilder addFlag(StringBuilder sb, int flags, int mask, String flagName) {\n        if ((flags & mask) > 0)\n            sb.append(sb.length() > 0 ? \",\" : \"\").append(flagName);\n\n        return sb;\n    }\n\n"
  },
  {
    "id": "apache_ignite-6775-Param-0",
    "old_comment_raw": "@param msg Message to send.",
    "new_code_raw": "    @Nullable private Integer sendMessageDirectly(TcpDiscoveryAbstractMessage msg, InetSocketAddress addr)\n        throws IgniteSpiException {\n        assert msg != null;\n        assert addr != null;\n\n        Collection<Throwable> errs = null;\n\n        long ackTimeout0 = spi.ackTimeout;\n\n        int connectAttempts = 1;\n\n        boolean joinReqSent = false;\n\n        UUID locNodeId = getLocalNodeId();\n\n        for (int i = 0; i < spi.reconCnt; i++) {\n            // Need to set to false on each new iteration,\n            // since remote node may leave in the middle of the first iteration.\n            joinReqSent = false;\n\n            boolean openSock = false;\n\n            Socket sock = null;\n\n            try {\n                long tstamp = U.currentTimeMillis();\n\n                sock = spi.openSocket(addr);\n\n                openSock = true;\n\n                // Handshake.\n                spi.writeToSocket(sock, new TcpDiscoveryHandshakeRequest(locNodeId));\n\n                TcpDiscoveryHandshakeResponse res = spi.readMessage(sock, null, ackTimeout0);\n\n                if (locNodeId.equals(res.creatorNodeId())) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Handshake response from local node: \" + res);\n\n                    break;\n                }\n\n                spi.stats.onClientSocketInitialized(U.currentTimeMillis() - tstamp);\n\n                // Send message.\n                tstamp = U.currentTimeMillis();\n\n                spi.writeToSocket(sock, msg);\n\n                spi.stats.onMessageSent(msg, U.currentTimeMillis() - tstamp);\n\n                if (debugMode)\n                    debugLog(\"Message has been sent directly to address [msg=\" + msg + \", addr=\" + addr +\n                        \", rmtNodeId=\" + res.creatorNodeId() + ']');\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Message has been sent directly to address [msg=\" + msg + \", addr=\" + addr +\n                        \", rmtNodeId=\" + res.creatorNodeId() + ']');\n\n                // Connection has been established, but\n                // join request may not be unmarshalled on remote host.\n                // E.g. due to class not found issue.\n                joinReqSent = msg instanceof TcpDiscoveryJoinRequestMessage;\n\n                return spi.readReceipt(sock, ackTimeout0);\n            }\n            catch (ClassCastException e) {\n                // This issue is rarely reproducible on AmazonEC2, but never\n                // on dedicated machines.\n                if (log.isDebugEnabled())\n                    U.error(log, \"Class cast exception on direct send: \" + addr, e);\n\n                onException(\"Class cast exception on direct send: \" + addr, e);\n\n                if (errs == null)\n                    errs = new ArrayList<>();\n\n                errs.add(e);\n            }\n            catch (IOException | IgniteCheckedException e) {\n                if (log.isDebugEnabled())\n                    log.error(\"Exception on direct send: \" + e.getMessage(), e);\n\n                onException(\"Exception on direct send: \" + e.getMessage(), e);\n\n                if (errs == null)\n                    errs = new ArrayList<>();\n\n                errs.add(e);\n\n                if (!openSock) {\n                    // Reconnect for the second time, if connection is not established.\n                    if (connectAttempts < 2) {\n                        connectAttempts++;\n\n                        continue;\n                    }\n\n                    break; // Don't retry if we can not establish connection.\n                }\n\n                if (e instanceof SocketTimeoutException || X.hasCause(e, SocketTimeoutException.class)) {\n                    ackTimeout0 *= 2;\n\n                    if (!checkAckTimeout(ackTimeout0))\n                        break;\n                }\n            }\n            finally {\n                U.closeQuiet(sock);\n            }\n        }\n\n        if (joinReqSent) {\n            if (log.isDebugEnabled())\n                log.debug(\"Join request has been sent, but receipt has not been read (returning RES_WAIT).\");\n\n            // Topology will not include this node,\n            // however, warning on timed out join will be output.\n            return RES_OK;\n        }\n\n        throw new IgniteSpiException(\n            \"Failed to send message to address [addr=\" + addr + \", msg=\" + msg + ']',\n            U.exceptionWithSuppressed(\"Failed to send message to address \" +\n                \"[addr=\" + addr + \", msg=\" + msg + ']', errs));\n    }\n"
  },
  {
    "id": "Netflix_Hystrix-355-Param-0",
    "old_comment_raw": "@param executable  HystrixExecutable",
    "new_code_raw": "    public static Object execute(HystrixInvokable invokable, ExecutionType executionType, MetaHolder metaHolder) throws RuntimeException {\n        Validate.notNull(invokable);\n        Validate.notNull(metaHolder);\n\n        switch (executionType) {\n            case SYNCHRONOUS: {\n                return castToExecutable(invokable, executionType).execute();\n            }\n            case ASYNCHRONOUS: {\n                HystrixExecutable executable = castToExecutable(invokable, executionType);\n                if (metaHolder.hasFallbackMethodCommand()\n                        && ExecutionType.ASYNCHRONOUS == metaHolder.getFallbackExecutionType()) {\n                    return new FutureDecorator(executable.queue());\n                }\n                return executable.queue();\n            }\n            case OBSERVABLE: {\n                HystrixObservable observable = castToObservable(invokable);\n                return ObservableExecutionMode.EAGER == metaHolder.getObservableExecutionMode() ? observable.observe() : observable.toObservable();\n            }\n            default:\n                throw new RuntimeException(\"unsupported execution type: \" + executionType);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-4858-Param-0",
    "old_comment_raw": "@param threadId Thread id.",
    "new_code_raw": "    @Nullable public GridCacheMvccCandidate explicitLock(long threadId, KeyCacheObject key) {\n        if (threadId < 0)\n            return explicitLock(key, null);\n        else {\n            GridCacheExplicitLockSpan span = pendingExplicit.get(threadId);\n\n            return span == null ? null : span.candidate(key, null);\n        }\n    }\n"
  },
  {
    "id": "purplecabbage_phonegap_plugins-32-Param-2",
    "old_comment_raw": "@param callbackId The callback id used when calling back into JavaScript",
    "new_code_raw": "    public boolean execute(String action, JSONArray data, CallbackContext callbackContext) {\n        boolean actionValid = true;\n        if (NOTIFY.equals(action)) {\n            try {\n                String tag = data.getString(0);\n                String title = data.getString(1);\n                String body = data.getString(2);\n                String flag = data.getString(3);\n                Log.d(\"NotificationPlugin\", \"Notification: \" + tag + \", \" + title + \", \" + body);\n                int notificationFlag = getFlagValue(flag);\n                showNotification(tag, title, body, notificationFlag);\n            } catch (JSONException jsonEx) {\n                Log.d(\"NotificationPlugin\", \"Got JSON Exception \"\n                        + jsonEx.getMessage());\n                actionValid = false;\n            }\n        } else if (CLEAR.equals(action)){\n            try {\n                String tag = data.getString(0);\n                Log.d(\"NotificationPlugin\", \"Notification cancel: \" + tag);\n                clearNotification(tag);\n            } catch (JSONException jsonEx) {\n                Log.d(\"NotificationPlugin\", \"Got JSON Exception \" + jsonEx.getMessage());\n                actionValid = false;\n            }\n        } else {\n            actionValid = false;\n            Log.d(\"NotificationPlugin\", \"Invalid action : \"+action+\" passed\");\n        }\n        return actionValid;\n    }\n"
  },
  {
    "id": "apache_ignite-2225-Param-0",
    "old_comment_raw": "@param file file for digest calculations.",
    "new_code_raw": "    private static boolean addFileDigest(File file, MessageDigest digest, @Nullable IgniteLogger log) {\n        if (!file.isFile()) {\n            U.error(log, \"Failed to add file to directory digest (will not check MD5 hash): \" + file);\n\n            return false;\n        }\n\n        InputStream in = null;\n\n        try {\n            in = new BufferedInputStream(new FileInputStream(file));\n\n            byte[] buf = new byte[1024];\n\n            int read = in.read(buf, 0, 1024);\n\n            while (read > -1) {\n                digest.update(buf, 0, read);\n\n                read = in.read(buf, 0, 1024);\n            }\n        }\n        catch (IOException e) {\n            U.error(log, \"Failed to add file to directory digest (will not check MD5 hash): \" + file, e);\n\n            return false;\n        }\n        finally {\n            U.closeQuiet(in);\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "justinsb_android-libcore-713-Associations-Param0",
    "old_comment_raw": "@param dest the file containing the new name.",
    "new_code_raw": "    public boolean renameTo(File newPath) {\n        if (path.isEmpty() || newPath.path.isEmpty()) {\n            return false;\n        }\n        SecurityManager security = System.getSecurityManager();\n        if (security != null) {\n            security.checkWrite(path);\n            security.checkWrite(newPath.path);\n        }\n        return renameToImpl(absolutePath, newPath.absolutePath);\n    }\n\n"
  },
  {
    "id": "Netflix_Hystrix-1-Param-3",
    "old_comment_raw": "@param properties Pass-thru to  HystrixMetricsPublisher#getMetricsPublisherForThreadPool implementation",
    "new_code_raw": "    public static HystrixMetricsPublisherThreadPool createOrRetrievePublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) {\n        // attempt to retrieve from cache first\n        HystrixMetricsPublisherThreadPool publisher = threadPoolPublishers.get(threadPoolKey.name());\n        if (publisher != null) {\n            return publisher;\n        }\n        // it doesn't exist so we need to create it\n        publisher = HystrixPlugins.getInstance().getMetricsPublisher().getMetricsPublisherForThreadPool(threadPoolKey, metrics, properties);\n        // attempt to store it (race other threads)\n        HystrixMetricsPublisherThreadPool existing = threadPoolPublishers.putIfAbsent(threadPoolKey.name(), publisher);\n        if (existing == null) {\n            // we won the thread-race to store the instance we created so initialize it\n            publisher.initialize();\n            // done registering, return instance that got cached\n            return publisher;\n        } else {\n            // we lost so return 'existing' and let the one we created be garbage collected\n            // without calling initialize() on it\n            return existing;\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-796-Param-1",
    "old_comment_raw": "@param integer",
    "new_code_raw": "  public Long decrBy(final byte[] key, final long decrement) {\n    checkIsInMultiOrPipeline();\n    client.decrBy(key, decrement);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "apache_ignite-12346-Param-1",
    "old_comment_raw": "@param pageMem Page memory.",
    "new_code_raw": "    protected ReuseList createReuseList(int cacheId, PageMemory pageMem, long rootId, boolean initNew)\n        throws IgniteCheckedException {\n        return null;\n    }\n"
  },
  {
    "id": "apache_ignite-12021-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static CacheQueue<String> initializeQueue(Ignite ignite, String queueName) throws IgniteCheckedException {\n        // Initialize new FIFO queue.\n        CacheQueue<String> queue = ignite.cache(CACHE_NAME).dataStructures().queue(queueName, 0, false, true);\n\n        // Initialize queue items.\n        // We will be use blocking operation and queue size must be appropriated.\n        for (int i = 0; i < ignite.cluster().nodes().size() * RETRIES * 2; i++)\n            queue.put(Integer.toString(i));\n\n        System.out.println(\"Queue size after initializing: \" + queue.size());\n\n        return queue;\n    }\n"
  },
  {
    "id": "apache_ignite-3380-Param-0",
    "old_comment_raw": "@param nodeId Node ID.",
    "new_code_raw": "    private static byte[] serializeMetrics(UUID nodeId, ClusterMetrics metrics) {\n        assert nodeId != null;\n        assert metrics != null;\n\n        byte[] buf = new byte[16 + ClusterMetricsSnapshot.METRICS_SIZE];\n\n        U.longToBytes(nodeId.getMostSignificantBits(), buf, 0);\n        U.longToBytes(nodeId.getLeastSignificantBits(), buf, 8);\n\n        ClusterMetricsSnapshot.serialize(buf, 16, metrics);\n\n        return buf;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-954-Param-1",
    "old_comment_raw": "@param settings",
    "new_code_raw": "\tprivate Object getValue(ByteBuffer byteBuffer, TelegramValue telegramValue) {\n\n\t\tString type = telegramValue.getType().toLowerCase();\n\t\tint pos = telegramValue.getPos() != null ? telegramValue.getPos() : -1;\n\n\t\tObject value = null;\n\n\t\t// requested pos is greater as whole buffer\n\t\tif(pos > byteBuffer.position()) {\n\t\t\tlogger.warn(\"eBus buffer pos error! Can happen ...\");\n\t\t}\n\n\t\t// replace similar data types\n\t\tif(type.equals(\"uint\"))\n\t\t\ttype = \"word\";\n\t\tif(type.equals(\"byte\"))\n\t\t\ttype = \"uchar\";\n\n\t\tbyte[] bytes = null;\n\t\tif(type.equals(\"data2b\") || type.equals(\"data2c\") || type.equals(\"word\")) {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos), byteBuffer.get(pos-1)};\n\t\t} else {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos-1)};\n\t\t}\n\n\t\tif(type.equals(\"bit\")) {\n\t\t\tint bit = telegramValue.getBit();\n\t\t\tvalue = bytes[0];\n\n\t\t\tboolean isSet = ((Byte)value >> bit& 0x1) == 1;\n\t\t\tvalue = isSet;\n\n\t\t} else {\n\t\t\tvalue = NumberUtils.toBigDecimal(EBusCodecUtils.decode(type, bytes, telegramValue.getReplaceValue()));\n\t\t}\n\n\t\t// if BigDecimal check for min, max and replace value\n\t\tif(value instanceof BigDecimal) {\n\t\t\tBigDecimal b = (BigDecimal)value;\n\n\t\t\t// multiply before check min and max\n\t\t\tif(b != null && telegramValue.getFactor() != null) {\n\t\t\t\tlogger.trace(\"Value multiplied ...\");\n\t\t\t\tvalue = b = b.multiply(telegramValue.getFactor());\n\t\t\t}\n\n\t\t\t// value is below min value, return null\n\t\t\tif(telegramValue.getMin() != null && b != null && b.compareTo(telegramValue.getMin()) == -1) {\n\t\t\t\tlogger.trace(\"Minimal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\n\t\t\t\t// value is above max value, return null\n\t\t\t} else if (telegramValue.getMax() != null && b != null && b.compareTo(telegramValue.getMax()) == 1) {\n\t\t\t\tlogger.trace(\"Maximal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\t\t\t}\n\n\t\t}\n\n\t\treturn value;\n\t}\n"
  },
  {
    "id": "code_troopers_android_betterpickers-12-Param-2",
    "old_comment_raw": "@param setSelected Whether to set the given time as selected",
    "new_code_raw": "    public boolean goTo(CalendarDay day, boolean animate, boolean setSelected, boolean forceScroll) {\n\n        // Set the selected day\n        if (setSelected) {\n            mSelectedDay.set(day);\n        }\n\n        mTempDay.set(day);\n        final int position = (day.year - mController.getMinYear())\n                * SimpleMonthAdapter.MONTHS_IN_YEAR + day.month;\n\n        View child;\n        int i = 0;\n        int top = 0;\n        // Find a child that's completely in the view\n        do {\n            child = getChildAt(i++);\n            if (child == null) {\n                break;\n            }\n            top = child.getTop();\n            if (Log.isLoggable(TAG, Log.DEBUG)) {\n                Log.d(TAG, \"child at \" + (i - 1) + \" has top \" + top);\n            }\n        } while (top < 0);\n\n        // Compute the first and last position visible\n        int selectedPosition;\n        if (child != null) {\n            selectedPosition = getPositionForView(child);\n        } else {\n            selectedPosition = 0;\n        }\n\n        if (setSelected) {\n            mAdapter.setSelectedDay(mSelectedDay);\n        }\n\n        if (Log.isLoggable(TAG, Log.DEBUG)) {\n            Log.d(TAG, \"GoTo position \" + position);\n        }\n        // Check if the selected day is now outside of our visible range\n        // and if so scroll to the month that contains it\n        if (position != selectedPosition || forceScroll) {\n            setMonthDisplayed(mTempDay);\n            mPreviousScrollState = OnScrollListener.SCROLL_STATE_FLING;\n            if (animate && Build.VERSION.SDK_INT >= Build.VERSION_CODES.HONEYCOMB) {\n                smoothScrollToPositionFromTop(\n                        position, LIST_TOP_OFFSET, GOTO_SCROLL_DURATION);\n                return true;\n            } else {\n                postSetSelection(position);\n            }\n        } else if (setSelected) {\n            setMonthDisplayed(mSelectedDay);\n        }\n        return false;\n    }\n"
  },
  {
    "id": "Angel-ML_angel-37-Associations-Param0",
    "old_comment_raw": "@param msg request",
    "new_code_raw": "  private boolean needAsync(TransportMethod method) {\n    return !(method == TransportMethod.GET_CLOCKS || method == TransportMethod.UPDATE_CLOCK);\n  }\n\n"
  },
  {
    "id": "apache_ignite-2317-Param-1",
    "old_comment_raw": "@param blockId Block ID.",
    "new_code_raw": "    private GridGgfsBlockKey blockKey(IgniteFsPath path, long blockId) throws Exception {\n        GridGgfsEx ggfs0 = (GridGgfsEx)grid(0).fileSystem(GGFS_NAME);\n\n        IgniteUuid fileId = ggfs0.context().meta().fileId(path);\n\n        return new GridGgfsBlockKey(fileId, null, true, blockId);\n    }\n"
  },
  {
    "id": "gephi_gephi-406-Param-0",
    "old_comment_raw": "@param pStruct",
    "new_code_raw": "    public double finalQ(int[] struct, double[] degrees, HierarchicalUndirectedGraph graph, AttributeModel attributeModel) {\n        AttributeTable nodeTable = attributeModel.getNodeTable();\n        AttributeColumn modCol = nodeTable.getColumn(MODULARITY_CLASS);\n        if (modCol == null) {\n            modCol = nodeTable.addColumn(MODULARITY_CLASS, \"Modularity Class\", AttributeType.INT, AttributeOrigin.COMPUTED, new Integer(0));\n        }\n\n        double res = 0;\n        double[] internal = new double[degrees.length];\n        for (Node n : graph.getNodes()) {\n            int n_index = structure.map.get(n);\n            AttributeRow row = (AttributeRow) n.getNodeData().getAttributes();\n            row.setValue(modCol, struct[n_index]);\n            for (Node neighbor : graph.getNeighbors(n)) {\n                if (n == neighbor) {\n                    continue;\n                }\n                int neigh_index = structure.map.get(neighbor);\n                if (struct[neigh_index] == struct[n_index]) {\n                    internal[struct[neigh_index]]++;\n                }\n            }\n        }\n        for (int i = 0; i < degrees.length; i++) {\n            internal[i] /= 2.0;\n            res += (internal[i] / graph.getEdgeCount()) - Math.pow(degrees[i] / (2 * graph.getEdgeCount()), 2);\n        }\n        return res;\n    }\n"
  },
  {
    "id": "google_tink-112-Param-0",
    "old_comment_raw": "@param curve the elliptic curve",
    "new_code_raw": "  public static byte[] ecPointEncode(EllipticCurve curve, PointFormatEnum format, ECPoint point)\n      throws GeneralSecurityException {\n    EcUtil.checkPointOnCurve(point, curve);\n    int coordinateSize = EcUtil.fieldSizeInBytes(curve);\n    switch (format) {\n      case UNCOMPRESSED:\n        {\n          byte[] encoded = new byte[2 * coordinateSize + 1];\n          byte[] x = point.getAffineX().toByteArray();\n          byte[] y = point.getAffineY().toByteArray();\n          // Order of System.arraycopy is important because x,y can have leading 0's.\n          System.arraycopy(y, 0, encoded, 1 + 2 * coordinateSize - y.length, y.length);\n          System.arraycopy(x, 0, encoded, 1 + coordinateSize - x.length, x.length);\n          encoded[0] = 4;\n          return encoded;\n        }\n      case COMPRESSED:\n        {\n          byte[] encoded = new byte[coordinateSize + 1];\n          byte[] x = point.getAffineX().toByteArray();\n          System.arraycopy(x, 0, encoded, 1 + coordinateSize - x.length, x.length);\n          encoded[0] = (byte) (point.getAffineY().testBit(0) ? 3 : 2);\n          return encoded;\n        }\n      default:\n        throw new GeneralSecurityException(\"invalid format:\" + format);\n    }\n  }\n"
  },
  {
    "id": "xetorthio_jedis-780-Param-1",
    "old_comment_raw": "@param string",
    "new_code_raw": "    public Long rpush(final byte[] key, final byte[]... strings) {\n        checkIsInMulti();\n        client.rpush(key, strings);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-857-Param-0",
    "old_comment_raw": "@param bridge Initialized Velux bridge handler.",
    "new_code_raw": "    public Channel retrieve(VeluxBridge bridge) {\n        logger.trace(\"retrieve() called.\");\n\n        if (this.channel == null) {\n            this.channel = new Channel();\n        }\n\n        GetLANConfig bcp = bridge.bridgeAPI().getLANConfig();\n        if (bridge.bridgeCommunicate(bcp) && bcp.isCommunicationSuccessful()) {\n            logger.trace(\"retrieve() found successfully configuration {}.\", bcp.getLANConfig());\n            channel.openHABipAddress = new StringType(bcp.getLANConfig().getIpAddress());\n            channel.openHABsubnetMask = new StringType(bcp.getLANConfig().getSubnetMask());\n            channel.openHABdefaultGW = new StringType(bcp.getLANConfig().getDefaultGW());\n            channel.openHABenabledDHCP = bcp.getLANConfig().getDHCP() ? OnOffType.ON : OnOffType.OFF;\n            channel.isRetrieved = true;\n            return channel;\n        } else {\n            logger.trace(\"retrieve() finished with failure.\");\n            return null;\n        }\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-782-Param-1",
    "old_comment_raw": "@param contributor",
    "new_code_raw": "    public AvatarLoader bind(final ImageView view, final SearchUser user) {\n        if (user == null)\n            return setImage(loadingAvatar, view);\n\n        final String avatarUrl = getAvatarUrl(user.getGravatarId());\n\n        if (TextUtils.isEmpty(avatarUrl))\n            return setImage(loadingAvatar, view);\n\n        final String userId = user.getId();\n\n        BitmapDrawable loadedImage = loaded.get(userId);\n        if (loadedImage != null)\n            return setImage(loadedImage, view);\n\n        setImage(loadingAvatar, view, userId);\n        fetchAvatarTask(avatarUrl, userId, view).execute();\n\n        return this;\n    }\n"
  },
  {
    "id": "mockito_mockito-107-Param-0",
    "old_comment_raw": "@param matcher decides whether argument matches",
    "new_code_raw": "    public static byte byteThat(Matcher<Byte> matcher) {\n        return reportMatcher(matcher).returnZero();\n    }\n"
  },
  {
    "id": "apache_ignite-13277-Param-1",
    "old_comment_raw": "@param cacheName Cache name.",
    "new_code_raw": "    public static VisorCache from(Ignite ignite, GridCache c, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<GridCacheEntryEx> set = ca.map().entries0();\n\n        long memSz = 0;\n\n        Iterator<GridCacheEntryEx> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-5697-Param-2",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, long topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!U.hasNearCache(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture<K, V> txFut = null;\n\n        Collection<GridCacheMvccCandidate<K>> cands = null;\n\n        ReaderId<K, V> reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId<>(nodeId, msgId);\n\n                ReaderId<K, V>[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate<K> c : cands) {\n                    IgniteInternalTx<K, V> tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId<K, V> reader0 = reader;\n\n                txFut.listen(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        cctx.kernalContext().closure().runLocalSafe(new GridPlainRunnable() {\n                            @Override public void run() {\n                                synchronized (this) {\n                                    // Release memory.\n                                    reader0.resetTxFuture();\n                                }\n                            }\n                        });\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-804-Param-1",
    "old_comment_raw": "@param value",
    "new_code_raw": "  public Double incrByFloat(final String key, final double increment) {\n    checkIsInMultiOrPipeline();\n    client.incrByFloat(key, increment);\n    String dval = client.getBulkReply();\n    return (dval != null ? new Double(dval) : null);\n  }\n"
  },
  {
    "id": "apache_ignite-4397-Param-2",
    "old_comment_raw": "@param recursive Recursive flag.",
    "new_code_raw": "    public boolean deleteDual(final Igfs fs, final IgfsPath path, final boolean recursive)\n        throws IgniteCheckedException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert path != null;\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<IgfsPath, IgfsFileInfo> infos) throws Exception {\n                        IgfsFileInfo info = infos.get(path);\n\n                        if (info == null)\n                            return false; // File doesn't exist in the secondary file system.\n\n                        if (!fs.delete(path, recursive))\n                            return false; // Delete failed remotely.\n\n                        if (path.parent() != null) {\n                            assert infos.containsKey(path.parent());\n\n                            softDeleteNonTx(infos.get(path.parent()).id(), path.name(), info.id());\n                        }\n                        else {\n                            assert ROOT_ID.equals(info.id());\n\n                            softDeleteNonTx(null, path.name(), info.id());\n                        }\n\n                        // Update the deleted file info with path information for delete worker.\n                        id2InfoPrj.invoke(info.id(), new UpdatePath(path));\n\n                        return true; // No additional handling is required.\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Path delete in DUAL mode failed [path=\" + path + \", recursive=\" + recursive + ']',\n                            err);\n\n                        throw new IgniteCheckedException(\"Failed to delete the path due to secondary file system exception: \",\n                            err);\n                    }\n                };\n\n                Boolean res = synchronizeAndExecute(task, fs, false, Collections.singleton(TRASH_ID), path);\n\n                delWorker.signal();\n\n                return res;\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to delete in DUAL mode because Grid is stopping: \" + path);\n    }\n"
  },
  {
    "id": "xetorthio_jedis-787-Param-1",
    "old_comment_raw": "@param member",
    "new_code_raw": "    public Long srem(final String key, final String... members) {\n        checkIsInMulti();\n        client.srem(key, members);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "haifengl_smile-114-Param-0",
    "old_comment_raw": "@param Ap the preconditioned matrix of A.",
    "new_code_raw": "    public static double solve(Matrix A, Preconditioner Ap, double[] b, double[] x, double tol, int itol, int maxIter) {\n        if (tol <= 0.0) {\n            throw new IllegalArgumentException(\"Invalid tolerance: \" + tol);\n        }\n\n        if (maxIter <= 0) {\n            throw new IllegalArgumentException(\"Invalid maximum number of iterations: \" + maxIter);\n        }\n\n        if (itol < 1 || itol > 4) {\n            throw new IllegalArgumentException(String.format(\"Illegal itol: %d\", itol));\n        }\n\n        double err = 0.0;\n        double ak, akden, bk, bkden = 1.0, bknum, bnrm, dxnrm, xnrm, zm1nrm, znrm = 0.0;\n        int j, n = b.length;\n\n        double[] p = new double[n];\n        double[] pp = new double[n];\n        double[] r = new double[n];\n        double[] rr = new double[n];\n        double[] z = new double[n];\n        double[] zz = new double[n];\n\n        A.ax(x, r);\n        for (j = 0; j < n; j++) {\n            r[j] = b[j] - r[j];\n            rr[j] = r[j];\n        }\n\n        if (itol == 1) {\n            bnrm = snorm(b, itol);\n            Ap.asolve(r, z);\n        } else if (itol == 2) {\n            Ap.asolve(b, z);\n            bnrm = snorm(z, itol);\n            Ap.asolve(r, z);\n        } else if (itol == 3 || itol == 4) {\n            Ap.asolve(b, z);\n            bnrm = snorm(z, itol);\n            Ap.asolve(r, z);\n            znrm = snorm(z, itol);\n        } else {\n            throw new IllegalArgumentException(String.format(\"Illegal itol: %d\", itol));\n        }\n\n        for (int iter = 1; iter <= maxIter; iter++) {\n            Ap.asolve(rr, zz);\n            for (bknum = 0.0, j = 0; j < n; j++) {\n                bknum += z[j] * rr[j];\n            }\n            if (iter == 1) {\n                for (j = 0; j < n; j++) {\n                    p[j] = z[j];\n                    pp[j] = zz[j];\n                }\n            } else {\n                bk = bknum / bkden;\n                for (j = 0; j < n; j++) {\n                    p[j] = bk * p[j] + z[j];\n                    pp[j] = bk * pp[j] + zz[j];\n                }\n            }\n            bkden = bknum;\n            A.ax(p, z);\n            for (akden = 0.0, j = 0; j < n; j++) {\n                akden += z[j] * pp[j];\n            }\n            ak = bknum / akden;\n            A.atx(pp, zz);\n            for (j = 0; j < n; j++) {\n                x[j] += ak * p[j];\n                r[j] -= ak * z[j];\n                rr[j] -= ak * zz[j];\n            }\n            Ap.asolve(r, z);\n            if (itol == 1) {\n                err = snorm(r, itol) / bnrm;\n            } else if (itol == 2) {\n                err = snorm(z, itol) / bnrm;\n            } else if (itol == 3 || itol == 4) {\n                zm1nrm = znrm;\n                znrm = snorm(z, itol);\n                if (Math.abs(zm1nrm - znrm) > Math.EPSILON * znrm) {\n                    dxnrm = Math.abs(ak) * snorm(p, itol);\n                    err = znrm / Math.abs(zm1nrm - znrm) * dxnrm;\n                } else {\n                    err = znrm / bnrm;\n                    continue;\n                }\n                xnrm = snorm(x, itol);\n                if (err <= 0.5 * xnrm) {\n                    err /= xnrm;\n                } else {\n                    err = znrm / bnrm;\n                    continue;\n                }\n            }\n\n            if (iter % 10 == 0) {\n                logger.info(String.format(\"BCG: the error after %3d iterations: %.5g\", iter, err));\n            }\n\n            if (err <= tol) {\n                logger.info(String.format(\"BCG: the error after %3d iterations: %.5g\", iter, err));\n                break;\n            }\n        }\n\n        return err;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-509-Param-0",
    "old_comment_raw": "@param weightingMap all parameters influencing the weighting. E.g. parameters coming via GHRequest.getHints or directly via \"&api.xy=\" from the URL of the web UI",
    "new_code_raw": "    public Weighting createWeighting( WeightingMap wMap, FlagEncoder encoder )\n    {\n        String weighting = wMap.getWeighting();\n        Weighting result;\n\n        if (\"shortest\".equalsIgnoreCase(weighting))\n        {\n            result = new ShortestWeighting();\n        } else if (\"fastest\".equalsIgnoreCase(weighting) || weighting.isEmpty())\n        {\n            if (encoder.supports(PriorityWeighting.class))\n                result = new PriorityWeighting(encoder);\n            else\n                result = new FastestWeighting(encoder);\n        } else\n        {\n            throw new UnsupportedOperationException(\"weighting \" + weighting + \" not supported\");\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-4416-Param-0",
    "old_comment_raw": "@param path GGFS path.",
    "new_code_raw": "    private Path convert(IgfsPath path) {\n        URI uri = fileSys.getUri();\n\n        return new Path(uri.getScheme(), uri.getAuthority(), path.toString());\n    }\n"
  },
  {
    "id": "eclipse_elk-137-Associations-Param2",
    "old_comment_raw": "@param nodeLabelInsets the additional insets for node labels on this node",
    "new_code_raw": "    public static ElkPadding calculateRequiredNodeLabelSpace(final NodeAdapter<?> node,\n            final double labelSpacing, final ElkPadding nodeLabelPadding,\n            final Map<LabelLocation, LabelGroup> labelGroupsBoundingBoxes, final ElkPadding padding) {\n\n        // Check if there are any labels\n        if (!node.getLabels().iterator().hasNext()) {\n            return padding;\n        }\n        \n        // Retrieve the node's label placement policy\n        final Set<NodeLabelPlacement> nodeLabelPlacement = node.getProperty(CoreOptions.NODE_LABELS_PLACEMENT);\n        final LabelLocation nodeLabelLocation = LabelLocation.fromNodeLabelPlacement(nodeLabelPlacement);\n        \n        // Compute a bounding box for each location where labels should be placed.\n        // The size is calculated from the size of all labels stacked vertically at that location.\n        for (final LabelAdapter<?> label : node.getLabels()) {\n            LabelLocation labelPlacement =\n                    LabelLocation.fromNodeLabelPlacement(label.getProperty(CoreOptions.NODE_LABELS_PLACEMENT));\n            \n            // If no valid placement is set on the label, use the node's placement policy.\n            if (labelPlacement == LabelLocation.UNDEFINED) {\n                labelPlacement = nodeLabelLocation;\n            }\n            \n            // Save the location of this label in its id field for later use.\n            label.setVolatileId(labelPlacement.ordinal());\n            \n            // Create or retrieve the label group for the current label.\n            final Rectangle boundingBox = retrieveLabelGroupsBoundingBox(labelGroupsBoundingBoxes, labelPlacement);\n            boundingBox.width = Math.max(boundingBox.width, label.getSize().x);\n            boundingBox.height += label.getSize().y + labelSpacing;\n        }\n        \n        // We need to count different label placement boxes towards different kinds of padding, depending on whether\n        // or not H_PRIORITY is set on the node itself (see H_PRIORITY documentation)\n        boolean hPrio = nodeLabelPlacement.contains(NodeLabelPlacement.H_PRIORITY);\n        \n        // Calculate the node label space required inside the node (only label groups on the inside\n        // are relevant here).\n        for (final Entry<LabelLocation, LabelGroup> entry : labelGroupsBoundingBoxes.entrySet()) {\n            final Rectangle boundingBox = entry.getValue();\n            \n            // From each existing label group, remove the last superfluous label spacing\n            // (the mere existence of a label group implies that it contains at least one label)\n            boundingBox.height -= labelSpacing;\n            switch (entry.getKey()) {\n            case IN_T_L:\n                if (hPrio) {\n                    padding.left = Math.max(\n                            padding.left,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                } else {\n                    padding.top = Math.max(\n                            padding.top,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                }\n                break;\n                \n            case IN_T_C:\n                padding.top = Math.max(\n                        padding.top,\n                        boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                break;\n                \n            case IN_T_R:\n                if (hPrio) {\n                    padding.right = Math.max(\n                            padding.right,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                } else {\n                    padding.top = Math.max(\n                            padding.top,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                }\n                break;\n                \n            case IN_C_L:\n                padding.left = Math.max(\n                        padding.left,\n                        boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                break;\n                \n            case IN_C_R:\n                padding.right = Math.max(\n                        padding.right,\n                        boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                break;\n                \n            case IN_B_L:\n                if (hPrio) {\n                    padding.left = Math.max(\n                            padding.left,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                } else {\n                    padding.bottom = Math.max(\n                            padding.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                }\n                break;\n                \n            case IN_B_C:\n                padding.bottom = Math.max(\n                        padding.bottom,\n                        boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                break;\n                \n            case IN_B_R:\n                if (hPrio) {\n                    padding.right = Math.max(\n                            padding.right,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                } else {\n                    padding.bottom = Math.max(\n                            padding.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                }\n                break;\n                \n            default:\n                // In all other cases, no specific action is required\n            }\n        }\n\n        // Add node label padding that aren't set yet\n        // This happens if e.g. a top inset is set but no top label is present\n        padding.top    = Math.max(padding.top, nodeLabelPadding.top);\n        padding.left   = Math.max(padding.left, nodeLabelPadding.left);\n        padding.right  = Math.max(padding.right, nodeLabelPadding.right);\n        padding.bottom = Math.max(padding.bottom, nodeLabelPadding.bottom);\n\n        return padding;\n    }\n\n"
  },
  {
    "id": "apache_ignite-7886-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    public boolean update(CacheObject key, CacheObject val, long expirationTime, boolean rmv)\n        throws IgniteCheckedException {\n        assert desc != null;\n\n        GridH2Row row = desc.createRow(key, val, expirationTime);\n\n        return doUpdate(row, rmv);\n    }\n"
  },
  {
    "id": "apache_ignite-13590-Param-0",
    "old_comment_raw": "@param buf String buffer.",
    "new_code_raw": "    private StringBuilder addFlag(StringBuilder sb, int flags, int mask, String flagName) {\n        if ((flags & mask) > 0)\n            sb.append(sb.length() > 0 ? \",\" : \"\").append(flagName);\n\n        return sb;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1217-Param-0",
    "old_comment_raw": "@param idToken",
    "new_code_raw": "    public static ProtocolMapperRepresentation createAddressMapper(boolean idToken, boolean accessToken, boolean userInfo) {\n        return ModelToRepresentation.toRepresentation(AddressMapper.createAddressMapper(idToken, accessToken, userInfo));\n    }\n"
  },
  {
    "id": "mockito_mockito-1203-Param-1",
    "old_comment_raw": "@param clazz",
    "new_code_raw": "    private Set<Field> scanForInjection(final Object testClassInstance, final Class<?> clazz) {\n        Set<Field> mockDependentFields = new HashSet<Field>();\n        Field[] fields = clazz.getDeclaredFields();\n        for (Field field : fields) {\n            if (null != field.getAnnotation(InjectMocks.class)) {\n                assertNoAnnotations(field, Mock.class, MockitoAnnotations.Mock.class, Captor.class);\n                mockDependentFields.add(field);\n            }\n        }\n\n        return mockDependentFields;\n    }\n"
  },
  {
    "id": "todoroo_astrid-919-Param-0",
    "old_comment_raw": "@param task",
    "new_code_raw": "    public static Metadata newTagMetadata(Task task, String tagName, BigInteger tagUuid) {\n        return newTagMetadata(task.getId(), task.getValue(Task.UUID), tagName, tagUuid);\n    }\n"
  },
  {
    "id": "apache_ignite-13202-Param-0",
    "old_comment_raw": "@param grid Grid instance.",
    "new_code_raw": "    private GridSwapSpaceManager getSwapSpaceManager(Ignite ignite) {\n        assert ignite != null;\n\n        return ((GridKernal) ignite).context().swap();\n    }\n"
  },
  {
    "id": "apache_ignite-7869-Param-2",
    "old_comment_raw": "@param val New value.",
    "new_code_raw": "    @Override protected void clearIndex(CacheObject val, GridCacheVersion ver) {\n        // No-op.\n    }\n"
  },
  {
    "id": "singwhatiwanna_dynamic_load_apk-12-Param-0",
    "old_comment_raw": "@param base",
    "new_code_raw": "    public int startPluginActivityForResult(Context context, DLIntent dlIntent, int requestCode) {\n        if (mFrom == DLConstants.FROM_INTERNAL) {\n            dlIntent.setClassName(context, dlIntent.getPluginClass());\n            performStartActivityForResult(context, dlIntent, requestCode);\n            return DLPluginManager.START_RESULT_SUCCESS;\n        }\n\n        String packageName = dlIntent.getPluginPackage();\n        if (packageName == null) {\n            throw new NullPointerException(\"disallow null packageName.\");\n        }\n        DLPluginPackage pluginPackage = mPackagesHolder.get(packageName);\n        if (pluginPackage == null) {\n            return START_RESULT_NO_PKG;\n        } \n\n        DexClassLoader classLoader = pluginPackage.classLoader;\n        String className = dlIntent.getPluginClass();\n        className = (className == null ? pluginPackage.getDefaultActivity() : className);\n        if (className.startsWith(\".\")) {\n            className = packageName + className;\n        }\n        Class<?> clazz = null;\n        try {\n            clazz = classLoader.loadClass(className);\n        } catch (ClassNotFoundException e) {\n            e.printStackTrace();\n            return START_RESULT_NO_CLASS;\n        }\n\n        Class<? extends Activity> activityClass = null;\n        if (DLBasePluginActivity.class.isAssignableFrom(clazz)) {\n            activityClass = DLProxyActivity.class;\n        } else if (DLBasePluginFragmentActivity.class.isAssignableFrom(clazz)) {\n            activityClass = DLProxyFragmentActivity.class;\n        } else {\n            return START_RESULT_TYPE_ERROR;\n        }\n\n        dlIntent.putExtra(DLConstants.EXTRA_CLASS, className);\n        dlIntent.putExtra(DLConstants.EXTRA_PACKAGE, packageName);\n        dlIntent.setClass(mContext, activityClass);\n        performStartActivityForResult(context, dlIntent, requestCode);\n        return START_RESULT_SUCCESS;\n    }\n"
  },
  {
    "id": "voldemort_voldemort-112-Param-0",
    "old_comment_raw": "@param storeName",
    "new_code_raw": "    public int rebalanceNode(String storeName, RebalancePartitionsInfo stealInfo) {\n        VAdminProto.InitiateRebalanceNodeRequest rebalanceNodeRequest = VAdminProto.InitiateRebalanceNodeRequest.newBuilder()\n                                                                                                                .setAttempt(stealInfo.getAttempt())\n                                                                                                                .setDonorId(stealInfo.getDonorId())\n                                                                                                                .setStealerId(stealInfo.getStealerId())\n                                                                                                                .setCurrentStore(storeName)\n                                                                                                                .addAllPartitions(stealInfo.getPartitionList())\n                                                                                                                .addAllUnbalancedStore(stealInfo.getUnbalancedStoreList())\n                                                                                                                .build();\n        VAdminProto.VoldemortAdminRequest adminRequest = VAdminProto.VoldemortAdminRequest.newBuilder()\n                                                                                          .setType(VAdminProto.AdminRequestType.INITIATE_REBALANCE_NODE)\n                                                                                          .setInitiateRebalanceNode(rebalanceNodeRequest)\n                                                                                          .build();\n        VAdminProto.AsyncOperationStatusResponse.Builder response = sendAndReceive(stealInfo.getStealerId(),\n                                                                                   adminRequest,\n                                                                                   VAdminProto.AsyncOperationStatusResponse.newBuilder());\n\n        if(response.hasError())\n            throwException(response.getError());\n\n        return response.getRequestId();\n    }\n"
  },
  {
    "id": "fabric8io_kubernetes_client-26-Param-0",
    "old_comment_raw": "@param openShiftClient the OpenShift client to use",
    "new_code_raw": "  public static OpenShiftConfig withApiGroup(OkHttpClient httpClient, String apiGroupName, OpenShiftConfig config) {\n    OpenShiftClient openShiftClient = new DefaultOpenShiftClient(httpClient, config);\n    return withApiGroup(openShiftClient, apiGroupName, config);\n  }\n"
  },
  {
    "id": "apache_ignite-314-Param-2",
    "old_comment_raw": "@param entry Preloaded entry.",
    "new_code_raw": "        private boolean preloadEntry(GridNode pick, int p, GridCacheEntryInfo<K, V> entry, long topVer)\n            throws GridException, GridInterruptedException {\n            try {\n                GridCacheEntryEx<K, V> cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isGgfsDataCache() &&\n                        cctx.dht().ggfsDataSpaceUsed() > cctx.dht().ggfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload GGFS data cache (GGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            entry.valueBytes(),\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isDrEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (GridUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (GridInterruptedException e) {\n                throw e;\n            }\n            catch (GridException e) {\n                throw new GridException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "graphhopper_graphhopper-484-Param-1",
    "old_comment_raw": "@param encoder the FlagEncoder (to specify the vehicle)",
    "new_code_raw": "    public Weighting createWeighting( String weighting, FlagEncoder encoder )\n    {\n        // ignore case\n        weighting = weighting.toLowerCase();\n        if (\"fastest\".equals(weighting))\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                return new PriorityWeighting((BikeCommonFlagEncoder) encoder);\n            else\n                return new FastestWeighting(encoder);\n        }\n        return new ShortestWeighting();\n    }\n"
  },
  {
    "id": "haifengl_smile-110-Param-4",
    "old_comment_raw": "@param maxIter the maximum number of iterations in case that the algorithm does not converge.",
    "new_code_raw": "    public static double eigen(Matrix A, double[] v, double p, double tol, int maxIter) {\n        if (A.nrows() != A.ncols()) {\n            throw new IllegalArgumentException(\"Matrix is not square.\");\n        }\n\n        if (tol <= 0.0) {\n            throw new IllegalArgumentException(\"Invalid tolerance: \" + tol);            \n        }\n        \n        if (maxIter <= 0) {\n            throw new IllegalArgumentException(\"Invalid maximum number of iterations: \" + maxIter);            \n        }\n        \n        int n = A.nrows();\n        tol = Math.max(tol, Math.EPSILON * n);\n\n        double[] z = new double[n];\n        double lambda = ax(A, v, z, p);\n\n        for (int iter = 1; iter <= maxIter; iter++) {\n            double l = lambda;\n            lambda = ax(A, v, z, p);\n\n            double eps = Math.abs(lambda - l);\n            if (iter % 10 == 0) {\n                logger.trace(String.format(\"Largest eigenvalue after %3d power iterations: %.5f\\n\", iter, lambda + p));\n            }\n\n            if (eps < tol) {\n                logger.info(String.format(\"Largest eigenvalue after %3d power iterations: %.5f\\n\", iter, lambda + p));\n                return lambda + p;\n            }\n        }\n\n        logger.info(String.format(\"Largest eigenvalue after %3d power iterations: %.5f\\n\", maxIter, lambda + p));\n        logger.error(\"Power iteration exceeded the maximum number of iterations.\");\n        return lambda + p;\n    }\n"
  },
  {
    "id": "apache_ignite-12363-Param-0",
    "old_comment_raw": "@param igniteHome  Ignition installation folder.",
    "new_code_raw": "    public IgniteConfiguration setIgniteHome(String ggHome) {\n        this.ggHome = ggHome;\n\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-1774-Param-0",
    "old_comment_raw": "@param prj Projection.",
    "new_code_raw": "    protected GridMessaging message(ClusterGroup prj) {\n        return prj.grid().message(prj);\n    }\n"
  },
  {
    "id": "apache_ignite-13361-Param-0",
    "old_comment_raw": "@param part Partition.",
    "new_code_raw": "    public Collection<ClusterNode> backups(Object key, AffinityTopologyVersion topVer) {\n        return backups(partition(key), topVer);\n    }\n"
  },
  {
    "id": "haifengl_smile-114-Param-1",
    "old_comment_raw": "@param b the right hand side of linear equations.",
    "new_code_raw": "    public static double solve(Matrix A, Preconditioner Ap, double[] b, double[] x, double tol, int itol, int maxIter) {\n        if (tol <= 0.0) {\n            throw new IllegalArgumentException(\"Invalid tolerance: \" + tol);\n        }\n\n        if (maxIter <= 0) {\n            throw new IllegalArgumentException(\"Invalid maximum number of iterations: \" + maxIter);\n        }\n\n        if (itol < 1 || itol > 4) {\n            throw new IllegalArgumentException(String.format(\"Illegal itol: %d\", itol));\n        }\n\n        double err = 0.0;\n        double ak, akden, bk, bkden = 1.0, bknum, bnrm, dxnrm, xnrm, zm1nrm, znrm = 0.0;\n        int j, n = b.length;\n\n        double[] p = new double[n];\n        double[] pp = new double[n];\n        double[] r = new double[n];\n        double[] rr = new double[n];\n        double[] z = new double[n];\n        double[] zz = new double[n];\n\n        A.ax(x, r);\n        for (j = 0; j < n; j++) {\n            r[j] = b[j] - r[j];\n            rr[j] = r[j];\n        }\n\n        if (itol == 1) {\n            bnrm = snorm(b, itol);\n            Ap.asolve(r, z);\n        } else if (itol == 2) {\n            Ap.asolve(b, z);\n            bnrm = snorm(z, itol);\n            Ap.asolve(r, z);\n        } else if (itol == 3 || itol == 4) {\n            Ap.asolve(b, z);\n            bnrm = snorm(z, itol);\n            Ap.asolve(r, z);\n            znrm = snorm(z, itol);\n        } else {\n            throw new IllegalArgumentException(String.format(\"Illegal itol: %d\", itol));\n        }\n\n        for (int iter = 1; iter <= maxIter; iter++) {\n            Ap.asolve(rr, zz);\n            for (bknum = 0.0, j = 0; j < n; j++) {\n                bknum += z[j] * rr[j];\n            }\n            if (iter == 1) {\n                for (j = 0; j < n; j++) {\n                    p[j] = z[j];\n                    pp[j] = zz[j];\n                }\n            } else {\n                bk = bknum / bkden;\n                for (j = 0; j < n; j++) {\n                    p[j] = bk * p[j] + z[j];\n                    pp[j] = bk * pp[j] + zz[j];\n                }\n            }\n            bkden = bknum;\n            A.ax(p, z);\n            for (akden = 0.0, j = 0; j < n; j++) {\n                akden += z[j] * pp[j];\n            }\n            ak = bknum / akden;\n            A.atx(pp, zz);\n            for (j = 0; j < n; j++) {\n                x[j] += ak * p[j];\n                r[j] -= ak * z[j];\n                rr[j] -= ak * zz[j];\n            }\n            Ap.asolve(r, z);\n            if (itol == 1) {\n                err = snorm(r, itol) / bnrm;\n            } else if (itol == 2) {\n                err = snorm(z, itol) / bnrm;\n            } else if (itol == 3 || itol == 4) {\n                zm1nrm = znrm;\n                znrm = snorm(z, itol);\n                if (Math.abs(zm1nrm - znrm) > Math.EPSILON * znrm) {\n                    dxnrm = Math.abs(ak) * snorm(p, itol);\n                    err = znrm / Math.abs(zm1nrm - znrm) * dxnrm;\n                } else {\n                    err = znrm / bnrm;\n                    continue;\n                }\n                xnrm = snorm(x, itol);\n                if (err <= 0.5 * xnrm) {\n                    err /= xnrm;\n                } else {\n                    err = znrm / bnrm;\n                    continue;\n                }\n            }\n\n            if (iter % 10 == 0) {\n                logger.info(String.format(\"BCG: the error after %3d iterations: %.5g\", iter, err));\n            }\n\n            if (err <= tol) {\n                logger.info(String.format(\"BCG: the error after %3d iterations: %.5g\", iter, err));\n                break;\n            }\n        }\n\n        return err;\n    }\n"
  },
  {
    "id": "CalebFenton_simplify-21-Param-0",
    "old_comment_raw": "@param methodDescriptor",
    "new_code_raw": "    public boolean methodHasImplementation(String methodSignature) {\n        BuilderMethod method = getMethod(methodSignature);\n\n        return null != method.getImplementation();\n    }\n"
  },
  {
    "id": "apache_ignite-11623-Param-1",
    "old_comment_raw": "@param mode One of  #PRIMARY,  #BACKUP or  #NOT_PRIMARY_AND_BACKUP.",
    "new_code_raw": "    private Integer key(Ignite ignite, int mode) {\n        GridCache<Integer, Integer> cache = ignite.cache(null);\n\n        GridCacheAffinity<Integer> aff = cache.affinity();\n\n        Integer key = null;\n\n        for (int i = lastKey + 1; i < 1_000_000; i++) {\n            boolean pass = false;\n\n            switch(mode) {\n                case PRIMARY: pass = aff.isPrimary(ignite.cluster().localNode(), i); break;\n\n                case BACKUP: pass = aff.isBackup(ignite.cluster().localNode(), i); break;\n\n                case NOT_PRIMARY_AND_BACKUP: pass = !aff.isPrimaryOrBackup(ignite.cluster().localNode(), i); break;\n\n                default: fail();\n            }\n\n            lastKey = i;\n\n            if (pass) {\n                key = i;\n\n                break;\n            }\n        }\n\n        assertNotNull(key);\n\n        return key;\n    }\n"
  },
  {
    "id": "niklasb_pse-broadcast-encryption-18-Associations-Param0",
    "old_comment_raw": "@param r The $r$ value.",
    "new_code_raw": "    public NaorPinkasShare<T> getShare(BigInteger r, T gr) {\n        T x = group.pow(gr, pi);\n        return new NaorPinkasShare<T>(t, r, i, x, group);\n    }\n\n"
  },
  {
    "id": "json_path_JsonPath-196-Param-1",
    "old_comment_raw": "@param key property key",
    "new_code_raw": "    public Object getMapValue(Object obj, String key, boolean signalUndefined){\n        Map m = (Map) obj;\n        if(!m.containsKey(key) && signalUndefined){\n            return JsonProvider.UNDEFINED;\n        } else {\n            return m.get(key);\n        }\n    }\n"
  },
  {
    "id": "essentials_Essentials-234-Param-0",
    "old_comment_raw": "@param userName the username from the user to remove",
    "new_code_raw": "\tpublic boolean removeUser(String userId) {\n\n\t\tif (getUsers().containsKey(userId.toLowerCase())) {\n\t\t\tgetUsers().remove(userId.toLowerCase());\n\t\t\tsetUsersChanged(true);\n\t\t\tif (GroupManager.isLoaded())\n\t\t\t\tGroupManager.getGMEventHandler().callEvent(userId, GMUserEvent.Action.USER_REMOVED);\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n"
  },
  {
    "id": "apache_ignite-4796-Param-2",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteInternalTx tx, KeyCacheObject key, CacheObject val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key.internal())\n                return true;\n\n            Object storeKey = key.value(cctx);\n            Object storeVal = val.value(cctx);\n\n            if (convertPortable) {\n                storeKey = cctx.unwrapPortableIfNeeded(storeKey, false);\n                storeVal = cctx.unwrapPortableIfNeeded(storeVal, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            boolean ses = initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(storeKey, locStore ? F.t(storeVal, ver) : storeVal));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                if (ses)\n                    sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + storeKey + \", val=\" + storeVal + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "google_tink-272-Param-1",
    "old_comment_raw": "@param additionalData additional data",
    "new_code_raw": "  public byte[] encrypt(final byte[] plaintext, final byte[] associatedData)\n      throws GeneralSecurityException {\n    if (plaintext.length > Integer.MAX_VALUE - snuffle.nonceSizeInBytes() - MAC_TAG_SIZE_IN_BYTES) {\n      throw new GeneralSecurityException(\"plaintext too long\");\n    }\n    ByteBuffer ciphertext =\n        ByteBuffer.allocate(plaintext.length + snuffle.nonceSizeInBytes() + MAC_TAG_SIZE_IN_BYTES);\n\n    encrypt(ciphertext, plaintext, associatedData);\n    return ciphertext.array();\n  }\n"
  },
  {
    "id": "xetorthio_jedis-720-Param-1",
    "old_comment_raw": "@param offset",
    "new_code_raw": "    public boolean setbit(String key, long offset, boolean value) {\n        client.setbit(key, offset, value);\n        return client.getIntegerReply() == 1;\n    }\n"
  },
  {
    "id": "bneijt_unitrans-0-Associations-Param0",
    "old_comment_raw": "@param username",
    "new_code_raw": "    public List<MetadataBlock> reRoot(UUID rootBlockIdent, MetadataBlock targetBlock, MetadataBlock newTargetBlock) {\n        //Find all references to targetBlock and create new blocks restoring the original path to the user's root\n        // block\n        neo4JStorage.pathsFromTo(rootBlockIdent, targetBlock.ident);\n        //For all those references, do the same??\n        //LAST BLOCK MUST BE THE NEW ROOT\n        return Arrays.asList(MetadataBlock.emptyRandomBlock());\n    }\n\n"
  },
  {
    "id": "apache_ignite-2300-Param-1",
    "old_comment_raw": "@param mode Mode.",
    "new_code_raw": "    private GridGgfsFileInfo resolveFileInfo(IgniteFsPath path, GridGgfsMode mode) throws GridException {\n        assert path != null;\n        assert mode != null;\n\n        GridGgfsFileInfo info = null;\n\n        switch (mode) {\n            case PRIMARY:\n                info = meta.info(meta.fileId(path));\n\n                break;\n\n            case DUAL_SYNC:\n            case DUAL_ASYNC:\n                info = meta.info(meta.fileId(path));\n\n                if (info == null) {\n                    GridGgfsFile status = secondaryFs.info(path);\n\n                    if (status != null)\n                        info = status.isDirectory() ? new GridGgfsFileInfo(true, status.properties()) :\n                            new GridGgfsFileInfo(status.blockSize(), status.length(), null, null, false,\n                            status.properties());\n                }\n\n                break;\n\n            default:\n                assert false : \"Unknown mode: \" + mode;\n        }\n\n        return info;\n    }\n"
  },
  {
    "id": "Jasonchenlijian_FastBle-23-Param-0",
    "old_comment_raw": "@param operateTimeout",
    "new_code_raw": "    public BleManager setOperateTimeout(int count) {\n        this.operateTimeout = count;\n        return this;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-394-Param-1",
    "old_comment_raw": "@param negotiateHeader",
    "new_code_raw": "    protected Response optionalChallengeRedirect(AuthenticationFlowContext context, String negotiateHeader) {\n        String accessCode = context.generateAccessCode();\n        URI action = getActionUrl(context, accessCode);\n\n        StringBuilder builder = new StringBuilder();\n\n        builder.append(\"<HTML>\");\n        builder.append(\"<HEAD>\");\n\n        builder.append(\"<TITLE>Kerberos Unsupported</TITLE>\");\n        builder.append(\"</HEAD>\");\n        if (bypassChallengeJavascript) {\n            builder.append(\"<BODY>\");\n\n        } else {\n            builder.append(\"<BODY Onload=\\\"document.forms[0].submit()\\\">\");\n        }\n        builder.append(\"<FORM METHOD=\\\"POST\\\" ACTION=\\\"\" + action.toString() + \"\\\">\");\n        builder.append(\"<NOSCRIPT>\");\n        builder.append(\"<P>JavaScript is disabled. We strongly recommend to enable it. You were unable to login via Kerberos.  Click the button below to login via an alternative method .</P>\");\n        builder.append(\"<INPUT name=\\\"continue\\\" TYPE=\\\"SUBMIT\\\" VALUE=\\\"CONTINUE\\\" />\");\n        builder.append(\"</NOSCRIPT>\");\n\n        builder.append(\"</FORM></BODY></HTML>\");\n        return Response.status(Response.Status.UNAUTHORIZED)\n                .header(HttpHeaders.WWW_AUTHENTICATE, negotiateHeader)\n                .type(MediaType.TEXT_HTML_TYPE)\n                .entity(builder.toString()).build();\n    }\n"
  },
  {
    "id": "apache_ignite-13191-Param-1",
    "old_comment_raw": "@param defaultValue Default value.",
    "new_code_raw": "    private boolean getBooleanProperty(String name, boolean dfltVal) {\n        String val = manager.getProperty(name);\n\n        if (val == null)\n            return dfltVal;\n\n        val = val.toLowerCase();\n\n        if (\"true\".equals(val) || \"1\".equals(val))\n            return true;\n\n        if (\"false\".equals(val) || \"0\".equals(val))\n            return false;\n\n        return dfltVal;\n    }\n"
  },
  {
    "id": "apache_ignite-1665-Param-0",
    "old_comment_raw": "@param node Grid node.",
    "new_code_raw": "    private GridClientNodeBean createNodeBean(ClusterNode node, boolean mtr, boolean attr) {\n        assert node != null;\n\n        GridClientNodeBean nodeBean = new GridClientNodeBean();\n\n        nodeBean.setNodeId(node.id());\n        nodeBean.setConsistentId(node.consistentId());\n        nodeBean.setTcpPort(attribute(node, ATTR_REST_TCP_PORT, 0));\n\n        nodeBean.setTcpAddresses(nonEmptyList(node.<Collection<String>>attribute(ATTR_REST_TCP_ADDRS)));\n        nodeBean.setTcpHostNames(nonEmptyList(node.<Collection<String>>attribute(ATTR_REST_TCP_HOST_NAMES)));\n\n        Integer dfltReplicaCnt = node.attribute(GridCacheConsistentHashAffinityFunction.DFLT_REPLICA_COUNT_ATTR_NAME);\n\n        if (dfltReplicaCnt == null)\n            dfltReplicaCnt = GridCacheConsistentHashAffinityFunction.DFLT_REPLICA_COUNT;\n\n        nodeBean.setReplicaCount(dfltReplicaCnt);\n\n        GridCacheAttributes[] caches = node.attribute(ATTR_CACHE);\n\n        if (!F.isEmpty(caches)) {\n            Map<String, String> cacheMap = new HashMap<>();\n\n            for (GridCacheAttributes cacheAttr : caches) {\n                if (ctx.cache().systemCache(cacheAttr.cacheName()))\n                    continue;\n\n                if (cacheAttr.cacheName() != null)\n                    cacheMap.put(cacheAttr.cacheName(), cacheAttr.cacheMode().toString());\n                else\n                    nodeBean.setDefaultCacheMode(cacheAttr.cacheMode().toString());\n            }\n\n            nodeBean.setCaches(cacheMap);\n        }\n\n        if (mtr) {\n            GridNodeMetrics metrics = node.metrics();\n\n            GridClientNodeMetricsBean metricsBean = new GridClientNodeMetricsBean();\n\n            metricsBean.setStartTime(metrics.getStartTime());\n            metricsBean.setAverageActiveJobs(metrics.getAverageActiveJobs());\n            metricsBean.setAverageCancelledJobs(metrics.getAverageCancelledJobs());\n            metricsBean.setAverageCpuLoad(metrics.getAverageCpuLoad());\n            metricsBean.setAverageJobExecuteTime(metrics.getAverageJobExecuteTime());\n            metricsBean.setAverageJobWaitTime(metrics.getAverageJobWaitTime());\n            metricsBean.setAverageRejectedJobs(metrics.getAverageRejectedJobs());\n            metricsBean.setAverageWaitingJobs(metrics.getAverageWaitingJobs());\n            metricsBean.setCurrentActiveJobs(metrics.getCurrentActiveJobs());\n            metricsBean.setCurrentCancelledJobs(metrics.getCurrentCancelledJobs());\n            metricsBean.setCurrentCpuLoad(metrics.getCurrentCpuLoad());\n            metricsBean.setCurrentGcCpuLoad(metrics.getCurrentGcCpuLoad());\n            metricsBean.setCurrentDaemonThreadCount(metrics.getCurrentDaemonThreadCount());\n            metricsBean.setCurrentIdleTime(metrics.getCurrentIdleTime());\n            metricsBean.setCurrentJobExecuteTime(metrics.getCurrentJobExecuteTime());\n            metricsBean.setCurrentJobWaitTime(metrics.getCurrentJobWaitTime());\n            metricsBean.setCurrentRejectedJobs(metrics.getCurrentRejectedJobs());\n            metricsBean.setCurrentThreadCount(metrics.getCurrentThreadCount());\n            metricsBean.setCurrentWaitingJobs(metrics.getCurrentWaitingJobs());\n            metricsBean.setHeapMemoryCommitted(metrics.getHeapMemoryCommitted());\n            metricsBean.setHeapMemoryInitialized(metrics.getHeapMemoryInitialized());\n            metricsBean.setHeapMemoryMaximum(metrics.getHeapMemoryMaximum());\n            metricsBean.setHeapMemoryUsed(metrics.getHeapMemoryUsed());\n            metricsBean.setLastDataVersion(metrics.getLastDataVersion());\n            metricsBean.setLastUpdateTime(metrics.getLastUpdateTime());\n            metricsBean.setMaximumActiveJobs(metrics.getMaximumActiveJobs());\n            metricsBean.setMaximumCancelledJobs(metrics.getMaximumCancelledJobs());\n            metricsBean.setMaximumJobExecuteTime(metrics.getMaximumJobExecuteTime());\n            metricsBean.setMaximumJobWaitTime(metrics.getMaximumJobWaitTime());\n            metricsBean.setMaximumRejectedJobs(metrics.getMaximumRejectedJobs());\n            metricsBean.setMaximumThreadCount(metrics.getMaximumThreadCount());\n            metricsBean.setMaximumWaitingJobs(metrics.getMaximumWaitingJobs());\n            metricsBean.setNodeStartTime(metrics.getNodeStartTime());\n            metricsBean.setNonHeapMemoryCommitted(metrics.getNonHeapMemoryCommitted());\n            metricsBean.setNonHeapMemoryInitialized(metrics.getNonHeapMemoryInitialized());\n            metricsBean.setNonHeapMemoryMaximum(metrics.getNonHeapMemoryMaximum());\n            metricsBean.setNonHeapMemoryUsed(metrics.getNonHeapMemoryUsed());\n            metricsBean.setStartTime(metrics.getStartTime());\n            metricsBean.setTotalCancelledJobs(metrics.getTotalCancelledJobs());\n            metricsBean.setTotalCpus(metrics.getTotalCpus());\n            metricsBean.setTotalExecutedJobs(metrics.getTotalExecutedJobs());\n            metricsBean.setTotalIdleTime(metrics.getTotalIdleTime());\n            metricsBean.setTotalRejectedJobs(metrics.getTotalRejectedJobs());\n            metricsBean.setTotalStartedThreadCount(metrics.getTotalStartedThreadCount());\n            metricsBean.setTotalExecutedTasks(metrics.getTotalExecutedTasks());\n            metricsBean.setSentMessagesCount(metrics.getSentMessagesCount());\n            metricsBean.setSentBytesCount(metrics.getSentBytesCount());\n            metricsBean.setReceivedMessagesCount(metrics.getReceivedMessagesCount());\n            metricsBean.setReceivedBytesCount(metrics.getReceivedBytesCount());\n            metricsBean.setUpTime(metrics.getUpTime());\n\n            nodeBean.setMetrics(metricsBean);\n        }\n\n        if (attr) {\n            Map<String, Object> attrs = new HashMap<>(node.attributes());\n\n            attrs.remove(ATTR_CACHE);\n            attrs.remove(ATTR_SECURITY_SUBJECT);\n            attrs.remove(ATTR_SECURITY_CREDENTIALS);\n\n            for (Iterator<Map.Entry<String, Object>> i = attrs.entrySet().iterator(); i.hasNext();) {\n                Map.Entry<String, Object> e = i.next();\n\n                if (!e.getKey().startsWith(\"org.gridgain.\") && System.getProperty(e.getKey()) == null) {\n                    i.remove();\n\n                    continue;\n                }\n\n                if (e.getValue() != null) {\n                  if (e.getValue().getClass().isEnum() || e.getValue() instanceof InetAddress)\n                      e.setValue(e.getValue().toString());\n                  else if (e.getValue().getClass().isArray())\n                      i.remove();\n                }\n            }\n\n            nodeBean.setAttributes(attrs);\n        }\n\n        return nodeBean;\n    }\n"
  },
  {
    "id": "Netflix_Hystrix-354-Param-1",
    "old_comment_raw": "@param executionType  ExecutionType",
    "new_code_raw": "    public static Object execute(HystrixExecutable executable, ExecutionType executionType, MetaHolder metaHolder) throws RuntimeException {\n        Validate.notNull(executable);\n        Validate.notNull(metaHolder);\n\n        switch (executionType) {\n            case SYNCHRONOUS: {\n                return executable.execute();\n            }\n            case ASYNCHRONOUS: {\n                if(metaHolder.hasFallbackMethodCommand()\n                        && ExecutionType.ASYNCHRONOUS == metaHolder.getFallbackExecutionType()){\n                    return new FutureDecorator(executable.queue());\n                }\n                return executable.queue();\n            }\n            case OBSERVABLE: {\n                return executable.observe();\n            }\n            default:\n                throw new RuntimeException(\"unsupported execution type: \" + executionType);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-1524-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private Collection<GridNode> affinityNodes(Ignite g, int p) {\n        return affinity(g).mapPartitionToPrimaryAndBackups(p);\n    }\n"
  },
  {
    "id": "apache_ignite-12026-Param-0",
    "old_comment_raw": "@param ignite Ignite.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite g, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = g.streamer(\"priceBars\");\n\n                try {\n                    Collection<Bar> bars = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext, Collection<Bar>>() {\n                            @Override public Collection<Bar> apply(StreamerContext ctx) {\n                                Collection<Bar> values = ctx.<String, Bar>localSpace().values();\n\n                                Collection<Bar> res = new ArrayList<>(values.size());\n\n                                for (Bar bar : values)\n                                    res.add(bar.copy());\n\n                                return res;\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new IgniteReducer<Collection<Bar>, Collection<Bar>>() {\n                            private final Collection<Bar> res = new ArrayList<>();\n\n                            @Override public boolean collect(@Nullable Collection<Bar> col) {\n                                res.addAll(col);\n\n                                return true;\n                            }\n\n                            @Override public Collection<Bar> reduce() {\n                                return res;\n                            }\n                        }\n                    );\n\n                    for (Bar bar : bars)\n                        System.out.println(bar.toString());\n\n                    System.out.println(\"-----------------\");\n                }\n                catch (IgniteCheckedException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 2000, 2000);\n\n        return task;\n    }\n"
  },
  {
    "id": "apache_ignite-3055-Param-0",
    "old_comment_raw": "@param cfg Configuration to check.",
    "new_code_raw": "    public static boolean isAffinityNode(CacheConfiguration cfg) {\n        if (cfg.getCacheMode() == LOCAL)\n            return true;\n\n        GridCacheDistributionMode partTax = cfg.getDistributionMode();\n\n        if (partTax == null)\n            partTax = distributionMode(cfg);\n\n        return partTax == GridCacheDistributionMode.PARTITIONED_ONLY ||\n            partTax == GridCacheDistributionMode.NEAR_PARTITIONED;\n    }\n"
  },
  {
    "id": "mitreid_connect_OpenID_Connect_Java_Spring_Server-226-Param-0",
    "old_comment_raw": "@param resource",
    "new_code_raw": "\tprivate NormalizedURI normalizeResource(String identifier) {\n\t\t// try to parse the URI\t\t\n\t\t// NOTE: we can't use the Java built-in URI class because it doesn't split the parts appropriately\n\t\t\n\t\tif (Strings.isNullOrEmpty(identifier)) {\n\t\t\tlogger.warn(\"Can't normalize null or empty URI: \" + identifier);\n\t\t\treturn null; // nothing we can do\n\t\t} else {\n\t\t\t\t\n    \t\tNormalizedURI n = new NormalizedURI();    \t\t\n    \t\tMatcher m = pattern.matcher(identifier);\n\t\t\n\t\t\tif (m.matches()) {\n\t\t\t\tn.scheme = m.group(1); // includes colon and maybe initial slashes\n\t\t\t\tn.user = m.group(2); // includes at sign\n\t\t\t\tn.hostportpath = m.group(4);\n\t\t\t\tn.query = m.group(5); // includes question mark\n\t\t\t\tn.hash = m.group(7); // includes hash mark\n\t\t\t\t\n\t\t\t\t// normalize scheme portion\n\t\t\t\tif (Strings.isNullOrEmpty(n.scheme)) {\n\t\t\t\t\tif (!Strings.isNullOrEmpty(n.user)) {\n\t\t\t\t\t\t// no scheme, but have a user, assume acct:\n\t\t\t\t\t\tn.scheme = \"acct:\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// no scheme, no user, assume https://\n\t\t\t\t\t\tn.scheme = \"https://\";\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tn.source = Strings.nullToEmpty(n.scheme) +\n\t\t\t\t\t\tStrings.nullToEmpty(n.user) +\n\t\t\t\t\t\tStrings.nullToEmpty(n.hostportpath) + \n\t\t\t\t\t\tStrings.nullToEmpty(n.query); // note: leave fragment off\n\t\t\t\t\n\t\t\t\treturn n;\n\t\t\t} else {\n\t\t\t\tlogger.warn(\"Parser couldn't match input: \" + identifier);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\n\t\t\n\t}\n"
  },
  {
    "id": "apache_ignite-5971-Param-1",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public List<ClusterNode> nodes(Object key, long topVer) {\n        return nodes(partition(key), topVer);\n    }\n"
  },
  {
    "id": "apache_ignite-12045-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static CacheSet<String> initializeSet(Ignite ignite, String setName) throws IgniteCheckedException {\n        // Initialize new set.\n        CacheSet<String> set = ignite.cache(CACHE_NAME).dataStructures().set(setName, false, true);\n\n        // Initialize set items.\n        for (int i = 0; i < 10; i++)\n            set.add(Integer.toString(i));\n\n        System.out.println(\"Set size after initializing: \" + set.size());\n\n        return set;\n    }\n"
  },
  {
    "id": "voldemort_voldemort-729-Param-0",
    "old_comment_raw": "@param storeName Name of the store",
    "new_code_raw": "    private Node getNodeIfPresent(int proxyNodeId) {\n        try {\n            return metadata.getCluster().getNodeById(proxyNodeId);\n        } catch(Exception e) {\n            throw new VoldemortException(\"Failed to get proxyNode \" + proxyNodeId\n                                         + \" from current cluster \" + metadata.getCluster()\n                                         + \" at node \" + metadata.getNodeId(), e);\n        }\n    }\n"
  },
  {
    "id": "json_path_JsonPath-196-Param-2",
    "old_comment_raw": "@param throwOnMissing if true a PathNotFoundException is thrown if property is missing",
    "new_code_raw": "    public Object getMapValue(Object obj, String key, boolean signalUndefined){\n        Map m = (Map) obj;\n        if(!m.containsKey(key) && signalUndefined){\n            return JsonProvider.UNDEFINED;\n        } else {\n            return m.get(key);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5486-Param-0",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public IgniteInternalFuture<Boolean> finishTxs(AffinityTopologyVersion topVer) {\n        GridCompoundFuture<IgniteInternalTx, Boolean> res =\n            new GridCompoundFuture<>(context().kernalContext(),\n                new IgniteReducer<IgniteInternalTx, Boolean>() {\n                    @Override public boolean collect(IgniteInternalTx e) {\n                        return true;\n                    }\n\n                    @Override public Boolean reduce() {\n                        return true;\n                    }\n                });\n\n        for (IgniteInternalTx<K, V> tx : txs()) {\n            // Must wait for all transactions, even for DHT local and DHT remote since preloading may acquire\n            // values pending to be overwritten by prepared transaction.\n\n            if (tx.concurrency() == PESSIMISTIC) {\n                if (tx.topologyVersion().compareTo(AffinityTopologyVersion.ZERO) > 0\n                    && tx.topologyVersion().compareTo(topVer) < 0)\n                    // For PESSIMISTIC mode we must wait for all uncompleted txs\n                    // as we do not know in advance which keys will participate in tx.\n                    res.add(tx.finishFuture());\n            }\n            else if (tx.concurrency() == OPTIMISTIC) {\n                // For OPTIMISTIC mode we wait only for txs in PREPARING state that\n                // have keys for given partitions.\n                TransactionState state = tx.state();\n                AffinityTopologyVersion txTopVer = tx.topologyVersion();\n\n                if ((state == PREPARING || state == PREPARED || state == COMMITTING)\n                    && txTopVer.compareTo(AffinityTopologyVersion.ZERO) > 0 && txTopVer.compareTo(topVer) < 0) {\n                    res.add(tx.finishFuture());\n                }\n            }\n        }\n\n        res.markInitialized();\n\n        return res;\n    }\n"
  },
  {
    "id": "cloudfoundry_uaa-119-Param-0",
    "old_comment_raw": "@param authorizationRequest the current authorization request",
    "new_code_raw": "\tprotected boolean isRefreshTokenSupported(String grantType) {\n\t\treturn \"authorization_code\".equals(grantType) || \"password\".equals(grantType)\n\t\t\t\t|| \"refresh_token\".equals(grantType);\n\t}\n"
  },
  {
    "id": "apache_ignite-7833-Param-0",
    "old_comment_raw": "@param fileName Name of the file to read.",
    "new_code_raw": "    protected String readAndSortFile(String fileName, Configuration conf) throws Exception {\n        final List<String> list = new ArrayList<>();\n\n        final boolean snappyDecode = conf != null && conf.getBoolean(FileOutputFormat.COMPRESS, false);\n\n        if (snappyDecode) {\n            try (SequenceFile.Reader reader = new SequenceFile.Reader(conf,\n                    SequenceFile.Reader.file(new Path(fileName)))) {\n                Text key = new Text();\n\n                IntWritable val = new IntWritable();\n\n                while (reader.next(key, val))\n                    list.add(key + \"\\t\" + val);\n            }\n        }\n        else {\n            try (InputStream is0 = igfs.open(new IgfsPath(fileName))) {\n                BufferedReader reader = new BufferedReader(new InputStreamReader(is0));\n\n                String line;\n\n                while ((line = reader.readLine()) != null)\n                    list.add(line);\n            }\n        }\n\n        Collections.sort(list);\n\n        return Joiner.on('\\n').join(list) + \"\\n\";\n    }\n"
  },
  {
    "id": "zxing_zxing-675-Param-0",
    "old_comment_raw": "@param image the scanned barcode image.",
    "new_code_raw": "  private static ResultPoint[] findVertices180(BitMatrix matrix) throws ReaderException {\n    int height = matrix.getHeight();\n    int width = matrix.getWidth();\n    int halfWidth = width >> 1;\n\n    ResultPoint[] result = new ResultPoint[8];\n    boolean found = false;\n\n    int[] loc = null;\n    // Top Left\n    for (int i = height - 1; i > 0; i--) {\n      loc = findGuardPattern(matrix, halfWidth, i, halfWidth, START_PATTERN_REVERSE);\n      if (loc != null) {\n        result[0] = new ResultPoint(loc[1], i);\n        result[4] = new ResultPoint(loc[0], i);\n        found = true;\n        break;\n      }\n    }\n    // Bottom Left\n    if (found) { // Found the Top Left vertex\n      found = false;\n      for (int i = 0; i < height; i++) {\n        loc = findGuardPattern(matrix, halfWidth, i, halfWidth, START_PATTERN_REVERSE);\n        if (loc != null) {\n          result[1] = new ResultPoint(loc[1], i);\n          result[5] = new ResultPoint(loc[0], i);\n          found = true;\n          break;\n        }\n      }\n    }\n    // Top Right\n    if (found) { // Found the Bottom Left vertex\n      found = false;\n      for (int i = height - 1; i > 0; i--) {\n        loc = findGuardPattern(matrix, 0, i, halfWidth, STOP_PATTERN_REVERSE);\n        if (loc != null) {\n          result[2] = new ResultPoint(loc[0], i);\n          result[6] = new ResultPoint(loc[1], i);\n          found = true;\n          break;\n        }\n      }\n    }\n    // Bottom Right\n    if (found) { // Found the Top Right vertex\n      found = false;\n      for (int i = 0; i < height; i++) {\n        loc = findGuardPattern(matrix, 0, i, halfWidth, STOP_PATTERN_REVERSE);\n        if (loc != null) {\n          result[3] = new ResultPoint(loc[0], i);\n          result[7] = new ResultPoint(loc[1], i);\n          found = true;\n          break;\n        }\n      }\n    }\n    return found ? result : null;\n  }\n"
  },
  {
    "id": "zxing_zxing-317-Param-0",
    "old_comment_raw": "@param msg the message",
    "new_code_raw": "  private static int determineConsecutiveDigitCount(CharSequence msg, int startpos) {\n    int count = 0;\n    int len = msg.length();\n    int idx = startpos;\n    if (idx < len) {\n      char ch = msg.charAt(idx);\n      while (isDigit(ch) && idx < len) {\n        count++;\n        idx++;\n        if (idx < len) {\n          ch = msg.charAt(idx);\n        }\n      }\n    }\n    return count;\n  }\n"
  },
  {
    "id": "sanluan_PublicCMS-606-Param-0",
    "old_comment_raw": "@param createDate",
    "new_code_raw": "    public int delete(Date now) {\n        if (null != now) {\n            QueryHandler queryHandler = getQueryHandler(\"delete from SysUserToken bean\");\n            queryHandler.condition(\"bean.expiryDate is not null\");\n            queryHandler.condition(\"bean.expiryDate <= :expiryDate\").setParameter(\"expiryDate\", now);\n            return delete(queryHandler);\n        }\n        return 0;\n    }\n"
  },
  {
    "id": "todoroo_astrid-196-Param-0",
    "old_comment_raw": "@param listId",
    "new_code_raw": "    public String getListName(String listId) {\n        readLists();\n        for(StoreObject list : lists)\n            if(list.getValue(GtasksList.REMOTE_ID).equals(listId))\n                return list.getValue(GtasksList.NAME);\n        return LIST_NOT_FOUND;\n    }\n"
  },
  {
    "id": "apache_shiro-739-Param-0",
    "old_comment_raw": "@param originatingHost the originating host InetAddress of the external party (user, 3rd party product, etc) that is attempting to initiate the session, or  null if not known.",
    "new_code_raw": "    public Session createSession(String host) {\n        return new SimpleSession(host);\n    }\n"
  },
  {
    "id": "apache_ignite-4960-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    private boolean map(KeyCacheObject key, Collection<GridDhtLocalPartition> parts) {\n        GridDhtLocalPartition part = topVer > 0 ?\n            cache().topology().localPartition(cctx.affinity().partition(key), topVer, true) :\n            cache().topology().localPartition(key, false);\n\n        if (part == null)\n            return false;\n\n        if (!parts.contains(part)) {\n            // By reserving, we make sure that partition won't be unloaded while processed.\n            if (part.reserve()) {\n                parts.add(part);\n\n                return true;\n            }\n            else\n                return false;\n        }\n        else\n            return true;\n    }\n"
  },
  {
    "id": "json_path_JsonPath-179-Param-1",
    "old_comment_raw": "@param field the field to extract from the document alt. the documents contained in the array",
    "new_code_raw": "    private Object getContainerValue(Object container, JSONPathFragment fragment) {\n        Object result;\n\n        if (container instanceof JSONArray) {\n            List list = new LinkedList();\n            for (Object doc : toArray(container)) {\n                list.add(getContainerValue(doc, fragment));\n            }\n            result = list;\n\n        } else if (container instanceof JSONObject) {\n            JSONObject document = toDocument(container);\n\n            if (!document.containsKey(fragment.value())) {\n                throw new InvalidPathException(\"Invalid path element: \" + currentPath + \" <==\");\n            }\n\n            result = document.get(fragment.value());\n        } else {\n            throw new InvalidPathException(\"Invalid path element: \" + currentPath + \" <==\");\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-5697-Param-1",
    "old_comment_raw": "@param msgId Message ID.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, long topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!U.hasNearCache(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture<K, V> txFut = null;\n\n        Collection<GridCacheMvccCandidate<K>> cands = null;\n\n        ReaderId<K, V> reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId<>(nodeId, msgId);\n\n                ReaderId<K, V>[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate<K> c : cands) {\n                    IgniteInternalTx<K, V> tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId<K, V> reader0 = reader;\n\n                txFut.listen(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        cctx.kernalContext().closure().runLocalSafe(new GridPlainRunnable() {\n                            @Override public void run() {\n                                synchronized (this) {\n                                    // Release memory.\n                                    reader0.resetTxFuture();\n                                }\n                            }\n                        });\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "apache_ignite-11537-Param-0",
    "old_comment_raw": "@param ctx Cache context.",
    "new_code_raw": "    public static boolean cacheNode(String cacheName, GridCacheAttributes[] caches) {\n        if (caches != null)\n            for (GridCacheAttributes attrs : caches)\n                if (F.eq(cacheName, attrs.cacheName()))\n                    return true;\n\n        return false;\n    }\n"
  },
  {
    "id": "Netflix_zuul-66-Param-0",
    "old_comment_raw": "@param msg",
    "new_code_raw": "    public ZuulMessage processSyncFilter(ZuulMessage msg, SyncZuulFilter filter, boolean shouldSendErrorResponse)\n    {\n        final FilterExecInfo info = new FilterExecInfo();\n        info.bDebug = msg.getContext().debugRouting();\n\n        if (info.bDebug) {\n            Debug.addRoutingDebug(msg.getContext(), \"Filter \" + filter.filterType().toString() + \" \" + filter.filterOrder() + \" \" + filter.filterName());\n            info.debugCopy = msg.clone();\n        }\n\n        // Apply this filter.\n        ZuulMessage result;\n        long ltime = System.currentTimeMillis();\n        try {\n            if (filter.isDisabled()) {\n                result = filter.getDefaultOutput(msg);\n                info.status = DISABLED;\n            }\n            else if (msg.getContext().shouldStopFilterProcessing()) {\n                // This is typically set by a filter when wanting to reject a request, and also reduce load on the server by\n                // not processing any more filters.\n                result = filter.getDefaultOutput(msg);\n                info.status = SKIPPED;\n            }\n            else {\n                // Only apply the filter if both the shouldFilter() method AND the filter has a priority of\n                // equal or above the requested.\n                int requiredPriority = msg.getContext().getFilterPriorityToApply();\n                ZuulMessage input = chooseFilterInput(filter, msg);\n                if (isFilterPriority(filter, requiredPriority) && filter.shouldFilter(input)) {\n                    result = filter.apply(input);\n\n                    // If no result returned from filter, then use the original input.\n                    if (result == null) {\n                        result = filter.getDefaultOutput(msg);\n                    }\n                }\n                else {\n                    result = filter.getDefaultOutput(msg);\n                    info.status = SKIPPED;\n                }\n            }\n        }\n        catch (Exception e) {\n            result = filter.getDefaultOutput(msg);\n            msg.getContext().setError(e);\n            if (shouldSendErrorResponse) msg.getContext().setShouldSendErrorResponse(true);\n            info.status = FAILED;\n            recordFilterError(filter, msg, e);\n        }\n\n        // Record info when filter processing completes.\n        if (info.status == null) {\n            info.status = SUCCESS;\n        }\n        info.execTime = System.currentTimeMillis() - ltime;\n        recordFilterCompletion(result, filter, info);\n\n        return result;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-506-Param-0",
    "old_comment_raw": "@param weightingParameters the request parameters",
    "new_code_raw": "    public Weighting createWeighting( WeightingMap wMap, FlagEncoder encoder )\n    {\n        String weighting = wMap.getWeighting();\n        Weighting result;\n\n        if (\"shortest\".equalsIgnoreCase(weighting))\n        {\n            result = new ShortestWeighting();\n        } else if (\"fastest\".equalsIgnoreCase(weighting) || weighting.isEmpty())\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                result = new PriorityWeighting(encoder);\n            else\n                result = new FastestWeighting(encoder);\n        } else\n        {\n            throw new UnsupportedOperationException(\"weighting \" + weighting + \" not supported\");\n        }\n\n        if (encoder.supportsTurnCosts())\n        {\n            result = new TurnWeighting(result, encoder, (TurnCostStorage) graph.getExtendedStorage());\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-3052-Param-0",
    "old_comment_raw": "@param cfg Cache configuration.",
    "new_code_raw": "    private GridCacheQueryManager queryManager(CacheConfiguration cfg) {\n        return cfg.getCacheMode() == LOCAL ? new GridCacheLocalQueryManager() : new GridCacheDistributedQueryManager();\n    }\n"
  },
  {
    "id": "json_path_JsonPath-197-Param-2",
    "old_comment_raw": "@param expected expected value",
    "new_code_raw": "    public static Criteria create(String left, String operator, String right) {\n        Object leftPrepared = left;\n        Object rightPrepared = right;\n        Path leftPath = null;\n        Path rightPath = null;\n\n        if(isPath(left)){\n            leftPath = PathCompiler.compile(left);\n            if(!leftPath.isDefinite()){\n                throw new InvalidPathException(\"the predicate path: \" + left + \" is not definite\");\n            }\n            leftPrepared = leftPath;\n        } else if(isString(left)) {\n            leftPrepared = left.substring(1, left.length() - 1);\n        }\n\n        if(isPath(right)){\n            rightPath = PathCompiler.compile(right);\n            if(!rightPath.isDefinite()){\n                throw new InvalidPathException(\"the predicate path: \" + right + \" is not definite\");\n            }\n            rightPrepared = rightPath;\n        } else if(isString(right)) {\n            rightPrepared = right.substring(1, right.length() - 1);\n        }\n\n        if(leftPath != null && operator.isEmpty()){\n            return Criteria.where(leftPath).exists(true);\n        } else {\n            return new Criteria(leftPrepared, CriteriaType.parse(operator), rightPrepared);\n        }\n    }\n"
  },
  {
    "id": "cloudfoundry_uaa-63-Param-0",
    "old_comment_raw": "@param originKey The unique identifier used to reference the identity provider in UAA.",
    "new_code_raw": "    public static IdentityProvider createIdentityProvider(String name, String originKey, boolean addShadowUserOnLogin, String baseUrl, ServerRunning serverRunning, SamlIdentityProviderDefinition samlIdentityProviderDefinition) throws Exception {\n        String zoneAdminToken = getZoneAdminToken(baseUrl, serverRunning);\n\n        samlIdentityProviderDefinition.setAddShadowUserOnLogin(addShadowUserOnLogin);\n        IdentityProvider provider = new IdentityProvider();\n        provider.setIdentityZoneId(OriginKeys.UAA);\n        provider.setType(OriginKeys.SAML);\n        provider.setActive(true);\n        provider.setConfig(samlIdentityProviderDefinition);\n        provider.setOriginKey(samlIdentityProviderDefinition.getIdpEntityAlias());\n        provider.setName(name);\n        provider = IntegrationTestUtils.createOrUpdateProvider(zoneAdminToken,baseUrl,provider);\n        assertNotNull(provider.getId());\n        return provider;\n    }\n"
  },
  {
    "id": "eclipse_elk-76-Associations-Param0",
    "old_comment_raw": "@param edges an  Iterable of edges that shall be checked",
    "new_code_raw": "    public static Iterator<KEdge> getConnectedEdges(final Iterable<KEdge> kedges) {\n        return Iterators.concat(\n                Iterators.transform(kedges.iterator(), new Function<KEdge, Iterator<KEdge>>() {\n\n            public Iterator<KEdge> apply(final KEdge kedge) {\n                return getConnectedEdges(kedge);\n            }\n        }));\n    }\n\n"
  },
  {
    "id": "apache_ignite-1908-Param-1",
    "old_comment_raw": "@param update Value to set.",
    "new_code_raw": "    public boolean checkAndSet(IgnitePredicate<Long> p, long update) {\n        while (true) {\n            long cur = get();\n\n            if (p.apply(cur)) {\n                if (compareAndSet(cur, update))\n                    return true;\n            }\n            else\n                return false;\n        }\n    }\n"
  },
  {
    "id": "cglib_cglib-0-Associations-Param0",
    "old_comment_raw": "@param clazz Class or inteface to extend or implement",
    "new_code_raw": "    public static Factory enhance(Class cls, MethodInterceptor ih) {\n        return (Factory)enhanceHelper(cls.isInterface() ? null : cls,\n                                      cls.isInterface() ? new Class[]{ cls } : null,\n                                      ih, cls.getClassLoader(), null, null );\n    }\n\n"
  },
  {
    "id": "keycloak_keycloak-1328-Param-0",
    "old_comment_raw": "@param value",
    "new_code_raw": "    public static XMLGregorianCalendar subtract(XMLGregorianCalendar value, long millis) {\n        return add(value, - millis);\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-641-Param-0",
    "old_comment_raw": "@param createDate",
    "new_code_raw": "    public int delete(Date now) {\n        return dao.delete(now);\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-429-Param-3",
    "old_comment_raw": "@param session",
    "new_code_raw": "    public String delete(String path, Long[] ids, String _csrf, HttpServletRequest request, HttpSession session, ModelMap model) {\n        if (ControllerUtils.verifyNotEquals(\"_csrf\", ControllerUtils.getAdminToken(request), _csrf, model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        SysUser user = ControllerUtils.getAdminFromSession(session);\n        SysDept dept = sysDeptService.getEntity(user.getDeptId());\n        if (ControllerUtils.verifyNotEmpty(\"deptId\", user.getDeptId(), model)\n                || ControllerUtils.verifyNotEmpty(\"deptId\", dept, model)\n                || ControllerUtils.verifyCustom(\"noright\",\n                        !(dept.isOwnsAllPage() || null != sysDeptPageService.getEntity(new SysDeptPageId(user.getDeptId(),\n                                CommonConstants.SEPARATOR + TemplateComponent.INCLUDE_DIRECTORY + path))),\n                        model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        if (CommonUtils.notEmpty(ids)) {\n            SysSite site = getSite(request);\n            service.delete(site.getId(), ids, path);\n            logOperateService.save(new LogOperate(site.getId(), ControllerUtils.getAdminFromSession(session).getId(),\n                    LogLoginService.CHANNEL_WEB_MANAGER, \"delete.place\", RequestUtils.getIpAddress(request),\n                    CommonUtils.getDate(), StringUtils.join(ids, ',')));\n        }\n        return CommonConstants.TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-805-Param-2",
    "old_comment_raw": "@param end",
    "new_code_raw": "  public String ltrim(final String key, final long start, final long stop) {\n    checkIsInMultiOrPipeline();\n    client.ltrim(key, start, stop);\n    return client.getStatusCodeReply();\n  }\n"
  },
  {
    "id": "apache_ignite-7898-Param-2",
    "old_comment_raw": "@param expirationTime Expiration time.",
    "new_code_raw": "    public boolean update(KeyCacheObject key, CacheObject val, GridCacheVersion ver, long expirationTime, boolean rmv)\n        throws IgniteCheckedException {\n        assert desc != null;\n\n        GridH2Row row = desc.createRow(key, val, ver, expirationTime);\n\n        return doUpdate(row, rmv);\n    }\n"
  },
  {
    "id": "apache_ignite-13299-Param-0",
    "old_comment_raw": "@param cls Collection class.",
    "new_code_raw": "    private Collection readCollection0(@Nullable BinaryCollectionFactory factory)\n        throws BinaryObjectException {\n        switch (checkFlag(COL)) {\n            case NORMAL:\n                return (Collection)PortableUtils.doReadCollection(in, ctx, ldr, this, true, factory);\n\n            case HANDLE: {\n                int handlePos = PortableUtils.positionForHandle(in) - in.readInt();\n\n                Object obj = getHandle(handlePos);\n\n                if (obj == null) {\n                    int retPos = in.position();\n\n                    streamPosition(handlePos);\n\n                    obj = readCollection0(factory);\n\n                    streamPosition(retPos);\n                }\n\n                return (Collection)obj;\n            }\n\n            default:\n                return null;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5051-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    public List<ClusterNode> nodes(K key, long topVer) {\n        return nodes(partition(key), topVer);\n    }\n"
  },
  {
    "id": "apache_ignite-13179-Param-1",
    "old_comment_raw": "@param localCombiner If we have mapper with combiner.",
    "new_code_raw": "    private GridHadoopTaskOutput createOutput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case REDUCE:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case MAP:\n                if (locCombiner) {\n                    assert local == null;\n\n                    local = get(job.info(), SHUFFLE_COMBINER_NO_SORTING, false) ?\n                        new GridHadoopHashMultimap(job, mem, get(job.info(), COMBINER_HASHMAP_SIZE, 8 * 1024)):\n                        new GridHadoopSkipList(job, mem, job.sortComparator()); // TODO replace with red-black tree\n\n                    return local.startAdding();\n                }\n\n            default:\n                return createOutput(ctx);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-1795-Param-0",
    "old_comment_raw": "@param c Grid configuration.",
    "new_code_raw": "    public static VisorLifecycleConfiguration from(IgniteConfiguration c) {\n        VisorLifecycleConfiguration cfg = new VisorLifecycleConfiguration();\n\n        cfg.beans(compactArray(c.getLifecycleBeans()));\n        cfg.emailNotification(boolValue(GG_LIFECYCLE_EMAIL_NOTIFY, c.isLifeCycleEmailNotification()));\n\n        return cfg;\n    }\n"
  },
  {
    "id": "CalebFenton_simplify-22-Param-0",
    "old_comment_raw": "@param typeDescriptor",
    "new_code_raw": "    public boolean isSafe(String typeSignature) {\n        String[] parts = typeSignature.split(\"->\");\n        String className = parts[0];\n\n        if (safeClasses.contains(className) && !unsafeMethods.contains(typeSignature)) {\n            return true;\n        }\n\n        if (parts.length > 1) {\n            // It's a method name\n            if (safeMethods.contains(typeSignature)) {\n                return true;\n            }\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-2198-Param-0",
    "old_comment_raw": "@param ann Annotation.",
    "new_code_raw": "    private GridLogger resource(IgniteLoggerResource ann, Object target) {\n        Class<?> cls = ann.categoryClass();\n        String cat = ann.categoryName();\n\n        GridLogger rsrc = getResource();\n\n        if (cls != null && cls != Void.class)\n            rsrc = rsrc.getLogger(cls);\n        else if (cat != null && !cat.isEmpty())\n            rsrc = rsrc.getLogger(cat);\n        else\n            rsrc = rsrc.getLogger(target.getClass());\n\n        return rsrc;\n    }\n"
  },
  {
    "id": "apache_shiro-102-Associations-Param0",
    "old_comment_raw": "@param host the originating host name or IP string of the external party (user, 3rd party product, etc) that is attempting to initiate the session, or  null if not known.",
    "new_code_raw": "    public Session createSession(SessionContext initData) {\r\n        if (initData != null) {\r\n            String host = initData.getHost();\r\n            if (host != null) {\r\n                return new SimpleSession(host);\r\n            }\r\n        }\r\n        return new SimpleSession();\r\n    }\r\n\n"
  },
  {
    "id": "xetorthio_jedis-803-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "  public Long incrBy(final String key, final long increment) {\n    checkIsInMultiOrPipeline();\n    client.incrBy(key, increment);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "todoroo_astrid-982-Param-0",
    "old_comment_raw": "@param requestCode if this equals the requestCode specified by constructor, then results of voice-recognition",
    "new_code_raw": "    public boolean handleActivityResult(int activityRequestCode, int resultCode, Intent data) {\n        boolean result = false;\n        // handle the result of voice recognition, put it into the textfield\n        if (activityRequestCode == this.requestCode) {\n            // this was handled here, even if voicerecognition fails for any reason\n            // so your program flow wont get chaotic if you dont explicitly state\n            // your own requestCodes.\n            result = true;\n            if (resultCode == Activity.RESULT_OK) {\n                // Fill the quickAddBox-view with the string the recognizer thought it could have heard\n                ArrayList<String> match = data.getStringArrayListExtra(\n                        RecognizerIntent.EXTRA_RESULTS);\n                // make sure we only do this if there is SomeThing (tm) returned\n                if (match != null && match.size() > 0 && match.get(0).length() > 0) {\n                    Editable currentText = textField.getText();\n                    String recognizedSpeech = match.get(0);\n\n                    if (currentText.length() > 0) {\n                        // if something is already typed in, append the recognized speech,\n                        // add a space if it isn't already there\n                        textField.append((currentText.toString().endsWith(\" \") ? recognizedSpeech : \" \"+recognizedSpeech ));\n                    } else {\n                        textField.setText(recognizedSpeech);\n                    }\n                }\n            }\n        }\n\n        return result;\n    }\n"
  },
  {
    "id": "haifengl_smile-254-Param-0",
    "old_comment_raw": "@param size the population size of Genetic Algorithm.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, double[][] x, int[] y, int k, ClassificationMeasure measure, BiFunction<double[][], int[], Classifier<double[]>> trainer) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (k < 2) {\n            throw new IllegalArgumentException(\"Invalid k-fold cross validation: \" + k);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        int p = x[0].length;\n        ClassificationFitness fitness = new ClassificationFitness(trainer, measure, x, y, k);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;\n    }\n"
  },
  {
    "id": "apache_ignite-12213-Param-0",
    "old_comment_raw": "@param ver Version.",
    "new_code_raw": "    public IgniteInternalFuture<Boolean> txCommitted(GridCacheVersion xidVer) {\n        final GridFutureAdapter<Boolean> resFut = new GridFutureAdapter<>();\n\n        final IgniteInternalTx tx = cctx.tm().tx(xidVer);\n\n        if (tx != null) {\n            assert tx.near() && tx.local() : tx;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Found near transaction, will wait for completion: \" + tx);\n\n            tx.finishFuture().listen(new CI1<IgniteInternalFuture<IgniteInternalTx>>() {\n                @Override public void apply(IgniteInternalFuture<IgniteInternalTx> fut) {\n                    TransactionState state = tx.state();\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Near transaction finished with state: \" + state);\n\n                    resFut.onDone(state == COMMITTED);\n                }\n            });\n\n            return resFut;\n        }\n\n        Boolean committed = null;\n\n        for (Map.Entry<GridCacheVersion, Boolean> entry : completedVers.entrySet()) {\n            if (entry.getValue() == null)\n                continue;\n\n            if (entry.getKey() instanceof CommittedVersion) {\n                CommittedVersion comm = (CommittedVersion)entry.getKey();\n\n                if (comm.nearVer.equals(xidVer)) {\n                    committed = entry.getValue();\n\n                    break;\n                }\n            }\n        }\n\n        if (log.isDebugEnabled())\n            log.debug(\"Near transaction committed: \" + committed);\n\n        resFut.onDone(committed != null && committed);\n\n        return resFut;\n    }\n"
  },
  {
    "id": "apache_ignite-2958-Param-1",
    "old_comment_raw": "@param keys Key.",
    "new_code_raw": "    public boolean removeAllFromStore(@Nullable GridCacheTx tx, Collection<? extends K> keys) throws IgniteCheckedException {\n        if (F.isEmpty(keys))\n            return true;\n\n        if (keys.size() == 1) {\n            K key = keys.iterator().next();\n\n            return removeFromStore(tx, key);\n        }\n\n        if (store != null) {\n            Collection<? extends K> keys0;\n\n            keys0 = convertPortable ?\n                F.viewReadOnly(keys, new C1<K, K>() {\n                    @Override public K apply(K k) {\n                        return (K)cctx.unwrapPortableIfNeeded(k, false);\n                    }\n                }) :\n                keys;\n\n            if (log.isDebugEnabled())\n                log.debug(\"Removing values from cache store [keys=\" + keys0 + ']');\n\n            try {\n                store.removeAll(tx, keys0);\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Removed values from cache store [keys=\" + keys0 + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-927-Param-0",
    "old_comment_raw": "@param tweet the Tweet to send",
    "new_code_raw": "\tpublic static boolean sendTweet(String tweetTxt) {\n\t\tif (!isEnabled) {\n\t\t\tlogger.debug(\"Twitter client is disabled > execution aborted!\");\n\t\t\treturn false;\n\t\t}\n\n\t\ttry {\n\t\t\t// abbreviate the Tweet to meet the 140 character limit ...\n\t\t\ttweetTxt = StringUtils.abbreviate(tweetTxt, CHARACTER_LIMIT);\n\t\t\t// send the Tweet\n\t\t\tStatus status = client.updateStatus(tweetTxt);\n\t\t\tlogger.debug(\"Successfully sent Tweet '{}'\", status.getText());\n\t\t\treturn true;\n\t\t} catch (TwitterException e) {\n\t\t\tlogger.error(\"Failed to send Tweet '\" + tweetTxt + \"' because of: \" + e.getLocalizedMessage());\n\t\t\treturn false;\n\t\t}\n\t}\n"
  },
  {
    "id": "xetorthio_jedis-478-Param-2",
    "old_comment_raw": "@param end",
    "new_code_raw": "    public String ltrim(final String key, final long start, final long end) {\n        checkIsInMulti();\n        client.ltrim(key, start, end);\n        return client.getStatusCodeReply();\n    }\n"
  },
  {
    "id": "openMF_mifosx-94-Param-0",
    "old_comment_raw": "@param incrementBy Amount used to pay off this charge",
    "new_code_raw": "    public Money updatePaidAmountBy(final Money incrementBy,final Integer installmentNumber) {\n        Money processAmount = Money.zero(incrementBy.getCurrency());\n        if(this.isInstalmentFee()){\n            if(installmentNumber == null){\n                processAmount = getUnpaidInstallmentLoanCharge().updatePaidAmountBy(incrementBy);\n            }else{\n                processAmount = getInstallmentLoanCharge(installmentNumber).updatePaidAmountBy(incrementBy);\n            }\n        }else{\n            processAmount = incrementBy;\n        }\n        Money amountPaidToDate = Money.of(processAmount.getCurrency(), this.amountPaid);\n        final Money amountOutstanding = Money.of(processAmount.getCurrency(), this.amountOutstanding);\n\n        Money amountPaidOnThisCharge = Money.zero(processAmount.getCurrency());\n        if (processAmount.isGreaterThanOrEqualTo(amountOutstanding)) {\n            amountPaidOnThisCharge = amountOutstanding;\n            amountPaidToDate = amountPaidToDate.plus(amountOutstanding);\n            this.amountPaid = amountPaidToDate.getAmount();\n            this.amountOutstanding = BigDecimal.ZERO;\n        } else {\n            amountPaidOnThisCharge = processAmount;\n            amountPaidToDate = amountPaidToDate.plus(processAmount);\n            this.amountPaid = amountPaidToDate.getAmount();\n\n            final Money amountExpected = Money.of(processAmount.getCurrency(), this.amount);\n            this.amountOutstanding = amountExpected.minus(amountPaidToDate).getAmount();\n        }\n\n        this.paid = determineIfFullyPaid();\n\n        return amountPaidOnThisCharge;\n    }\n"
  },
  {
    "id": "xianrendzw_EasyReport-14-Param-1",
    "old_comment_raw": "@param parameter",
    "new_code_raw": "\tpublic static ReportDataSet getDataSet(Queryer queryer, ReportParameter parameter) {\n\t\treturn new DataExecutor(queryer, parameter).execute();\n\t}\n"
  },
  {
    "id": "spockframework_spock-15-Param-0",
    "old_comment_raw": "@param bytecodeName a method name in bytecode",
    "new_code_raw": "  public boolean isAssociatedWithBytecodeName(String name) {\n    if (hasBytecodeName(name)) return true;\n    if (dataProcessor != null && dataProcessor.hasBytecodeName(name)) return true;\n    for (MethodInfo provider : dataProviders)\n      if (provider.hasBytecodeName(name)) return true;\n    return false;\n  }\n"
  },
  {
    "id": "bytedeco_javacpp-116-Param-1",
    "old_comment_raw": "@param outputFilename the output filename of the shared library",
    "new_code_raw": "    int compile(String[] sourceFilenames, String outputFilename, ClassProperties properties, File workingDirectory)\n            throws IOException, InterruptedException {\n        ArrayList<String> command = new ArrayList<String>();\n\n        includeJavaPaths(properties, header);\n\n        String platform  = Loader.getPlatform();\n        String compilerPath = properties.getProperty(\"platform.compiler\");\n        command.add(compilerPath);\n\n        {\n            String p = properties.getProperty(\"platform.sysroot.prefix\", \"\");\n            for (String s : properties.get(\"platform.sysroot\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.includepath.prefix\", \"\");\n            for (String s : properties.get(\"platform.includepath\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                }\n            }\n            for (String s : properties.get(\"platform.includeresource\")) {\n                for (File f : Loader.cacheResources(s)) {\n                    if (f.isDirectory()) {\n                        if (p.endsWith(\" \")) {\n                            command.add(p.trim()); command.add(f.getCanonicalPath());\n                        } else {\n                            command.add(p + f.getCanonicalPath());\n                        }\n                    }\n                }\n            }\n        }\n\n        for (String sourceFilename : sourceFilenames) {\n            command.add(sourceFilename);\n        }\n\n        List<String> allOptions = properties.get(\"platform.compiler.*\");\n        if (!allOptions.contains(\"!default\") && !allOptions.contains(\"default\")) {\n            allOptions.add(0, \"default\");\n        }\n        for (String s : allOptions) {\n            if (s == null || s.length() == 0) {\n                continue;\n            }\n            String p = \"platform.compiler.\" + s;\n            String options = properties.getProperty(p);\n            if (options != null && options.length() > 0) {\n                command.addAll(Arrays.asList(options.split(\" \")));\n            } else if (!\"!default\".equals(s) && !\"default\".equals(s)) {\n                logger.warn(\"Could not get the property named \\\"\" + p + \"\\\"\");\n            }\n        }\n\n        command.addAll(compilerOptions);\n\n        String output = properties.getProperty(\"platform.compiler.output\");\n        for (int i = 1; i < 2 || output != null; i++,\n                output = properties.getProperty(\"platform.compiler.output\" + i)) {\n            if (output != null && output.length() > 0) {\n                command.addAll(Arrays.asList(output.split(\" \")));\n            }\n\n            if (output == null || output.length() == 0 || output.endsWith(\" \")) {\n                command.add(outputFilename);\n            } else {\n                command.add(command.remove(command.size() - 1) + outputFilename);\n            }\n        }\n\n        {\n            String p  = properties.getProperty(\"platform.linkpath.prefix\", \"\");\n            String p2 = properties.getProperty(\"platform.linkpath.prefix2\");\n            for (String s : properties.get(\"platform.linkpath\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                    if (p2 != null) {\n                        if (p2.endsWith(\" \")) {\n                            command.add(p2.trim()); command.add(s);\n                        } else {\n                            command.add(p2 + s);\n                        }\n                    }\n                }\n            }\n            for (String s : properties.get(\"platform.linkresource\")) {\n                for (File f : Loader.cacheResources(s)) {\n                    if (f.isDirectory()) {\n                        if (p.endsWith(\" \")) {\n                            command.add(p.trim()); command.add(f.getCanonicalPath());\n                        } else {\n                            command.add(p + f.getCanonicalPath());\n                        }\n                        if (p2 != null) {\n                            if (p2.endsWith(\" \")) {\n                                command.add(p2.trim()); command.add(f.getCanonicalPath());\n                            } else {\n                                command.add(p2 + f.getCanonicalPath());\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.link.prefix\", \"\");\n            String x = properties.getProperty(\"platform.link.suffix\", \"\");\n            int i = command.size(); // to inverse order and satisfy typical compilers\n            for (String s : properties.get(\"platform.link\")) {\n                String[] libnameversion = s.split(\"#\")[0].split(\"@\");\n                if (libnameversion.length == 3 && libnameversion[1].length() == 0) {\n                    // Only use the version number when the user gave us a double @\n                    s = libnameversion[0] + libnameversion[2];\n                } else {\n                    s = libnameversion[0];\n                }\n                if (p.endsWith(\" \") && x.startsWith(\" \")) {\n                    command.add(i, p.trim()); command.add(i + 1, s); command.add(i + 2, x.trim());\n                } else if (p.endsWith(\" \")) {\n                    command.add(i, p.trim()); command.add(i + 1, s + x);\n                } else if (x.startsWith(\" \")) {\n                    command.add(i, p + s); command.add(i + 1, x.trim());\n                } else {\n                    command.add(i, p + s + x);\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.frameworkpath.prefix\", \"\");\n            for (String s : properties.get(\"platform.frameworkpath\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.framework.prefix\", \"\");\n            String x = properties.getProperty(\"platform.framework.suffix\", \"\");\n            for (String s : properties.get(\"platform.framework\")) {\n                if (p.endsWith(\" \") && x.startsWith(\" \")) {\n                    command.add(p.trim()); command.add(s); command.add(x.trim());\n                } else if (p.endsWith(\" \")) {\n                    command.add(p.trim()); command.add(s + x);\n                } else if (x.startsWith(\" \")) {\n                    command.add(p + s); command.add(x.trim());\n                } else {\n                    command.add(p + s + x);\n                }\n            }\n        }\n\n        String text = \"\";\n        boolean windows = platform.startsWith(\"windows\");\n        for (String s : command) {\n            boolean hasSpaces = s.indexOf(\" \") > 0;\n            if (hasSpaces) {\n                text += windows ? \"\\\"\" : \"'\";\n            }\n            text += s;\n            if (hasSpaces) {\n                text += windows ? \"\\\"\" : \"'\";\n            }\n            text += \" \";\n        }\n        logger.info(text);\n\n        ProcessBuilder pb = new ProcessBuilder(command);\n        // Use the library output path as the working directory so that all\n        // build files, including intermediate ones from MSVC, are dumped there\n        pb.directory(workingDirectory);\n        if (environmentVariables != null) {\n            pb.environment().putAll(environmentVariables);\n        }\n        return pb.inheritIO().start().waitFor();\n    }\n"
  },
  {
    "id": "apache_ignite-12309-Param-0",
    "old_comment_raw": "@param config path to config file.",
    "new_code_raw": "    public static ClusterProperties from(String cfg) {\n        try {\n            Properties props = null;\n\n            if (cfg != null) {\n                props = new Properties();\n\n                props.load(new FileInputStream(cfg));\n            }\n\n            ClusterProperties prop = new ClusterProperties();\n\n            prop.mesosUrl = getStringProperty(MESOS_MASTER_URL, props, DEFAULT_MESOS_MASTER_URL);\n\n            prop.httpSrvHost = getStringProperty(IGNITE_HTTP_SERVER_HOST, props, getNonLoopbackAddress());\n\n            String port = System.getProperty(\"PORT0\");\n\n            if (port != null && !port.isEmpty())\n                prop.httpSrvPort = Integer.valueOf(port);\n            else\n                prop.httpSrvPort = Integer.valueOf(getStringProperty(IGNITE_HTTP_SERVER_PORT, props,\n                    DEFAULT_HTTP_SERVER_PORT));\n\n            prop.clusterName = getStringProperty(IGNITE_CLUSTER_NAME, props, DEFAULT_CLUSTER_NAME);\n\n            prop.userLibsUrl = getStringProperty(IGNITE_USERS_LIBS_URL, props, null);\n            prop.ignitePkgUrl = getStringProperty(IGNITE_PACKAGE_URL, props, null);\n            prop.ignitePkgPath = getStringProperty(IGNITE_PACKAGE_PATH, props, null);\n            prop.licenceUrl = getStringProperty(LICENCE_URL, props, null);\n            prop.igniteCfgUrl = getStringProperty(IGNITE_CONFIG_XML_URL, props, null);\n\n            prop.cpu = getDoubleProperty(IGNITE_TOTAL_CPU, props, UNLIMITED);\n            prop.cpuPerNode = getDoubleProperty(IGNITE_RUN_CPU_PER_NODE, props, UNLIMITED);\n            prop.mem = getDoubleProperty(IGNITE_TOTAL_MEMORY, props, UNLIMITED);\n            prop.memPerNode = getDoubleProperty(IGNITE_MEMORY_PER_NODE, props, UNLIMITED);\n            prop.disk = getDoubleProperty(IGNITE_TOTAL_DISK_SPACE, props, UNLIMITED);\n            prop.diskPerNode = getDoubleProperty(IGNITE_DISK_SPACE_PER_NODE, props, 1024.0);\n            prop.nodeCnt = getDoubleProperty(IGNITE_NODE_COUNT, props, UNLIMITED);\n            prop.minCpu = getDoubleProperty(IGNITE_MIN_CPU_PER_NODE, props, DEFAULT_RESOURCE_MIN_CPU);\n            prop.minMemory = getDoubleProperty(IGNITE_MIN_MEMORY_PER_NODE, props, DEFAULT_RESOURCE_MIN_MEM);\n\n            prop.jvmOpts = getStringProperty(IGNITE_JVM_OPTS, props, \"\");\n\n            prop.igniteVer = getStringProperty(IGNITE_VERSION, props, DEFAULT_IGNITE_VERSION);\n            prop.igniteWorkDir = getStringProperty(IGNITE_WORK_DIR, props, DEFAULT_IGNITE_WORK_DIR);\n            prop.igniteCfg = getStringProperty(IGNITE_CONFIG_XML, props, null);\n            prop.userLibs = getStringProperty(IGNITE_USERS_LIBS, props, null);\n\n            String ptrn = getStringProperty(IGNITE_HOSTNAME_CONSTRAINT, props, null);\n\n            if (ptrn != null) {\n                try {\n                    prop.hostnameConstraint = Pattern.compile(ptrn);\n                }\n                catch (PatternSyntaxException e) {\n                    log.log(Level.WARNING, \"IGNITE_HOSTNAME_CONSTRAINT has invalid pattern. It will be ignore.\", e);\n                }\n            }\n\n            return prop;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5063-Param-0",
    "old_comment_raw": "@param pick Node picked for preloading.",
    "new_code_raw": "        private boolean preloadEntry(ClusterNode pick, int p, GridCacheEntryInfo entry, long topVer)\n            throws IgniteCheckedException {\n            try {\n                GridCacheEntryEx cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isIgfsDataCache() &&\n                        cctx.dht().igfsDataSpaceUsed() > cctx.dht().igfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload IGFS data cache (IGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            null,\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isDrEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (IgniteUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false, null, null, null);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (IgniteInterruptedCheckedException e) {\n                throw e;\n            }\n            catch (IgniteCheckedException e) {\n                throw new IgniteCheckedException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "pubnub_java-61-Param-0",
    "old_comment_raw": "@param string",
    "new_code_raw": "    public static byte[] md5(String input) {\n        MD5Digest digest = new MD5Digest();\n        byte[] bytes = input.getBytes();\n        digest.update(bytes, 0, bytes.length);\n        byte[] md5 = new byte[digest.getDigestSize()];\n        digest.doFinal(md5, 0);\n        StringBuffer hex = new StringBuffer(md5.length * 2);\n        for (int i = 0; i < md5.length; i++) {\n            byte b = md5[i];\n            if ((b & 0xFF) < 0x10) {\n                hex.append(\"0\");\n            }\n            hex.append(Integer.toHexString(b & 0xFF));\n        }\n        return hexStringToByteArray(hex.toString());\n    }\n"
  },
  {
    "id": "zxing_zxing-320-Param-0",
    "old_comment_raw": "@param image booleans representing white/black QR Code modules",
    "new_code_raw": "  public DecoderResult decode(boolean[][] image, Map<DecodeHintType,?> hints)\n      throws ChecksumException, FormatException {\n    int dimension = image.length;\n    BitMatrix bits = new BitMatrix(dimension);\n    for (int i = 0; i < dimension; i++) {\n      for (int j = 0; j < dimension; j++) {\n        if (image[i][j]) {\n          bits.set(j, i);\n        }\n      }\n    }\n    return decode(bits, hints);\n  }\n"
  },
  {
    "id": "Ramotion_paper_onboarding_android-0-Param-0",
    "old_comment_raw": "@param activeElementIndex index of newly active element (from 0)",
    "new_code_raw": "    protected int calculateNewPagerPosition(int newActiveElement) {\n        newActiveElement++;\n        if (newActiveElement <= 0)\n            newActiveElement = 1;\n        int pagerActiveElemCenterPosX = mPagerElementActiveSize / 2\n                + newActiveElement * mPagerElementLeftMargin\n                + (newActiveElement - 1) * (mPagerElementNormalSize + mPagerElementRightMargin);\n        return mRootLayout.getWidth() / 2 - pagerActiveElemCenterPosX;\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-362-Param-0",
    "old_comment_raw": "@param address The Bitcoin address to send the money to.",
    "new_code_raw": "    public Transaction createSend(Address address, Coin value) throws InsufficientMoneyException {\n        SendRequest req = SendRequest.to(address, value);\n        if (params == UnitTestParams.get())\n            req.shuffleOutputs = false;\n        completeTx(req);\n        return req.tx;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-797-Param-1",
    "old_comment_raw": "@param integer",
    "new_code_raw": "  public Long incrBy(final byte[] key, final long increment) {\n    checkIsInMultiOrPipeline();\n    client.incrBy(key, increment);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "gephi_gephi-311-Param-2",
    "old_comment_raw": "@param acm AttributeColumnsManipulator",
    "new_code_raw": "    private JCommandButton prepareJCommandButton(final Table table, final Column[] columns, final AttributeColumnsManipulator acm) {\n        JCommandButton manipulatorButton;\n        if (acm.getIcon() != null) {\n            manipulatorButton = new JCommandButton(acm.getName(), ImageWrapperResizableIcon.getIcon(acm.getIcon(), new Dimension(16, 16)));\n        } else {\n            manipulatorButton = new JCommandButton(acm.getName());\n        }\n        manipulatorButton.setCommandButtonKind(JCommandButton.CommandButtonKind.POPUP_ONLY);\n        manipulatorButton.setDisplayState(CommandButtonDisplayState.MEDIUM);\n        if (acm.getDescription() != null && !acm.getDescription().isEmpty()) {\n            manipulatorButton.setPopupRichTooltip(new RichTooltip(NbBundle.getMessage(DataTableTopComponent.class, \"DataTableTopComponent.RichToolTip.title.text\"), acm.getDescription()));\n        }\n\n        final ArrayList<Column> availableColumns = new ArrayList<Column>();\n        for (final Column column : columns) {\n            if (acm.canManipulateColumn(table, column)) {\n                availableColumns.add(column);\n            }\n        }\n\n        if (!availableColumns.isEmpty()) {\n            manipulatorButton.setPopupCallback(new PopupPanelCallback() {\n\n                public JPopupPanel getPopupPanel(JCommandButton jcb) {\n                    JCommandPopupMenu popup = new JCommandPopupMenu();\n\n                    JCommandMenuButton button;\n                    for (final Column column : availableColumns) {\n\n                        button = new JCommandMenuButton(column.getTitle(), ImageWrapperResizableIcon.getIcon(ImageUtilities.loadImage(\"org/gephi/desktop/datalab/resources/column.png\"), new Dimension(16, 16)));\n                        button.addActionListener(new ActionListener() {\n\n                            public void actionPerformed(ActionEvent e) {\n                                DataLaboratoryHelper.getDefault().executeAttributeColumnsManipulator(acm, table, column);\n                            }\n                        });\n                        popup.addMenuButton(button);\n                    }\n                    return popup;\n                }\n            });\n        } else {\n            manipulatorButton.setEnabled(false);\n        }\n\n        return manipulatorButton;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-781-Param-1",
    "old_comment_raw": "@param user",
    "new_code_raw": "    public AvatarLoader bind(final ImageView view, final Contributor contributor) {\n        if (contributor == null)\n            return setImage(loadingAvatar, view);\n\n        final String avatarUrl = contributor.getAvatarUrl();\n\n        if (TextUtils.isEmpty(avatarUrl))\n            return setImage(loadingAvatar, view);\n\n        final String contributorId = contributor.getLogin();\n\n        BitmapDrawable loadedImage = loaded.get(contributorId);\n        if (loadedImage != null)\n            return setImage(loadedImage, view);\n\n        setImage(loadingAvatar, view, contributorId);\n        fetchAvatarTask(avatarUrl, contributorId, view).execute();\n\n        return this;\n    }\n"
  },
  {
    "id": "apache_curator-274-Param-0",
    "old_comment_raw": "@param parent the parent",
    "new_code_raw": "    public static String makePath(String parent, String... children)\n    {\n        StringBuilder path = new StringBuilder();\n\n        // Add parent piece, with no trailing slash.\n        if ( (parent != null) && (parent.length() > 0) )\n        {\n            if ( !parent.startsWith(PATH_SEPARATOR) )\n            {\n                path.append(PATH_SEPARATOR);\n            }\n            if ( parent.endsWith(PATH_SEPARATOR) )\n            {\n                path.append(parent.substring(0, parent.length() - 1));\n            }\n            else\n            {\n                path.append(parent);\n            }\n        }\n\n        if (children == null || children.length == 0)\n        {\n            // Special case, empty parent and child\n            if ( path.length() == 0 )\n            {\n                return PATH_SEPARATOR;\n            }\n            return path.toString();\n        }\n\n        for (String child : children)\n        {\n            if ( (child == null) || (child.length() == 0) || (child.equals(PATH_SEPARATOR)) )\n            {\n                // Special case, empty parent and child\n                if ( path.length() == 0 )\n                {\n                    path.append(PATH_SEPARATOR);\n                }\n\n                continue;\n            }\n\n            // Now add the separator between parent and child.\n            path.append(PATH_SEPARATOR);\n\n            if ( child.startsWith(PATH_SEPARATOR) )\n            {\n                child = child.substring(1);\n            }\n\n            if ( child.endsWith(PATH_SEPARATOR) )\n            {\n                child = child.substring(0, child.length() - 1);\n            }\n\n            // Finally, add the child.\n            path.append(child);\n        }\n\n        return path.toString();\n    }\n"
  },
  {
    "id": "apache_ignite-12083-Param-1",
    "old_comment_raw": "@param ggfsCfg GGFS configuration.",
    "new_code_raw": "    protected IgniteConfiguration getConfiguration(String gridName, IgfsConfiguration igfsCfg) throws Exception {\n        IgniteConfiguration cfg = IgnitionEx.loadConfiguration(\"config/hadoop/default-config.xml\").get1();\n\n        assert cfg != null;\n\n        cfg.setGridName(gridName);\n\n        cfg.setIncludeEventTypes(concat(EVTS_IGFS, EVT_TASK_FAILED, EVT_TASK_FINISHED, EVT_JOB_MAPPED));\n\n        cfg.setIgfsConfiguration(igfsCfg);\n\n        cfg.setCacheConfiguration(getCacheConfiguration(gridName));\n\n        cfg.setHadoopConfiguration(null);\n\n        TcpDiscoverySpi discoSpi = new TcpDiscoverySpi();\n\n        discoSpi.setIpFinder(new TcpDiscoveryVmIpFinder(true));\n\n        cfg.setDiscoverySpi(discoSpi);\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_ignite-5312-Param-2",
    "old_comment_raw": "@param dest Destination path.",
    "new_code_raw": "    public boolean renameDual(final IgfsSecondaryFileSystem fs, final IgfsPath src, final IgfsPath dest) throws\n        IgniteCheckedException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert src != null;\n                assert dest != null;\n\n                if (src.parent() == null)\n                    return false; // Root directory cannot be renamed.\n\n                // Events to fire (can be done outside of a transaction).\n                final Collection<IgfsEvent> pendingEvts = new LinkedList<>();\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<IgfsPath, IgfsFileInfo> infos) throws Exception {\n                        IgfsFileInfo srcInfo = infos.get(src);\n                        IgfsFileInfo srcParentInfo = infos.get(src.parent());\n                        IgfsFileInfo destInfo = infos.get(dest);\n                        IgfsFileInfo destParentInfo = dest.parent() != null ? infos.get(dest.parent()) : null;\n\n                        // Source path and destination (or destination parent) must exist.\n                        if (srcInfo == null)\n                            throw fsException(new IgfsFileNotFoundException(\"Failed to rename \" +\n                                    \"(source path not found): \" + src));\n\n                        if (destInfo == null && destParentInfo == null)\n                            throw fsException(new IgfsFileNotFoundException(\"Failed to rename \" +\n                                \"(destination path not found): \" + dest));\n\n                        // Delegate to the secondary file system.\n                        fs.rename(src, dest);\n\n                        // Rename was successful, perform compensation in the local file system.\n                        if (destInfo == null) {\n                            // Move and rename.\n                            assert destParentInfo != null;\n\n                            moveNonTx(srcInfo.id(), src.name(), srcParentInfo.id(), dest.name(), destParentInfo.id());\n                        }\n                        else {\n                            // Move.\n                            if (destInfo.isFile())\n                                throw fsException(\"Failed to rename the path in the local file system \" +\n                                    \"because destination path already exists and it is a file: \" + dest);\n                            else\n                                moveNonTx(srcInfo.id(), src.name(), srcParentInfo.id(), src.name(), destInfo.id());\n                        }\n\n                        // Record event if needed.\n                        if (srcInfo.isFile()) {\n                            if (evts.isRecordable(EVT_IGFS_FILE_RENAMED))\n                                pendingEvts.add(new IgfsEvent(\n                                    src,\n                                    destInfo == null ? dest : new IgfsPath(dest, src.name()),\n                                    locNode,\n                                    EVT_IGFS_FILE_RENAMED));\n                        }\n                        else if (evts.isRecordable(EVT_IGFS_DIR_RENAMED))\n                            pendingEvts.add(new IgfsEvent(src, dest, locNode, EVT_IGFS_DIR_RENAMED));\n\n                        return true;\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Path rename in DUAL mode failed [source=\" + src + \", destination=\" + dest + ']',\n                            err);\n\n                        throw new IgniteCheckedException(\"Failed to rename the path due to secondary file system \" +\n                            \"exception: \" + src, err);\n                    }\n                };\n\n                try {\n                    return synchronizeAndExecute(task, fs, false, src, dest);\n                }\n                finally {\n                    for (IgfsEvent evt : pendingEvts)\n                        evts.record(evt);\n                }\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to rename in DUAL mode because Grid is stopping [src=\" + src +\n                \", dest=\" + dest + ']');\n    }\n"
  },
  {
    "id": "nytimes_Store-32-Param-0",
    "old_comment_raw": "@param barCode resource identifier",
    "new_code_raw": "    Observable<Parsed> fetchAndPersist(@Nonnull final Key key) {\n        try {\n            return inFlightRequests.get(key, new Callable<Observable<Parsed>>() {\n                @Nonnull\n                @Override\n                public Observable<Parsed> call() {\n                    return response(key);\n                }\n            });\n        } catch (ExecutionException e) {\n            return Observable.empty();\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-4431-Param-0",
    "old_comment_raw": "@param m GGFS metrics.",
    "new_code_raw": "    public static VisorGgfsMetrics from(IgfsMetrics m) {\n        assert m != null;\n\n        VisorGgfsMetrics metrics = new VisorGgfsMetrics();\n\n        metrics.totalSpaceSize(m.maxSpaceSize());\n        metrics.usedSpaceSize(m.localSpaceSize());\n        metrics.foldersCount(m.directoriesCount());\n        metrics.filesCount(m.filesCount());\n        metrics.filesOpenedForRead(m.filesOpenedForRead());\n        metrics.filesOpenedForWrite(m.filesOpenedForWrite());\n        metrics.blocksRead(m.blocksReadTotal());\n        metrics.blocksReadRemote(m.blocksReadRemote());\n        metrics.blocksWritten(m.blocksWrittenTotal());\n        metrics.blocksWrittenRemote(m.blocksWrittenRemote());\n        metrics.bytesRead(m.bytesRead());\n        metrics.bytesReadTime(m.bytesReadTime());\n        metrics.bytesWritten(m.bytesWritten());\n        metrics.bytesWriteTime(m.bytesWriteTime());\n\n        return metrics;\n    }\n"
  },
  {
    "id": "alibaba_Sentinel-66-Param-0",
    "old_comment_raw": "@param time a valid timestamp",
    "new_code_raw": "    public WindowWrap<T> getPreviousWindow(long timeMillis) {\n        if (timeMillis < 0) {\n            return null;\n        }\n        int idx = calculateTimeIdx(timeMillis);\n\n        long previousTime = timeMillis - windowLengthInMs;\n        WindowWrap<T> wrap = array.get(idx);\n\n        if (wrap == null || isWindowDeprecated(wrap)) {\n            return null;\n        }\n\n        if (wrap.windowStart() + windowLengthInMs < previousTime) {\n            return null;\n        }\n\n        return wrap;\n    }\n"
  },
  {
    "id": "apache_ignite-5020-Param-2",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public int offheapEntriesCount(boolean primary, boolean backup, AffinityTopologyVersion topVer) throws IgniteCheckedException {\n        assert primary || backup;\n\n        if (!offheapEnabled)\n            return 0;\n\n        if (!(primary && backup)) {\n            Set<Integer> parts = primary ? cctx.affinity().primaryPartitions(cctx.localNodeId(), topVer) :\n                cctx.affinity().backupPartitions(cctx.localNodeId(), topVer);\n\n            return (int)offheap.entriesCount(spaceName, parts);\n        }\n        else\n            return (int)offheap.entriesCount(spaceName);\n    }\n"
  },
  {
    "id": "mockito_mockito-1203-Param-0",
    "old_comment_raw": "@param testClass",
    "new_code_raw": "    private Set<Field> scanForInjection(final Object testClassInstance, final Class<?> clazz) {\n        Set<Field> mockDependentFields = new HashSet<Field>();\n        Field[] fields = clazz.getDeclaredFields();\n        for (Field field : fields) {\n            if (null != field.getAnnotation(InjectMocks.class)) {\n                assertNoAnnotations(field, Mock.class, MockitoAnnotations.Mock.class, Captor.class);\n                mockDependentFields.add(field);\n            }\n        }\n\n        return mockDependentFields;\n    }\n"
  },
  {
    "id": "apache_ignite-6623-Param-1",
    "old_comment_raw": "@param c Cache.",
    "new_code_raw": "    public static VisorCacheMetrics from(IgniteEx ignite, GridCache c) {\n        VisorCacheMetrics cm = new VisorCacheMetrics();\n\n        CacheMetrics m = c.metrics();\n\n        GridCacheProcessor cacheProcessor = ignite.context().cache();\n\n        cm.name = c.name();\n        cm.mode = cacheProcessor.cacheMode(c.name());\n        cm.sys = cacheProcessor.systemCache(c.name());\n\n        cm.size = m.getSize();\n        cm.keySize = m.getKeySize();\n\n        cm.reads = m.getCacheGets();\n        cm.writes = m.getCachePuts() + m.getCacheRemovals();\n        cm.hits = m.getCacheHits();\n        cm.misses = m.getCacheMisses();\n\n        cm.txCommits = m.getCacheTxCommits();\n        cm.txRollbacks = m.getCacheTxRollbacks();\n\n        cm.avgTxCommitTime = m.getAverageTxCommitTime();\n        cm.avgTxRollbackTime = m.getAverageTxRollbackTime();\n\n        cm.puts = m.getCachePuts();\n        cm.removals = m.getCacheRemovals();\n        cm.evictions = m.getCacheEvictions();\n\n        cm.avgReadTime = m.getAverageGetTime();\n        cm.avgPutTime = m.getAveragePutTime();\n        cm.avgRemovalTime = m.getAverageRemoveTime();\n\n        cm.readsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageGetTime());\n        cm.writesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAveragePutTime());\n        cm.hitsPerSec = -1;\n        cm.missesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageRemoveTime());\n        cm.commitsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxCommitTime());\n        cm.rollbacksPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxRollbackTime());\n\n        cm.qryMetrics = VisorCacheQueryMetrics.from(c.queries().metrics());\n\n        cm.dhtEvictQueueCurrSize = m.getDhtEvictQueueCurrentSize();\n        cm.txThreadMapSize = m.getTxThreadMapSize();\n        cm.txXidMapSize = m.getTxXidMapSize();\n        cm.txCommitQueueSize = m.getTxCommitQueueSize();\n        cm.txPrepareQueueSize = m.getTxPrepareQueueSize();\n        cm.txStartVerCountsSize = m.getTxStartVersionCountsSize();\n        cm.txCommittedVersionsSize = m.getTxCommittedVersionsSize();\n        cm.txRolledbackVersionsSize = m.getTxRolledbackVersionsSize();\n        cm.txDhtThreadMapSize = m.getTxDhtThreadMapSize();\n        cm.txDhtXidMapSize = m.getTxDhtXidMapSize();\n        cm.txDhtCommitQueueSize = m.getTxDhtCommitQueueSize();\n        cm.txDhtPrepareQueueSize = m.getTxDhtPrepareQueueSize();\n        cm.txDhtStartVerCountsSize = m.getTxDhtStartVersionCountsSize();\n        cm.txDhtCommittedVersionsSize = m.getTxDhtCommittedVersionsSize();\n        cm.txDhtRolledbackVersionsSize = m.getTxDhtRolledbackVersionsSize();\n\n        return cm;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-422-Param-1",
    "old_comment_raw": "@param local whether to only create enough chunks to max out all cores on one node only",
    "new_code_raw": "  private Frame reBalance(final Frame fr, long seed) {\n    return force_load_balance || shuffle_training_data ? MRUtils.shuffleAndBalance(fr, seed, shuffle_training_data) : fr;\n  }\n"
  },
  {
    "id": "apache_ignite-2233-Param-1",
    "old_comment_raw": "@param pubKey Public key to be tested with.",
    "new_code_raw": "    private static boolean verify0(String jarName, PublicKey pubKey, boolean allSigned, IgniteLogger log)\n        throws IOException {\n        JarFile jarFile = null;\n\n        try {\n            jarFile = new JarFile(jarName, true);\n\n            Manifest manifest = jarFile.getManifest();\n\n            // Manifest must be included in signed GAR file.\n            if (manifest == null)\n                return pubKey == null;\n\n            Set<String> manifestFiles = getSignedFiles(manifest);\n\n            Enumeration<JarEntry> entries = jarFile.entries();\n\n            while (entries.hasMoreElements()) {\n                JarEntry jarEntry = entries.nextElement();\n\n                if (jarEntry.isDirectory())\n                    continue;\n\n                // Verify by reading the file if altered.\n                // Will return quietly if no problem.\n                verifyDigestsImplicitly(jarFile.getInputStream(jarEntry));\n\n                if (verifyEntry(jarEntry, manifest, pubKey, allSigned, false) == false)\n                    return false;\n\n                manifestFiles.remove(jarEntry.getName());\n            }\n\n            return manifestFiles.size() <= 0;\n        }\n        catch (SecurityException e) {\n            if (log.isDebugEnabled())\n                log.debug(\"Got security error (ignoring): \" + e.getMessage());\n        }\n        finally {\n            U.close(jarFile, log);\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-12149-Param-0",
    "old_comment_raw": "@param prj Cluster to check size for.",
    "new_code_raw": "    public static boolean checkMinTopologySize(ClusterGroup grp, int size) {\n        int prjSize = grp.nodes().size();\n\n        if (prjSize < size) {\n            System.err.println(\">>> Please start at least \" + size + \" cluster nodes to run example.\");\n\n            return false;\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_shiro-906-Param-1",
    "old_comment_raw": "@param response the outgoing ServletResponse",
    "new_code_raw": "    protected boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception {\n        return true;\n    }\n"
  },
  {
    "id": "eclipse_rt.equinox.framework-53-Associations-Param0",
    "old_comment_raw": "@param target the managed target to lookup",
    "new_code_raw": "\tpublic File lookup(String managedFile, boolean add) throws IOException {\n\t\tif (!open)\n\t\t\tthrow new IOException(EclipseAdaptorMsg.fileManager_notOpen);\n\t\tEntry entry = (Entry) table.get(managedFile);\n\t\tif (entry == null) {\n\t\t\tif (add) {\n\t\t\t\tadd(managedFile);\n\t\t\t\tentry = (Entry) table.get(managedFile);\n\t\t\t} else {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\treturn new File(getAbsolutePath(managedFile + '.' + entry.getReadId()));\n\t}\n\n"
  },
  {
    "id": "apache_ignite-4397-Param-0",
    "old_comment_raw": "@param fs Secondary file system.",
    "new_code_raw": "    public boolean deleteDual(final Igfs fs, final IgfsPath path, final boolean recursive)\n        throws IgniteCheckedException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert path != null;\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<IgfsPath, IgfsFileInfo> infos) throws Exception {\n                        IgfsFileInfo info = infos.get(path);\n\n                        if (info == null)\n                            return false; // File doesn't exist in the secondary file system.\n\n                        if (!fs.delete(path, recursive))\n                            return false; // Delete failed remotely.\n\n                        if (path.parent() != null) {\n                            assert infos.containsKey(path.parent());\n\n                            softDeleteNonTx(infos.get(path.parent()).id(), path.name(), info.id());\n                        }\n                        else {\n                            assert ROOT_ID.equals(info.id());\n\n                            softDeleteNonTx(null, path.name(), info.id());\n                        }\n\n                        // Update the deleted file info with path information for delete worker.\n                        id2InfoPrj.invoke(info.id(), new UpdatePath(path));\n\n                        return true; // No additional handling is required.\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Path delete in DUAL mode failed [path=\" + path + \", recursive=\" + recursive + ']',\n                            err);\n\n                        throw new IgniteCheckedException(\"Failed to delete the path due to secondary file system exception: \",\n                            err);\n                    }\n                };\n\n                Boolean res = synchronizeAndExecute(task, fs, false, Collections.singleton(TRASH_ID), path);\n\n                delWorker.signal();\n\n                return res;\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to delete in DUAL mode because Grid is stopping: \" + path);\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1292-Param-0",
    "old_comment_raw": "@param clientSession for current request",
    "new_code_raw": "    protected Response handleBrowserAuthenticationRequest(LoginSessionModel loginSession, LoginProtocol protocol, boolean isPassive, boolean redirectToAuthentication) {\n        AuthenticationFlowModel flow = getAuthenticationFlow();\n        String flowId = flow.getId();\n        AuthenticationProcessor processor = createProcessor(loginSession, flowId, LoginActionsService.AUTHENTICATE_PATH);\n        event.detail(Details.CODE_ID, loginSession.getId());\n        if (isPassive) {\n            // OIDC prompt == NONE or SAML 2 IsPassive flag\n            // This means that client is just checking if the user is already completely logged in.\n            // We cancel login if any authentication action or required action is required\n            try {\n                if (processor.authenticateOnly() == null) {\n                    // processor.attachSession();\n                } else {\n                    Response response = protocol.sendError(loginSession, Error.PASSIVE_LOGIN_REQUIRED);\n                    session.loginSessions().removeLoginSession(realm, loginSession);\n                    return response;\n                }\n                if (processor.isActionRequired()) {\n                    Response response = protocol.sendError(loginSession, Error.PASSIVE_INTERACTION_REQUIRED);\n                    session.loginSessions().removeLoginSession(realm, loginSession);\n                    return response;\n                }\n\n                // Attach session once no requiredActions or other things are required\n                processor.attachSession();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n            return processor.finishAuthentication(protocol);\n        } else {\n            try {\n                // TODO: Check if this is required...\n                RestartLoginCookie.setRestartCookie(session, realm, clientConnection, uriInfo, loginSession);\n                if (redirectToAuthentication) {\n                    return processor.redirectToFlow();\n                }\n                return processor.authenticate();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n        }\n    }\n"
  },
  {
    "id": "haifengl_smile-234-Param-4",
    "old_comment_raw": "@param x training instances.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, BiFunction<double[][], int[], Classifier<double[]>> trainer, ClassificationMeasure measure, double[][] x, int[] y, int k) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (k < 2) {\n            throw new IllegalArgumentException(\"Invalid k-fold cross validation: \" + k);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        int p = x[0].length;\n        ClassificationFitness fitness = new ClassificationFitness(trainer, measure, x, y, k);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;\n    }\n"
  },
  {
    "id": "apache_ignite-13190-Param-1",
    "old_comment_raw": "@param defaultValue Default value.",
    "new_code_raw": "    private int getIntProperty(String name, int dfltVal) {\n        String val = manager.getProperty(name);\n\n        if (val == null)\n            return dfltVal;\n\n        try {\n            return Integer.parseInt(val.trim());\n        }\n        catch (Exception ex) {\n            ex.printStackTrace();\n\n            return dfltVal;\n        }\n    }\n"
  },
  {
    "id": "bauerca_drag_sort_listview-16-Param-0",
    "old_comment_raw": "@param position",
    "new_code_raw": "    private int getShuffleEdge(int position, int top) {\n\n        final int numHeaders = getHeaderViewsCount();\n        final int numFooters = getFooterViewsCount();\n\n        // shuffle edges are defined between items that can be\n        // dragged; there are N-1 of them if there are N draggable\n        // items.\n\n        if (position <= numHeaders || (position >= getCount() - numFooters)) {\n            return top;\n        }\n\n        int divHeight = getDividerHeight();\n\n        int edge;\n\n        int maxBlankHeight = mFloatViewHeight - mItemHeightCollapsed;\n        int childHeight = getChildHeight(position);\n        int itemHeight = getItemHeight(position);\n\n        // first calculate top of item given that floating View is\n        // centered over src position\n        int otop = top;\n        if (mSecondExpPos <= mSrcPos) {\n            // items are expanded on and/or above the source position\n\n            if (position == mSecondExpPos && mFirstExpPos != mSecondExpPos) {\n                if (position == mSrcPos) {\n                    otop = top + itemHeight - mFloatViewHeight;\n                } else {\n                    int blankHeight = itemHeight - childHeight;\n                    otop = top + blankHeight - maxBlankHeight;\n                }\n            } else if (position > mSecondExpPos && position <= mSrcPos) {\n                otop = top - maxBlankHeight;\n            }\n\n        } else {\n            // items are expanded on and/or below the source position\n\n            if (position > mSrcPos && position <= mFirstExpPos) {\n                otop = top + maxBlankHeight;\n            } else if (position == mSecondExpPos && mFirstExpPos != mSecondExpPos) {\n                int blankHeight = itemHeight - childHeight;\n                otop = top + blankHeight;\n            }\n        }\n\n        // otop is set\n        if (position <= mSrcPos) {\n            edge = otop + (mFloatViewHeight - divHeight - getChildHeight(position - 1)) / 2;\n        } else {\n            edge = otop + (childHeight - divHeight - mFloatViewHeight) / 2;\n        }\n\n        return edge;\n    }\n"
  },
  {
    "id": "haifengl_smile-234-Param-6",
    "old_comment_raw": "@param k k-fold cross validation for the evaluation.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, BiFunction<double[][], int[], Classifier<double[]>> trainer, ClassificationMeasure measure, double[][] x, int[] y, int k) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (k < 2) {\n            throw new IllegalArgumentException(\"Invalid k-fold cross validation: \" + k);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        int p = x[0].length;\n        ClassificationFitness fitness = new ClassificationFitness(trainer, measure, x, y, k);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;\n    }\n"
  },
  {
    "id": "sonatype_sonatype-peaberry-14-Associations-Param0",
    "old_comment_raw": "@param attributes service attributes",
    "new_code_raw": "  public static AttributeFilter attributes(final Map<String, ?> sampleAttributes) {\n    return new AttributeFilter() {\n      public boolean matches(final Map<String, ?> attributes) {\n        return null != attributes && attributes.entrySet().containsAll(sampleAttributes.entrySet());\n      }\n    };\n  }\n\n"
  },
  {
    "id": "openhab_openhab1_addons-954-Param-3",
    "old_comment_raw": "@param pos",
    "new_code_raw": "\tprivate Object getValue(ByteBuffer byteBuffer, TelegramValue telegramValue) {\n\n\t\tString type = telegramValue.getType().toLowerCase();\n\t\tint pos = telegramValue.getPos() != null ? telegramValue.getPos() : -1;\n\n\t\tObject value = null;\n\n\t\t// requested pos is greater as whole buffer\n\t\tif(pos > byteBuffer.position()) {\n\t\t\tlogger.warn(\"eBus buffer pos error! Can happen ...\");\n\t\t}\n\n\t\t// replace similar data types\n\t\tif(type.equals(\"uint\"))\n\t\t\ttype = \"word\";\n\t\tif(type.equals(\"byte\"))\n\t\t\ttype = \"uchar\";\n\n\t\tbyte[] bytes = null;\n\t\tif(type.equals(\"data2b\") || type.equals(\"data2c\") || type.equals(\"word\")) {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos), byteBuffer.get(pos-1)};\n\t\t} else {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos-1)};\n\t\t}\n\n\t\tif(type.equals(\"bit\")) {\n\t\t\tint bit = telegramValue.getBit();\n\t\t\tvalue = bytes[0];\n\n\t\t\tboolean isSet = ((Byte)value >> bit& 0x1) == 1;\n\t\t\tvalue = isSet;\n\n\t\t} else {\n\t\t\tvalue = NumberUtils.toBigDecimal(EBusCodecUtils.decode(type, bytes, telegramValue.getReplaceValue()));\n\t\t}\n\n\t\t// if BigDecimal check for min, max and replace value\n\t\tif(value instanceof BigDecimal) {\n\t\t\tBigDecimal b = (BigDecimal)value;\n\n\t\t\t// multiply before check min and max\n\t\t\tif(b != null && telegramValue.getFactor() != null) {\n\t\t\t\tlogger.trace(\"Value multiplied ...\");\n\t\t\t\tvalue = b = b.multiply(telegramValue.getFactor());\n\t\t\t}\n\n\t\t\t// value is below min value, return null\n\t\t\tif(telegramValue.getMin() != null && b != null && b.compareTo(telegramValue.getMin()) == -1) {\n\t\t\t\tlogger.trace(\"Minimal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\n\t\t\t\t// value is above max value, return null\n\t\t\t} else if (telegramValue.getMax() != null && b != null && b.compareTo(telegramValue.getMax()) == 1) {\n\t\t\t\tlogger.trace(\"Maximal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\t\t\t}\n\n\t\t}\n\n\t\treturn value;\n\t}\n"
  },
  {
    "id": "keyboardsurfer_Crouton-30-Param-0",
    "old_comment_raw": "@param textColor The resource id of the text colorResourceId.",
    "new_code_raw": "\t\tpublic Builder setTextColor(int textColorResourceId) {\n\t\t\tthis.textColorResourceId = textColorResourceId;\n\n\t\t\treturn this;\n\t\t}\n"
  },
  {
    "id": "apache_ignite-5060-Param-0",
    "old_comment_raw": "@param key Key to map.",
    "new_code_raw": "    private Collection<ClusterNode> mapKey(KeyCacheObject key, long topVer, boolean fastMap) {\n        GridCacheAffinityManager affMgr = cctx.affinity();\n\n        // If we can send updates in parallel - do it.\n        return fastMap ?\n            cctx.topology().nodes(affMgr.partition(key), topVer) :\n            Collections.singletonList(affMgr.primary(key, topVer));\n    }\n"
  },
  {
    "id": "apache_ignite-12330-Param-2",
    "old_comment_raw": "@param segments Segments.",
    "new_code_raw": "    protected ReuseList createReuseList(int cacheId, PageMemory pageMem, long[] rootIds, boolean initNew)\n        throws IgniteCheckedException {\n        return null;\n    }\n"
  },
  {
    "id": "apache_ignite-5314-Param-0",
    "old_comment_raw": "@param fs Secondary file system.",
    "new_code_raw": "    public IgfsFileInfo updateDual(final IgfsSecondaryFileSystem fs, final IgfsPath path, final Map<String, String> props)\n        throws IgniteCheckedException {\n        assert fs != null;\n        assert path != null;\n        assert props != null && !props.isEmpty();\n\n        if (busyLock.enterBusy()) {\n            try {\n                SynchronizationTask<IgfsFileInfo> task = new SynchronizationTask<IgfsFileInfo>() {\n                    @Override public IgfsFileInfo onSuccess(Map<IgfsPath, IgfsFileInfo> infos)\n                        throws Exception {\n                        if (infos.get(path) == null)\n                            return null;\n\n                        fs.update(path, props);\n\n                        assert path.parent() == null || infos.get(path.parent()) != null;\n\n                        return updatePropertiesNonTx(infos.get(path.parent()).id(), infos.get(path).id(), path.name(),\n                            props);\n                    }\n\n                    @Override public IgfsFileInfo onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Path update in DUAL mode failed [path=\" + path + \", properties=\" + props + ']',\n                            err);\n\n                        throw new IgniteCheckedException(\"Failed to update the path due to secondary file system exception: \" +\n                            path, err);\n                    }\n                };\n\n                return synchronizeAndExecute(task, fs, false, path);\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to update in DUAL mode because Grid is stopping: \" + path);\n    }\n"
  },
  {
    "id": "xetorthio_jedis-789-Param-1",
    "old_comment_raw": "@param strings",
    "new_code_raw": "    public Long lpush(final byte[] key, final byte[]... string) {\n        checkIsInMulti();\n        client.lpush(key, string);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-2013-Param-0",
    "old_comment_raw": "@param parentId Parent file ID.",
    "new_code_raw": "    public IgniteUuid putIfAbsent(IgniteUuid parentId, String fileName, GridGgfsFileInfo newFileInfo)\n        throws GridException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert validTxState(false);\n                assert parentId != null;\n                assert fileName != null;\n                assert newFileInfo != null;\n\n                IgniteUuid res = null;\n\n                GridCacheTx tx = metaCache.txStart(PESSIMISTIC, REPEATABLE_READ);\n\n                try {\n                    res = putIfAbsentNonTx(parentId, fileName, newFileInfo);\n\n                    tx.commit();\n                }\n                finally {\n                    tx.close();\n                }\n\n                return res;\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to put file because Grid is stopping [parentId=\" + parentId +\n                \", fileName=\" + fileName + \", newFileInfo=\" + newFileInfo + ']');\n    }\n"
  },
  {
    "id": "apache_ignite-11622-Param-0",
    "old_comment_raw": "@param grid Grid",
    "new_code_raw": "    private static UUID primaryId(Ignite ignite, Object key) {\n        GridCacheAffinity aff = ignite.cache(null).cache().affinity();\n\n        Collection<GridNode> affNodes = aff.mapPartitionToPrimaryAndBackups(aff.partition(key));\n\n        GridNode first = F.first(affNodes);\n\n        assert first != null;\n\n        return first.id();\n    }\n"
  },
  {
    "id": "apache_ignite-1798-Param-0",
    "old_comment_raw": "@param c Grid configuration.",
    "new_code_raw": "    public static VisorRestConfiguration from(IgniteConfiguration c) {\n        VisorRestConfiguration cfg = new VisorRestConfiguration();\n\n        GridClientConnectionConfiguration clnCfg = c.getClientConnectionConfiguration();\n\n        boolean restEnabled = clnCfg != null;\n\n        cfg.restEnabled(restEnabled);\n\n        if (restEnabled) {\n            cfg.tcpSslEnabled(clnCfg.isRestTcpSslEnabled());\n            cfg.accessibleFolders(clnCfg.getRestAccessibleFolders());\n            cfg.jettyPath(clnCfg.getRestJettyPath());\n            cfg.jettyHost(getProperty(GG_JETTY_HOST));\n            cfg.jettyPort(intValue(GG_JETTY_PORT, null));\n            cfg.tcpHost(clnCfg.getRestTcpHost());\n            cfg.tcpPort(clnCfg.getRestTcpPort());\n            cfg.tcpSslContextFactory(compactClass(clnCfg.getRestTcpSslContextFactory()));\n        }\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_shiro-324-Param-1",
    "old_comment_raw": "@param account the Account stored in the system matching the token principal.",
    "new_code_raw": "    public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) {\n        Object tokenCredentials = getCredentials(token);\n        Object accountCredentials = getCredentials(info);\n        return equals(tokenCredentials, accountCredentials);\n    }\n"
  },
  {
    "id": "apache_ignite-1939-Param-1",
    "old_comment_raw": "@param job Callable job.",
    "new_code_raw": "    private GridFuture<Integer> callAsync(int idx, Callable<Integer> job, @Nullable IgnitePredicate<ClusterNode> p)\n        throws GridException {\n        assert idx >= 0 && idx < NODES_CNT;\n        assert job != null;\n\n        execCntr.set(0);\n\n        GridCompute comp = p != null ? compute(grid(idx).forPredicate(p)) : grid(idx).compute();\n\n        comp = comp.enableAsync();\n\n        comp.call(job);\n\n        return comp.future();\n    }\n"
  },
  {
    "id": "eclipse_californium-27-Associations-Param0",
    "old_comment_raw": "@param byteArray the potentially encrypted fragment.",
    "new_code_raw": "\tprivate byte[] decryptFragment(byte[] ciphertextFragment) throws GeneralSecurityException {\r\n\t\tif (session == null) {\r\n\t\t\treturn ciphertextFragment;\r\n\t\t}\r\n\r\n\t\tbyte[] fragment = ciphertextFragment;\r\n\r\n\t\tCipherSuite cipherSuite = session.getReadState().getCipherSuite();\r\n\t\tLOGGER.log(Level.FINER, \"Decrypting record fragment using current read state\\n{0}\", session.getReadState());\r\n\t\t\r\n\t\tswitch (cipherSuite.getCipherType()) {\r\n\t\tcase NULL:\r\n\t\t\t// do nothing\r\n\t\t\tbreak;\r\n\t\t\t\r\n\t\tcase AEAD:\r\n\t\t\tfragment = decryptAEAD(ciphertextFragment);\r\n\t\t\tbreak;\r\n\t\t\t\r\n\t\tcase BLOCK:\r\n\t\t\tfragment = decryptBlockCipher(ciphertextFragment);\r\n\t\t\tbreak;\r\n\t\t\t\r\n\t\tcase STREAM:\r\n\t\t\t// Currently, Scandium does not support any stream ciphers\r\n\t\t\t// RC4 is explicitly ruled out from being used in DTLS\r\n\t\t\t// see http://tools.ietf.org/html/rfc6347#section-4.1.2.2\r\n\t\t\tbreak;\r\n\r\n\t\tdefault:\r\n\t\t\tbreak;\r\n\t\t}\r\n\r\n\t\treturn fragment;\r\n\t}\r\n\n"
  },
  {
    "id": "apache_ignite-12112-Param-1",
    "old_comment_raw": "@param c Grid configuration.",
    "new_code_raw": "    public static VisorBasicConfiguration from(IgniteEx g, IgniteConfiguration c) {\n        VisorBasicConfiguration cfg = new VisorBasicConfiguration();\n\n        cfg.gridName(c.getGridName());\n        cfg.ggHome(getProperty(IGNITE_HOME, c.getIgniteHome()));\n        cfg.localHost(getProperty(IGNITE_LOCAL_HOST, c.getLocalHost()));\n        cfg.nodeId(g.localNode().id());\n        cfg.marshaller(compactClass(c.getMarshaller()));\n        cfg.deploymentMode(compactObject(c.getDeploymentMode()));\n        cfg.daemon(boolValue(IGNITE_DAEMON, c.isDaemon()));\n        cfg.jmxRemote(g.isJmxRemoteEnabled());\n        cfg.restart(g.isRestartEnabled());\n        cfg.networkTimeout(c.getNetworkTimeout());\n        cfg.logger(compactClass(c.getGridLogger()));\n        cfg.discoStartupDelay(c.getDiscoveryStartupDelay());\n        cfg.mBeanServer(compactClass(c.getMBeanServer()));\n        cfg.noAscii(boolValue(IGNITE_NO_ASCII, false));\n        cfg.noDiscoOrder(boolValue(IGNITE_NO_DISCO_ORDER, false));\n        cfg.noShutdownHook(boolValue(IGNITE_NO_SHUTDOWN_HOOK, false));\n        cfg.programName(getProperty(IGNITE_PROG_NAME));\n        cfg.quiet(boolValue(IGNITE_QUIET, true));\n        cfg.successFile(getProperty(IGNITE_SUCCESS_FILE));\n        cfg.updateNotifier(boolValue(IGNITE_UPDATE_NOTIFIER, true));\n        cfg.securityCredentialsProvider(compactClass(c.getSecurityCredentialsProvider()));\n\n        return cfg;\n    }\n"
  },
  {
    "id": "eclipse_rt.equinox.framework-79-Associations-Param1",
    "old_comment_raw": "@param trackClass the class name with which the service was registered, or null for all services.",
    "new_code_raw": "\tprivate ServiceReference[] getInitialReferences(boolean trackAllServices,\n\t\t\tString className, String filterString)\n\t\t\tthrows InvalidSyntaxException {\n\t\tif (trackAllServices) {\n\t\t\treturn context.getAllServiceReferences(className, filterString);\n\t\t}\n\t\telse {\n\t\t\treturn context.getServiceReferences(className, filterString);\n\t\t}\n\t}\n\n"
  },
  {
    "id": "apache_ignite-5652-Param-2",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "        private GridCacheMapEntry put0(KeyCacheObject key, int hash, CacheObject val, AffinityTopologyVersion topVer, long ttl) {\n            try {\n                SegmentHeader hdr = this.hdr;\n\n                int c = hdr.size();\n\n                if (c++ > threshold) {// Ensure capacity.\n                    rehash();\n\n                    hdr = this.hdr;\n                }\n\n                int hdrId = hdr.id();\n\n                GridCacheMapEntry[] tab = hdr.table();\n\n                int idx = hash & (tab.length - 1);\n\n                GridCacheMapEntry bin = tab[idx];\n\n                GridCacheMapEntry e = bin;\n\n                while (e != null && (e.hash() != hash || !key.equals(e.key)))\n                    e = e.next(hdrId);\n\n                GridCacheMapEntry retVal;\n\n                if (e != null) {\n                    retVal = e;\n\n                    e.rawPut(val, ttl);\n                }\n                else {\n                    GridCacheMapEntry next = bin != null ? bin : null;\n\n                    GridCacheMapEntry newRoot = factory.create(ctx, topVer, key, hash, val, next, ttl, hdr.id());\n\n                    // Avoiding delete (decrement) before creation (increment).\n                    synchronized (newRoot) {\n                        tab[idx] = newRoot;\n\n                        retVal = newRoot;\n\n                        // Modify counters.\n                        if (!retVal.isInternal()) {\n                            mapPubSize.increment();\n\n                            pubSize.increment();\n                        }\n                    }\n\n                    mapSize.increment();\n\n                    hdr.size(c);\n                }\n\n                return retVal;\n            }\n            finally {\n                if (DEBUG)\n                    checkSegmentConsistency();\n            }\n        }\n"
  },
  {
    "id": "apache_ignite-11519-Param-1",
    "old_comment_raw": "@param groupId Group Id for kafka subscriber.",
    "new_code_raw": "    private ConsumerConfig createDefaultConsumerConfig(String zooKeeper, String grpId) {\n        A.notNull(zooKeeper, \"zookeeper\");\n        A.notNull(grpId, \"groupId\");\n\n        Properties props = new Properties();\n\n        props.put(\"zookeeper.connect\", zooKeeper);\n        props.put(\"group.id\", grpId);\n        props.put(\"zookeeper.session.timeout.ms\", \"400\");\n        props.put(\"zookeeper.sync.time.ms\", \"200\");\n        props.put(\"auto.commit.interval.ms\", \"1000\");\n        props.put(\"auto.offset.reset\", \"smallest\");\n\n        return new ConsumerConfig(props);\n    }\n"
  },
  {
    "id": "gephi_gephi-407-Param-0",
    "old_comment_raw": "@param struct",
    "new_code_raw": "    public double finalQ(int[] struct, double[] degrees, HierarchicalUndirectedGraph hgraph, AttributeModel attributeModel) {\n        AttributeTable nodeTable = attributeModel.getNodeTable();\n        AttributeColumn modCol = nodeTable.getColumn(MODULARITY_CLASS);\n        if (modCol == null) {\n            modCol = nodeTable.addColumn(MODULARITY_CLASS, \"Modularity Class\", AttributeType.INT, AttributeOrigin.COMPUTED, new Integer(0));\n        }\n\n        double res = 0;\n        double[] internal = new double[degrees.length];\n        for (Node n : hgraph.getNodes()) {\n            int n_index = structure.map.get(n);\n            AttributeRow row = (AttributeRow) n.getNodeData().getAttributes();\n            row.setValue(modCol, struct[n_index]);\n            for (Node neighbor : hgraph.getNeighbors(n)) {\n                if (n == neighbor) {\n                    continue;\n                }\n                int neigh_index = structure.map.get(neighbor);\n                if (struct[neigh_index] == struct[n_index]) {\n                    internal[struct[neigh_index]]++;\n                }\n            }\n        }\n        for (int i = 0; i < degrees.length; i++) {\n            internal[i] /= 2.0;\n            res += (internal[i] / hgraph.getTotalEdgeCount()) - Math.pow(degrees[i] / (2 * hgraph.getTotalEdgeCount()), 2);\n        }\n        return res;\n    }\n"
  },
  {
    "id": "eclipse_objectteams-24-Associations-Param0",
    "old_comment_raw": "@param binding the field or local to check",
    "new_code_raw": "public boolean cannotBeNull(LocalVariableBinding local) {\n\treturn isDefinitelyNonNull(local) || isProtectedNonNull(local);\n}\n\n"
  },
  {
    "id": "h2oai_h2o_2-29-Param-0",
    "old_comment_raw": "@param chol",
    "new_code_raw": "  public Cholesky cholesky(Cholesky chol, int parallelize) {\n    long start = System.currentTimeMillis();\n    if( chol == null ) {\n      double[][] xx = _xx.clone();\n      for( int i = 0; i < xx.length; ++i )\n        xx[i] = xx[i].clone();\n      chol = new Cholesky(xx, _diag.clone());\n    }\n    final Cholesky fchol = chol;\n    final int sparseN = _diag.length;\n    final int denseN = _fullN - sparseN;\n    boolean spd=true;\n    // compute the cholesky of the diagonal and diagonal*dense parts\n    if( _diag != null ) for( int i = 0; i < sparseN; ++i ) {\n      double d = 1.0 / (chol._diag[i] = Math.sqrt(_diag[i]));\n      for( int j = 0; j < denseN; ++j )\n        chol._xx[j][i] = d*_xx[j][i];\n    }\n    Futures fs = new Futures();\n    // compute the outer product of diagonal*dense\n    final int chk = Math.max(denseN/10, 1); \n    Log.info(\"SPARSEN = \" + sparseN + \"    DENSEN = \" + denseN);\n\n    for( int i = 0; i < denseN; ++i ) {\n      final int fi = i;\n      fs.add(new RecursiveAction() {\n          @Override protected void compute() {\n            for( int j = 0; j <= fi; ++j ) {\n              double s = 0;\n              for( int k = 0; k < sparseN; ++k )\n                s += fchol._xx[fi][k] * fchol._xx[j][k];\n                 fchol._xx[fi][j + sparseN] = _xx[fi][j + sparseN] - s;\n            }\n          }\n        }.fork());\n    }\n    fs.blockForPending();\n    // compute the cholesky of dense*dense-outer_product(diagonal*dense)\n    // TODO we still use Jama, which requires (among other things) copy and expansion of the matrix. Do it here without copy and faster.\n    double[][] arr = new double[denseN][];\n    for( int i = 0; i < arr.length; ++i )\n      arr[i] = Arrays.copyOfRange(fchol._xx[i], sparseN, sparseN + denseN);\n\n    Log.info (\"CHOLESKY PRECOMPUTE TIME \" + (System.currentTimeMillis()-start));\n    start = System.currentTimeMillis();\n    // parallelize cholesky\n    if (parallelize == 1) {\n      int p = Runtime.getRuntime().availableProcessors();\n      InPlaceCholesky d = InPlaceCholesky.decompose_2(arr, 10, p);\n      fchol.setSPD(d.isSPD());\n      arr = d.getL();\n      Log.info (\"H2O CHOLESKY DECOMPOSE TAKES: \" + (System.currentTimeMillis()-start));\n    } else {\n      // make it symmetric\n      for( int i = 0; i < arr.length; ++i )\n        for( int j = 0; j < i; ++j )\n          arr[j][i] = arr[i][j];\n      CholeskyDecomposition c = new Matrix(arr).chol();\n      fchol.setSPD(c.isSPD());\n      arr = c.getL().getArray();\n      Log.info (\"JAMA CHOLESKY DECOMPOSE TAKES: \" + (System.currentTimeMillis()-start));\n    }\n    for( int i = 0; i < arr.length; ++i )\n      System.arraycopy(arr[i], 0, fchol._xx[i], sparseN, i + 1);\n    return chol;\n  }\n"
  },
  {
    "id": "openhab_openhab1_addons-950-Param-0",
    "old_comment_raw": "@param deviceNumber The bulb number the bridge has filed the bulb under.",
    "new_code_raw": "\tpublic int getHue(String deviceId) {\n\t\tif (settingsData == null) {\n\t\t\tlogger.error(\"Hue bridge settings not initialized correctly.\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tObject hue = settingsData.node(\"lights\")\n\t\t\t\t.node(deviceId).node(\"state\")\n\t\t\t\t.value(\"hue\");\n\t\tif(hue instanceof Integer) {\n\t\t\treturn (Integer) hue;\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n"
  },
  {
    "id": "apache_ignite-1299-Param-0",
    "old_comment_raw": "@param ver Obsolete entry version.",
    "new_code_raw": "    public boolean addRemoved(GridCacheContext<K, V> cacheCtx, GridCacheVersion ver) {\n        if (cacheCtx.isNear() || cacheCtx.isLocal())\n            return true;\n\n        boolean ret = rmvLocks.add(ver);\n\n        if (log.isDebugEnabled())\n            log.debug(\"Added removed lock version: \" + ver);\n\n        return ret;\n    }\n"
  },
  {
    "id": "spring_projects_spring_kafka-129-Param-0",
    "old_comment_raw": "@param partitions the partitions.",
    "new_code_raw": "\tpublic TopicBuilder partitions(int partitionCount) {\n\t\tthis.partitions = partitionCount;\n\t\treturn this;\n\t}\n"
  },
  {
    "id": "apache_ignite-5559-Param-2",
    "old_comment_raw": "@param dest Destination path.",
    "new_code_raw": "    public boolean renameDual(final Igfs fs, final IgfsPath src, final IgfsPath dest) throws\n        IgniteCheckedException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert src != null;\n                assert dest != null;\n\n                if (src.parent() == null)\n                    return false; // Root directory cannot be renamed.\n\n                // Events to fire (can be done outside of a transaction).\n                final Collection<IgfsEvent> pendingEvts = new LinkedList<>();\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<IgfsPath, IgfsFileInfo> infos) throws Exception {\n                        IgfsFileInfo srcInfo = infos.get(src);\n                        IgfsFileInfo srcParentInfo = infos.get(src.parent());\n                        IgfsFileInfo destInfo = infos.get(dest);\n                        IgfsFileInfo destParentInfo = dest.parent() != null ? infos.get(dest.parent()) : null;\n\n                        // Source path and destination (or destination parent) must exist.\n                        if (srcInfo == null)\n                            throw fsException(new IgfsFileNotFoundException(\"Failed to rename \" +\n                                    \"(source path not found): \" + src));\n\n                        if (destInfo == null && destParentInfo == null)\n                            throw fsException(new IgfsFileNotFoundException(\"Failed to rename \" +\n                                \"(destination path not found): \" + dest));\n\n                        // Delegate to the secondary file system.\n                        fs.rename(src, dest);\n\n                        // Rename was successful, perform compensation in the local file system.\n                        if (destInfo == null) {\n                            // Move and rename.\n                            assert destParentInfo != null;\n\n                            moveNonTx(srcInfo.id(), src.name(), srcParentInfo.id(), dest.name(), destParentInfo.id());\n                        }\n                        else {\n                            // Move.\n                            if (destInfo.isFile())\n                                throw fsException(\"Failed to rename the path in the local file system \" +\n                                    \"because destination path already exists and it is a file: \" + dest);\n                            else\n                                moveNonTx(srcInfo.id(), src.name(), srcParentInfo.id(), src.name(), destInfo.id());\n                        }\n\n                        // Record event if needed.\n                        if (srcInfo.isFile()) {\n                            if (evts.isRecordable(EVT_IGFS_FILE_RENAMED))\n                                pendingEvts.add(new IgfsEvent(\n                                    src,\n                                    destInfo == null ? dest : new IgfsPath(dest, src.name()),\n                                    locNode,\n                                    EVT_IGFS_FILE_RENAMED));\n                        }\n                        else if (evts.isRecordable(EVT_IGFS_DIR_RENAMED))\n                            pendingEvts.add(new IgfsEvent(src, dest, locNode, EVT_IGFS_DIR_RENAMED));\n\n                        return true;\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Path rename in DUAL mode failed [source=\" + src + \", destination=\" + dest + ']',\n                            err);\n\n                        throw new IgniteCheckedException(\"Failed to rename the path due to secondary file system \" +\n                            \"exception: \" + src, err);\n                    }\n                };\n\n                try {\n                    return synchronizeAndExecute(task, fs, false, src, dest);\n                }\n                finally {\n                    for (IgfsEvent evt : pendingEvts)\n                        evts.record(evt);\n                }\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to rename in DUAL mode because Grid is stopping [src=\" + src +\n                \", dest=\" + dest + ']');\n    }\n"
  },
  {
    "id": "apache_ignite-13181-Param-1",
    "old_comment_raw": "@param localCombiner If we have mapper with combiner.",
    "new_code_raw": "    private GridHadoopTaskInput createInput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case MAP:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case COMBINE:\n                if (locCombiner) {\n                    assert local != null;\n\n                    return local.input(ctx, (Comparator<Object>) ctx.combineGroupComparator());\n                }\n\n            default:\n                return createInput(ctx);\n        }\n    }\n"
  },
  {
    "id": "zxing_zxing-300-Param-0",
    "old_comment_raw": "@param image The pixel data to decode",
    "new_code_raw": "  public Result decode(BinaryBitmap image, Map<DecodeHintType,?> hints) throws NotFoundException {\n    setHints(hints);\n    return decodeInternal(image);\n  }\n"
  },
  {
    "id": "apache_ignite-13257-Param-0",
    "old_comment_raw": "@param loc Enforce local.",
    "new_code_raw": "    private ClusterGroup projection(boolean local) {\n        return local || ctx.isLocal() || ctx.isReplicated() ? ctx.kernalContext().grid().forLocal() : null;\n    }\n"
  },
  {
    "id": "apache_ignite-5775-Param-1",
    "old_comment_raw": "@param topOrder Maximum allowed node order.",
    "new_code_raw": "    public static Collection<ClusterNode> aliveRemoteNodes(final GridCacheContext ctx, AffinityTopologyVersion topOrder) {\n        return ctx.discovery().aliveRemoteCacheNodes(ctx.namex(), topOrder);\n    }\n"
  },
  {
    "id": "voldemort_voldemort-716-Param-0",
    "old_comment_raw": "@param k The key",
    "new_code_raw": "    public int getCheckedInResourcesCount(K key) {\n        Pool<V> resourcePool = getResourcePoolForExistingKey(key);\n        return resourcePool.queue.size();\n    }\n"
  },
  {
    "id": "apache_ignite-311-Param-1",
    "old_comment_raw": "@param exclude Versions to ignore.",
    "new_code_raw": "    public boolean isLocallyOwnedByThread(long threadId, boolean allowDhtLoc, GridCacheVersion... exclude) {\n        GridCacheMvccCandidate<K> owner = localOwner();\n\n        return owner != null && owner.threadId() == threadId && owner.nodeId().equals(cctx.nodeId()) &&\n            (allowDhtLoc || !owner.dhtLocal()) && !U.containsObjectArray(exclude, owner.version());\n    }\n"
  },
  {
    "id": "essentials_Essentials-228-Param-0",
    "old_comment_raw": "@param method Plugin data from bukkit, Internal Class file.",
    "new_code_raw": "\tpublic static boolean setMethod(PluginManager manager)\n\t{\n\t\tif (hasMethod())\n\t\t{\n\t\t\treturn true;\n\t\t}\n\n\t\tif (self)\n\t\t{\n\t\t\tself = false;\n\t\t\treturn false;\n\t\t}\n\n\t\tint count = 0;\n\t\tboolean match = false;\n\t\tPlugin plugin = null;\n\n\t\tfor (String name : getDependencies())\n\t\t{\n\t\t\tif (hasMethod())\n\t\t\t{\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tplugin = manager.getPlugin(name);\n\t\t\tif (plugin == null)\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tMethod current = createMethod(plugin);\n\t\t\tif (current == null)\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (preferred.isEmpty())\n\t\t\t{\n\t\t\t\tMethod = current;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tAttachables.add(current);\n\t\t\t}\n\t\t}\n\n\t\tif (!preferred.isEmpty())\n\t\t{\n\t\t\tdo\n\t\t\t{\n\t\t\t\tif (hasMethod())\n\t\t\t\t{\n\t\t\t\t\tmatch = true;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tfor (Method attached : Attachables)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (attached == null)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (hasMethod())\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tmatch = true;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (preferred.isEmpty())\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tMethod = attached;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (count == 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif (preferred.equalsIgnoreCase(attached.getName()))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tMethod = attached;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tMethod = attached;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t\twhile (!match);\n\t\t}\n\n\t\treturn hasMethod();\n\t}\n"
  },
  {
    "id": "apache_ignite-1768-Param-0",
    "old_comment_raw": "@param prj Projection to check size for.",
    "new_code_raw": "    public static boolean checkMinTopologySize(ClusterGroup prj, int size) {\n        int prjSize = prj.nodes().size();\n\n        if (prjSize < size) {\n            System.out.println();\n            System.out.println(\">>> Please start at least \" + size + \" grid nodes to run example.\");\n            System.out.println();\n\n            return false;\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-13611-Param-0",
    "old_comment_raw": "@param key If this is a key property.",
    "new_code_raw": "    private static ClassProperty buildClassProperty(Class<?> keyCls, Class<?> valCls, String pathStr, Class<?> resType)\n        throws IgniteCheckedException {\n        ClassProperty res = buildClassProperty(true, keyCls, pathStr, resType);\n\n        if (res == null) // We check key before value consistently with PortableProperty.\n            res = buildClassProperty(false, valCls, pathStr, resType);\n\n        if (res == null)\n            throw new IgniteCheckedException(\"Failed to initialize property '\" + pathStr + \"' for \" +\n                \"key class '\" + keyCls + \"' and value class '\" + valCls + \"'. \" +\n                \"Make sure that one of these classes contains respective getter method or field.\");\n\n        return res;\n    }\n"
  },
  {
    "id": "apache_ignite-1693-Param-0",
    "old_comment_raw": "@param node Node to get version from.",
    "new_code_raw": "    public static GridProductVersion productVersion(ClusterNode node) {\n        String verStr = node.attribute(ATTR_BUILD_VER);\n        String buildDate = node.attribute(ATTR_BUILD_DATE);\n\n        if (buildDate != null)\n            verStr += '-' + buildDate;\n\n        return GridProductVersion.fromString(verStr);\n    }\n"
  },
  {
    "id": "google_protobuf-dt-10-Associations-Param0",
    "old_comment_raw": "@param o an option or an option container.",
    "new_code_raw": "  public Collection<Property> availableOptionPropertiesFor(EObject optionContainer) {\n    if (optionContainer instanceof Protobuf) return fileOptions();\n    if (optionContainer instanceof Enum) return enumOptions();\n    if (optionContainer instanceof Message) return messageOptions();\n    return emptyList();\n  }\n\n"
  },
  {
    "id": "apache_ignite-2918-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    @Nullable protected V peek0(K key, @Nullable Collection<GridCachePeekMode> modes, IgniteTxEx<K, V> tx)\n        throws IgniteCheckedException {\n        try {\n            GridTuple<V> peek = peek0(false, key, modes, tx);\n\n            return peek != null ? peek.get() : null;\n        }\n        catch (GridCacheFilterFailedException ex) {\n            ex.printStackTrace();\n\n            assert false; // Should never happen.\n\n            return null;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-12035-Param-0",
    "old_comment_raw": "@param ignite Ignite.",
    "new_code_raw": "    private static IgniteSet<String> initializeSet(Ignite g, String setName) throws IgniteCheckedException {\n        IgniteCollectionConfiguration setCfg = new IgniteCollectionConfiguration();\n\n        // Initialize new set.\n        IgniteSet<String> set = g.set(setName, setCfg, true);\n\n        // Initialize set items.\n        for (int i = 0; i < 10; i++)\n            set.add(Integer.toString(i));\n\n        System.out.println(\"Set size after initializing: \" + set.size());\n\n        return set;\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-357-Param-1",
    "old_comment_raw": "@param request the SendRequest that describes what to do, get one using static methods on SendRequest itself.",
    "new_code_raw": "    public SendResult sendCoins(TransactionBroadcaster broadcaster, SendRequest request) {\n        // Does not need to be synchronized as sendCoinsOffline is and the rest is all thread-local.\n\n        // Commit the TX to the wallet immediately so the spent coins won't be reused.\n        // TODO: We should probably allow the request to specify tx commit only after the network has accepted it.\n        Transaction tx = sendCoinsOffline(request);\n        if (tx == null)\n            return null;  // Not enough money.\n        SendResult result = new SendResult();\n        result.tx = tx;\n        // The tx has been committed to the pending pool by this point (via sendCoinsOffline -> commitTx), so it has\n        // a txConfidenceListener registered. Once the tx is broadcast the peers will update the memory pool with the\n        // count of seen peers, the memory pool will update the transaction confidence object, that will invoke the\n        // txConfidenceListener which will in turn invoke the wallets event listener onTransactionConfidenceChanged\n        // method.\n        result.broadcastComplete = broadcaster.broadcastTransaction(tx);\n        return result;\n    }\n"
  },
  {
    "id": "apache_shiro-756-Param-0",
    "old_comment_raw": "@param token the authentication token provided by the user.",
    "new_code_raw": "    protected AuthorizingAccount queryForLdapAccount( Object principal, LdapContextFactory ldapContextFactory) throws NamingException {\n\n        String username = null;\n\n        if ( !(principal instanceof String ) ) {\n            String msg = \"This implementation expects the principal argument to be a String.\";\n            throw new IllegalArgumentException( msg );\n        }\n\n        username = (String)principal;\n\n        // Perform context search\n        LdapContext ldapContext = ldapContextFactory.getSystemLdapContext();\n\n        List<String> roleNames;\n\n        try {\n\n            roleNames = getRoleNamesForUser(username, ldapContext);\n\n        } finally {\n\n            LdapUtils.closeContext( ldapContext );\n        }\n\n        return new SimpleAuthorizingAccount( roleNames, null );\n    }\n"
  },
  {
    "id": "apache_ignite-6249-Param-2",
    "old_comment_raw": "@param target Extracted parameters.",
    "new_code_raw": "    private static List<Object> findParams(GridSqlQuery qry, Object[] params, ArrayList<Object> target) {\n        if (params.length == 0)\n            return target;\n\n        for (GridSqlElement el : qry.select())\n            findParams(el, params, target);\n\n        findParams(qry.from(), params, target);\n        findParams(qry.where(), params, target);\n\n        for (GridSqlElement el : qry.groups())\n            findParams(el, params, target);\n\n        findParams(qry.having(), params, target);\n\n        for (GridSqlElement el : qry.sort().keySet())\n            findParams(el, params, target);\n\n        findParams(qry.limit(), params, target);\n        findParams(qry.offset(), params, target);\n\n        return target;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-780-Param-1",
    "old_comment_raw": "@param userId",
    "new_code_raw": "    protected BitmapDrawable fetchAvatar(final String url, final String cachedAvatarFilename) {\n        File rawAvatar = new File(avatarDir, cachedAvatarFilename + \"-raw\");\n        HttpRequest request = HttpRequest.get(url);\n        if (request.ok())\n            request.receive(rawAvatar);\n\n        if (!rawAvatar.exists() || rawAvatar.length() == 0)\n            return null;\n\n        Bitmap bitmap = decode(rawAvatar);\n        if (bitmap == null) {\n            rawAvatar.delete();\n            return null;\n        }\n\n        bitmap = ImageUtils.roundCorners(bitmap, cornerRadius);\n        if (bitmap == null) {\n            rawAvatar.delete();\n            return null;\n        }\n\n        File roundedAvatar = new File(avatarDir, cachedAvatarFilename);\n        FileOutputStream output = null;\n        try {\n            output = new FileOutputStream(roundedAvatar);\n            if (bitmap.compress(PNG, 100, output))\n                return new BitmapDrawable(context.getResources(), bitmap);\n            else\n                return null;\n        } catch (IOException e) {\n            Log.d(TAG, \"Exception writing rounded avatar\", e);\n            return null;\n        } finally {\n            if (output != null)\n                try {\n                    output.close();\n                } catch (IOException e) {\n                    // Ignored\n                }\n            rawAvatar.delete();\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5035-Param-2",
    "old_comment_raw": "@param entry Preloaded entry.",
    "new_code_raw": "        private boolean preloadEntry(ClusterNode pick, int p, GridCacheEntryInfo<K, V> entry, AffinityTopologyVersion topVer)\n            throws IgniteCheckedException {\n            try {\n                GridCacheEntryEx<K, V> cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isIgfsDataCache() &&\n                        cctx.dht().igfsDataSpaceUsed() > cctx.dht().igfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload IGFS data cache (IGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            entry.valueBytes(),\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isDrEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (IgniteUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false, null, null, null);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (IgniteInterruptedCheckedException e) {\n                throw e;\n            }\n            catch (IgniteCheckedException e) {\n                throw new IgniteCheckedException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "apache_ignite-12104-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    public static VisorBasicConfiguration from(IgniteEx ignite, IgniteConfiguration c) {\n        VisorBasicConfiguration cfg = new VisorBasicConfiguration();\n\n        cfg.gridName(c.getGridName());\n        cfg.ggHome(getProperty(IGNITE_HOME, c.getIgniteHome()));\n        cfg.localHost(getProperty(IGNITE_LOCAL_HOST, c.getLocalHost()));\n        cfg.nodeId(ignite.localNode().id());\n        cfg.marshaller(compactClass(c.getMarshaller()));\n        cfg.deploymentMode(compactObject(c.getDeploymentMode()));\n        cfg.daemon(boolValue(IGNITE_DAEMON, c.isDaemon()));\n        cfg.jmxRemote(ignite.isJmxRemoteEnabled());\n        cfg.restart(ignite.isRestartEnabled());\n        cfg.networkTimeout(c.getNetworkTimeout());\n        cfg.logger(compactClass(c.getGridLogger()));\n        cfg.discoStartupDelay(c.getDiscoveryStartupDelay());\n        cfg.mBeanServer(compactClass(c.getMBeanServer()));\n        cfg.noAscii(boolValue(IGNITE_NO_ASCII, false));\n        cfg.noDiscoOrder(boolValue(IGNITE_NO_DISCO_ORDER, false));\n        cfg.noShutdownHook(boolValue(IGNITE_NO_SHUTDOWN_HOOK, false));\n        cfg.programName(getProperty(IGNITE_PROG_NAME));\n        cfg.quiet(boolValue(IGNITE_QUIET, true));\n        cfg.successFile(getProperty(IGNITE_SUCCESS_FILE));\n        cfg.updateNotifier(boolValue(IGNITE_UPDATE_NOTIFIER, true));\n\n        return cfg;\n    }\n"
  },
  {
    "id": "gephi_gephi-408-Param-3",
    "old_comment_raw": "@param height Image height",
    "new_code_raw": "    public BufferedImage createTimeIntervalImage(double starts[], double ends[], int width, int height, Color fill, Color border, Color background) {\n        if (starts.length != ends.length) {\n            throw new IllegalArgumentException(\"start and ends length should be equal\");\n        }\n        if (fill == null) {\n            fill = DEFAULT_FILL;\n        }\n        if (border == null) {\n            border = DEFAULT_BORDER;\n        }\n\n        final BufferedImage image = new BufferedImage(width, height, BufferedImage.TYPE_INT_ARGB);\n\n        final Graphics2D g = image.createGraphics();\n        g.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);\n\n        //Draw brackground if any:\n        if (background != null) {\n            g.setBackground(background);\n            g.clearRect(0, 0, width, height);\n        }\n\n        g.translate(1, 0);//Start drawing at pixel 1\n\n        width -= 2;//Reduce fill area in 2 pixels for the borders\n        double xTickWidth = (double) width / range;\n\n        //Draw time interval filled parts:\n        if (range == 0) {//No range, Min=Max\n            //Fill all drawing area:\n            g.setColor(fill);\n            g.fillRect(0, 0, width, height);\n            g.setColor(border);\n            //Draw borders:\n            g.drawLine(-1, 0, -1, height);\n            g.drawLine(width, 0, width, height);\n        } else {\n            int startPixel, endPixel;\n            for (int i = 0; i < starts.length; i++) {\n                g.setColor(fill);\n                startPixel = (int) (xTickWidth * (normalizeToRange(starts[i]) - min));\n                endPixel = (int) (xTickWidth * (normalizeToRange(ends[i]) - min));\n\n                int rectWidth = endPixel - startPixel;\n                if (rectWidth == 0) {\n                    rectWidth = 1;//Draw at least 1 pixel if a range is small\n                }\n                g.fillRect(startPixel, 0, rectWidth, height);\n\n                //Draw borders:\n                g.setColor(border);\n                g.drawLine(startPixel, 0, startPixel, height);\n                g.drawLine(endPixel, 0, endPixel, height);\n            }\n        }\n\n        return image;\n    }\n"
  },
  {
    "id": "apache_ignite-13613-Param-0",
    "old_comment_raw": "@param nodeId Node ID.",
    "new_code_raw": "    public boolean alive(ClusterNode node) {\n        assert node != null;\n\n        return alive(node.id());\n    }\n"
  },
  {
    "id": "apache_ignite-3716-Param-0",
    "old_comment_raw": "@param tx Transaction to check.",
    "new_code_raw": "    public boolean isCompleted(IgniteInternalTx<K, V> tx) {\n        return committedVers.contains(tx.xidVersion()) || rolledbackVers.contains(tx.xidVersion());\n    }\n"
  },
  {
    "id": "xetorthio_jedis-788-Param-1",
    "old_comment_raw": "@param member",
    "new_code_raw": "    public Long zrem(final String key, final String... members) {\n        checkIsInMulti();\n        client.zrem(key, members);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-12044-Param-1",
    "old_comment_raw": "@param queueName Name of queue.",
    "new_code_raw": "    private static CacheQueue<String> initializeQueue(Ignite ignite, String queueName) throws IgniteCheckedException {\n        // Initialize new FIFO queue.\n        CacheQueue<String> queue = ignite.cache(CACHE_NAME).dataStructures().queue(queueName, 0, false, true);\n\n        // Initialize queue items.\n        // We will be use blocking operation and queue size must be appropriated.\n        for (int i = 0; i < ignite.cluster().nodes().size() * RETRIES * 2; i++)\n            queue.put(Integer.toString(i));\n\n        System.out.println(\"Queue size after initializing: \" + queue.size());\n\n        return queue;\n    }\n"
  },
  {
    "id": "Bearded_Hen_Android_Bootstrap-22-Param-1",
    "old_comment_raw": "@param path the typeface path",
    "new_code_raw": "    public static Typeface getTypeface(Context context, IconSet iconSet) {\n        String path = iconSet.fontPath().toString();\n\n        if (TYPEFACE_MAP.get(path) == null) {\n            final Typeface font = Typeface.createFromAsset(context.getAssets(), path);\n            TYPEFACE_MAP.put(path, font);\n        }\n        return TYPEFACE_MAP.get(path);\n    }\n"
  },
  {
    "id": "apache_ignite-3611-Param-0",
    "old_comment_raw": "@param tx Cache transaction.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteTxEx tx, K key, V val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key instanceof GridCacheInternal)\n                return true;\n\n            if (convertPortable) {\n                key = (K)cctx.unwrapPortableIfNeeded(key, false);\n                val = (V)cctx.unwrapPortableIfNeeded(val, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(key, locStore ? F.t(val, ver) : val));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-13311-Param-2",
    "old_comment_raw": "@param expFwdId Expected forward page ID.",
    "new_code_raw": "    private boolean findDown(final Get g, final long pageId, final long fwdId, final int lvl)\n        throws IgniteCheckedException {\n        for (;;) {\n            try (Page page = page(pageId)) {\n                if (page == null)\n                    return true; // Page was removed, retry.\n\n                // Init args.\n                g.pageId = pageId;\n                g.fwdId = fwdId;\n\n                int res = readPage(page, search, g, lvl);\n\n                switch (res) {\n                    case Get.RETRY:\n                        return true;\n\n                    case Get.GO_DOWN:\n                        assert g.pageId != pageId;\n                        assert g.fwdId != fwdId || fwdId == 0;\n\n                        // Go down recursively.\n                        if (findDown(g, g.pageId, g.fwdId, lvl - 1)) {\n                            checkInterrupted();\n\n                            continue; // The child page got splitted, need to reread our page.\n                        }\n\n                        return false;\n\n                    case Get.FOUND:\n                        return false; // We are done.\n\n                    case Get.NOT_FOUND:\n                        g.row = null; // Mark not found result.\n\n                        return false;\n\n                    default:\n                        assert false: res;\n                }\n            }\n        }\n    }\n"
  },
  {
    "id": "Red5_red5_server-41-Param-1",
    "old_comment_raw": "@param scope Scope",
    "new_code_raw": "    public boolean connect(IConnection conn) {\n        // ensure the log is not null at this point\n        if (log == null) {\n            log = Red5LoggerFactory.getLogger(this.getClass());\n        }\n        // get the scope from the connection\n        IScope scope = conn.getScope();\n        log.debug(\"connect: {} > {}\", conn, scope);\n        return connect(conn, scope, null);\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-483-Param-1",
    "old_comment_raw": "@param encoder",
    "new_code_raw": "    public Weighting createWeighting( String weightingStr, FlagEncoder encoder )\n    {\n        // ignore case\n        Weighting weighting;\n        weightingStr = weightingStr.toLowerCase();\n        if (\"fastest\".equals(weightingStr))\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                weighting = new PriorityWeighting((BikeCommonFlagEncoder) encoder);\n            else\n                weighting = new FastestWeighting(encoder);\n        } else\n            weighting = new ShortestWeighting();\n\n        if (encoder.supportsTurnCosts())\n            weighting = new TurnWeighting(weighting, encoder, (TurnCostStorage) graph.getExtendedStorage());\n\n        return weighting;\n    }\n"
  },
  {
    "id": "todoroo_astrid-982-Param-1",
    "old_comment_raw": "@param resultCode",
    "new_code_raw": "    public boolean handleActivityResult(int activityRequestCode, int resultCode, Intent data) {\n        boolean result = false;\n        // handle the result of voice recognition, put it into the textfield\n        if (activityRequestCode == this.requestCode) {\n            // this was handled here, even if voicerecognition fails for any reason\n            // so your program flow wont get chaotic if you dont explicitly state\n            // your own requestCodes.\n            result = true;\n            if (resultCode == Activity.RESULT_OK) {\n                // Fill the quickAddBox-view with the string the recognizer thought it could have heard\n                ArrayList<String> match = data.getStringArrayListExtra(\n                        RecognizerIntent.EXTRA_RESULTS);\n                // make sure we only do this if there is SomeThing (tm) returned\n                if (match != null && match.size() > 0 && match.get(0).length() > 0) {\n                    Editable currentText = textField.getText();\n                    String recognizedSpeech = match.get(0);\n\n                    if (currentText.length() > 0) {\n                        // if something is already typed in, append the recognized speech,\n                        // add a space if it isn't already there\n                        textField.append((currentText.toString().endsWith(\" \") ? recognizedSpeech : \" \"+recognizedSpeech ));\n                    } else {\n                        textField.setText(recognizedSpeech);\n                    }\n                }\n            }\n        }\n\n        return result;\n    }\n"
  },
  {
    "id": "kymjs_KJFrameForAndroid-3-Param-0",
    "old_comment_raw": "@param action the privileged action to run",
    "new_code_raw": "    public static Callable<Object> callable(Runnable task) {\n        if (task == null) {\n            throw new NullPointerException();\n        }\n        return new RunnableAdapter<Object>(task, null);\n    }\n"
  },
  {
    "id": "apache_ignite-1972-Param-2",
    "old_comment_raw": "@param collocated Collocation flag.",
    "new_code_raw": "    private static GridCacheQueueItemKey itemKey(IgniteUuid id, String queueName, boolean collocated, long idx) {\n        return collocated ? new CollocatedItemKey(id, queueName, idx) :\n            new GridCacheQueueItemKey(id, queueName, idx);\n    }\n"
  },
  {
    "id": "apache_pulsar-304-Param-0",
    "old_comment_raw": "@param destination: topic-name",
    "new_code_raw": "    public CompletableFuture<PartitionedTopicMetadata> getPartitionedTopicMetadata(TopicName topicName) {\n    \treturn httpClient.get(String.format(\"admin/%s/partitions\", topicName.getLookupName()),\n                PartitionedTopicMetadata.class);\n    }\n"
  },
  {
    "id": "apache_curator-72-Param-0",
    "old_comment_raw": "@param newCount the new value to attempt",
    "new_code_raw": "    public boolean  trySetCount(VersionedValue<Integer> previous, int newCount) throws Exception\n    {\n        VersionedValue<byte[]> previousCopy = new VersionedValue<byte[]>(previous.getVersion(), toBytes(previous.getValue()));\n        return sharedValue.trySetValue(previousCopy, toBytes(newCount));\n    }\n"
  },
  {
    "id": "apache_ignite-12185-Param-1",
    "old_comment_raw": "@param c Cache.",
    "new_code_raw": "    public static VisorCacheMetrics from(IgniteEx ignite, String cacheName) {\n        VisorCacheMetrics cm = new VisorCacheMetrics();\n\n        GridCacheProcessor cacheProcessor = ignite.context().cache();\n\n        IgniteCache<Object, Object> c = cacheProcessor.jcache(cacheName);\n\n        cm.name = cacheName;\n        cm.mode = cacheProcessor.cacheMode(cacheName);\n        cm.sys = cacheProcessor.systemCache(cacheName);\n\n        CacheMetrics m = c.metrics();\n\n        cm.size = m.getSize();\n        cm.keySize = m.getKeySize();\n\n        cm.reads = m.getCacheGets();\n        cm.writes = m.getCachePuts() + m.getCacheRemovals();\n        cm.hits = m.getCacheHits();\n        cm.misses = m.getCacheMisses();\n\n        cm.txCommits = m.getCacheTxCommits();\n        cm.txRollbacks = m.getCacheTxRollbacks();\n\n        cm.avgTxCommitTime = m.getAverageTxCommitTime();\n        cm.avgTxRollbackTime = m.getAverageTxRollbackTime();\n\n        cm.puts = m.getCachePuts();\n        cm.removals = m.getCacheRemovals();\n        cm.evictions = m.getCacheEvictions();\n\n        cm.avgReadTime = m.getAverageGetTime();\n        cm.avgPutTime = m.getAveragePutTime();\n        cm.avgRemovalTime = m.getAverageRemoveTime();\n\n        cm.readsPerSec = perSecond(m.getAverageGetTime());\n        cm.putsPerSec = perSecond(m.getAveragePutTime());\n        cm.removalsPerSec = perSecond(m.getAverageRemoveTime());\n        cm.commitsPerSec = perSecond(m.getAverageTxCommitTime());\n        cm.rollbacksPerSec = perSecond(m.getAverageTxRollbackTime());\n\n        cm.qryMetrics = VisorCacheQueryMetrics.from(c.queryMetrics());\n\n        cm.dhtEvictQueueCurrSize = m.getDhtEvictQueueCurrentSize();\n        cm.txThreadMapSize = m.getTxThreadMapSize();\n        cm.txXidMapSize = m.getTxXidMapSize();\n        cm.txCommitQueueSize = m.getTxCommitQueueSize();\n        cm.txPrepareQueueSize = m.getTxPrepareQueueSize();\n        cm.txStartVerCountsSize = m.getTxStartVersionCountsSize();\n        cm.txCommittedVersionsSize = m.getTxCommittedVersionsSize();\n        cm.txRolledbackVersionsSize = m.getTxRolledbackVersionsSize();\n        cm.txDhtThreadMapSize = m.getTxDhtThreadMapSize();\n        cm.txDhtXidMapSize = m.getTxDhtXidMapSize();\n        cm.txDhtCommitQueueSize = m.getTxDhtCommitQueueSize();\n        cm.txDhtPrepareQueueSize = m.getTxDhtPrepareQueueSize();\n        cm.txDhtStartVerCountsSize = m.getTxDhtStartVersionCountsSize();\n        cm.txDhtCommittedVersionsSize = m.getTxDhtCommittedVersionsSize();\n        cm.txDhtRolledbackVersionsSize = m.getTxDhtRolledbackVersionsSize();\n\n        return cm;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-954-Param-2",
    "old_comment_raw": "@param type",
    "new_code_raw": "\tprivate Object getValue(ByteBuffer byteBuffer, TelegramValue telegramValue) {\n\n\t\tString type = telegramValue.getType().toLowerCase();\n\t\tint pos = telegramValue.getPos() != null ? telegramValue.getPos() : -1;\n\n\t\tObject value = null;\n\n\t\t// requested pos is greater as whole buffer\n\t\tif(pos > byteBuffer.position()) {\n\t\t\tlogger.warn(\"eBus buffer pos error! Can happen ...\");\n\t\t}\n\n\t\t// replace similar data types\n\t\tif(type.equals(\"uint\"))\n\t\t\ttype = \"word\";\n\t\tif(type.equals(\"byte\"))\n\t\t\ttype = \"uchar\";\n\n\t\tbyte[] bytes = null;\n\t\tif(type.equals(\"data2b\") || type.equals(\"data2c\") || type.equals(\"word\")) {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos), byteBuffer.get(pos-1)};\n\t\t} else {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos-1)};\n\t\t}\n\n\t\tif(type.equals(\"bit\")) {\n\t\t\tint bit = telegramValue.getBit();\n\t\t\tvalue = bytes[0];\n\n\t\t\tboolean isSet = ((Byte)value >> bit& 0x1) == 1;\n\t\t\tvalue = isSet;\n\n\t\t} else {\n\t\t\tvalue = NumberUtils.toBigDecimal(EBusCodecUtils.decode(type, bytes, telegramValue.getReplaceValue()));\n\t\t}\n\n\t\t// if BigDecimal check for min, max and replace value\n\t\tif(value instanceof BigDecimal) {\n\t\t\tBigDecimal b = (BigDecimal)value;\n\n\t\t\t// multiply before check min and max\n\t\t\tif(b != null && telegramValue.getFactor() != null) {\n\t\t\t\tlogger.trace(\"Value multiplied ...\");\n\t\t\t\tvalue = b = b.multiply(telegramValue.getFactor());\n\t\t\t}\n\n\t\t\t// value is below min value, return null\n\t\t\tif(telegramValue.getMin() != null && b != null && b.compareTo(telegramValue.getMin()) == -1) {\n\t\t\t\tlogger.trace(\"Minimal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\n\t\t\t\t// value is above max value, return null\n\t\t\t} else if (telegramValue.getMax() != null && b != null && b.compareTo(telegramValue.getMax()) == 1) {\n\t\t\t\tlogger.trace(\"Maximal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\t\t\t}\n\n\t\t}\n\n\t\treturn value;\n\t}\n"
  },
  {
    "id": "Netflix_Hystrix-373-Param-0",
    "old_comment_raw": "@param action the command action",
    "new_code_raw": "    Object process(Action action) throws RuntimeException {\n        Object result;\n        try {\n            result = action.execute();\n        } catch (Throwable throwable) {\n            if (isIgnorable(throwable)) {\n                throw new HystrixBadRequestException(throwable.getMessage(), throwable);\n            }\n            throw Throwables.propagate(throwable);\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-6112-Param-0",
    "old_comment_raw": "@param entry Entry to touch.",
    "new_code_raw": "    private boolean touch(CacheEvictableEntry<K, V> entry) {\n        Node<CacheEvictableEntry<K, V>> node = entry.meta();\n\n        // Entry has not been enqueued yet.\n        if (node == null) {\n            while (true) {\n                node = queue.offerLastx(entry);\n\n                if (entry.putMetaIfAbsent(node) != null) {\n                    // Was concurrently added, need to clear it from queue.\n                    queue.unlinkx(node);\n\n                    // Queue has not been changed.\n                    return false;\n                }\n                else if (node.item() != null) {\n                    if (!entry.isCached()) {\n                        // Was concurrently evicted, need to clear it from queue.\n                        queue.unlinkx(node);\n\n                        return false;\n                    }\n\n                    return true;\n                }\n                // If node was unlinked by concurrent shrink() call, we must repeat the whole cycle.\n                else if (!entry.removeMeta(node))\n                    return false;\n            }\n        }\n        else if (queue.unlinkx(node)) {\n            // Move node to tail.\n            Node<CacheEvictableEntry<K, V>> newNode = queue.offerLastx(entry);\n\n            if (!entry.replaceMeta(node, newNode))\n                // Was concurrently added, need to clear it from queue.\n                queue.unlinkx(newNode);\n        }\n\n        // Entry is already in queue.\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-11620-Param-0",
    "old_comment_raw": "@param grid Grid.",
    "new_code_raw": "    private boolean checkDeployed(Ignite ignite, String taskName) {\n        Map<String, Class<? extends GridComputeTask<?, ?>>> locTasks = ignite.compute().localTasks();\n\n        if (log().isInfoEnabled())\n            log().info(\"Local tasks found: \" + locTasks);\n\n        return locTasks.get(taskName) != null;\n    }\n"
  },
  {
    "id": "apache_ignite-5785-Param-0",
    "old_comment_raw": "@param cctx Cache context.",
    "new_code_raw": "    public static ClusterNode oldest(GridCacheContext cctx, long topOrder) {\n        ClusterNode oldest = null;\n\n        for (ClusterNode n : aliveNodes(cctx, topOrder))\n            if (oldest == null || n.order() < oldest.order())\n                oldest = n;\n\n        assert oldest != null;\n        assert oldest.order() <= topOrder || topOrder < 0;\n\n        return oldest;\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-346-Param-1",
    "old_comment_raw": "@param disconnect Whether to abort if there's a pre-existing connection or not.",
    "new_code_raw": "    ConnectionResult connect(Map<Sha256Hash, Transaction> transactions, ConnectMode mode) {\n        Transaction tx = transactions.get(outpoint.getHash());\n        if (tx == null) {\n            return TransactionInput.ConnectionResult.NO_SUCH_TX;\n        }\n        TransactionOutput out = tx.getOutputs().get((int) outpoint.getIndex());\n        if (!out.isAvailableForSpending()) {\n            if (mode == ConnectMode.DISCONNECT_ON_CONFLICT) {\n                out.markAsUnspent();\n            } else if (mode == ConnectMode.ABORT_ON_CONFLICT) {\n                outpoint.fromTx = checkNotNull(out.parentTransaction);\n                return TransactionInput.ConnectionResult.ALREADY_SPENT;\n            }\n        }\n        connect(out);\n        return TransactionInput.ConnectionResult.SUCCESS;\n    }\n"
  },
  {
    "id": "apache_ignite-2225-Param-1",
    "old_comment_raw": "@param digest digest object to add file.",
    "new_code_raw": "    private static boolean addFileDigest(File file, MessageDigest digest, @Nullable IgniteLogger log) {\n        if (!file.isFile()) {\n            U.error(log, \"Failed to add file to directory digest (will not check MD5 hash): \" + file);\n\n            return false;\n        }\n\n        InputStream in = null;\n\n        try {\n            in = new BufferedInputStream(new FileInputStream(file));\n\n            byte[] buf = new byte[1024];\n\n            int read = in.read(buf, 0, 1024);\n\n            while (read > -1) {\n                digest.update(buf, 0, read);\n\n                read = in.read(buf, 0, 1024);\n            }\n        }\n        catch (IOException e) {\n            U.error(log, \"Failed to add file to directory digest (will not check MD5 hash): \" + file, e);\n\n            return false;\n        }\n        finally {\n            U.closeQuiet(in);\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "Jasonchenlijian_FastBle-22-Param-0",
    "old_comment_raw": "@param maxCount",
    "new_code_raw": "    public BleManager setMaxConnectCount(int count) {\n        if (count > DEFAULT_MAX_MULTIPLE_DEVICE)\n            count = DEFAULT_MAX_MULTIPLE_DEVICE;\n        this.maxConnectCount = count;\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-5462-Param-2",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteInternalTx tx, KeyCacheObject key, CacheObject val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key.internal())\n                return true;\n\n            Object storeKey = key.value(cctx.cacheObjectContext(), false);\n            Object storeVal = val.value(cctx.cacheObjectContext(), false);\n\n            if (convertPortable) {\n                storeKey = cctx.unwrapPortableIfNeeded(storeKey, false);\n                storeVal = cctx.unwrapPortableIfNeeded(storeVal, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            boolean ses = initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(storeKey, locStore ? F.t(storeVal, ver) : storeVal));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                if (ses)\n                    sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + storeKey + \", val=\" + storeVal + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-12144-Param-1",
    "old_comment_raw": "@param store Cache store.",
    "new_code_raw": "    private CacheConfiguration cacheConfiguration(String cacheName, Factory<CacheStore> factory) {\n        CacheConfiguration cfg = defaultCacheConfiguration();\n\n        cfg.setNearConfiguration(null);\n        cfg.setName(cacheName);\n\n        cfg.setBackups(1);\n\n        if (factory != null) {\n            cfg.setCacheStoreFactory(factory);\n\n            cfg.setWriteThrough(true);\n        }\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_ignite-5027-Param-0",
    "old_comment_raw": "@param nodeId Reader to add.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, AffinityTopologyVersion topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!U.hasNearCache(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture<K, V> txFut = null;\n\n        Collection<GridCacheMvccCandidate<K>> cands = null;\n\n        ReaderId<K, V> reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId<>(nodeId, msgId);\n\n                ReaderId<K, V>[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate<K> c : cands) {\n                    IgniteInternalTx<K, V> tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId<K, V> reader0 = reader;\n\n                txFut.listenAsync(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        synchronized (this) {\n                            // Release memory.\n                            reader0.resetTxFuture();\n                        }\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "apache_ignite-11537-Param-1",
    "old_comment_raw": "@param s Node shadow to check.",
    "new_code_raw": "    public static boolean cacheNode(String cacheName, GridCacheAttributes[] caches) {\n        if (caches != null)\n            for (GridCacheAttributes attrs : caches)\n                if (F.eq(cacheName, attrs.cacheName()))\n                    return true;\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-1591-Param-1",
    "old_comment_raw": "@param n Node from which affinity is requested.",
    "new_code_raw": "    private AffinityInfo affinityInfoFromNode(@Nullable String cacheName, long topVer, ClusterNode n)\n        throws GridException {\n        GridTuple3<GridAffinityMessage, GridAffinityMessage, GridAffinityAssignment> t = ctx.closure()\n            .callAsyncNoFailover(BALANCE, affinityJob(cacheName, topVer), F.asList(n), true/*system pool*/).get();\n\n        GridCacheAffinityFunction f = (GridCacheAffinityFunction)unmarshall(ctx, n.id(), t.get1());\n        GridCacheAffinityKeyMapper m = (GridCacheAffinityKeyMapper)unmarshall(ctx, n.id(), t.get2());\n\n        assert m != null;\n\n        // Bring to initial state.\n        f.reset();\n        m.reset();\n\n        Boolean portableEnabled = U.portableEnabled(n, cacheName);\n\n        return new AffinityInfo(f, m, t.get3(), portableEnabled != null && portableEnabled);\n    }\n"
  },
  {
    "id": "apache_pulsar-322-Param-1",
    "old_comment_raw": "@param authParamsString string which represents parameters for the Authentication-Plugin, e.g., \"key1:val1,key2:val2\"",
    "new_code_raw": "    public static Authentication create(String authPluginClassName, Map<String, String> authParams)\n            throws UnsupportedAuthenticationException {\n        try {\n            return DefaultImplementation.createAuthentication(authPluginClassName, authParams);\n        } catch (Throwable t) {\n            throw new UnsupportedAuthenticationException(t);\n        }\n    }\n"
  },
  {
    "id": "bytedeco_javacpp-209-Param-1",
    "old_comment_raw": "@param direct  true to use a direct buffer, see  Indexer for details",
    "new_code_raw": "    public static ByteIndexer create(final BytePointer pointer, long[] sizes, long[] strides, boolean direct) {\n        if (direct) {\n            return Raw.getInstance() != null ? new ByteRawIndexer(pointer, sizes, strides)\n                                             : new ByteBufferIndexer(pointer.asBuffer(), sizes, strides);\n        } else {\n            final long position = pointer.position();\n            byte[] array = new byte[(int)Math.min(pointer.limit() - position, Integer.MAX_VALUE)];\n            pointer.get(array);\n            return new ByteArrayIndexer(array, sizes, strides) {\n                @Override public void release() {\n                    pointer.position(position).put(array);\n                    super.release();\n                }\n            };\n        }\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-356-Param-1",
    "old_comment_raw": "@param relativePath whether the path is relative to the root path",
    "new_code_raw": "    public ExtendedHierarchicKey deriveNextChild(ImmutableList<ChildNumber> parentPath, boolean relative, boolean createParent, boolean privateDerivation) {\n        ExtendedHierarchicKey parent = get(parentPath, relative, createParent);\n        int nAttempts = 0;\n        while (nAttempts++ < MAX_CHILD_DERIVATION_ATTEMPTS) {\n            try {\n                ChildNumber createChildNumber = getNextChildNumberToDerive(parent.getChildNumberPath(), privateDerivation);\n                return deriveChild(parent, createChildNumber);\n            } catch (HDDerivationException ignore) { }\n        }\n        throw new HDDerivationException(\"Maximum number of child derivation attempts reached, this is probably an indication of a bug.\");\n    }\n"
  },
  {
    "id": "apache_ignite-5311-Param-1",
    "old_comment_raw": "@param path Path to create.",
    "new_code_raw": "    public boolean mkdirsDual(final IgfsSecondaryFileSystem fs, final IgfsPath path, final Map<String, String> props)\n        throws IgniteCheckedException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert path != null;\n                assert props != null;\n\n                if (path.parent() == null)\n                    return true; // No additional handling for root directory is needed.\n\n                // Events to fire (can be done outside of a transaction).\n                final Deque<IgfsEvent> pendingEvts = new LinkedList<>();\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<IgfsPath, IgfsFileInfo> infos) throws Exception {\n                        fs.mkdirs(path, props);\n\n                        assert !infos.isEmpty();\n\n                        // Now perform synchronization again starting with the last created parent.\n                        IgfsPath parentPath = null;\n\n                        for (IgfsPath curPath : infos.keySet()) {\n                            if (parentPath == null || curPath.isSubDirectoryOf(parentPath))\n                                parentPath = curPath;\n                        }\n\n                        assert parentPath != null;\n\n                        IgfsFileInfo parentPathInfo = infos.get(parentPath);\n\n                        synchronize(fs, parentPath, parentPathInfo, path, true, null);\n\n                        if (evts.isRecordable(EVT_IGFS_DIR_CREATED)) {\n                            IgfsPath evtPath = path;\n\n                            while (!parentPath.equals(evtPath)) {\n                                pendingEvts.addFirst(new IgfsEvent(evtPath, locNode, EVT_IGFS_DIR_CREATED));\n\n                                evtPath = evtPath.parent();\n\n                                assert evtPath != null; // If this fails, then ROOT does not exist.\n                            }\n                        }\n\n                        return true;\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Directory creation in DUAL mode failed [path=\" + path + \", properties=\" + props +\n                            ']', err);\n\n                        throw new IgniteCheckedException(\"Failed to create the path due to secondary file system exception: \" +\n                            path, err);\n                    }\n                };\n\n                try {\n                    return synchronizeAndExecute(task, fs, false, path.parent());\n                }\n                finally {\n                    for (IgfsEvent evt : pendingEvts)\n                        evts.record(evt);\n                }\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to create directory in DUAL mode because Grid is stopping: \" +\n                path);\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-412-Param-0",
    "old_comment_raw": "@param l2 Vector containing L2 reconstruction errors",
    "new_code_raw": "  public double calcOutlierThreshold(Vec mse, double quantile) {\n    Frame mse_frame = new Frame(Key.make(), new String[]{\"Reconstruction.MSE\"}, new Vec[]{mse});\n    QuantilesPage qp = new QuantilesPage();\n    qp.column = mse_frame.vec(0);\n    qp.source_key = mse_frame;\n    qp.quantile = quantile;\n    qp.invoke();\n    DKV.remove(mse_frame._key);\n    return qp.result;\n  }\n"
  },
  {
    "id": "natario1_CameraView-73-Param-2",
    "old_comment_raw": "@param rotation rotation",
    "new_code_raw": "    public Frame getFrame(@NonNull T data, long time, int rotation) {\n        if (!isSetUp()) {\n            throw new IllegalStateException(\"Can't call getFrame() after releasing \" +\n                    \"or before setUp.\");\n        }\n\n        Frame frame = mFrameQueue.poll();\n        if (frame != null) {\n            LOG.v(\"getFrame for time:\", time, \"RECYCLING.\");\n        } else {\n            LOG.v(\"getFrame for time:\", time, \"CREATING.\");\n            frame = new Frame(this);\n        }\n        frame.setContent(data, time, rotation, mFrameSize, mFrameFormat);\n        return frame;\n    }\n"
  },
  {
    "id": "gephi_gephi-408-Param-0",
    "old_comment_raw": "@param start Start of the interval (must be greater or equal than minimum time)",
    "new_code_raw": "    public BufferedImage createTimeIntervalImage(double starts[], double ends[], int width, int height, Color fill, Color border, Color background) {\n        if (starts.length != ends.length) {\n            throw new IllegalArgumentException(\"start and ends length should be equal\");\n        }\n        if (fill == null) {\n            fill = DEFAULT_FILL;\n        }\n        if (border == null) {\n            border = DEFAULT_BORDER;\n        }\n\n        final BufferedImage image = new BufferedImage(width, height, BufferedImage.TYPE_INT_ARGB);\n\n        final Graphics2D g = image.createGraphics();\n        g.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);\n\n        //Draw brackground if any:\n        if (background != null) {\n            g.setBackground(background);\n            g.clearRect(0, 0, width, height);\n        }\n\n        g.translate(1, 0);//Start drawing at pixel 1\n\n        width -= 2;//Reduce fill area in 2 pixels for the borders\n        double xTickWidth = (double) width / range;\n\n        //Draw time interval filled parts:\n        if (range == 0) {//No range, Min=Max\n            //Fill all drawing area:\n            g.setColor(fill);\n            g.fillRect(0, 0, width, height);\n            g.setColor(border);\n            //Draw borders:\n            g.drawLine(-1, 0, -1, height);\n            g.drawLine(width, 0, width, height);\n        } else {\n            int startPixel, endPixel;\n            for (int i = 0; i < starts.length; i++) {\n                g.setColor(fill);\n                startPixel = (int) (xTickWidth * (normalizeToRange(starts[i]) - min));\n                endPixel = (int) (xTickWidth * (normalizeToRange(ends[i]) - min));\n\n                int rectWidth = endPixel - startPixel;\n                if (rectWidth == 0) {\n                    rectWidth = 1;//Draw at least 1 pixel if a range is small\n                }\n                g.fillRect(startPixel, 0, rectWidth, height);\n\n                //Draw borders:\n                g.setColor(border);\n                g.drawLine(startPixel, 0, startPixel, height);\n                g.drawLine(endPixel, 0, endPixel, height);\n            }\n        }\n\n        return image;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-643-Param-0",
    "old_comment_raw": "@param manufacturerId The manufacturer ID",
    "new_code_raw": "\tpublic boolean FindProduct(int manufacturerId, int productType, int productId, String version) {\n\t\tif (FindManufacturer(manufacturerId) == false) {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn FindProduct(productType, productId, version);\n\t}\n"
  },
  {
    "id": "sanluan_PublicCMS-590-Param-1",
    "old_comment_raw": "@param domainName",
    "new_code_raw": "    public boolean virify(String name, String domain, String oldName, ModelMap model) {\n        if (CommonUtils.notEmpty(name)) {\n            if (CommonUtils.notEmpty(oldName) && !name.equals(oldName)\n                    && ControllerUtils.verifyHasExist(\"domain\", service.getEntity(name), model)\n                    || CommonUtils.empty(oldName) && ControllerUtils.verifyHasExist(\"domain\", service.getEntity(name), model)) {\n                return false;\n            }\n        }\n        if (CommonUtils.notEmpty(domain) && ControllerUtils.verifyHasExist(\"domain\", service.getEntity(domain), model)) {\n            return false;\n        }\n        return true;\n    }\n"
  },
  {
    "id": "apache_curator-93-Param-1",
    "old_comment_raw": "@param path path to ensure",
    "new_code_raw": "    public static CompletionStage<Void> asyncEnsureContainers(AsyncCuratorFramework client, ZPath path)\n    {\n        Set<ExistsOption> options = Collections.singleton(ExistsOption.createParentsAsContainers);\n        return client\n            .checkExists()\n            .withOptions(options)\n            .forPath(path.child(\"foo\").fullPath())\n            .thenApply(__ -> null)\n            ;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-784-Param-0",
    "old_comment_raw": "@param user",
    "new_code_raw": "    public EditAssigneeTask edit(User assignee) {\n        String assigneeLogin = assignee != null ? assignee.login() : \"\";\n\n        IssueRequest edit = IssueRequest.builder()\n                .assignees(Collections.singletonList(assigneeLogin))\n                .build();\n\n        store.editIssue(repositoryId, issueNumber, edit)\n                .subscribeOn(Schedulers.io())\n                .observeOn(AndroidSchedulers.mainThread())\n                .compose(activity.bindToLifecycle())\n                .subscribe(observer);\n\n        return this;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-783-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "    public Long hdel(final String key, final String... fields) {\n        checkIsInMulti();\n        client.hdel(key, fields);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_shiro-711-Param-1",
    "old_comment_raw": "@param info the AuthenticationInfo returned by  #doAuthenticate after the successful attempt.",
    "new_code_raw": "    protected AuthenticationEvent createSuccessEvent( AuthenticationToken token, Account account ) {\n        AuthenticationEventFactory factory = getAuthenticationEventFactory();\n        return factory.createSuccessEvent( token, account );\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-146-Param-0",
    "old_comment_raw": "@param channel",
    "new_code_raw": "    public String callback(@PathVariable(\"channel\") String channel, String state, String code, HttpServletRequest request,\n            HttpSession session, HttpServletResponse response, ModelMap model) {\n        Oauth oauthComponent = oauthChannelMap.get(channel);\n        SysSite site = getSite(request);\n        Cookie stateCookie = RequestUtils.getCookie(request.getCookies(), STATE_COOKIE_NAME);\n        if (null != oauthComponent && oauthComponent.enabled(site.getId()) && null != stateCookie && null != state\n                && state.equals(stateCookie.getValue())) {\n            try {\n                OauthAccess oauthAccess = oauthComponent.getOpenId(site.getId(), code);\n                if (null != oauthAccess && null != oauthAccess.getOpenId()) {\n                    Cookie cookie = RequestUtils.getCookie(request.getCookies(), RETURN_URL);\n                    String returnUrl = site.getDynamicPath();\n                    if (null != cookie && null != cookie.getValue()) {\n                        returnUrl = cookie.getValue();\n                    }\n                    SysUserToken entity = sysUserTokenService.getEntity(oauthAccess.getOpenId());\n                    if (null != entity) {\n                        if (entity.getChannel().equals(channel)) {\n                            ControllerUtils.setUserToSession(session, sysUserService.getEntity(entity.getUserId()));\n                            return UrlBasedViewResolver.REDIRECT_URL_PREFIX + returnUrl;\n                        }\n                    } else {\n                        SysUser user = ControllerUtils.getUserFromSession(session);\n                        if (null == user) {\n                            OauthUser oauthUser = oauthComponent.getUserInfo(site.getId(), oauthAccess);\n                            Map<String, String> config = configComponent.getConfigData(site.getId(), AbstractOauth.CONFIG_CODE);\n                            if (null != oauthUser && CommonUtils.notEmpty(config)\n                                    && CommonUtils.notEmpty(config.get(LoginConfigComponent.CONFIG_REGISTER_URL))) {\n                                model.addAttribute(\"nickname\", oauthUser.getNickname());\n                                model.addAttribute(\"openId\", oauthUser.getOpenId());\n                                model.addAttribute(\"avatar\", oauthUser.getAvatar());\n                                model.addAttribute(\"gender\", oauthUser.getGender());\n                                model.addAttribute(\"channel\", channel);\n                                model.addAttribute(\"returnUrl\", returnUrl);\n                                return UrlBasedViewResolver.REDIRECT_URL_PREFIX\n                                        + config.get(LoginConfigComponent.CONFIG_REGISTER_URL);\n                            }\n                        } else {\n                            String authToken = new StringBuilder(channel).append(CommonConstants.DOT).append(site.getId())\n                                    .append(CommonConstants.DOT).append(oauthAccess.getOpenId()).toString();\n                            Date now = CommonUtils.getDate();\n                            Map<String, String> config = configComponent.getConfigData(site.getId(), Config.CONFIG_CODE_SITE);\n                            int expiryMinutes = ConfigComponent.getInt(config.get(LoginConfigComponent.CONFIG_EXPIRY_MINUTES_WEB),\n                                    LoginConfigComponent.DEFAULT_EXPIRY_MINUTES);\n                            entity = new SysUserToken(authToken, site.getId(), user.getId(), channel, now,\n                                    DateUtils.addMinutes(now, expiryMinutes), RequestUtils.getIpAddress(request));\n                            sysUserTokenService.save(entity);\n                            LoginController.addLoginStatus(user, authToken, request, response, expiryMinutes);\n                            return UrlBasedViewResolver.REDIRECT_URL_PREFIX + returnUrl;\n                        }\n                    }\n                }\n            } catch (IOException e) {\n                log.error(e);\n            }\n        }\n        return UrlBasedViewResolver.REDIRECT_URL_PREFIX + site.getDynamicPath();\n    }\n"
  },
  {
    "id": "guoguibing_librec-227-Param-1",
    "old_comment_raw": "@param nd the other fixed dimension indices",
    "new_code_raw": "\tpublic SparseVector fiber(int dim, int... keys) {\n\t\tif ((keys.length != numDimensions - 1) || size() < 1)\n\t\t\tthrow new Error(\"The input indices do not match the fiber specification!\");\n\n\t\t// find an indexed dimension for searching indices\n\t\tint d = -1;\n\t\tif ((indexedDimensions.size() == 0) || (indexedDimensions.contains(dim) && indexedDimensions.size() == 1)) {\n\t\t\td = (dim != 0 ? 0 : 1);\n\t\t\tbuildIndex(d);\n\t\t} else {\n\t\t\tfor (int dd : indexedDimensions) {\n\t\t\t\tif (dd != dim) {\n\t\t\t\t\td = dd;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tSparseVector res = new SparseVector(dimensions[dim]);\n\n\t\t// all relevant positions\n\t\tCollection<Integer> indices = keyIndices[d].get(keys[d < dim ? d : d - 1]);\n\t\tif (indices == null || indices.size() == 0)\n\t\t\treturn res;\n\n\t\t// for each possible position\n\t\tfor (int index : indices) {\n\t\t\tboolean found = true;\n\t\t\tfor (int dd = 0, ndi = 0; dd < numDimensions; dd++) {\n\n\t\t\t\tif (dd == dim)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tif (keys[ndi++] != key(dd, index)) {\n\t\t\t\t\tfound = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (found) {\n\t\t\t\tres.set(key(dim, index), value(index));\n\t\t\t}\n\t\t}\n\n\t\treturn res;\n\t}\n"
  },
  {
    "id": "apache_ignite-5052-Param-1",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public Collection<ClusterNode> backups(Object key, long topVer) {\n        return backups(partition(key), topVer);\n    }\n"
  },
  {
    "id": "apache_wss4j-34-Associations-Param2",
    "old_comment_raw": "@param results where to store the found results data for the action",
    "new_code_raw": "    public static List fetchAllActionResults(\n        List resultList,\n        int action, \n        List actionResultList\n    ) {\n        for (int i = 0; i < resultList.size(); i++) {\n            //\n            // Check the result of every action whether it matches the given action\n            //\n            WSSecurityEngineResult result = \n                (WSSecurityEngineResult) resultList.get(i);\n            int resultAction = \n                ((java.lang.Integer)result.get(WSSecurityEngineResult.TAG_ACTION)).intValue();\n            if (resultAction == action) {\n                actionResultList.add(result);\n            }\n        }\n        return actionResultList;\n    }\n\n"
  },
  {
    "id": "haifengl_smile-236-Param-1",
    "old_comment_raw": "@param generation the maximum number of iterations.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, BiFunction<double[][], double[], Regression<double[]>> trainer, RegressionMeasure measure, double[][] x, double[] y, int k) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (k < 2) {\n            throw new IllegalArgumentException(\"Invalid k-fold cross validation: \" + k);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        int p = x[0].length;\n        RegressionFitness fitness = new RegressionFitness(trainer, measure, x, y, k);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-457-Param-0",
    "old_comment_raw": "@param transactions Map of txhash->transaction.",
    "new_code_raw": "    public ConnectionResult connect(Transaction transaction, ConnectMode mode) {\n        if (!transaction.getHash().equals(outpoint.getHash()))\n            return ConnectionResult.NO_SUCH_TX;\n        checkElementIndex((int) outpoint.getIndex(), transaction.getOutputs().size(), \"Corrupt transaction\");\n        TransactionOutput out = transaction.getOutput((int) outpoint.getIndex());\n        if (!out.isAvailableForSpending()) {\n            if (mode == ConnectMode.DISCONNECT_ON_CONFLICT) {\n                out.markAsUnspent();\n            } else if (mode == ConnectMode.ABORT_ON_CONFLICT) {\n                outpoint.fromTx = checkNotNull(out.parentTransaction);\n                return TransactionInput.ConnectionResult.ALREADY_SPENT;\n            }\n        }\n        connect(out);\n        return TransactionInput.ConnectionResult.SUCCESS;\n    }\n"
  },
  {
    "id": "apache_ignite-5697-Param-0",
    "old_comment_raw": "@param nodeId Reader to add.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, long topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!U.hasNearCache(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture<K, V> txFut = null;\n\n        Collection<GridCacheMvccCandidate<K>> cands = null;\n\n        ReaderId<K, V> reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId<>(nodeId, msgId);\n\n                ReaderId<K, V>[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate<K> c : cands) {\n                    IgniteInternalTx<K, V> tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId<K, V> reader0 = reader;\n\n                txFut.listen(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        cctx.kernalContext().closure().runLocalSafe(new GridPlainRunnable() {\n                            @Override public void run() {\n                                synchronized (this) {\n                                    // Release memory.\n                                    reader0.resetTxFuture();\n                                }\n                            }\n                        });\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "apache_ignite-13255-Param-1",
    "old_comment_raw": "@param deserializePortable Deserialize portable flag.",
    "new_code_raw": "    @Nullable public V get(K key, boolean deserializePortable, @Nullable IgnitePredicate<Cache.Entry<K, V>> filter)\n        throws IgniteCheckedException {\n        return getAllAsync(F.asList(key), deserializePortable, filter).get().get(key);\n    }\n"
  },
  {
    "id": "apache_ignite-1796-Param-0",
    "old_comment_raw": "@param c Grid configuration.",
    "new_code_raw": "    public static VisorMetricsConfiguration from(IgniteConfiguration c) {\n        VisorMetricsConfiguration cfg = new VisorMetricsConfiguration();\n\n        cfg.expireTime(c.getMetricsExpireTime());\n        cfg.historySize(c.getMetricsHistorySize());\n        cfg.loggerFrequency(c.getMetricsLogFrequency());\n\n        return cfg;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-806-Param-2",
    "old_comment_raw": "@param end",
    "new_code_raw": "  public List<String> lrange(final String key, final long start, final long stop) {\n    checkIsInMultiOrPipeline();\n    client.lrange(key, start, stop);\n    return client.getMultiBulkReply();\n  }\n"
  },
  {
    "id": "h2oai_h2o_2-287-Param-0",
    "old_comment_raw": "@param dataset Dataset to parse.",
    "new_code_raw": "  public static DParseTask createPassOne(Value dataset, Job job, CustomParser.Type parserType) {\n    return new DParseTask(dataset,job,parserType);\n  }\n"
  },
  {
    "id": "nickman_UnsafeAdapter-11-Associations-Param0",
    "old_comment_raw": "@param address the memory address of the AllocationPointerOperations",
    "new_code_raw": "\tpublic static final String print(final long address[]) {\n\t\tif(address==null || address.length==0) throw new IllegalArgumentException(\"Address array was null or zero length\");\n\t\tfinal byte dim = getDimension(address[0]);\n\t\tStringBuilder b = new StringBuilder(String.format(\"AllocationPointer >> [size: %s, capacity: %s, byteSize: %s]\", getSize(address[0]), getCapacity(address[0]), getEndOffset(address[0])));\n\t\tif(dim>1) {\n\t\t\tb.append(String.format(\"\\n\\tAllocation Sizes >> [size: %s, capacity: %s, byteSize: %s]\", getSize(address[1]), getCapacity(address[1]), getEndOffset(address[1])));\n\t\t\tif(dim>2) b.append(String.format(\"\\n\\tAllocation Alignment Overheads >> [size: %s, capacity: %s, byteSize: %s]\", getSize(address[2]), getCapacity(address[2]), getEndOffset(address[2])));\n\t\t}\n\t\treturn b.toString();\n\t}\n\n"
  },
  {
    "id": "apache_ignite-5008-Param-0",
    "old_comment_raw": "@param node Node.",
    "new_code_raw": "    public boolean belongs(ClusterNode node, K key, AffinityTopologyVersion topVer) {\n        assert node != null;\n\n        return belongs(node, partition(key), topVer);\n    }\n"
  },
  {
    "id": "Netflix_Hystrix-357-Param-0",
    "old_comment_raw": "@param type type",
    "new_code_raw": "    public FallbackMethod getFallbackMethod(Class<?> enclosingType, Method commandMethod, boolean extended) {\n        if (commandMethod.isAnnotationPresent(HystrixCommand.class)) {\n            return FALLBACK_METHOD_FINDER.find(enclosingType, commandMethod, extended);\n        }\n        return FallbackMethod.ABSENT;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-680-Param-0",
    "old_comment_raw": "@param commit",
    "new_code_raw": "    public static String abbreviate(final GitCommit commit) {\n        return commit != null ? abbreviate(commit.sha) : null;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-769-Param-0",
    "old_comment_raw": "@param title",
    "new_code_raw": "    public EditMilestoneTask edit(Milestone milestone) {\n        if (milestone != null)\n            milestoneNumber = milestone.getNumber();\n        else\n            milestoneNumber = -1;\n\n        dismissProgress();\n        showIndeterminate(string.updating_milestone);\n\n        super.execute();\n\n        return this;\n    }\n"
  },
  {
    "id": "todoroo_astrid-597-Param-2",
    "old_comment_raw": "@param data",
    "new_code_raw": "    public boolean handleActivityResult(int activityRequestCode, int resultCode, Intent data, EditText textField) {\n        boolean result = false;\n        // handle the result of voice recognition, put it into the textfield\n        if (activityRequestCode == this.requestCode) {\n            // this was handled here, even if voicerecognition fails for any reason\n            // so your program flow wont get chaotic if you dont explicitly state\n            // your own requestCodes.\n            result = true;\n            if (resultCode == Activity.RESULT_OK) {\n                // Fill the quickAddBox-view with the string the recognizer thought it could have heard\n                ArrayList<String> match = data.getStringArrayListExtra(\n                        RecognizerIntent.EXTRA_RESULTS);\n                // make sure we only do this if there is SomeThing (tm) returned\n                if (match != null && match.size() > 0 && match.get(0).length() > 0) {\n                    String recognizedSpeech = match.get(0);\n                    recognizedSpeech = recognizedSpeech.substring(0, 1).toUpperCase() +\n                        recognizedSpeech.substring(1).toLowerCase();\n\n                    if(append)\n                        textField.setText((textField.getText() + \" \" + recognizedSpeech).trim());\n                    else\n                        textField.setText(recognizedSpeech);\n                }\n            }\n        }\n\n        return result;\n    }\n"
  },
  {
    "id": "essentials_Essentials-249-Param-0",
    "old_comment_raw": "@param userName",
    "new_code_raw": "\tpublic User surpassOverload(String userId) {\n\n\t\tif (!isOverloaded(userId)) {\n\t\t\treturn getUser(userId);\n\t\t}\n\t\tif (getUsers().containsKey(userId.toLowerCase())) {\n\t\t\treturn getUsers().get(userId.toLowerCase());\n\t\t}\n\t\tUser newUser = createUser(userId);\n\t\treturn newUser;\n\t}\n"
  },
  {
    "id": "apache_ignite-960-Param-2",
    "old_comment_raw": "@param recursive Recursive flag.",
    "new_code_raw": "    public boolean deleteDual(final GridGgfsFileSystem fs, final GridGgfsPath path, final boolean recursive)\n        throws GridException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert path != null;\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<GridGgfsPath, GridGgfsFileInfo> infos) throws Exception {\n                        GridGgfsFileInfo info = infos.get(path);\n\n                        if (info == null)\n                            return false; // File doesn't exist in the secondary file system.\n\n                        if (!fs.delete(secondaryPath(path), recursive))\n                            return false; // Delete failed remotely.\n\n                        if (path.parent() != null) {\n                            assert infos.containsKey(path.parent());\n\n                            softDeleteNonTx(infos.get(path.parent()).id(), path.name(), info.id());\n                        }\n                        else {\n                            assert ROOT_ID.equals(info.id());\n\n                            softDeleteNonTx(null, path.name(), info.id());\n                        }\n\n                        // Update the deleted file info with path information for delete worker.\n                        id2InfoPrj.transform(info.id(), new UpdatePath(path));\n\n                        return true; // No additional handling is required.\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws GridException {\n                        U.error(log, \"Path delete in DUAL mode failed [path=\" + path + \", recursive=\" + recursive + ']',\n                            err);\n\n                        throw new GridException(\"Failed to delete the path due to secondary file system exception: \",\n                            err);\n                    }\n                };\n\n                Boolean res = synchronizeAndExecute(task, fs, false, Collections.singleton(TRASH_ID), path);\n\n                delWorker.signal();\n\n                return res;\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to delete in DUAL mode because Grid is stopping: \" + path);\n    }\n"
  },
  {
    "id": "eclipse_pdt-128-Associations-Param0",
    "old_comment_raw": "@param elements an array of model elements",
    "new_code_raw": "\tprivate boolean allOfSameKind(IFolder[] folders) {\n\t\tint libraryFolderCount = 0;\n\n\t\t// count the library folders in the array\n\t\tfor (IResource folder : folders) {\n\t\t\tif (LibraryFolderManager.getInstance().isInLibraryFolder(folder)) {\n\t\t\t\tlibraryFolderCount++;\n\t\t\t}\n\t\t}\n\n\t\t// If the number of library folders is 0, then all folders are source\n\t\t// folders. If the number of library folders equals the number of given\n\t\t// folders, then all folders are library folders. In any other case,\n\t\t// there is a mixture of library folders and source folders.\n\t\treturn libraryFolderCount == 0 || libraryFolderCount == folders.length;\n\t}\n\n"
  },
  {
    "id": "apache_ignite-9869-Param-0",
    "old_comment_raw": "@param msg Message.",
    "new_code_raw": "    protected boolean ensured(TcpDiscoveryAbstractMessage msg) {\n        return U.getAnnotation(msg.getClass(), TcpDiscoveryEnsureDelivery.class) != null;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-783-Param-1",
    "old_comment_raw": "@param field",
    "new_code_raw": "    public Long hdel(final String key, final String... fields) {\n        checkIsInMulti();\n        client.hdel(key, fields);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-6263-Param-0",
    "old_comment_raw": "@param ignite Grid.",
    "new_code_raw": "    public static Iterable<VisorCacheConfiguration> list(IgniteEx ignite, CacheConfiguration[] caches) {\n        if (caches == null)\n            return Collections.emptyList();\n\n        final Collection<VisorCacheConfiguration> cfgs = new ArrayList<>(caches.length);\n\n        for (CacheConfiguration cache : caches)\n            cfgs.add(from(ignite, cache));\n\n        return cfgs;\n    }\n"
  },
  {
    "id": "apache_ignite-12146-Param-1",
    "old_comment_raw": "@param c Actual cache.",
    "new_code_raw": "    public static VisorCache from(Ignite ignite, String cacheName, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && ca.context().affinityNode();\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(AffinityTopologyVersion.NONE)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<GridCacheEntryEx> set = ca.map().entries0();\n\n        long memSz = 0;\n\n        Iterator<GridCacheEntryEx> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name = cacheName;\n        cache.mode = mode;\n        cache.memorySize = memSz;\n        cache.size = size;\n        cache.nearSize = near;\n        cache.dhtSize = size - near;\n        cache.primarySize = ca.primarySize();\n        cache.offHeapAllocatedSize = ca.offHeapAllocatedSize();\n        cache.offHeapEntriesCnt = ca.offHeapEntriesCount();\n        cache.swapSize = swapSize;\n        cache.swapKeys = swapKeys;\n        cache.partitions = ca.affinity().partitions();\n        cache.primaryPartitions = pps;\n        cache.backupPartitions = bps;\n        cache.metrics = VisorCacheMetrics.from(ca);\n        cache.partitionsMap = partsMap;\n\n        return cache;\n    }\n"
  },
  {
    "id": "gephi_gephi-118-Param-2",
    "old_comment_raw": "@param pX",
    "new_code_raw": "    private String createImageFile(double[] pVals, String pName, String pX, String pY) {\n        XYSeries series = new XYSeries(pName);\n        for (int i = 0; i < N; i++) {\n            series.add(i, pVals[i]);\n        }\n        XYSeriesCollection dataSet = new XYSeriesCollection();\n        dataSet.addSeries(series);\n\n        JFreeChart chart = ChartFactory.createXYLineChart(\n                pName,\n                pX,\n                pY,\n                dataSet,\n                PlotOrientation.VERTICAL,\n                true,\n                false,\n                false);\n        XYPlot plot = (XYPlot) chart.getPlot();\n        XYLineAndShapeRenderer renderer = new XYLineAndShapeRenderer();\n        renderer.setSeriesLinesVisible(0, false);\n        renderer.setSeriesShapesVisible(0, true);\n        renderer.setSeriesShape(0, new java.awt.geom.Ellipse2D.Double(0, 0, 1, 1));\n        plot.setBackgroundPaint(java.awt.Color.WHITE);\n        plot.setDomainGridlinePaint(java.awt.Color.GRAY);\n        plot.setRangeGridlinePaint(java.awt.Color.GRAY);\n        plot.setRenderer(renderer);\n\n        String imageFile = \"\";\n        try {\n            final ChartRenderingInfo info = new ChartRenderingInfo(new StandardEntityCollection());\n            final File file1 = new File(pY + \".png\");\n            String fullPath = file1.getAbsolutePath();\n\n            fullPath = fullPath.replaceAll(\"\\\\\\\\\", \"\\\\\\\\\\\\\\\\\");\n\n            imageFile = \"<IMG SRC=\\\"file:\\\\\\\\\\\\\\\\\" + fullPath + \"\\\" \" + \"WIDTH=\\\"600\\\" HEIGHT=\\\"400\\\" BORDER=\\\"0\\\" USEMAP=\\\"#chart\\\"></IMG>\";\n\n            File f2 = new File(fullPath);\n            ChartUtilities.saveChartAsPNG(file1, chart, 600, 400, info);\n        } catch (IOException e) {\n            System.out.println(e.toString());\n        }\n\n        return imageFile;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-489-Param-0",
    "old_comment_raw": "@param weightingMap all parameters influencing the weighting. E.g. parameters coming via GHRequest.getHints or directly via \"&amp;api.xy=\" from the URL of the web UI",
    "new_code_raw": "    public Weighting createWeighting(HintsMap hintsMap, FlagEncoder encoder) {\n        String weighting = hintsMap.getWeighting().toLowerCase();\n\n        if (encoder.supports(GenericWeighting.class)) {\n            DataFlagEncoder dataEncoder = (DataFlagEncoder) encoder;\n            return new GenericWeighting(dataEncoder, dataEncoder.readStringMap(hintsMap));\n        } else if (\"shortest\".equalsIgnoreCase(weighting)) {\n            return new ShortestWeighting(encoder);\n        } else if (\"fastest\".equalsIgnoreCase(weighting) || weighting.isEmpty()) {\n            if (encoder.supports(PriorityWeighting.class))\n                return new PriorityWeighting(encoder, hintsMap);\n            else\n                return new FastestWeighting(encoder, hintsMap);\n        } else if (\"curvature\".equalsIgnoreCase(weighting)) {\n            if (encoder.supports(CurvatureWeighting.class))\n                return new CurvatureWeighting(encoder, hintsMap);\n\n        } else if (\"short_fastest\".equalsIgnoreCase(weighting)) {\n            return new ShortFastestWeighting(encoder, hintsMap);\n        }\n\n        throw new IllegalArgumentException(\"weighting \" + weighting + \" not supported\");\n    }\n"
  },
  {
    "id": "apache_ignite-4861-Param-0",
    "old_comment_raw": "@param key Key to check.",
    "new_code_raw": "    public boolean containsKey(KeyCacheObject key, byte[] keyBytes) throws IgniteCheckedException {\n        if (!offheapEnabled && !swapEnabled)\n            return false;\n\n        checkIteratorQueue();\n\n        int part = cctx.affinity().partition(key);\n\n        // First check off-heap store.\n        if (offheapEnabled)\n            if (offheap.contains(spaceName, part, key, keyBytes))\n                return true;\n\n        if (swapEnabled) {\n            assert key != null;\n\n            byte[] valBytes = swapMgr.read(spaceName, new SwapKey(key, part, keyBytes),\n                cctx.deploy().globalLoader());\n\n            return valBytes != null;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-11591-Param-0",
    "old_comment_raw": "@param cls Input split class.",
    "new_code_raw": "    public static GridHadoopFileBlock readFileBlock(String clsName, FSDataInputStream in, @Nullable String[] hosts)\n        throws GridException {\n        if (!FileSplit.class.getName().equals(clsName))\n            return null;\n\n        FileSplit split = new FileSplit();\n\n        try {\n            split.readFields(in);\n        }\n        catch (IOException e) {\n            throw new GridException(e);\n        }\n\n        if (hosts == null)\n            hosts = EMPTY_HOSTS;\n\n        return new GridHadoopFileBlock(hosts, split.getPath().toUri(), split.getStart(), split.getLength());\n    }\n"
  },
  {
    "id": "todoroo_astrid-746-Param-1",
    "old_comment_raw": "@param text",
    "new_code_raw": "    public static ProgressDialog progressDialog(Activity context, String text) {\n        ProgressDialog dialog = new ProgressDialog(context);\n        dialog.setIndeterminate(true);\n        dialog.setProgressStyle(ProgressDialog.STYLE_SPINNER);\n        dialog.setMessage(text);\n        dialog.show();\n        dialog.setOwnerActivity(context);\n        return dialog;\n    }\n"
  },
  {
    "id": "apache_ignite-12065-Param-0",
    "old_comment_raw": "@param ignite Grid.",
    "new_code_raw": "    public static VisorCache from(Ignite g, GridCache c, int sample) throws IgniteCheckedException {\n        assert g != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)g).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = g.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<Cache.Entry> set = ca.entrySet();\n\n        long memSz = 0;\n\n        Iterator<Cache.Entry> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n//        TODO ignite-96\n//        while (it.hasNext() && cnt < sz) {\n//            memSz += it.next().memorySize();\n//\n//            cnt++;\n//        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-4097-Param-0",
    "old_comment_raw": "@param vis Visitor.",
    "new_code_raw": "            @Override public void apply(Cache.Entry<K, V> e) {\n                if (isAll(e, true))\n                    vis.apply(e);\n            }\n"
  },
  {
    "id": "eclipse_rt.equinox.framework-55-Associations-Param0",
    "old_comment_raw": "@param target the base name of the managed target to open.",
    "new_code_raw": "\tpublic InputStream getInputStream(String managedFile) throws IOException {\n\t\treturn getInputStream(managedFile, ReliableFile.OPEN_BEST_AVAILABLE);\n\t}\n\n"
  },
  {
    "id": "bytedeco_javacpp-210-Param-0",
    "old_comment_raw": "@param pointer data to access via a buffer or to copy to an array",
    "new_code_raw": "    public static CharIndexer create(final CharPointer pointer, long[] sizes, long[] strides, boolean direct) {\n        if (direct) {\n            return Raw.getInstance() != null ? new CharRawIndexer(pointer, sizes, strides)\n                                             : new CharBufferIndexer(pointer.asBuffer(), sizes, strides);\n        } else {\n            final long position = pointer.position();\n            char[] array = new char[(int)Math.min(pointer.limit() - position, Integer.MAX_VALUE)];\n            pointer.get(array);\n            return new CharArrayIndexer(array, sizes, strides) {\n                @Override public void release() {\n                    pointer.position(position).put(array);\n                    super.release();\n                }\n            };\n        }\n    }\n"
  },
  {
    "id": "andyglick_hk2-fork-41-Associations-Param1",
    "old_comment_raw": "@param annotatedGuy The annotated class or producer method",
    "new_code_raw": "    public static InjectionResolver<?> getInjectionResolver(\n            ServiceLocatorImpl locator, Injectee injectee) throws IllegalStateException {\n        return getInjectionResolver(locator, injectee.getParent(), injectee.getPosition());\n\n    }\n\n"
  },
  {
    "id": "xetorthio_jedis-486-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "    public Long lrem(final String key, final int count, final String value) {\n        runChecks();\n        client.lrem(key, count, value);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "haifengl_smile-301-Param-3",
    "old_comment_raw": "@param itol specify which convergence test is applied. If itol = 1, iteration stops when |Ax - b| / |b| is less than the parameter tolerance. If itol = 2, the stop criterion is |A-1 (Ax - b)| / |A-1b| is less than tolerance. If tol = 3, |xk+1 - xk|2 is less than tolerance. The setting of tol = 4 is same as tol = 3 except that the L&infin; norm instead of L2.",
    "new_code_raw": "    public static double solve(Matrix A, Preconditioner Ap, double[] b, double[] x, double tol, int itol) {\n        return solve(A, Ap, b, x, tol, itol, 2 * Math.max(A.nrows(), A.ncols()));\n    }\n"
  },
  {
    "id": "zxing_zxing-708-Param-0",
    "old_comment_raw": "@param rawFormatInfo",
    "new_code_raw": "  static FormatInformation decodeFormatInformation(int maskedFormatInfo) {\n    FormatInformation formatInfo = doDecodeFormatInformation(maskedFormatInfo);\n    if (formatInfo != null) {\n      return formatInfo;\n    }\n    // Should return null, but, some QR codes apparently\n    // do not mask this info. Try again by actually masking the pattern\n    // first\n    return doDecodeFormatInformation(maskedFormatInfo ^ FORMAT_INFO_MASK_QR);\n  }\n"
  },
  {
    "id": "todoroo_astrid-772-Param-1",
    "old_comment_raw": "@param where",
    "new_code_raw": "    public int deleteWhere(AbstractDatabase database, Criterion where) {\n        return database.getDatabase().delete(Metadata.TABLE.getName(),\n                where.toString(), null);\n    }\n"
  },
  {
    "id": "apache_ignite-11549-Param-0",
    "old_comment_raw": "@param jCommander JCommander instance.",
    "new_code_raw": "    private String reformatArguments(List<String> args) {\n        StringBuilder sb = new StringBuilder();\n\n        addArgWithValue(sb, \"INTERACTIVE\", formatBooleanValue(interactive));\n        addArgWithValue(sb, \"QUIET\", \"-DGRIDGAIN_QUIET=\" + !verbose);\n        addArgWithValue(sb, \"NO_PAUSE\", formatBooleanValue(noPause));\n        addArgWithValue(sb, \"HADOOP_LIB_DIR\", useHadoop1 ? \"hadoop1\" : \"hadoop2\");\n\n        parseJvmOptionsAndSpringConfig(args);\n\n        addArgWithValue(sb, \"JVM_XOPTS\", jvmOptions);\n        addArgWithValue(sb, \"CONFIG\", springCfgPath);\n\n        return sb.toString().trim();\n    }\n"
  },
  {
    "id": "apache_ignite-5491-Param-0",
    "old_comment_raw": "@param filter Entry filter.",
    "new_code_raw": "    public boolean visitable(CacheEntryPredicate[] filter) {\n        try {\n            if (obsoleteOrDeleted() || (filter != CU.empty0() &&\n                !cctx.isAll(this, filter)))\n                return false;\n        }\n        catch (IgniteCheckedException e) {\n            U.error(log, \"An exception was thrown while filter checking.\", e);\n\n            RuntimeException ex = e.getCause(RuntimeException.class);\n\n            if (ex != null)\n                throw ex;\n\n            Error err = e.getCause(Error.class);\n\n            if (err != null)\n                throw err;\n\n            return false;\n        }\n\n        IgniteInternalTx tx = cctx.tm().localTxx();\n\n        return tx == null || !tx.removed(txKey());\n    }\n"
  },
  {
    "id": "JetBrains_android-18-Associations-Param0",
    "old_comment_raw": "@param mavenCoordinate the coordinate to retrieve an archive file for",
    "new_code_raw": "  @Nullable\n  public static File getArchiveForCoordinate(GradleCoordinate gradleCoordinate) {\n    SdkManager sdk = AndroidSdkUtils.tryToChooseAndroidSdk();\n\n    if (sdk == null) {\n      return null;\n    }\n\n    // Get the parameters to include in the path\n    String sdkLocation = sdk.getLocation();\n    String artifactId = gradleCoordinate.getArtifactId();\n    String revision = gradleCoordinate.getFullRevision();\n    RepositoryLibrary library = EXTRAS_REPOSITORY.get(artifactId);\n\n    File path = new File(String.format(library.basePath, sdkLocation, library.id));\n    String revisionPath = String.format(MAVEN_REVISION_PATH, library.id, revision) + library.archiveExtension;\n\n    return new File(path, revisionPath);\n  }\n\n"
  },
  {
    "id": "apache_ignite-4862-Param-1",
    "old_comment_raw": "@param keyBytes Key bytes.",
    "new_code_raw": "    boolean removeOffheap(final KeyCacheObject key, byte[] keyBytes) throws IgniteCheckedException {\n        assert offheapEnabled;\n\n        checkIteratorQueue();\n\n        int part = cctx.affinity().partition(key);\n\n        return offheap.removex(spaceName, part, key, keyBytes);\n    }\n"
  },
  {
    "id": "apache_shiro-906-Param-2",
    "old_comment_raw": "@param configValue the configured value for this filter for the matching path.",
    "new_code_raw": "    protected boolean onPreHandle(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception {\n        return true;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-26-Param-0",
    "old_comment_raw": "@param chol",
    "new_code_raw": "  public Cholesky cholesky(Cholesky chol, int parallelize) {\n    if( chol == null ) {\n      double[][] xx = _xx.clone();\n      for( int i = 0; i < xx.length; ++i )\n        xx[i] = xx[i].clone();\n      chol = new Cholesky(xx, _diag.clone());\n    }\n    final Cholesky fchol = chol;\n    final int sparseN = _diag.length;\n    final int denseN = _fullN - sparseN;\n    boolean spd=true;\n    // compute the cholesky of the diagonal and diagonal*dense parts\n    if( _diag != null ) for( int i = 0; i < sparseN; ++i ) {\n      double d = 1.0 / (chol._diag[i] = Math.sqrt(_diag[i]));\n      for( int j = 0; j < denseN; ++j )\n        chol._xx[j][i] = d*_xx[j][i];\n    }\n    Futures fs = new Futures();\n    // compute the outer product of diagonal*dense\n    for( int i = 0; i < denseN; ++i ) {\n      final int fi = i;\n      fs.add(new RecursiveAction() {\n        @Override protected void compute() {\n          for( int j = 0; j <= fi; ++j ) {\n            double s = 0;\n            for( int k = 0; k < sparseN; ++k )\n              s += fchol._xx[fi][k] * fchol._xx[j][k];\n            fchol._xx[fi][j + sparseN] = _xx[fi][j + sparseN] - s;\n          }\n        }\n      }.fork());\n    }\n    fs.blockForPending();\n        \n    // compute the cholesky of dense*dense-outer_product(diagonal*dense)\n    // TODO we still use Jama, which requires (among other things) copy and expansion of the matrix. Do it here without copy and faster.\n    double[][] arr = new double[denseN][];\n    for( int i = 0; i < arr.length; ++i )\n      arr[i] = Arrays.copyOfRange(fchol._xx[i], sparseN, sparseN + denseN);\n    // parallelize cholesky\n    if (parallelize == 1) {\n      int p = Runtime.getRuntime().availableProcessors();\n      InPlaceCholesky d = InPlaceCholesky.decompose_2(arr, 10, p);\n      fchol.setSPD(d.isSPD());\n      arr = d.getL();\n    } else {\n      // make it symmetric\n      for( int i = 0; i < arr.length; ++i )\n        for( int j = 0; j < i; ++j )\n          arr[j][i] = arr[i][j];\n      CholeskyDecomposition c = new Matrix(arr).chol();\n      fchol.setSPD(c.isSPD());\n      arr = c.getL().getArray();\n    }\n    for( int i = 0; i < arr.length; ++i )\n      System.arraycopy(arr[i], 0, fchol._xx[i], sparseN, i + 1);\n    return chol;\n  }\n"
  },
  {
    "id": "graphhopper_graphhopper-482-Param-1",
    "old_comment_raw": "@param encoder the FlagEncoder (to specify the vehicle)",
    "new_code_raw": "    public Weighting createWeighting( String weighting, FlagEncoder encoder )\n    {\n        // ignore case\n        weighting = weighting.toLowerCase();\n        if (\"fastest\".equals(weighting))\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                return new PriorityWeighting((BikeCommonFlagEncoder) encoder);\n            else\n                return new FastestWeighting(encoder);\n        }\n        return new ShortestWeighting();\n    }\n"
  },
  {
    "id": "apache_ignite-1487-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite g, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final GridStreamer streamer = g.streamer(\"popular-numbers\");\n\n                try {\n                    // Send reduce query to all 'popular-numbers' streamers\n                    // running on local and remote nodes.\n                    Collection<GridStreamerIndexEntry<Integer, Integer, Long>> col = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new GridClosure<GridStreamerContext,\n                            Collection<GridStreamerIndexEntry<Integer, Integer, Long>>>() {\n                            @Override public Collection<GridStreamerIndexEntry<Integer, Integer, Long>> apply(\n                                GridStreamerContext ctx) {\n                                GridStreamerIndex<Integer, Integer, Long> view = ctx.<Integer>window().index();\n\n                                return view.entries(-1 * POPULAR_NUMBERS_CNT);\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new PopularNumbersReducer());\n\n                    for (GridStreamerIndexEntry<Integer, Integer, Long> cntr : col)\n                        System.out.printf(\"%3d=%d\\n\", cntr.key(), cntr.value());\n\n                    System.out.println(\"----------------\");\n                }\n                catch (GridException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 3000, 3000);\n\n        return task;\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-368-Param-0",
    "old_comment_raw": "@param privateKeyToDecode The private key to decrypt",
    "new_code_raw": "    public byte[] decrypt(EncryptedData dataToDecrypt, KeyParameter aesKey) throws KeyCrypterException {\n        checkNotNull(dataToDecrypt);\n        checkNotNull(aesKey);\n\n        try {\n            ParametersWithIV keyWithIv = new ParametersWithIV(new KeyParameter(aesKey.getKey()), dataToDecrypt.initialisationVector);\n\n            // Decrypt the message.\n            BufferedBlockCipher cipher = new PaddedBufferedBlockCipher(new CBCBlockCipher(new AESFastEngine()));\n            cipher.init(false, keyWithIv);\n\n            byte[] cipherBytes = dataToDecrypt.encryptedBytes;\n            byte[] decryptedBytes = new byte[cipher.getOutputSize(cipherBytes.length)];\n            final int length1 = cipher.processBytes(cipherBytes, 0, cipherBytes.length, decryptedBytes, 0);\n            final int length2 = cipher.doFinal(decryptedBytes, length1);\n\n            return Arrays.copyOf(decryptedBytes, length1 + length2);\n        } catch (Exception e) {\n            throw new KeyCrypterException(\"Could not decrypt bytes\", e);\n        }\n    }\n"
  },
  {
    "id": "haifengl_smile-236-Param-0",
    "old_comment_raw": "@param size the population size of Genetic Algorithm.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, BiFunction<double[][], double[], Regression<double[]>> trainer, RegressionMeasure measure, double[][] x, double[] y, int k) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (k < 2) {\n            throw new IllegalArgumentException(\"Invalid k-fold cross validation: \" + k);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        int p = x[0].length;\n        RegressionFitness fitness = new RegressionFitness(trainer, measure, x, y, k);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;\n    }\n"
  },
  {
    "id": "shopizer_ecommerce_shopizer-45-Param-1",
    "old_comment_raw": "@param imageName",
    "new_code_raw": "\tpublic String buildStaticFilePath(MerchantStore store) {\n\t\tStringBuilder sb = new StringBuilder().append(Constants.STATIC_URI).append(Constants.FILES_URI).append(Constants.SLASH).append(store.getCode()).append(Constants.SLASH);\n\t\treturn sb.toString();\n\t}\n"
  },
  {
    "id": "zxing_zxing-171-Param-0",
    "old_comment_raw": "@param image The image to decode",
    "new_code_raw": "  private Result doDecode(BinaryBitmap image, Hashtable hints) throws ReaderException {\n    int width = image.getWidth();\n    int height = image.getHeight();\n    BitArray row = new BitArray(width);\n\n    int middle = height >> 1;\n    boolean tryHarder = hints != null && hints.containsKey(DecodeHintType.TRY_HARDER);\n    int rowStep = Math.max(1, height >> (tryHarder ? 7 : 4));\n    int maxLines;\n    if (tryHarder) {\n      maxLines = height; // Look at the whole image, not just the center\n    } else {\n      maxLines = 9; // Nine rows spaced 1/16 apart is roughly the middle half of the image\n    }\n\n    for (int x = 0; x < maxLines; x++) {\n\n      // Scanning from the middle out. Determine which row we're looking at next:\n      int rowStepsAboveOrBelow = (x + 1) >> 1;\n      boolean isAbove = (x & 0x01) == 0; // i.e. is x even?\n      int rowNumber = middle + rowStep * (isAbove ? rowStepsAboveOrBelow : -rowStepsAboveOrBelow);\n      if (rowNumber < 0 || rowNumber >= height) {\n        // Oops, if we run off the top or bottom, stop\n        break;\n      }\n\n      // Estimate black point for this row and load it:\n      try {\n        row = image.getBlackRow(rowNumber, row);\n      } catch (ReaderException re) {\n        continue;\n      }      \n\n      // While we have the image data in a BitArray, it's fairly cheap to reverse it in place to\n      // handle decoding upside down barcodes.\n      for (int attempt = 0; attempt < 2; attempt++) {\n        if (attempt == 1) { // trying again?\n          row.reverse(); // reverse the row and continue\n        }\n        try {\n          // Look for a barcode\n          Result result = decodeRow(rowNumber, row, hints);\n          // We found our barcode\n          if (attempt == 1) {\n            // But it was upside down, so note that\n            result.putMetadata(ResultMetadataType.ORIENTATION, new Integer(180));\n            // And remember to flip the result points horizontally.\n            ResultPoint[] points = result.getResultPoints();\n            points[0] = new ResultPoint(width - points[0].getX() - 1, points[0].getY());\n            points[1] = new ResultPoint(width - points[1].getX() - 1, points[1].getY());\n          }\n          return result;\n        } catch (ReaderException re) {\n          // continue -- just couldn't decode this row\n        }\n      }\n    }\n\n    throw ReaderException.getInstance();\n  }\n"
  },
  {
    "id": "xetorthio_jedis-830-Param-2",
    "old_comment_raw": "@param end",
    "new_code_raw": "  public Long zremrangeByScore(final byte[] key, final double min, final double max) {\n    return zremrangeByScore(key, toByteArray(min), toByteArray(max));\n  }\n"
  },
  {
    "id": "openhab_openhab1_addons-725-Param-0",
    "old_comment_raw": "@param data The byte to crc check",
    "new_code_raw": "\tpublic static byte crc8_tab(byte data, byte crcInit) {\n\t\tshort ci = (short) (crcInit & 0xFF);\n\t\tbyte crc = (byte) (CRC_TAB_8_VALUE[ci] ^ (data & 0xFF));\n\t\treturn crc;\n\t}\n"
  },
  {
    "id": "apache_ignite-4386-Param-1",
    "old_comment_raw": "@param out Output stream to that file.",
    "new_code_raw": "    private IgfsFileWorkerBatch newBatch(final IgfsPath path, OutputStream out) throws IgniteCheckedException {\n        assert path != null;\n        assert out != null;\n\n        if (enterBusy()) {\n            try {\n                IgfsFileWorkerBatch batch = new IgfsFileWorkerBatch(path, out);\n\n                while (true) {\n                    IgfsFileWorker worker = workerMap.get(path);\n\n                    if (worker != null) {\n                        if (worker.addBatch(batch)) // Added batch to active worker.\n                            break;\n                        else\n                            workerMap.remove(path, worker); // Worker is stopping. Remove it from map.\n                    }\n                    else {\n                        worker = new IgfsFileWorker(\"ggfs-file-worker-\" + path) {\n                            @Override protected void onFinish() {\n                                workerMap.remove(path, this);\n                            }\n                        };\n\n                        boolean b = worker.addBatch(batch);\n\n                        assert b;\n\n                        if (workerMap.putIfAbsent(path, worker) == null) {\n                            worker.start();\n\n                            break;\n                        }\n                    }\n                }\n\n                return batch;\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IgniteCheckedException(\"Cannot create new output stream to the secondary file system because GGFS is \" +\n                \"stopping: \" + path);\n    }\n"
  },
  {
    "id": "apache_pulsar-309-Param-0",
    "old_comment_raw": "@param inputRecordContext",
    "new_code_raw": "    public static ByteBuffer serializeRecordToFlatBuffer(Record<byte[]> record) {\n        DEFAULT_FB_BUILDER.clear();\n        return serializeRecordToFlatBuffer(DEFAULT_FB_BUILDER, record);\n    }\n"
  },
  {
    "id": "xetorthio_jedis-501-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "    public Boolean setbit(byte[] key, long offset, boolean value) {\n\tclient.setbit(key, offset, value);\n\treturn client.getIntegerReply() == 1;\n    }\n"
  },
  {
    "id": "RSB4760_apq8016_packages_apps_QuickSearchBox-0-Associations-Param0",
    "old_comment_raw": "@param sourcePos",
    "new_code_raw": "    public SuggestionCursor getSourceResult(ComponentName source) {\n        if (mClosed) {\n            throw new IllegalStateException(\"Called getSourceResult(\" + source\n                + \") when closed.\");\n        }\n        return mSourceResultsBySource.get(source);\n    }\n\n"
  },
  {
    "id": "zxing_zxing-536-Param-0",
    "old_comment_raw": "@param bits booleans representing white/black QR Code modules",
    "new_code_raw": "  public DecoderResult decode(BitMatrix bits, Hashtable hints) throws ReaderException {\n\n    // Construct a parser and read version, error-correction level\n    BitMatrixParser parser = new BitMatrixParser(bits);\n    Version version = parser.readVersion();\n    ErrorCorrectionLevel ecLevel = parser.readFormatInformation().getErrorCorrectionLevel();\n\n    // Read codewords\n    byte[] codewords = parser.readCodewords();\n    // Separate into data blocks\n    DataBlock[] dataBlocks = DataBlock.getDataBlocks(codewords, version, ecLevel);\n\n    // Count total number of data bytes\n    int totalBytes = 0;\n    for (int i = 0; i < dataBlocks.length; i++) {\n      totalBytes += dataBlocks[i].getNumDataCodewords();\n    }\n    byte[] resultBytes = new byte[totalBytes];\n    int resultOffset = 0;\n\n    // Error-correct and copy data blocks together into a stream of bytes\n    for (int j = 0; j < dataBlocks.length; j++) {\n      DataBlock dataBlock = dataBlocks[j];\n      byte[] codewordBytes = dataBlock.getCodewords();\n      int numDataCodewords = dataBlock.getNumDataCodewords();\n      correctErrors(codewordBytes, numDataCodewords);\n      for (int i = 0; i < numDataCodewords; i++) {\n        resultBytes[resultOffset++] = codewordBytes[i];\n      }\n    }\n\n    // Decode the contents of that stream of bytes\n    return DecodedBitStreamParser.decode(resultBytes, version, ecLevel, hints);\n  }\n"
  },
  {
    "id": "spring_projects_spring_kafka-130-Param-1",
    "old_comment_raw": "@param categories the categories to use for logging level adjusting",
    "new_code_raw": "\tpublic Log4j2LevelAdjuster categories(boolean merge, String... categoriesToAdjust) {\n\t\treturn new Log4j2LevelAdjuster(this.level, this.classes,\n\t\t\t\tmerge\n\t\t\t\t\t\t? Stream.of(this.categories, categoriesToAdjust).flatMap(Stream::of).toArray(String[]::new)\n\t\t\t\t\t\t: categoriesToAdjust);\n\t}\n"
  },
  {
    "id": "apache_ignite-7314-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    @Nullable public GridCacheMvccCandidate explicitLock(IgniteTxKey key, @Nullable GridCacheVersion ver) {\n        for (GridCacheExplicitLockSpan span : pendingExplicit.values()) {\n            GridCacheMvccCandidate cand = span.candidate(key, ver);\n\n            if (cand != null)\n                return cand;\n        }\n\n        return null;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-507-Param-0",
    "old_comment_raw": "@param wMap all parameters influencing the weighting. E.g. URL parameters coming via GHRequest",
    "new_code_raw": "    public Weighting createWeighting( WeightingMap weightingMap, FlagEncoder encoder )\n    {\n        String weighting = weightingMap.getWeighting();\n        Weighting result;\n\n        if (\"shortest\".equalsIgnoreCase(weighting))\n        {\n            result = new ShortestWeighting();\n        } else if (\"fastest\".equalsIgnoreCase(weighting) || weighting.isEmpty())\n        {\n            if (encoder.supports(PriorityWeighting.class))\n                result = new PriorityWeighting(encoder);\n            else\n                result = new FastestWeighting(encoder);\n        } else\n        {\n            throw new UnsupportedOperationException(\"weighting \" + weighting + \" not supported\");\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-4392-Param-0",
    "old_comment_raw": "@param path Path.",
    "new_code_raw": "    private List<IgniteUuid> fileIds(IgfsPath path, boolean skipTx) throws IgniteCheckedException {\n        assert path != null;\n\n        // Path components.\n        Collection<String> components = path.components();\n\n        // Collection of file IDs for components of specified path.\n        List<IgniteUuid> ids = new ArrayList<>(components.size() + 1);\n\n        ids.add(ROOT_ID); // Always add root ID.\n\n        IgniteUuid fileId = ROOT_ID;\n\n        for (String s : components) {\n            assert !s.isEmpty();\n\n            if (fileId != null)\n                fileId = fileId(fileId, s, skipTx);\n\n            ids.add(fileId);\n        }\n\n        return ids;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-795-Param-0",
    "old_comment_raw": "@param file",
    "new_code_raw": "    public static String getName(final String path) {\n        if (TextUtils.isEmpty(path))\n            return path;\n\n        int lastSlash = path.lastIndexOf('/');\n        if (lastSlash != -1 && lastSlash + 1 < path.length())\n            return path.substring(lastSlash + 1);\n        else\n            return path;\n    }\n"
  },
  {
    "id": "voldemort_voldemort-665-Param-0",
    "old_comment_raw": "@param key : keyName strings serialized as bytes eg. 'cluster.xml'",
    "new_code_raw": "    public void put(ByteArray keyBytes, Versioned<byte[]> valueBytes) throws VoldemortException {\n        try {\n            String key = ByteUtils.getString(keyBytes.get(), \"UTF-8\");\n            Versioned<String> value = new Versioned<String>(ByteUtils.getString(valueBytes.getValue(),\n                                                                                \"UTF-8\"),\n                                                            valueBytes.getVersion());\n            if(METADATA_KEYS.contains(key)) {\n\n                // cache all keys\n                metadataCache.put(key, convertBytesToObject(key, value));\n\n                // only persistent_keys should be persisted\n                if(PERSISTENT_KEYS.contains(key)) {\n                    innerStore.put(key, value);\n                }\n            } else {\n                throw new VoldemortException(\"Unhandled Key:\" + key + \" for MetadataStore put()\");\n            }\n        } catch(Exception e) {\n            throw new VoldemortException(\"Failed to put() for key:\"\n                                         + ByteUtils.getString(keyBytes.get(), \"UTF-8\"), e);\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-778-Param-1",
    "old_comment_raw": "@param field",
    "new_code_raw": "    public Long hdel(final byte[] key, final byte[]... fields) {\n        checkIsInMulti();\n        client.hdel(key, fields);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-6249-Param-1",
    "old_comment_raw": "@param params Parameters.",
    "new_code_raw": "    private static List<Object> findParams(GridSqlQuery qry, Object[] params, ArrayList<Object> target) {\n        if (params.length == 0)\n            return target;\n\n        for (GridSqlElement el : qry.select())\n            findParams(el, params, target);\n\n        findParams(qry.from(), params, target);\n        findParams(qry.where(), params, target);\n\n        for (GridSqlElement el : qry.groups())\n            findParams(el, params, target);\n\n        findParams(qry.having(), params, target);\n\n        for (GridSqlElement el : qry.sort().keySet())\n            findParams(el, params, target);\n\n        findParams(qry.limit(), params, target);\n        findParams(qry.offset(), params, target);\n\n        return target;\n    }\n"
  },
  {
    "id": "grpc_grpc_java-145-Param-0",
    "old_comment_raw": "@param max the maximum number of bytes a single message can be.",
    "new_code_raw": "  public T maxInboundMessageSize(int bytes) {\n    // intentional noop rather than throw, this method is only advisory.\n    Preconditions.checkArgument(bytes >= 0, \"bytes must be >= 0\");\n    return thisT();\n  }\n"
  },
  {
    "id": "apache_ignite-1555-Param-2",
    "old_comment_raw": "@param node Node to move partition to.",
    "new_code_raw": "        boolean assign(int part, int tier, ClusterNode node, boolean force, Map<Integer, Queue<Integer>> pendingParts) {\n            UUID nodeId = node.id();\n\n            if (!fullMap.get(nodeId).contains(part)) {\n                tierMaps[tier].get(nodeId).add(part);\n\n                fullMap.get(nodeId).add(part);\n\n                List<ClusterNode> assignment = assignments.get(part);\n\n                if (assignment.size() <= tier)\n                    assignment.add(node);\n                else {\n                    ClusterNode oldNode = assignment.set(tier, node);\n\n                    if (oldNode != null) {\n                        UUID oldNodeId = oldNode.id();\n\n                        tierMaps[tier].get(oldNodeId).remove(part);\n                        fullMap.get(oldNodeId).remove(part);\n                    }\n                }\n\n                return true;\n            }\n            else if (force) {\n                assert !tierMaps[tier].get(nodeId).contains(part);\n\n                // Check previous tiers first.\n                for (int t = 0; t < tier; t++) {\n                    if (tierMaps[t].get(nodeId).contains(part))\n                        return false;\n                }\n\n                // Partition is on some lower tier, switch it.\n                for (int t = tier + 1; t < tierMaps.length; t++) {\n                    if (tierMaps[t].get(nodeId).contains(part)) {\n                        ClusterNode oldNode = assignments.get(part).get(tier);\n\n                        // Move partition from level t to tier.\n                        assignments.get(part).set(tier, node);\n                        assignments.get(part).set(t, null);\n\n                        if (oldNode != null) {\n                            tierMaps[tier].get(oldNode.id()).remove(part);\n                            fullMap.get(oldNode.id()).remove(part);\n                        }\n\n                        tierMaps[tier].get(nodeId).add(part);\n                        tierMaps[t].get(nodeId).remove(part);\n\n                        Queue<Integer> pending = pendingParts.get(t);\n\n                        if (pending == null) {\n                            pending = new LinkedList<>();\n\n                            pendingParts.put(t, pending);\n                        }\n\n                        pending.add(part);\n\n                        return true;\n                    }\n                }\n\n                throw new IllegalStateException(\"Unable to assign partition to node while force is true.\");\n            }\n\n            // !force.\n            return false;\n        }\n"
  },
  {
    "id": "spring_projects_spring_data_book-3-Param-0",
    "old_comment_raw": "@param source",
    "new_code_raw": "\tpublic static boolean isValid(String candidate) {\n\t\treturn candidate == null ? false : PATTERN.matcher(candidate).matches();\n\t}\n"
  },
  {
    "id": "apache_ignite-5459-Param-0",
    "old_comment_raw": "@param tx Cache transaction.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteInternalTx tx, Object key, Object val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key instanceof GridCacheInternal)\n                return true;\n\n            if (convertPortable) {\n                key = cctx.unwrapPortableIfNeeded(key, false);\n                val = cctx.unwrapPortableIfNeeded(val, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            boolean ses = initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(key, locStore ? F.t(val, ver) : val));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                if (ses)\n                    sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "zxing_zxing-665-Param-1",
    "old_comment_raw": "@param bytes the message converted to a byte array",
    "new_code_raw": "  private static int determineConsecutiveBinaryCount(String msg, int startpos, Charset encoding)\n      throws WriterException {\n    final CharsetEncoder encoder = encoding.newEncoder();\n    int len = msg.length();\n    int idx = startpos;\n    while (idx < len) {\n      char ch = msg.charAt(idx);\n      int numericCount = 0;\n\n      while (numericCount < 13 && isDigit(ch)) {\n        numericCount++;\n        //textCount++;\n        int i = idx + numericCount;\n        if (i >= len) {\n          break;\n        }\n        ch = msg.charAt(i);\n      }\n      if (numericCount >= 13) {\n        return idx - startpos;\n      }\n      ch = msg.charAt(idx);\n\n      if (!encoder.canEncode(ch)) {\n        throw new WriterException(\"Non-encodable character detected: \" + ch + \" (Unicode: \" + (int) ch + ')');\n      }\n      idx++;\n    }\n    return idx - startpos;\n  }\n"
  },
  {
    "id": "haifengl_smile-256-Param-0",
    "old_comment_raw": "@param size the population size of Genetic Algorithm.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, double[][] x, double[] y, int k, RegressionMeasure measure, BiFunction<double[][], double[], Regression<double[]>> trainer) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (k < 2) {\n            throw new IllegalArgumentException(\"Invalid k-fold cross validation: \" + k);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        int p = x[0].length;\n        RegressionFitness fitness = new RegressionFitness(trainer, measure, x, y, k);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;\n    }\n"
  },
  {
    "id": "klout_Cloud9-forked-14-Associations-Param0",
    "old_comment_raw": "@param n number of entries to return",
    "new_code_raw": "\tpublic Int2IntMap.Entry[] getEntriesSortedByValue(int k) {\n\t\tInt2IntMap.Entry[] entries = getEntriesSortedByValue();\n\n\t\tif (entries == null)\n\t\t\treturn null;\n\n\t\tif (entries.length < k)\n\t\t\treturn entries;\n\n\t\treturn Arrays.copyOfRange(entries, 0, k);\n\t}\n\n"
  },
  {
    "id": "apache_shiro-807-Param-1",
    "old_comment_raw": "@param accountCredentials the Account's stored credentials.",
    "new_code_raw": "    protected boolean equals( byte[] tokenCredentials, byte[] accountCredentials ) {\n\n        return Arrays.equals( tokenCredentials, accountCredentials );\n    }\n"
  },
  {
    "id": "eclipse_elk-149-Associations-Param2",
    "old_comment_raw": "@param nodeLabelInsets the additional insets for node labels on this node",
    "new_code_raw": "    public static ElkPadding calculateRequiredNodeLabelSpace(final NodeAdapter<?> node,\n            final double labelSpacing, final ElkPadding nodeLabelPadding,\n            final Map<LabelLocation, LabelGroup> labelGroupsBoundingBoxes, final ElkPadding padding) {\n\n        // Check if there are any labels\n        if (!node.getLabels().iterator().hasNext()) {\n            return padding;\n        }\n        \n        // Retrieve the node's label placement policy\n        final Set<NodeLabelPlacement> nodeLabelPlacement = node.getProperty(CoreOptions.NODE_LABELS_PLACEMENT);\n        final LabelLocation nodeLabelLocation = LabelLocation.fromNodeLabelPlacement(nodeLabelPlacement);\n        \n        // Compute a bounding box for each location where labels should be placed.\n        // The size is calculated from the size of all labels stacked vertically at that location.\n        for (final LabelAdapter<?> label : node.getLabels()) {\n            LabelLocation labelPlacement =\n                    LabelLocation.fromNodeLabelPlacement(label.getProperty(CoreOptions.NODE_LABELS_PLACEMENT));\n            \n            // If no valid placement is set on the label, use the node's placement policy.\n            if (labelPlacement == LabelLocation.UNDEFINED) {\n                labelPlacement = nodeLabelLocation;\n            }\n            \n            // Save the location of this label in its id field for later use.\n            label.setVolatileId(labelPlacement.ordinal());\n            \n            // Create or retrieve the label group for the current label.\n            final Rectangle boundingBox = retrieveLabelGroupsBoundingBox(labelGroupsBoundingBoxes, labelPlacement);\n            boundingBox.width = Math.max(boundingBox.width, label.getSize().x);\n            boundingBox.height += label.getSize().y + labelSpacing;\n        }\n        \n        // We need to count different label placement boxes towards different kinds of padding, depending on whether\n        // or not H_PRIORITY is set on the node itself (see H_PRIORITY documentation)\n        boolean hPrio = nodeLabelPlacement.contains(NodeLabelPlacement.H_PRIORITY);\n        \n        // Calculate the node label space required inside the node (only label groups on the inside\n        // are relevant here).\n        for (final Entry<LabelLocation, LabelGroup> entry : labelGroupsBoundingBoxes.entrySet()) {\n            final Rectangle boundingBox = entry.getValue();\n            \n            // From each existing label group, remove the last superfluous label spacing\n            // (the mere existence of a label group implies that it contains at least one label)\n            boundingBox.height -= labelSpacing;\n            switch (entry.getKey()) {\n            case IN_T_L:\n                if (hPrio) {\n                    padding.left = Math.max(\n                            padding.left,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                } else {\n                    padding.top = Math.max(\n                            padding.top,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                }\n                break;\n                \n            case IN_T_C:\n                padding.top = Math.max(\n                        padding.top,\n                        boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                break;\n                \n            case IN_T_R:\n                if (hPrio) {\n                    padding.right = Math.max(\n                            padding.right,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                } else {\n                    padding.top = Math.max(\n                            padding.top,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                }\n                break;\n                \n            case IN_C_L:\n                padding.left = Math.max(\n                        padding.left,\n                        boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                break;\n                \n            case IN_C_R:\n                padding.right = Math.max(\n                        padding.right,\n                        boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                break;\n                \n            case IN_B_L:\n                if (hPrio) {\n                    padding.left = Math.max(\n                            padding.left,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                } else {\n                    padding.bottom = Math.max(\n                            padding.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                }\n                break;\n                \n            case IN_B_C:\n                padding.bottom = Math.max(\n                        padding.bottom,\n                        boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                break;\n                \n            case IN_B_R:\n                if (hPrio) {\n                    padding.right = Math.max(\n                            padding.right,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                } else {\n                    padding.bottom = Math.max(\n                            padding.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                }\n                break;\n                \n            default:\n                // In all other cases, no specific action is required\n            }\n        }\n\n        // Add node label padding that aren't set yet\n        // This happens if e.g. a top inset is set but no top label is present\n        padding.top    = Math.max(padding.top, nodeLabelPadding.top);\n        padding.left   = Math.max(padding.left, nodeLabelPadding.left);\n        padding.right  = Math.max(padding.right, nodeLabelPadding.right);\n        padding.bottom = Math.max(padding.bottom, nodeLabelPadding.bottom);\n\n        return padding;\n    }\n\n"
  },
  {
    "id": "gephi_gephi-111-Param-1",
    "old_comment_raw": "@param pName",
    "new_code_raw": "    private String createImageFile(TempDir tempDir, double[] pVals, String pName, String pX, String pY) throws IOException {\n        XYSeries series = new XYSeries(pName);\n        for (int i = 0; i < mN; i++) {\n            series.add(i, pVals[i]);\n        }\n        XYSeriesCollection dataSet = new XYSeriesCollection();\n        dataSet.addSeries(series);\n\n        JFreeChart chart = ChartFactory.createXYLineChart(\n                pName,\n                pX,\n                pY,\n                dataSet,\n                PlotOrientation.VERTICAL,\n                true,\n                false,\n                false);\n        XYPlot plot = (XYPlot) chart.getPlot();\n        XYLineAndShapeRenderer renderer = new XYLineAndShapeRenderer();\n        renderer.setSeriesLinesVisible(0, false);\n        renderer.setSeriesShapesVisible(0, true);\n        renderer.setSeriesShape(0, new java.awt.geom.Ellipse2D.Double(0, 0, 1, 1));\n        plot.setBackgroundPaint(java.awt.Color.WHITE);\n        plot.setDomainGridlinePaint(java.awt.Color.GRAY);\n        plot.setRangeGridlinePaint(java.awt.Color.GRAY);\n        plot.setRenderer(renderer);\n\n        String imageFile = \"\";\n\n        ChartRenderingInfo info = new ChartRenderingInfo(new StandardEntityCollection());\n        String fileName = pY + \".png\";\n        File file1 = tempDir.createFile(fileName);\n        imageFile = \"<IMG SRC=\\\"file:\" + file1.getAbsolutePath() + \"\\\" \" + \"WIDTH=\\\"600\\\" HEIGHT=\\\"400\\\" BORDER=\\\"0\\\" USEMAP=\\\"#chart\\\"></IMG>\";\n\n        ChartUtilities.saveChartAsPNG(file1, chart, 600, 400, info);\n\n        return imageFile;\n    }\n"
  },
  {
    "id": "eclipse_gmf-runtime-72-Associations-Param0",
    "old_comment_raw": "@param domain an editing domain",
    "new_code_raw": "\tpublic static CrossReferenceAdapter getCrossReferenceAdapter(ResourceSet resourceSet) {\n\t\tif ( resourceSet == null ) {\n\t\t\treturn null;\n\t\t}\n\t\t\n\t\tCrossReferenceAdapter result = getExistingCrossReferenceAdapter(\n\t\t\tresourceSet);\n\t\t\n\t\tif (result == null) {\n\t\t\tresult = new CrossReferenceAdapter();\n\t\t\tresourceSet.eAdapters().add(result);\n\t\t}\n\t\t\n\t\treturn result;\n\t}\n\n"
  },
  {
    "id": "apache_ignite-4949-Param-9",
    "old_comment_raw": "@param evt Event flag.",
    "new_code_raw": "    @Override protected void clearIndex(CacheObject val) {\n        // No-op.\n    }\n"
  },
  {
    "id": "aurelhubert_ahbottomnavigation-2-Param-0",
    "old_comment_raw": "@param context",
    "new_code_raw": "\tpublic static Drawable getTintDrawable(Drawable drawable, int color, boolean forceTint) {\n\t\tif (forceTint) {\n\t\t\tdrawable.clearColorFilter();\n\t\t\tdrawable.setColorFilter(color, PorterDuff.Mode.SRC_ATOP);\n\t\t\tdrawable.invalidateSelf();\n\t\t\treturn drawable;\n\t\t}\n\t\tDrawable wrapDrawable = DrawableCompat.wrap(drawable);\n\t\tDrawableCompat.setTint(wrapDrawable, color);\n\t\treturn wrapDrawable;\n\t}\n"
  },
  {
    "id": "bytedeco_javacpp-217-Param-1",
    "old_comment_raw": "@param direct  true to use a direct buffer, see  Indexer for details",
    "new_code_raw": "    public static UShortIndexer create(final ShortPointer pointer, long[] sizes, long[] strides, boolean direct) {\n        if (direct) {\n            return Raw.getInstance() != null ? new UShortRawIndexer(pointer, sizes, strides)\n                                             : new UShortBufferIndexer(pointer.asBuffer(), sizes, strides);\n        } else {\n            final long position = pointer.position();\n            short[] array = new short[(int)Math.min(pointer.limit() - position, Integer.MAX_VALUE)];\n            pointer.get(array);\n            return new UShortArrayIndexer(array, sizes, strides) {\n                @Override public void release() {\n                    pointer.position(position).put(array);\n                    super.release();\n                }\n            };\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-11599-Param-1",
    "old_comment_raw": "@param out Output stream to that file.",
    "new_code_raw": "    private GridGgfsFileWorkerBatch newBatch(final GridGgfsPath path, OutputStream out) throws GridException {\n        assert path != null;\n        assert out != null;\n\n        if (busyLock.enterBusy()) {\n            try {\n                GridGgfsFileWorkerBatch batch = new GridGgfsFileWorkerBatch(path, out);\n\n                while (true) {\n                    GridGgfsFileWorker worker = workerMap.get(path);\n\n                    if (worker != null) {\n                        if (worker.addBatch(batch)) // Added batch to active worker.\n                            break;\n                        else\n                            workerMap.remove(path, worker); // Worker is stopping. Remove it from map.\n                    }\n                    else {\n                        worker = new GridGgfsFileWorker(\"ggfs-file-worker-\" + path) {\n                            @Override protected void onFinish() {\n                                workerMap.remove(path, this);\n                            }\n                        };\n\n                        boolean b = worker.addBatch(batch);\n\n                        assert b;\n\n                        if (workerMap.putIfAbsent(path, worker) == null) {\n                            worker.start();\n\n                            break;\n                        }\n                    }\n                }\n\n                return batch;\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new GridException(\"Cannot create new output stream to the secondary file system because GGFS is \" +\n                \"stopping: \" + path);\n    }\n"
  },
  {
    "id": "apache_ignite-1528-Param-1",
    "old_comment_raw": "@param cnt Count.",
    "new_code_raw": "    private long checkCountPerformance0(Ignite g, int cnt) throws Exception {\n        GridCacheAffinity<Object> aff = affinity(g);\n\n        GridTimer timer = new GridTimer(\"test\");\n\n        for (int i = 0; i < cnt; i++) {\n            Object key = RAND.nextInt(Integer.MAX_VALUE);\n\n            Collection<? extends GridNode> affNodes = nodes(aff, key);\n\n            assert excNeighbores ? affNodes.size() == 1 : affNodes.size() == GRIDS;\n        }\n\n        timer.stop();\n\n        return timer.duration();\n    }\n"
  },
  {
    "id": "apache_ignite-13182-Param-1",
    "old_comment_raw": "@param localCombiner If we have mapper with combiner.",
    "new_code_raw": "    private GridHadoopTaskOutput createOutput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case REDUCE:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case MAP:\n                if (locCombiner) {\n                    assert local == null;\n\n                    local = get(job.info(), SHUFFLE_COMBINER_NO_SORTING, false) ?\n                        new GridHadoopHashMultimap(job, mem, get(job.info(), COMBINER_HASHMAP_SIZE, 8 * 1024)):\n                        new GridHadoopSkipList(job, mem, ctx.sortComparator()); // TODO replace with red-black tree\n\n                    return local.startAdding(ctx);\n                }\n\n            default:\n                return createOutput(ctx);\n        }\n    }\n"
  },
  {
    "id": "guoguibing_librec-159-Param-0",
    "old_comment_raw": "@param row row id",
    "new_code_raw": "\tpublic DenseVector row(int rowId) {\n\t\treturn row(rowId, true);\n\t}\n"
  },
  {
    "id": "Netflix_zuul-138-Param-0",
    "old_comment_raw": "@param portName",
    "new_code_raw": "    public static int chooseIntChannelProperty(String listenAddressName, String propertySuffix, int defaultValue) {\n        String globalPropertyName = \"server.\" + propertySuffix;\n        String listenAddressPropertyName = \"server.\" + listenAddressName + \".\" + propertySuffix;\n        Integer value = new DynamicIntProperty(listenAddressPropertyName, -999).get();\n        if (value == -999) {\n            value = new DynamicIntProperty(globalPropertyName, -999).get();\n            if (value == -999) {\n                value = defaultValue;\n            }\n        }\n        return value;\n    }\n"
  },
  {
    "id": "apache_ignite-2166-Param-0",
    "old_comment_raw": "@param ses Session.",
    "new_code_raw": "    public Collection<ComputeJobSibling> requestJobSiblings(final ComputeTaskSession ses) throws GridException {\n        assert ses != null;\n\n        final UUID taskNodeId = ses.getTaskNodeId();\n\n        ClusterNode taskNode = ctx.discovery().node(taskNodeId);\n\n        if (taskNode == null)\n            throw new GridException(\"Node that originated task execution has left grid: \" + taskNodeId);\n\n        // Tuple: error message-response.\n        final IgniteBiTuple<String, GridJobSiblingsResponse> t = F.t2();\n\n        final Lock lock = new ReentrantLock();\n        final Condition cond = lock.newCondition();\n\n        GridMessageListener msgLsnr = new GridMessageListener() {\n            @Override public void onMessage(UUID nodeId, Object msg) {\n                String err = null;\n                GridJobSiblingsResponse res = null;\n\n                if (!(msg instanceof GridJobSiblingsResponse))\n                    err = \"Received unexpected message: \" + msg;\n                else if (!nodeId.equals(taskNodeId))\n                    err = \"Received job siblings response from unexpected node [taskNodeId=\" + taskNodeId +\n                        \", nodeId=\" + nodeId + ']';\n                else\n                    // Sender and message type are fine.\n                    res = (GridJobSiblingsResponse)msg;\n\n                if (res.jobSiblings() == null) {\n                    try {\n                        res.unmarshalSiblings(marsh);\n                    }\n                    catch (GridException e) {\n                        U.error(log, \"Failed to unmarshal job siblings.\", e);\n\n                        err = e.getMessage();\n                    }\n                }\n\n                lock.lock();\n\n                try {\n                    if (t.isEmpty()) {\n                        t.set(err, res);\n\n                        cond.signalAll();\n                    }\n                }\n                finally {\n                    lock.unlock();\n                }\n            }\n        };\n\n        GridLocalEventListener discoLsnr = new GridLocalEventListener() {\n            @Override public void onEvent(GridEvent evt) {\n                assert evt instanceof GridDiscoveryEvent &&\n                    (evt.type() == EVT_NODE_FAILED || evt.type() == EVT_NODE_LEFT) : \"Unexpected event: \" + evt;\n\n                GridDiscoveryEvent discoEvt = (GridDiscoveryEvent)evt;\n\n                if (taskNodeId.equals(discoEvt.eventNode().id())) {\n                    lock.lock();\n\n                    try {\n                        if (t.isEmpty()) {\n                            t.set(\"Node that originated task execution has left grid: \" + taskNodeId, null);\n\n                            cond.signalAll();\n                        }\n                    }\n                    finally {\n                        lock.unlock();\n                    }\n                }\n            }\n        };\n\n        boolean loc = ctx.localNodeId().equals(taskNodeId);\n\n        // 1. Create unique topic name.\n        Object topic = TOPIC_JOB_SIBLINGS.topic(ses.getId(), topicIdGen.getAndIncrement());\n\n        try {\n            // 2. Register listener.\n            ctx.io().addMessageListener(topic, msgLsnr);\n\n            // 3. Send message.\n            ctx.io().send(taskNode, TOPIC_JOB_SIBLINGS,\n                new GridJobSiblingsRequest(ses.getId(),\n                    loc ? topic : null,\n                    loc ? null : marsh.marshal(topic)),\n                SYSTEM_POOL);\n\n            // 4. Listen to discovery events.\n            ctx.event().addLocalEventListener(discoLsnr, EVT_NODE_FAILED, EVT_NODE_LEFT);\n\n            // 5. Check whether node has left before disco listener has been installed.\n            taskNode = ctx.discovery().node(taskNodeId);\n\n            if (taskNode == null)\n                throw new GridException(\"Node that originated task execution has left grid: \" + taskNodeId);\n\n            // 6. Wait for result.\n            lock.lock();\n\n            try {\n                long netTimeout = ctx.config().getNetworkTimeout();\n\n                if (t.isEmpty())\n                    cond.await(netTimeout, MILLISECONDS);\n\n                if (t.isEmpty())\n                    throw new GridException(\"Timed out waiting for job siblings (consider increasing\" +\n                        \"'networkTimeout' configuration property) [ses=\" + ses + \", netTimeout=\" + netTimeout + ']');\n\n                // Error is set?\n                if (t.get1() != null)\n                    throw new GridException(t.get1());\n                else\n                    // Return result\n                    return t.get2().jobSiblings();\n            }\n            catch (InterruptedException e) {\n                throw new GridException(\"Interrupted while waiting for job siblings response: \" + ses, e);\n            }\n            finally {\n                lock.unlock();\n            }\n        }\n        finally {\n            ctx.io().removeMessageListener(topic, msgLsnr);\n            ctx.event().removeLocalEventListener(discoLsnr);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-12062-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    public static VisorCache from(Ignite ignite, GridCache c, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<CacheEntry> set = ca.entrySet();\n\n        long memSz = 0;\n\n        Iterator<CacheEntry> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-2214-Param-0",
    "old_comment_raw": "@param port Endpoint port.",
    "new_code_raw": "    private static GridIpcEndpoint connectSharedMemoryEndpoint(int port, IgniteLogger log) throws GridException {\n        return new GridIpcSharedMemoryClientEndpoint(port, log);\n    }\n"
  },
  {
    "id": "eclipse_californium-26-Associations-Param0",
    "old_comment_raw": "@param byteArray the fragment to encrypt",
    "new_code_raw": "\tprivate byte[] encryptFragment(byte[] plaintextFragment) throws GeneralSecurityException {\r\n\t\t\r\n\t\tif (session == null) {\r\n\t\t\treturn plaintextFragment;\r\n\t\t}\r\n\r\n\t\tbyte[] encryptedFragment = plaintextFragment;\r\n\r\n\t\tCipherSuite cipherSuite = session.getWriteState().getCipherSuite();\r\n\t\tLOGGER.log(Level.FINER, \"Encrypting record fragment using current write state\\n{0}\", session.getWriteState());\r\n\t\t\r\n\t\tswitch (cipherSuite.getCipherType()) {\r\n\t\tcase NULL:\r\n\t\t\t// do nothing\r\n\t\t\tbreak;\r\n\t\t\t\r\n\t\tcase AEAD:\r\n\t\t\tencryptedFragment = encryptAEAD(plaintextFragment);\r\n\t\t\tbreak;\r\n\t\t\t\r\n\t\tcase BLOCK:\r\n\t\t\tencryptedFragment = encryptBlockCipher(plaintextFragment);\r\n\t\t\tbreak;\r\n\t\t\t\r\n\t\tcase STREAM:\r\n\t\t\t// Currently, Scandium does not support any stream ciphers\r\n\t\t\t// RC4 is explicitly ruled out from being used in DTLS\r\n\t\t\t// see http://tools.ietf.org/html/rfc6347#section-4.1.2.2\r\n\t\t\tbreak;\r\n\r\n\t\tdefault:\r\n\t\t\tbreak;\r\n\t\t}\r\n\r\n\t\treturn encryptedFragment;\r\n\t}\r\n\n"
  },
  {
    "id": "apache_ignite-2559-Param-0",
    "old_comment_raw": "@param ipFinder IP finder.",
    "new_code_raw": "    private IgniteConfiguration dataNode(TcpDiscoveryIpFinder ipFinder, String gridName)\n        throws Exception {\n        GridCacheConfiguration ccfg = new GridCacheConfiguration();\n\n        ccfg.setName(CACHE_NAME);\n        ccfg.setCacheMode(PARTITIONED);\n        ccfg.setAtomicityMode(TRANSACTIONAL);\n        ccfg.setDistributionMode(NEAR_PARTITIONED);\n        ccfg.setWriteSynchronizationMode(FULL_SYNC);\n        ccfg.setBackups(1);\n\n        IgniteConfiguration cfg = getConfiguration(gridName);\n\n        TcpDiscoverySpi spi = new TcpDiscoverySpi();\n\n        spi.setIpFinder(ipFinder);\n\n        cfg.setLocalHost(\"127.0.0.1\");\n        cfg.setDiscoverySpi(spi);\n        cfg.setCacheConfiguration(ccfg);\n        cfg.setIncludeProperties();\n        cfg.setRestEnabled(false);\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_ignite-1513-Param-1",
    "old_comment_raw": "@param cnt Key count.",
    "new_code_raw": "    protected UUID[] primaryKeysForCache(Ignite primary, int cnt) throws GridException {\n        Collection<UUID> keys = new LinkedHashSet<>();\n\n        int iters = 0;\n\n        do {\n            keys.add(primaryKeyForCache(primary));\n\n            iters++;\n\n            if (iters > 10000)\n                throw new IllegalStateException(\"Cannot find keys for primary node [nodeId=\" +\n                    primary.cluster().localNode().id() + \", cnt=\" + cnt + ']');\n        }\n        while (keys.size() < cnt);\n\n        UUID[] res = new UUID[keys.size()];\n\n        return keys.toArray(res);\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-364-Param-0",
    "old_comment_raw": "@param wallet The wallet that controls addresses and watches scripts.",
    "new_code_raw": "    public List<TransactionOutput> getWalletOutputs(TransactionBag transactionBag){\n        maybeParse();\n        List<TransactionOutput> walletOutputs = new LinkedList<TransactionOutput>();\n        Coin v = Coin.ZERO;\n        for (TransactionOutput o : outputs) {\n            if (!o.isMineOrWatched(transactionBag)) continue;\n            walletOutputs.add(o);\n        }\n\n        return walletOutputs;\n    }\n"
  },
  {
    "id": "todoroo_astrid-626-Param-1",
    "old_comment_raw": "@param properties",
    "new_code_raw": "    public Task fetchByRemoteId(BigInteger uuid, Property<?>... properties) {\n        TodorooCursor<Task> task = query(Query.select(properties).where(Task.UUID.eq(uuid)));\n        try {\n            if (task.getCount() > 0) {\n                task.moveToFirst();\n                return new Task(task);\n            }\n            return null;\n        } finally {\n            task.close();\n        }\n    }\n"
  },
  {
    "id": "airbnb_DeepLinkDispatch-0-Param-0",
    "old_comment_raw": "@param hostPath the combined host and path of the deep link",
    "new_code_raw": "  DeepLinkEntry parseUri(String uri) {\n    for (DeepLinkEntry entry : registry) {\n      if (entry.matches(uri)) {\n        return entry;\n      }\n    }\n\n    return null;\n  }\n"
  },
  {
    "id": "apache_ignite-7456-Param-1",
    "old_comment_raw": "@param fields Fields.",
    "new_code_raw": "    private BinaryObject copy(BinaryObject po, Map<String, Object> fields) {\n        BinaryObjectBuilder builder = BinaryObjectBuilderImpl.wrap(po);\n\n        if (fields != null) {\n            for (Map.Entry<String, Object> e : fields.entrySet())\n                builder.setField(e.getKey(), e.getValue());\n        }\n\n        return builder.build();\n    }\n"
  },
  {
    "id": "apache_ignite-11525-Param-0",
    "old_comment_raw": "@param lvl Level.",
    "new_code_raw": "        private boolean merge(Tail<L> prnt) throws IgniteCheckedException {\n            if (prnt.io.getCount(prnt.buf) == 0)\n                return false; // Parent is an empty routing page, child forward page will have another parent.\n\n            Tail<L> right = prnt.down;\n            Tail<L> left = right.sibling;\n\n            assert right.type == Tail.EXACT;\n            assert left != null: \"we must have a partner to merge with\";\n\n            if (left.type != Tail.BACK) { // Flip if it was actually FORWARD but not BACK.\n                assert left.type == Tail.FORWARD: left.type;\n\n                left = right;\n                right = right.sibling;\n            }\n\n            assert right.io == left.io: \"must always be the same\"; // Otherwise can be not compatible.\n\n            if (!mergePages(prnt, left, right))\n                return false;\n\n            // left from BACK becomes EXACT.\n            if (left.type == Tail.BACK) {\n                assert left.sibling == null;\n\n                left.down = right.down;\n                left.type = Tail.EXACT;\n                prnt.down = left;\n            }\n            else { // left is already EXACT.\n                assert left.type == Tail.EXACT: left.type;\n\n                left.sibling = null;\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "apache_ignite-6503-Param-1",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "    public boolean onUnswap(CacheObject key, CacheObject val) throws IgniteCheckedException {\n        assert val != null : \"Key=\" + key;\n\n        return onSwapUnswap(key, val);\n    }\n"
  },
  {
    "id": "apache_ignite-13254-Param-0",
    "old_comment_raw": "@param local Enforce local.",
    "new_code_raw": "    private ClusterGroup projection(boolean loc) {\n        return loc ? ctx.kernalContext().grid().cluster().forLocal() : null;\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-190-Param-3",
    "old_comment_raw": "@param model",
    "new_code_raw": "    public boolean virify(String name, String domain, String oldName) {\n        if (CommonUtils.notEmpty(name)) {\n            if (CommonUtils.notEmpty(oldName) && !name.equals(oldName) && null != service.getEntity(name)\n                    || CommonUtils.empty(oldName) && null != service.getEntity(name)) {\n                return false;\n            }\n        }\n        if (CommonUtils.notEmpty(domain) && null != service.getEntity(domain)) {\n            return false;\n        }\n        return true;\n    }\n"
  },
  {
    "id": "apache_shiro-323-Param-1",
    "old_comment_raw": "@param account the account being verified for access",
    "new_code_raw": "    public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) {\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-5007-Param-1",
    "old_comment_raw": "@param part Partition number to check.",
    "new_code_raw": "    public boolean belongs(ClusterNode node, int part, AffinityTopologyVersion topVer) {\n        assert node != null;\n        assert part >= 0 : \"Invalid partition: \" + part;\n\n        return nodes(part, topVer).contains(node);\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-952-Param-0",
    "old_comment_raw": "@param deviceNumber The bulb number the bridge has filed the bulb under.",
    "new_code_raw": "\tpublic int getSaturation(String deviceId) {\n\t\tif (settingsData == null) {\n\t\t\tlogger.error(\"Hue bridge settings not initialized correctly.\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tObject sat = settingsData.node(\"lights\")\n\t\t\t\t.node(deviceId).node(\"state\")\n\t\t\t\t.value(\"sat\");\n\t\tif(sat instanceof Integer) {\n\t\t\treturn (Integer) sat;\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n"
  },
  {
    "id": "apache_ignite-6504-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    public boolean update(CacheObject key, CacheObject val, long expirationTime, boolean rmv)\n        throws IgniteCheckedException {\n        assert desc != null;\n\n        GridH2Row row = desc.createRow(key, val, expirationTime);\n\n        return doUpdate(row, rmv);\n    }\n"
  },
  {
    "id": "voldemort_voldemort-659-Param-0",
    "old_comment_raw": "@param rebalanceNodePlan Node plan for a particular stealer node",
    "new_code_raw": "    private List<RebalancePartitionsInfo> orderedPartitionInfos(List<RebalancePartitionsInfo> clusterRebalancePartitionsInfo) {\n        List<RebalancePartitionsInfo> listPrimaries = new ArrayList<RebalancePartitionsInfo>();\n        List<RebalancePartitionsInfo> listReplicas = new ArrayList<RebalancePartitionsInfo>();\n\n        for(RebalancePartitionsInfo partitionInfo: clusterRebalancePartitionsInfo) {\n            List<Integer> stealMasterPartitions = partitionInfo.getStealMasterPartitions();\n            if(stealMasterPartitions != null && !stealMasterPartitions.isEmpty()) {\n                listPrimaries.add(partitionInfo);\n            } else {\n                listReplicas.add(partitionInfo);\n            }\n        }\n\n        // Add all the plans which list the replicas at the end\n        listPrimaries.addAll(listReplicas);\n\n        return listPrimaries;\n    }\n"
  },
  {
    "id": "apache_ignite-12066-Param-2",
    "old_comment_raw": "@param sample Sample size.",
    "new_code_raw": "    public static VisorCache from(Ignite g, GridCache c, int sample) throws IgniteCheckedException {\n        assert g != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)g).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = g.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<CacheEntry> set = ca.entrySet();\n\n        long memSz = 0;\n\n        Iterator<CacheEntry> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-11590-Param-0",
    "old_comment_raw": "@param reduceAddresses Addresses of reducers.",
    "new_code_raw": "    public boolean initializeReduceAddresses(T[] reduceAddrs) {\n        if (this.reduceAddrs == null) {\n            this.reduceAddrs = reduceAddrs;\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-8259-Param-2",
    "old_comment_raw": "@param ldr Class loader.",
    "new_code_raw": "    private boolean readSwapBeforeRemove(@Nullable KeyCacheObject key, int partId, SwapKey swapKey, ClassLoader ldr)\n        throws IgniteCheckedException {\n        assert cctx.queries().enabled();\n\n        byte[] entryBytes = swapMgr.read(spaceName, swapKey, ldr);\n\n        if (cctx.config().isStatisticsEnabled())\n            cctx.cache().metrics0().onSwapRead(entryBytes != null);\n\n        if (entryBytes == null)\n            return false;\n\n        GridCacheSwapEntry entry = swapEntry(unmarshalSwapEntry(entryBytes, true));\n\n        if (entry == null)\n            return false;\n\n        if (key == null) {\n            key = cctx.toCacheKeyObject(swapKey.keyBytes());\n\n            partId = cctx.affinity().partition(key);\n        }\n\n        cctx.queries().onUnswap(key, partId, entry.value());\n\n        return true;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-483-Param-0",
    "old_comment_raw": "@param weighting specify e.g. fastest or shortest (or empty for default)",
    "new_code_raw": "    public Weighting createWeighting( String weightingStr, FlagEncoder encoder )\n    {\n        // ignore case\n        Weighting weighting;\n        weightingStr = weightingStr.toLowerCase();\n        if (\"fastest\".equals(weightingStr))\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                weighting = new PriorityWeighting((BikeCommonFlagEncoder) encoder);\n            else\n                weighting = new FastestWeighting(encoder);\n        } else\n            weighting = new ShortestWeighting();\n\n        if (encoder.supportsTurnCosts())\n            weighting = new TurnWeighting(weighting, encoder, (TurnCostStorage) graph.getExtendedStorage());\n\n        return weighting;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-480-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "    public String lset(final String key, final long index, final String value) {\n        checkIsInMulti();\n        client.lset(key, index, value);\n        return client.getStatusCodeReply();\n    }\n"
  },
  {
    "id": "keyboardsurfer_Crouton-19-Param-1",
    "old_comment_raw": "@param resId The resource id of the text you want to display.",
    "new_code_raw": "\tpublic static Crouton makeText(Activity activity, int textResourceId, Style style) {\n\t\treturn makeText(activity, activity.getString(textResourceId), style);\n\t}\n"
  },
  {
    "id": "apache_ignite-2103-Param-0",
    "old_comment_raw": "@param t Event type.",
    "new_code_raw": "        public int count(LifecycleEventType t) {\n            return callsCntr.get(t).get();\n        }\n"
  },
  {
    "id": "apache_ignite-12024-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite ignite, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = ignite.streamer(\"priceBars\");\n\n                try {\n                    Collection<Bar> bars = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext, Collection<Bar>>() {\n                            @Override public Collection<Bar> apply(StreamerContext ctx) {\n                                Collection<Bar> values = ctx.<String, Bar>localSpace().values();\n\n                                Collection<Bar> res = new ArrayList<>(values.size());\n\n                                for (Bar bar : values)\n                                    res.add(bar.copy());\n\n                                return res;\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new IgniteReducer<Collection<Bar>, Collection<Bar>>() {\n                            private final Collection<Bar> res = new ArrayList<>();\n\n                            @Override public boolean collect(@Nullable Collection<Bar> col) {\n                                res.addAll(col);\n\n                                return true;\n                            }\n\n                            @Override public Collection<Bar> reduce() {\n                                return res;\n                            }\n                        }\n                    );\n\n                    for (Bar bar : bars)\n                        System.out.println(bar.toString());\n\n                    System.out.println(\"-----------------\");\n                }\n                catch (IgniteCheckedException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 2000, 2000);\n\n        return task;\n    }\n"
  },
  {
    "id": "apache_ignite-3333-Param-1",
    "old_comment_raw": "@param l Number of added elements.",
    "new_code_raw": "    private long getAndAdd(IgniteAtomicSequence seq, long l) throws Exception {\n        long locSeqVal = seq.get();\n\n        assertEquals(locSeqVal, seq.getAndAdd(l));\n\n        assertEquals(locSeqVal + l, seq.get());\n\n        return seq.get();\n    }\n"
  },
  {
    "id": "eclipse_objectteams-23-Associations-Param0",
    "old_comment_raw": "@param binding the field or local variable to check",
    "new_code_raw": "public boolean cannotBeDefinitelyNullOrNonNull(LocalVariableBinding local) {\n\treturn isPotentiallyUnknown(local) ||\n\t\tisPotentiallyNonNull(local) && isPotentiallyNull(local);\n}\n\n"
  },
  {
    "id": "apache_ignite-958-Param-1",
    "old_comment_raw": "@param path Path.",
    "new_code_raw": "    @Nullable public GridGgfsFileInfo synchronizeFileDual(final GridGgfsFileSystem fs, final GridGgfsPath path)\n        throws GridException {\n        assert fs != null;\n        assert path != null;\n\n        if (busyLock.enterBusy()) {\n            try {\n                // First, try getting file info without any transactions and synchronization.\n                GridGgfsFileInfo info = info(fileId(path));\n\n                if (info != null)\n                    return info;\n\n                // If failed, try synchronize.\n                SynchronizationTask<GridGgfsFileInfo> task =\n                    new SynchronizationTask<GridGgfsFileInfo>() {\n                        @Override public GridGgfsFileInfo onSuccess(Map<GridGgfsPath, GridGgfsFileInfo> infos)\n                            throws Exception {\n                            return infos.get(path);\n                        }\n\n                        @Override public GridGgfsFileInfo onFailure(@Nullable Exception err) throws GridException {\n                            if (err instanceof GridGgfsException)\n                                throw (GridException)err;\n                            else\n                                throw new GridException(\"Failed to synchronize path due to secondary file system \" +\n                                    \"exception: \" + path, err);\n                        }\n                    };\n\n                return synchronizeAndExecute(task, fs, false, path);\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to synchronize file because Grid is stopping: \" + path);\n\n\n    }\n"
  },
  {
    "id": "apache_shiro-756-Param-1",
    "old_comment_raw": "@param ldapContextFactory the factory used to build connections to the LDAP server.",
    "new_code_raw": "    protected AuthorizingAccount queryForLdapAccount( Object principal, LdapContextFactory ldapContextFactory) throws NamingException {\n\n        String username = null;\n\n        if ( !(principal instanceof String ) ) {\n            String msg = \"This implementation expects the principal argument to be a String.\";\n            throw new IllegalArgumentException( msg );\n        }\n\n        username = (String)principal;\n\n        // Perform context search\n        LdapContext ldapContext = ldapContextFactory.getSystemLdapContext();\n\n        List<String> roleNames;\n\n        try {\n\n            roleNames = getRoleNamesForUser(username, ldapContext);\n\n        } finally {\n\n            LdapUtils.closeContext( ldapContext );\n        }\n\n        return new SimpleAuthorizingAccount( roleNames, null );\n    }\n"
  },
  {
    "id": "apache_ignite-4380-Param-0",
    "old_comment_raw": "@param is GGFS input stream.",
    "new_code_raw": "    private Delimiter nextDelimiter(IgfsInputStream is, State state) throws IOException {\n        assert is != null;\n        assert state != null;\n\n        Map<Integer, Integer> parts = state.parts;\n        LinkedList<Delimiter> delimQueue = state.delims;\n\n        int nextByte = is.read();\n\n        while (nextByte != -1) {\n            // Process read byte.\n            for (int idx = 0; idx < delims.length; idx++) {\n                byte[] delim = delims[idx];\n\n                int val = parts.containsKey(idx) ? parts.get(idx) : 0;\n\n                if (delim[val] == nextByte) {\n                    if (val == delim.length - 1) {\n                        // Full delimiter is found.\n                        parts.remove(idx);\n\n                        Delimiter newDelim = new Delimiter(is.position() - delim.length, is.position());\n\n                        // Read queue from the end looking for the \"inner\" delimiters.\n                        boolean ignore = false;\n\n                        int replaceIdx = -1;\n\n                        for (int i = delimQueue.size() - 1; i >= 0; i--) {\n                            Delimiter prevDelim = delimQueue.get(i);\n\n                            if (prevDelim.start < newDelim.start) {\n                                if (prevDelim.end > newDelim.start) {\n                                    // Ignore this delimiter.\n                                    ignore = true;\n\n                                    break;\n                                }\n                            }\n                            else if (prevDelim.start == newDelim.start) {\n                                // Ok, we found matching delimiter.\n                                replaceIdx = i;\n\n                                break;\n                            }\n                        }\n\n                        if (!ignore) {\n                            if (replaceIdx >= 0)\n                                delimQueue.removeAll(delimQueue.subList(replaceIdx, delimQueue.size()));\n\n                            delimQueue.add(newDelim);\n                        }\n                    }\n                    else\n                        parts.put(idx, ++val);\n                }\n                else if (val != 0) {\n                    if (delim[0] == nextByte) {\n                        boolean shift = true;\n\n                        for (int k = 1; k < val; k++) {\n                            if (delim[k] != nextByte) {\n                                shift = false;\n\n                                break;\n                            }\n                        }\n\n                        if (!shift)\n                            parts.put(idx, 1);\n                    }\n                    else\n                        // Delimiter sequence is totally broken.\n                        parts.remove(idx);\n                }\n            }\n\n            // Check whether we can be sure that the first delimiter will not change.\n            if (!delimQueue.isEmpty()) {\n                Delimiter delim = delimQueue.get(0);\n\n                if (is.position() - delim.end >= maxDelimLen)\n                    return delimQueue.poll();\n            }\n\n            nextByte = is.read();\n        }\n\n        return delimQueue.poll();\n    }\n"
  },
  {
    "id": "apache_shiro-755-Param-0",
    "old_comment_raw": "@param tokenClass the class of the authenticationToken being submitted for authentication.",
    "new_code_raw": "    public boolean supports(AuthenticationToken token) {\n        if ( log.isInfoEnabled() ) {\n            log.info( \"Received null AuthenticationToken.  Returning false for supports(token) implementation (can't \" +\n                \"process null tokens).\" );\n        }\n        return token != null && getAuthenticationTokenClass().isAssignableFrom(token.getClass());\n    }\n"
  },
  {
    "id": "apache_ignite-2210-Param-0",
    "old_comment_raw": "@param ws Collection of workers to join.",
    "new_code_raw": "    public static boolean join(Iterable<? extends GridWorker> ws, IgniteLogger log) {\n        boolean retval = true;\n\n        if (ws != null)\n            for (GridWorker w : ws)\n                if (!join(w, log))\n                    retval = false;\n\n        return retval;\n    }\n"
  },
  {
    "id": "apache_ignite-13200-Param-0",
    "old_comment_raw": "@param grid Grid.",
    "new_code_raw": "    public static GridKernalContext context(Ignite ignite) {\n        assert ignite != null;\n\n        return ((GridKernal) ignite).context();\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-194-Param-2",
    "old_comment_raw": "@param replicate_training_data whether or not the training data is replicated on each node",
    "new_code_raw": "  private static long computeTrainSamplesPerIteration(final long train_samples_per_iteration, final long numRows, final boolean replicate_training_data, final boolean single_node_mode, final boolean quiet_mode) {\n    long tspi = train_samples_per_iteration;\n    assert(tspi == 0 || tspi == -1 || tspi >= 1);\n    if (tspi == 0 || (!replicate_training_data && tspi == -1) ) {\n      tspi = numRows;\n      if (!quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + train_samples_per_iteration + \") to one epoch: #rows (\" + tspi + \").\");\n    }\n    else if (tspi == -1) {\n      tspi = H2O.CLOUD.size() * numRows;\n      if (!quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + train_samples_per_iteration + \") to #nodes x #rows (\" + tspi + \").\");\n    }\n    assert(tspi != 0 && tspi != -1 && tspi >= 1);\n    return tspi;\n  }\n"
  },
  {
    "id": "apache_ignite-12176-Param-2",
    "old_comment_raw": "@param colocated Colocated query.",
    "new_code_raw": "    public static GridCacheTwoStepQuery split(JdbcPreparedStatement stmt, Object[] params, boolean collocated) {\n        if (params == null)\n            params = GridCacheSqlQuery.EMPTY_PARAMS;\n\n        GridSqlQuery qry0 = GridSqlQueryParser.parse(stmt);\n\n        GridSqlSelect srcQry;\n\n        if (qry0 instanceof GridSqlSelect)\n            srcQry = (GridSqlSelect)qry0;\n        else { // Handle UNION.\n            srcQry = new GridSqlSelect().from(new GridSqlSubquery(qry0));\n\n            GridSqlSelect left = leftest(qry0);\n\n            int c = 0;\n\n            for (GridSqlElement expr : left.select(true)) {\n                String colName;\n\n                if (expr instanceof GridSqlAlias)\n                    colName = ((GridSqlAlias)expr).alias();\n                else if (expr instanceof GridSqlColumn)\n                    colName = ((GridSqlColumn)expr).columnName();\n                else {\n                    colName = columnName(c);\n\n                    expr = alias(colName, expr);\n\n                    // Set generated alias to the expression.\n                    left.setSelectExpression(c, expr);\n                }\n\n                GridSqlColumn col = column(colName);\n\n                srcQry.addSelectExpression(col, true);\n\n                qry0.sort();\n\n                c++;\n            }\n\n            // ORDER BY\n            if (!qry0.sort().isEmpty()) {\n                for (GridSqlSortColumn col : qry0.sort())\n                    srcQry.addSort(col);\n            }\n        }\n\n        final String mergeTable = TABLE_FUNC_NAME + \"()\"; // table(0); TODO\n\n        // Create map and reduce queries.\n        GridSqlSelect mapQry = srcQry.clone();\n        GridSqlSelect rdcQry = new GridSqlSelect().from(new GridSqlFunction(\"PUBLIC\", TABLE_FUNC_NAME)); // table(mergeTable)); TODO\n\n        // Split all select expressions into map-reduce parts.\n        List<GridSqlElement> mapExps = F.addAll(\n            new ArrayList<GridSqlElement>(srcQry.allColumns()),\n            srcQry.select(false));\n\n        GridSqlElement[] rdcExps = new GridSqlElement[srcQry.visibleColumns()];\n\n        Set<String> colNames = new HashSet<>();\n\n        boolean aggregateFound = false;\n\n        for (int i = 0, len = mapExps.size(); i < len; i++) // Remember len because mapExps list can grow.\n            aggregateFound |= splitSelectExpression(mapExps, rdcExps, colNames, i, collocated);\n\n        // Fill select expressions.\n        mapQry.clearSelect();\n\n        for (GridSqlElement exp : mapExps) // Add all map expressions as visible.\n            mapQry.addSelectExpression(exp, true);\n\n        for (GridSqlElement rdcExp : rdcExps) // Add corresponding visible reduce columns.\n            rdcQry.addSelectExpression(rdcExp, true);\n\n        for (int i = rdcExps.length; i < mapExps.size(); i++)  // Add all extra map columns as invisible reduce columns.\n            rdcQry.addSelectExpression(column(((GridSqlAlias)mapExps.get(i)).alias()), false);\n\n        // -- GROUP BY\n        if (srcQry.hasGroupBy()) {\n            mapQry.clearGroups();\n\n            for (int col : srcQry.groupColumns())\n                mapQry.addGroupExpression(column(((GridSqlAlias)mapExps.get(col)).alias()));\n\n            if (!collocated) {\n                for (int col : srcQry.groupColumns())\n                    rdcQry.addGroupExpression(column(((GridSqlAlias)mapExps.get(col)).alias()));\n            }\n        }\n\n        // -- HAVING\n        if (srcQry.having() != null && !collocated) {\n            // TODO Find aggregate functions in HAVING clause.\n            rdcQry.whereAnd(column(columnName(srcQry.havingColumn())));\n\n            mapQry.having(null);\n        }\n\n        // -- ORDER BY\n        if (!srcQry.sort().isEmpty()) {\n            if (aggregateFound) // Ordering over aggregates does not make sense.\n                mapQry.clearSort(); // Otherwise map sort will be used by offset-limit.\n\n            for (GridSqlSortColumn sortCol : srcQry.sort())\n                rdcQry.addSort(sortCol);\n        }\n\n        // -- LIMIT\n        if (srcQry.limit() != null) {\n            if (aggregateFound)\n                mapQry.limit(null);\n\n            rdcQry.limit(srcQry.limit());\n        }\n\n        // -- OFFSET\n        if (srcQry.offset() != null) {\n            mapQry.offset(null);\n\n            rdcQry.offset(srcQry.offset());\n        }\n\n        // -- DISTINCT\n        if (srcQry.distinct()) {\n            mapQry.distinct(false);\n            rdcQry.distinct(true);\n        }\n\n        // Build resulting two step query.\n        GridCacheTwoStepQuery res = new GridCacheTwoStepQuery(rdcQry.getSQL(),\n            findParams(rdcQry, params, new ArrayList<>()).toArray());\n\n        res.addMapQuery(mergeTable, mapQry.getSQL(),\n            findParams(mapQry, params, new ArrayList<>(params.length)).toArray());\n\n        return res;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-651-Param-1",
    "old_comment_raw": "@param productId The product ID",
    "new_code_raw": "\tpublic boolean FindProduct(int productType, int productId) {\n\t\tif (selManufacturer == null)\n\t\t\treturn false;\n\n\t\tfor (ZWaveDbProduct product : selManufacturer.Product) {\n\t\t\tfor (ZWaveDbProductReference reference : product.Reference) {\n\t\t\t\tif (reference.Type == productType && reference.Id == productId) {\n\t\t\t\t\tselProduct = product;\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n"
  },
  {
    "id": "apache_ignite-12123-Param-1",
    "old_comment_raw": "@param idx The index of the character in the source",
    "new_code_raw": "    public static int toDigit(char ch, int index) throws IgniteCheckedException {\n        int digit = Character.digit(ch, 16);\n\n        if (digit == -1)\n            throw new IgniteCheckedException(\"Illegal hexadecimal character \" + ch + \" at index \" + index);\n\n        return digit;\n    }\n"
  },
  {
    "id": "code_troopers_android_betterpickers-23-Param-1",
    "old_comment_raw": "@param themeResId the style resource ID for theming",
    "new_code_raw": "    public static HmsPickerDialogFragment newInstance(int reference, int themeResId, Integer plusMinusVisibility) {\n        final HmsPickerDialogFragment frag = new HmsPickerDialogFragment();\n        Bundle args = new Bundle();\n        args.putInt(REFERENCE_KEY, reference);\n        args.putInt(THEME_RES_ID_KEY, themeResId);\n        if (plusMinusVisibility != null) {\n            args.putInt(PLUS_MINUS_VISIBILITY_KEY, plusMinusVisibility);\n        }\n        frag.setArguments(args);\n        return frag;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-481-Param-1",
    "old_comment_raw": "@param encoder",
    "new_code_raw": "    public Weighting createWeighting( String weightingStr, FlagEncoder encoder )\n    {\n        // ignore case\n        Weighting weighting;\n        weightingStr = weightingStr.toLowerCase();\n        if (\"fastest\".equals(weightingStr))\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                weighting = new PriorityWeighting((BikeCommonFlagEncoder) encoder);\n            else\n                weighting = new FastestWeighting(encoder);\n        } else\n            weighting = new ShortestWeighting();\n\n        if (hasTurnCosts())\n            weighting = new TurnWeighting(weighting, encoder);\n\n        return weighting;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1324-Param-3",
    "old_comment_raw": "@param redirectToAuthentication if true redirect to flow url. If initial call to protocol is a POST, you probably want to do this. This is so we can disable the back button on browser",
    "new_code_raw": "    protected Response handleBrowserAuthenticationRequest(AuthenticationSessionModel authSession, LoginProtocol protocol, boolean isPassive, boolean redirectToAuthentication) {\n        AuthenticationFlowModel flow = getAuthenticationFlow();\n        String flowId = flow.getId();\n        AuthenticationProcessor processor = createProcessor(authSession, flowId, LoginActionsService.AUTHENTICATE_PATH);\n        event.detail(Details.CODE_ID, authSession.getId());\n        if (isPassive) {\n            // OIDC prompt == NONE or SAML 2 IsPassive flag\n            // This means that client is just checking if the user is already completely logged in.\n            // We cancel login if any authentication action or required action is required\n            try {\n                if (processor.authenticateOnly() == null) {\n                    // processor.attachSession();\n                } else {\n                    Response response = protocol.sendError(authSession, Error.PASSIVE_LOGIN_REQUIRED);\n                    session.authenticationSessions().removeAuthenticationSession(realm, authSession);\n                    return response;\n                }\n\n                AuthenticationManager.setRolesAndMappersInSession(authSession);\n\n                if (processor.isActionRequired()) {\n                    Response response = protocol.sendError(authSession, Error.PASSIVE_INTERACTION_REQUIRED);\n                    session.authenticationSessions().removeAuthenticationSession(realm, authSession);\n                    return response;\n                }\n\n                // Attach session once no requiredActions or other things are required\n                processor.attachSession();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n            return processor.finishAuthentication(protocol);\n        } else {\n            try {\n                RestartLoginCookie.setRestartCookie(session, realm, clientConnection, uriInfo, authSession);\n                if (redirectToAuthentication) {\n                    return processor.redirectToFlow(null);\n                }\n                return processor.authenticate();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n        }\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-511-Param-0",
    "old_comment_raw": "@param way: needed to retrieve OSM tags",
    "new_code_raw": "    protected double applyMaxSpeed( ReaderWay way, double speed )\n    {\n        double maxSpeed = getMaxSpeed(way);\n        // We obay speed limits\n        if (maxSpeed >= 0)\n        {\n            // We assume that the average speed is 90% of the allowed maximum\n            return maxSpeed * 0.9;\n        }\n        return speed;\n    }\n"
  },
  {
    "id": "guoguibing_librec-233-Param-1",
    "old_comment_raw": "@param itemDim dimension of items",
    "new_code_raw": "\tpublic SparseMatrix rateMatrix() {\n\n\t\tTable<Integer, Integer, Double> dataTable = HashBasedTable.create();\n\t\tMultimap<Integer, Integer> colMap = HashMultimap.create();\n\n\t\tfor (TensorEntry te : this) {\n\t\t\tint u = te.key(userDimension);\n\t\t\tint i = te.key(itemDimension);\n\n\t\t\tdataTable.put(u, i, te.get());\n\t\t\tcolMap.put(i, u);\n\t\t}\n\n\t\treturn new SparseMatrix(dimensions[userDimension], dimensions[itemDimension], dataTable, colMap);\n\t}\n"
  },
  {
    "id": "alibaba_arthas-10-Param-0",
    "old_comment_raw": "@param mavenMetaDataUrl",
    "new_code_raw": "    public static String readMavenReleaseVersion(String mavenMetaData) {\n        try {\n            ByteArrayInputStream inputStream = new ByteArrayInputStream(mavenMetaData.getBytes(\"UTF-8\"));\n            DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n            DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n            Document document = dBuilder.parse(inputStream);\n\n            NodeList nodeList = document.getDocumentElement().getElementsByTagName(\"release\");\n\n            return nodeList.item(0).getTextContent();\n        } catch (Exception e) {\n            // ignore\n        }\n        return null;\n    }\n"
  },
  {
    "id": "apache_ignite-6262-Param-1",
    "old_comment_raw": "@param ccfg Cache configuration.",
    "new_code_raw": "    public static VisorCacheConfiguration from(IgniteEx ignite, CacheConfiguration ccfg) {\n        VisorCacheConfiguration cfg = new VisorCacheConfiguration();\n\n        cfg.name = ccfg.getName();\n        cfg.mode = ccfg.getCacheMode();\n        cfg.atomicityMode = ccfg.getAtomicityMode();\n        cfg.atomicWriteOrderMode = ccfg.getAtomicWriteOrderMode();\n        cfg.eagerTtl = ccfg.isEagerTtl();\n        cfg.writeSynchronizationMode = ccfg.getWriteSynchronizationMode();\n        cfg.swapEnabled = ccfg.isSwapEnabled();\n        cfg.invalidate = ccfg.isInvalidate();\n        cfg.startSize = ccfg.getStartSize();\n        cfg.tmLookupClsName = ccfg.getTransactionManagerLookupClassName();\n        cfg.offHeapMaxMemory = ccfg.getOffHeapMaxMemory();\n        cfg.maxConcurrentAsyncOps = ccfg.getMaxConcurrentAsyncOperations();\n        cfg.memoryMode = ccfg.getMemoryMode();\n        cfg.interceptor = compactClass(ccfg.getInterceptor());\n        cfg.typeMeta = VisorCacheTypeMetadata.list(ccfg.getTypeMetadata());\n        cfg.statisticsEnabled = ccfg.isStatisticsEnabled();\n        cfg.mgmtEnabled = ccfg.isManagementEnabled();\n        cfg.ldrFactory = compactClass(ccfg.getCacheLoaderFactory());\n        cfg.writerFactory = compactClass(ccfg.getCacheWriterFactory());\n        cfg.expiryPlcFactory = compactClass(ccfg.getExpiryPolicyFactory());\n        cfg.system = ignite.systemCache(ccfg.getName());\n\n        cfg.affinityCfg = VisorCacheAffinityConfiguration.from(ccfg);\n        cfg.rebalanceCfg = VisorCacheRebalanceConfiguration.from(ccfg);\n        cfg.evictCfg = VisorCacheEvictionConfiguration.from(ccfg);\n        cfg.nearCfg = VisorCacheNearConfiguration.from(ccfg);\n        cfg.dfltCfg = VisorCacheDefaultConfiguration.from(ccfg);\n        cfg.storeCfg = VisorCacheStoreConfiguration.from(ignite, ccfg);\n        cfg.qryCfg = VisorCacheQueryConfiguration.from(ccfg);\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_ignite-13199-Param-0",
    "old_comment_raw": "@param groupName Name of the group.",
    "new_code_raw": "    public int groupSize(String grpName) {\n        int res = 0;\n\n        for (GridHadoopCounter counter : cntrs.values()) {\n            if (grpName.equals(counter.group()))\n                res++;\n        }\n\n        return res;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-481-Param-0",
    "old_comment_raw": "@param weighting specify e.g. fastest or shortest (or empty for default)",
    "new_code_raw": "    public Weighting createWeighting( String weightingStr, FlagEncoder encoder )\n    {\n        // ignore case\n        Weighting weighting;\n        weightingStr = weightingStr.toLowerCase();\n        if (\"fastest\".equals(weightingStr))\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                weighting = new PriorityWeighting((BikeCommonFlagEncoder) encoder);\n            else\n                weighting = new FastestWeighting(encoder);\n        } else\n            weighting = new ShortestWeighting();\n\n        if (hasTurnCosts())\n            weighting = new TurnWeighting(weighting, encoder);\n\n        return weighting;\n    }\n"
  },
  {
    "id": "apache_ignite-12064-Param-0",
    "old_comment_raw": "@param g Grid instance.",
    "new_code_raw": "    public static boolean checkExplicitTaskMonitoring(Ignite ignite) {\n        int[] evts = ignite.configuration().getIncludeEventTypes();\n\n        if (F.isEmpty(evts))\n            return false;\n\n        for (int evt : VISOR_TASK_EVTS) {\n            if (!F.contains(evts, evt))\n                return false;\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-6962-Param-0",
    "old_comment_raw": "@param spaceName Space name.",
    "new_code_raw": "    @Nullable public byte[] get(@Nullable String spaceName, int part, KeyCacheObject key, byte[] keyBytes)\n        throws IgniteCheckedException {\n        GridOffHeapPartitionedMap m = offheap(spaceName);\n\n        return m == null ? null : m.get(part, U.hash(key), keyBytes(key, keyBytes));\n    }\n"
  },
  {
    "id": "xianrendzw_EasyReport-16-Param-0",
    "old_comment_raw": "@param metaDataSet",
    "new_code_raw": "    public static AbstractReportDataSet getDataSet(final Queryer queryer, final ReportParameter parameter) {\n        return new DataExecutor(queryer, parameter).execute();\n    }\n"
  },
  {
    "id": "apache_ignite-3697-Param-3",
    "old_comment_raw": "@param ver Version.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteInternalTx tx, K key, V val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key instanceof GridCacheInternal)\n                return true;\n\n            if (convertPortable) {\n                key = (K)cctx.unwrapPortableIfNeeded(key, false);\n                val = (V)cctx.unwrapPortableIfNeeded(val, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(key, locStore ? F.t(val, ver) : val));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "powermock_powermock-140-Param-0",
    "old_comment_raw": "@param type The type of the class where the method is located.",
    "new_code_raw": "\tpublic static Field field(Class<?> declaringClass, String fieldName) {\n\t\treturn Whitebox.getField(declaringClass, fieldName);\n\t}\n"
  },
  {
    "id": "zxing_zxing-503-Param-0",
    "old_comment_raw": "@param startI row where a finder pattern was detected",
    "new_code_raw": "  private float crossCheckVertical(int startI, int centerJ, int maxCount, int originalStateCountTotal) {\n    MonochromeBitmapSource image = this.image;\n\n    int maxI = image.getHeight();\n    int[] stateCount = new int[5];\n\n    // Start counting up from center\n    int i = startI;\n    while (i >= 0 && image.isBlack(centerJ, i)) {\n      stateCount[2]++;\n      i--;\n    }\n    if (i < 0) {\n      return Float.NaN;\n    }\n    while (i >= 0 && !image.isBlack(centerJ, i) && stateCount[1] <= maxCount) {\n      stateCount[1]++;\n      i--;\n    }\n    // If already too many modules in this state or ran off the edge:\n    if (i < 0 || stateCount[1] > maxCount) {\n      return Float.NaN;\n    }\n    while (i >= 0 && image.isBlack(centerJ, i) && stateCount[0] <= maxCount) {\n      stateCount[0]++;\n      i--;\n    }\n    if (stateCount[0] > maxCount) {\n      return Float.NaN;\n    }\n\n    // Now also count down from center\n    i = startI + 1;\n    while (i < maxI && image.isBlack(centerJ, i)) {\n      stateCount[2]++;\n      i++;\n    }\n    if (i == maxI) {\n      return Float.NaN;\n    }\n    while (i < maxI && !image.isBlack(centerJ, i) && stateCount[3] < maxCount) {\n      stateCount[3]++;\n      i++;\n    }\n    if (i == maxI || stateCount[3] >= maxCount) {\n      return Float.NaN;\n    }\n    while (i < maxI && image.isBlack(centerJ, i) && stateCount[4] < maxCount) {\n      stateCount[4]++;\n      i++;\n    }\n    if (stateCount[4] >= maxCount) {\n      return Float.NaN;\n    }\n\n    // If we found a finder-pattern-like section, but its size is more than 20% different than\n    // the original, assume it's a false positive\n    int stateCountTotal = stateCount[0] + stateCount[1] + stateCount[2] + stateCount[3] + stateCount[4];\n    if (5 * Math.abs(stateCountTotal - originalStateCountTotal) >= originalStateCountTotal) {\n      return Float.NaN;\n    }\n\n    return foundPatternCross(stateCount) ? centerFromEnd(stateCount, i) : Float.NaN;\n  }\n"
  },
  {
    "id": "apache_ignite-13605-Param-2",
    "old_comment_raw": "@param fwdId Expected forward page ID.",
    "new_code_raw": "    private boolean findDown(final Get g, final long pageId, final long expFwdId, final int lvl)\n        throws IgniteCheckedException {\n        try (Page page = page(pageId)) {\n            int res;\n\n            for (;;) {\n                // Init args.\n                g.pageId = pageId;\n                g.expFwdId = expFwdId;\n\n                res = readPage(page, search, g, lvl);\n\n                switch (res) {\n                    case Get.RETRY:\n                        return true;\n\n                    case Get.GO_DOWN:\n                        assert g.pageId != pageId;\n                        assert g.expFwdId != expFwdId || expFwdId == 0;\n\n                        // Go down recursively.\n                        if (findDown(g, g.pageId, g.expFwdId, lvl - 1)) {\n                            checkInterrupted();\n\n                            continue; // The child page got splitted, need to reread our page.\n                        }\n\n                        return false;\n\n                    case Get.FOUND:\n                        return false;\n\n                    case Get.NOT_FOUND:\n                        g.row = null; // Mark not found result.\n\n                        return false;\n\n                    default:\n                        throw new IllegalStateException(\"Invalid result: \" + res);\n                }\n            }\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-11329-Param-0",
    "old_comment_raw": "@param in Stream.",
    "new_code_raw": "    private static AffinityFunction readAffinityFunction(BinaryRawReaderEx in) {\n        byte plcTyp = in.readByte();\n\n        switch (plcTyp) {\n            case 0:\n                break;\n            case 1: {\n                FairAffinityFunction f = new FairAffinityFunction();\n                f.setPartitions(in.readInt());\n                f.setExcludeNeighbors(in.readBoolean());\n                return f;\n            }\n            case 2: {\n                RendezvousAffinityFunction f = new RendezvousAffinityFunction();\n                f.setPartitions(in.readInt());\n                f.setExcludeNeighbors(in.readBoolean());\n                return f;\n            }\n            case 3: {\n                return new PlatformAffinityFunction(in.readObjectDetached(), in.readInt());\n            }\n            default:\n                assert false;\n        }\n\n        return null;\n    }\n"
  },
  {
    "id": "eclipse_objectteams-25-Associations-Param0",
    "old_comment_raw": "@param binding the field or local to check",
    "new_code_raw": "public boolean canOnlyBeNull(LocalVariableBinding local) {\n\treturn isDefinitelyNull(local) || isProtectedNull(local);\n}\n\n"
  },
  {
    "id": "GoogleCloudPlatform_java_docs_samples-0-Param-2",
    "old_comment_raw": "@param projectId the project's unique identifier",
    "new_code_raw": "  public static int pubSub(String subId, int timeout, String projectId) throws Exception {\n    Subscriber subscriber = null;\n    MessageReceiverExample receiver = new MessageReceiverExample();\n\n    try {\n      // subscribe to the requested pubsub channel\n      ProjectSubscriptionName subName = ProjectSubscriptionName.of(projectId, subId);\n      subscriber = Subscriber.newBuilder(subName, receiver).build();\n      subscriber.startAsync().awaitRunning();\n      // listen to messages for 'timeout' seconds\n      for (int i = 0; i < timeout; i++) {\n        sleep(1000);\n      }\n    } finally {\n      // stop listening to the channel\n      if (subscriber != null) {\n        subscriber.stopAsync();\n      }\n    }\n    //print and return the number of pubsub messages received\n    System.out.println(receiver.messageCount);\n    return receiver.messageCount;\n  }\n"
  },
  {
    "id": "codehaus_coconut-22-Associations-Param0",
    "old_comment_raw": "@param filters the filters to test",
    "new_code_raw": "    public static <E> Predicates.AllPredicate<E> all(Predicate<E>... predicates) {\r\n        return new Predicates.AllPredicate<E>(predicates);\r\n    }\r\n\n"
  },
  {
    "id": "apache_ignite-5787-Param-0",
    "old_comment_raw": "@param p Partition.",
    "new_code_raw": "    private List<ClusterNode> nodes(int p, long topVer, GridDhtPartitionState state, GridDhtPartitionState... states) {\n        Collection<UUID> allIds = topVer > 0 ? F.nodeIds(CU.allNodes(cctx, topVer)) : null;\n\n        lock.readLock().lock();\n\n        try {\n            assert node2part != null && node2part.valid() : \"Invalid node-to-partitions map [topVer=\" + topVer +\n                \", allIds=\" + allIds + \", node2part=\" + node2part + ']';\n\n            Collection<UUID> nodeIds = part2node.get(p);\n\n            // Node IDs can be null if both, primary and backup, nodes disappear.\n            int size = nodeIds == null ? 0 : nodeIds.size();\n\n            if (size == 0)\n                return Collections.emptyList();\n\n            List<ClusterNode> nodes = new ArrayList<>(size);\n\n            for (UUID id : nodeIds) {\n                if (topVer > 0 && !allIds.contains(id))\n                    continue;\n\n                if (hasState(p, id, state, states)) {\n                    ClusterNode n = cctx.discovery().node(id);\n\n                    if (n != null && (topVer < 0 || n.order() <= topVer))\n                        nodes.add(n);\n                }\n            }\n\n            return nodes;\n        }\n        finally {\n            lock.readLock().unlock();\n        }\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1327-Param-1",
    "old_comment_raw": "@param milis",
    "new_code_raw": "    public static XMLGregorianCalendar add(XMLGregorianCalendar value, long millis) {\n        if (value == null) {\n            return null;\n        }\n\n        XMLGregorianCalendar newVal = (XMLGregorianCalendar) value.clone();\n\n        if (millis == 0) {\n            return newVal;\n        }\n\n        Duration duration;\n        duration = DATATYPE_FACTORY.get().newDuration(millis);\n        newVal.add(duration);\n        return newVal;\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-346-Param-0",
    "old_comment_raw": "@param transactions Map of txhash->transaction.",
    "new_code_raw": "    ConnectionResult connect(Map<Sha256Hash, Transaction> transactions, ConnectMode mode) {\n        Transaction tx = transactions.get(outpoint.getHash());\n        if (tx == null) {\n            return TransactionInput.ConnectionResult.NO_SUCH_TX;\n        }\n        TransactionOutput out = tx.getOutputs().get((int) outpoint.getIndex());\n        if (!out.isAvailableForSpending()) {\n            if (mode == ConnectMode.DISCONNECT_ON_CONFLICT) {\n                out.markAsUnspent();\n            } else if (mode == ConnectMode.ABORT_ON_CONFLICT) {\n                outpoint.fromTx = checkNotNull(out.parentTransaction);\n                return TransactionInput.ConnectionResult.ALREADY_SPENT;\n            }\n        }\n        connect(out);\n        return TransactionInput.ConnectionResult.SUCCESS;\n    }\n"
  },
  {
    "id": "apache_ignite-12276-Param-1",
    "old_comment_raw": "@param joinEventCount Expected events number.",
    "new_code_raw": "    private CountDownLatch expectJoinEvents(Ignite ignite, int joinEvtCnt) {\n        final CountDownLatch latch = new CountDownLatch(joinEvtCnt);\n\n        ignite.events().remoteListen(new IgniteBiPredicate<UUID, Event>() {\n            @Override public boolean apply(UUID uuid, Event evt) {\n                latch.countDown();\n                return true;\n            }\n        }, null, EventType.EVT_NODE_JOINED);\n\n        return latch;\n    }\n"
  },
  {
    "id": "apache_ignite-10376-Param-0",
    "old_comment_raw": "@param failFast Fail fast flag.",
    "new_code_raw": "    @Nullable private CacheObject peekDb(boolean failFast, CacheEntryPredicate[] filter)\n        throws IgniteCheckedException, GridCacheFilterFailedException {\n        if (!cctx.isAll(this, filter))\n            return CU.failed(failFast);\n\n        synchronized (this) {\n            if (checkExpired())\n                return null;\n        }\n\n        // TODO IGNITE-51.\n        return cctx.toCacheObject(cctx.store().loadFromStore(cctx.tm().localTxx(), key));\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-767-Param-1",
    "old_comment_raw": "@param activityUsedToStartLoginProcess",
    "new_code_raw": "    public static Account getAccount(final AccountManager manager, final Activity activity) {\n        final boolean loggable = Log.isLoggable(TAG, DEBUG);\n        if (loggable)\n            Log.d(TAG, \"Getting account\");\n\n        if (activity == null)\n            throw new RuntimeException(\"Can't create new GitHub account - no activity available\");\n\n        Account[] accounts;\n        try {\n            while ((accounts = getAccounts(manager)).length == 0) {\n                if (loggable)\n                    Log.d(TAG, \"No GitHub accounts for activity=\" + activity);\n\n                Bundle result = manager.addAccount(GITHUB_ACCOUNT_TYPE, null, null, null, activity, null, null)\n                        .getResult();\n\n                if (loggable)\n                    Log.d(TAG, \"Added account \" + result.getString(KEY_ACCOUNT_NAME));\n            }\n        } catch (AuthenticatorException e) {\n            Log.d(TAG, \"Excepting retrieving account\", e);\n            throw new RuntimeException(e);\n        } catch (IOException e) {\n            Log.d(TAG, \"Excepting retrieving account\", e);\n            throw new RuntimeException(e);\n        } catch (OperationCanceledException e) {\n            Log.d(TAG, \"Excepting retrieving account\", e);\n            throw new RuntimeException(e);\n        }\n\n        if (loggable)\n            Log.d(TAG, \"Returning account \" + accounts[0].name);\n\n        return accounts[0];\n    }\n"
  },
  {
    "id": "apache_ignite-13245-Param-3",
    "old_comment_raw": "@param val Value object.",
    "new_code_raw": "    protected int fillValueParameters(PreparedStatement stmt, int idx, EntryMapping em, Object val)\n        throws CacheWriterException {\n        for (CacheTypeFieldMetadata field : em.uniqValFields) {\n            Object fieldVal = extractField(em.cacheName, em.valueType(), field.getJavaName(), val);\n\n            try {\n                if (fieldVal != null)\n                    stmt.setObject(idx++, fieldVal);\n                else\n                    stmt.setNull(idx++, field.getDatabaseType());\n            }\n            catch (SQLException e) {\n                throw new CacheWriterException(\"Failed to set statement parameter name: \" + field.getDatabaseName(), e);\n            }\n        }\n\n        return idx;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-761-Param-0",
    "old_comment_raw": "@param ref",
    "new_code_raw": "    public static String getName(final String name) {\n        if (TextUtils.isEmpty(name))\n            return name;\n        if (name.startsWith(PREFIX_HEADS))\n            return name.substring(PREFIX_HEADS.length());\n        else if (name.startsWith(PREFIX_TAG))\n            return name.substring(PREFIX_TAG.length());\n        else if (name.startsWith(PREFIX_REFS))\n            return name.substring(PREFIX_REFS.length());\n        else\n            return name;\n    }\n"
  },
  {
    "id": "voldemort_voldemort-112-Param-1",
    "old_comment_raw": "@param stealInfo",
    "new_code_raw": "    public int rebalanceNode(String storeName, RebalancePartitionsInfo stealInfo) {\n        VAdminProto.InitiateRebalanceNodeRequest rebalanceNodeRequest = VAdminProto.InitiateRebalanceNodeRequest.newBuilder()\n                                                                                                                .setAttempt(stealInfo.getAttempt())\n                                                                                                                .setDonorId(stealInfo.getDonorId())\n                                                                                                                .setStealerId(stealInfo.getStealerId())\n                                                                                                                .setCurrentStore(storeName)\n                                                                                                                .addAllPartitions(stealInfo.getPartitionList())\n                                                                                                                .addAllUnbalancedStore(stealInfo.getUnbalancedStoreList())\n                                                                                                                .build();\n        VAdminProto.VoldemortAdminRequest adminRequest = VAdminProto.VoldemortAdminRequest.newBuilder()\n                                                                                          .setType(VAdminProto.AdminRequestType.INITIATE_REBALANCE_NODE)\n                                                                                          .setInitiateRebalanceNode(rebalanceNodeRequest)\n                                                                                          .build();\n        VAdminProto.AsyncOperationStatusResponse.Builder response = sendAndReceive(stealInfo.getStealerId(),\n                                                                                   adminRequest,\n                                                                                   VAdminProto.AsyncOperationStatusResponse.newBuilder());\n\n        if(response.hasError())\n            throwException(response.getError());\n\n        return response.getRequestId();\n    }\n"
  },
  {
    "id": "zxing_zxing-606-Param-0",
    "old_comment_raw": "@param image the scanned barcode image.",
    "new_code_raw": "  private static ResultPoint[] findVertices(BitMatrix matrix) throws ReaderException {\n    int height = matrix.getHeight();\n    int width = matrix.getWidth();\n    int halfWidth = width >> 1;\n\n    ResultPoint[] result = new ResultPoint[8];\n    boolean found = false;\n\n    int[] loc = null;\n    // Top Left\n    for (int i = 0; i < height; i++) {\n      loc = findGuardPattern(matrix, 0, i, halfWidth, START_PATTERN);\n      if (loc != null) {\n        result[0] = new ResultPoint(loc[0], i);\n        result[4] = new ResultPoint(loc[1], i);\n        found = true;\n        break;\n      }\n    }\n    // Bottom left\n    if (found) { // Found the Top Left vertex\n      found = false;\n      for (int i = height - 1; i > 0; i--) {\n        loc = findGuardPattern(matrix, 0, i, halfWidth, START_PATTERN);\n        if (loc != null) {\n          result[1] = new ResultPoint(loc[0], i);\n          result[5] = new ResultPoint(loc[1], i);\n          found = true;\n          break;\n        }\n      }\n    }\n    // Top right\n    if (found) { // Found the Bottom Left vertex\n      found = false;\n      for (int i = 0; i < height; i++) {\n        loc = findGuardPattern(matrix, halfWidth, i, halfWidth, STOP_PATTERN);\n        if (loc != null) {\n          result[2] = new ResultPoint(loc[1], i);\n          result[6] = new ResultPoint(loc[0], i);\n          found = true;\n          break;\n        }\n      }\n    }\n    // Bottom right\n    if (found) { // Found the Top right vertex\n      found = false;\n      for (int i = height - 1; i > 0; i--) {\n        loc = findGuardPattern(matrix, halfWidth, i, halfWidth, STOP_PATTERN);\n        if (loc != null) {\n          result[3] = new ResultPoint(loc[1], i);\n          result[7] = new ResultPoint(loc[0], i);\n          found = true;\n          break;\n        }\n      }\n    }\n    return found ? result : null;\n  }\n"
  },
  {
    "id": "apache_ignite-2150-Param-0",
    "old_comment_raw": "@param taskSes Task session.",
    "new_code_raw": "    public ClusterNode failover(GridTaskSessionImpl taskSes, ComputeJobResult jobRes, List<ClusterNode> top) {\n        return getSpi(taskSes.getFailoverSpi()).failover(new GridFailoverContextImpl(taskSes, jobRes,\n            ctx.loadBalancing()), top);\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-359-Param-2",
    "old_comment_raw": "@param exact",
    "new_code_raw": "  public static int[][] getDomainMapping(String colName, String[] modelDom, String[] colDom, boolean logNonExactMapping) {\n    int emap[] = new int[modelDom.length];\n    boolean bmap[] = new boolean[modelDom.length];\n    HashMap<String,Integer> md = new HashMap<String, Integer>();\n    for( int i = 0; i < colDom.length; i++) md.put(colDom[i], i);\n    for( int i = 0; i < modelDom.length; i++) {\n      Integer I = md.get(modelDom[i]);\n      if (I == null && logNonExactMapping)\n        Log.warn(Sys.SCORM, \"Column \"+colName+\" was trained with factor '\"+modelDom[i]+\"' which DOES NOT appear in column data\");\n      if (I!=null) {\n        emap[i] = I;\n        bmap[i] = true;\n      }\n    }\n    if (logNonExactMapping) { // Inform about additional values in column domain which do not appear in model domain\n      for (int i=0; i<colDom.length; i++) {\n        boolean found = false;\n        for (int j=0; j<emap.length; j++)\n          if (emap[j]==i) { found=true; break; }\n        if (!found)\n          Log.warn(Sys.SCORM, \"Column \"+colName+\" WAS NOT trained with factor '\"+colDom[i]+\"' which appears in column data\");\n      }\n    }\n\n    // produce packed values\n    return Utils.pack(emap, bmap);\n  }\n"
  },
  {
    "id": "apache_pulsar-84-Param-1",
    "old_comment_raw": "@param serviceUrl",
    "new_code_raw": "    public static SharedPulsarClient get(String componentId, ClientConfigurationData clientConf)\n            throws PulsarClientException {\n        AtomicReference<PulsarClientException> exception = new AtomicReference<PulsarClientException>();\n        instances.computeIfAbsent(componentId, pulsarClient -> {\n            SharedPulsarClient sharedPulsarClient = null;\n            try {\n                sharedPulsarClient = new SharedPulsarClient(componentId, clientConf);\n                LOG.info(\"[{}] Created a new Pulsar Client.\", componentId);\n            } catch (PulsarClientException e) {\n                exception.set(e);\n            }\n            return sharedPulsarClient;\n        });\n        if (exception.get() != null) {\n            throw exception.get();\n        }\n        return instances.get(componentId);\n    }\n"
  },
  {
    "id": "apache_ignite-13186-Param-0",
    "old_comment_raw": "@param taskInfo Task info.",
    "new_code_raw": "    public GridHadoopTaskInput input(GridHadoopTaskContext taskCtx) throws GridException {\n        switch (taskCtx.taskInfo().type()) {\n            case REDUCE:\n                int reducer = taskCtx.taskInfo().taskNumber();\n\n                GridHadoopMultimap m = maps.get(reducer);\n\n                if (m != null)\n                    return m.input(taskCtx);\n\n                return new GridHadoopTaskInput() { // Empty input.\n                    @Override public boolean next() {\n                        return false;\n                    }\n\n                    @Override public Object key() {\n                        throw new IllegalStateException();\n                    }\n\n                    @Override public Iterator<?> values() {\n                        throw new IllegalStateException();\n                    }\n\n                    @Override public void close() {\n                        // No-op.\n                    }\n                };\n\n            default:\n                throw new IllegalStateException(\"Illegal type: \" + taskCtx.taskInfo().type());\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-2906-Param-1",
    "old_comment_raw": "@param timedOut Timeout flag.",
    "new_code_raw": "    private boolean state(IgniteTxState state, boolean timedOut) {\n        boolean valid = false;\n\n        IgniteTxState prev;\n\n        boolean notify = false;\n\n        lock();\n\n        try {\n            prev = this.state;\n\n            switch (state) {\n                case ACTIVE: {\n                    valid = false;\n\n                    break;\n                } // Active is initial state and cannot be transitioned to.\n                case PREPARING: {\n                    valid = prev == ACTIVE;\n\n                    break;\n                }\n                case PREPARED: {\n                    valid = prev == PREPARING;\n\n                    break;\n                }\n                case COMMITTING: {\n                    valid = prev == PREPARED;\n\n                    break;\n                }\n\n                case UNKNOWN: {\n                    if (isDone.compareAndSet(false, true))\n                        notify = true;\n\n                    valid = prev == ROLLING_BACK || prev == COMMITTING;\n\n                    break;\n                }\n\n                case COMMITTED: {\n                    if (isDone.compareAndSet(false, true))\n                        notify = true;\n\n                    valid = prev == COMMITTING;\n\n                    break;\n                }\n\n                case ROLLED_BACK: {\n                    if (isDone.compareAndSet(false, true))\n                        notify = true;\n\n                    valid = prev == ROLLING_BACK;\n\n                    break;\n                }\n\n                case MARKED_ROLLBACK: {\n                    valid = prev == ACTIVE || prev == PREPARING || prev == PREPARED || prev == COMMITTING;\n\n                    break;\n                }\n\n                case ROLLING_BACK: {\n                    valid =\n                        prev == ACTIVE || prev == MARKED_ROLLBACK || prev == PREPARING ||\n                            prev == PREPARED || (prev == COMMITTING && local() && !dht());\n\n                    break;\n                }\n            }\n\n            if (valid) {\n                this.state = state;\n                this.timedOut = timedOut;\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Changed transaction state [prev=\" + prev + \", new=\" + this.state + \", tx=\" + this + ']');\n\n                // Notify of state change.\n                signalAll();\n            }\n            else {\n                if (log.isDebugEnabled())\n                    log.debug(\"Invalid transaction state transition [invalid=\" + state + \", cur=\" + this.state +\n                        \", tx=\" + this + ']');\n            }\n        }\n        finally {\n            unlock();\n        }\n\n        if (notify) {\n            GridFutureAdapter<IgniteTx> fut = finFut.get();\n\n            if (fut != null)\n                fut.onDone(this);\n        }\n\n        if (valid) {\n            // Seal transactions maps.\n            if (state != ACTIVE)\n                seal();\n\n            cctx.tm().onTxStateChange(prev, state, this);\n        }\n\n        return valid;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-808-Param-1",
    "old_comment_raw": "@param start",
    "new_code_raw": "  public Long zremrangeByScore(final String key, final double min, final double max) {\n    checkIsInMultiOrPipeline();\n    client.zremrangeByScore(key, min, max);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "pockethub_PocketHub-346-Param-1",
    "old_comment_raw": "@param id",
    "new_code_raw": "    public Commit getCommit(final Repository repo, final String id) {\n        final ItemReferences<Commit> repoCommits = commits.get(InfoUtils.createRepoId(repo));\n        return repoCommits != null ? repoCommits.get(id) : null;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-753-Param-1",
    "old_comment_raw": "@param user",
    "new_code_raw": "    public AvatarLoader bind(final ActionBar actionBar, final AtomicReference<User> userReference) {\n        if (userReference == null)\n            return this;\n\n        final User user = userReference.get();\n        if (user == null)\n            return this;\n\n        final String avatarUrl = user.getAvatarUrl();\n        if (TextUtils.isEmpty(avatarUrl))\n            return this;\n\n        final Integer userId = Integer.valueOf(user.getId());\n\n        BitmapDrawable loadedImage = loaded.get(userId);\n        if (loadedImage != null) {\n            actionBar.setLogo(loadedImage);\n            return this;\n        }\n\n        new FetchAvatarTask(context) {\n\n            @Override\n            public BitmapDrawable call() throws Exception {\n                final BitmapDrawable image = getImage(user);\n                if (image != null)\n                    return image;\n                else\n                    return fetchAvatar(avatarUrl, userId);\n            }\n\n            @Override\n            protected void onSuccess(BitmapDrawable image) throws Exception {\n                final User current = userReference.get();\n                if (current != null && userId.equals(current.getId()))\n                    actionBar.setLogo(image);\n            }\n        }.execute();\n\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-5777-Param-1",
    "old_comment_raw": "@param topOrder Maximum allowed node order.",
    "new_code_raw": "    public static Collection<ClusterNode> aliveCacheNodes(final GridCacheSharedContext ctx, AffinityTopologyVersion topOrder) {\n        return ctx.discovery().aliveNodesWithCaches(topOrder);\n    }\n"
  },
  {
    "id": "chubbymaggie_synoptic-5-Associations-Param0",
    "old_comment_raw": "@param string the task name. Choose something unique.",
    "new_code_raw": "\tpublic static TimedTask createTask(String taskName, boolean accumulativity) {\n\t\tpreviousTask = new TimedTask(taskName, previousTask, globalPerformanceMetrics,\n\t\t\t\taccumulativity);\n\t\treturn previousTask;\n\t}\n\n"
  },
  {
    "id": "apache_ignite-8799-Param-1",
    "old_comment_raw": "@param pageIdx Page index.",
    "new_code_raw": "    public static long pageId(int fileId, long pageIdx) {\n        assert (pageIdx & ~PAGE_IDX_MASK) == 0;\n\n        long pageId = 0;\n\n        pageId = (pageId << FILE_ID_SIZE) | (fileId & FILE_ID_MASK);\n        pageId = (pageId << PAGE_IDX_SIZE) | (pageIdx & PAGE_IDX_MASK);\n\n        return pageId;\n    }\n"
  },
  {
    "id": "apache_ignite-12217-Param-0",
    "old_comment_raw": "@param length Length.",
    "new_code_raw": "    static byte[] createChunk(int len) {\n        byte[] chunk = new byte[len];\n\n        for (int i = 0; i < chunk.length; i++)\n            chunk[i] = (byte)i;\n\n        return chunk;\n    }\n"
  },
  {
    "id": "apache_ignite-12170-Param-1",
    "old_comment_raw": "@param cacheName Cache name.",
    "new_code_raw": "    public static VisorCache from(IgniteEx ignite, String cacheName, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        // Cache was not started.\n        if (ca == null || !ca.context().started())\n            return null;\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && ca.context().affinityNode();\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(AffinityTopologyVersion.NONE)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<GridCacheEntryEx> set = ca.map().entries0();\n\n        long memSz = 0;\n\n        Iterator<GridCacheEntryEx> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name = cacheName;\n        cache.mode = mode;\n        cache.memorySize = memSz;\n        cache.size = size;\n        cache.nearSize = near;\n        cache.dhtSize = size - near;\n        cache.primarySize = ca.primarySize();\n        cache.offHeapAllocatedSize = ca.offHeapAllocatedSize();\n        cache.offHeapEntriesCnt = ca.offHeapEntriesCount();\n        cache.swapSize = swapSize;\n        cache.swapKeys = swapKeys;\n        cache.partitions = ca.affinity().partitions();\n        cache.primaryPartitions = pps;\n        cache.backupPartitions = bps;\n        cache.metrics = VisorCacheMetrics.from(ignite, ca);\n        cache.partitionsMap = partsMap;\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-12020-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite ignite, Timer timer, final int cnt) {\n        TimerTask task = new TimerTask() {\n            private CacheQuery<List<?>> qry;\n\n            @Override public void run() {\n                // Get reference to cache.\n                GridCache<Integer, Long> cache = ignite.cache(CACHE_NAME);\n\n                if (qry == null)\n                    qry = cache.queries().\n                        createSqlFieldsQuery(\"select _key, _val from Long order by _val desc limit \" + cnt);\n\n                try {\n                    List<List<?>> results = new ArrayList<>(qry.execute().get());\n\n                    Collections.sort(results, new Comparator<List<?>>() {\n                        @Override public int compare(List<?> r1, List<?> r2) {\n                            long cnt1 = (Long)r1.get(1);\n                            long cnt2 = (Long)r2.get(1);\n\n                            return cnt1 < cnt2 ? 1 : cnt1 > cnt2 ? -1 : 0;\n                        }\n                    });\n\n                    for (int i = 0; i < cnt && i < results.size(); i++) {\n                        List<?> res = results.get(i);\n\n                        System.out.println(res.get(0) + \"=\" + res.get(1));\n                    }\n\n                    System.out.println(\"----------------\");\n                }\n                catch (IgniteCheckedException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 3000, 3000);\n\n        return task;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1296-Param-0",
    "old_comment_raw": "@param runnable",
    "new_code_raw": "    public static int execute(Runnable runnable, int attemptsCount, long intervalMillis) {\n        int executionIndex = 0;\n        while (true) {\n            try {\n                runnable.run();\n                return executionIndex;\n            } catch (RuntimeException | AssertionError e) {\n                attemptsCount--;\n                executionIndex++;\n                if (attemptsCount > 0) {\n                    try {\n                        Thread.sleep(intervalMillis);\n                    } catch (InterruptedException ie) {\n                        ie.addSuppressed(e);\n                        throw new RuntimeException(ie);\n                    }\n                } else {\n                    throw e;\n                }\n            }\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-786-Param-1",
    "old_comment_raw": "@param member",
    "new_code_raw": "    public Long sadd(final String key, final String... members) {\n        checkIsInMulti();\n        client.sadd(key, members);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-3842-Param-0",
    "old_comment_raw": "@param obj Response object.",
    "new_code_raw": "    private static Object interceptSendObject(Object obj, ConnectorMessageInterceptor interceptor) {\n        if (obj instanceof Map) {\n            Map<Object, Object> original = (Map<Object, Object>)obj;\n\n            Map<Object, Object> m = new HashMap<>();\n\n            for (Map.Entry e : original.entrySet())\n                m.put(interceptor.onSend(e.getKey()), interceptor.onSend(e.getValue()));\n\n            return m;\n        }\n        else if (obj instanceof Collection) {\n            Collection<Object> original = (Collection<Object>)obj;\n\n            Collection<Object> c = new ArrayList<>(original.size());\n\n            for (Object e : original)\n                c.add(interceptor.onSend(e));\n\n            return c;\n        }\n        else\n            return interceptor.onSend(obj);\n    }\n"
  },
  {
    "id": "apache_ignite-12133-Param-2",
    "old_comment_raw": "@param plain Whether provided bytes is not some marshaled value, but rather real value.",
    "new_code_raw": "    public long putOffHeap(long ptr, byte[] val, byte type) {\n        int size = val.length;\n\n        assert size != 0;\n\n        int allocated = ptr == 0 ? 0 : readInt(ptr);\n\n        if (allocated != size) {\n            if (ptr != 0)\n                release(ptr, allocated + 5);\n\n            ptr = allocate(size + 5);\n\n            writeInt(ptr, size);\n        }\n\n        writeByte(ptr + 4, type);\n        writeBytes(ptr + 5, val);\n\n        return ptr;\n    }\n"
  },
  {
    "id": "apache_ignite-6140-Param-2",
    "old_comment_raw": "@param nodes Topology nodes.",
    "new_code_raw": "    private Collection<ClusterNode> nodes(AffinityFunction aff, int part, Collection<ClusterNode> nodes) {\n        List<List<ClusterNode>> assignment = aff.assignPartitions(\n            new GridAffinityFunctionContextImpl(new ArrayList<>(nodes), null, null, new AffinityTopologyVersion(1),\n                BACKUP_CNT));\n\n        return assignment.get(part);\n    }\n"
  },
  {
    "id": "apache_ignite-13198-Param-0",
    "old_comment_raw": "@param groupName Name of the group.",
    "new_code_raw": "    public int groupSize(String grpName) {\n        int res = 0;\n\n        for (GridHadoopCounter counter : userCounters) {\n            if (grpName.equals(counter.group()))\n                res++;\n        }\n\n        return res;\n    }\n"
  },
  {
    "id": "haifengl_smile-257-Param-0",
    "old_comment_raw": "@param size the population size of Genetic Algorithm.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, double[][] x, double[] y, double[][] testx, double[] testy, RegressionMeasure measure, BiFunction<double[][], double[], Regression<double[]>> trainer) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (generation <= 0) {\n            throw new IllegalArgumentException(\"Invalid number of generations to go: \" + generation);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        if (testx.length != testy.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of test X and Y don't match: %d != %d\", testx.length, testy.length));\n        }\n\n        int p = x[0].length;\n        RegressionFitness fitness = new RegressionFitness(trainer, measure, x, y, testx, testy);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;        \n    }\n"
  },
  {
    "id": "justinsb_android-libcore-695-Associations-Param0",
    "old_comment_raw": "@param dest the file containing the new name.",
    "new_code_raw": "    public boolean renameTo(File newPath) {\n        if (path.isEmpty() || newPath.path.isEmpty()) {\n            return false;\n        }\n        SecurityManager security = System.getSecurityManager();\n        if (security != null) {\n            security.checkWrite(path);\n            security.checkWrite(newPath.path);\n        }\n        return renameToImpl(pathBytes, newPath.pathBytes);\n    }\n\n"
  },
  {
    "id": "apache_ignite-12022-Param-1",
    "old_comment_raw": "@param setName Name of set.",
    "new_code_raw": "    private static CacheSet<String> initializeSet(Ignite ignite, String setName) throws IgniteCheckedException {\n        // Initialize new set.\n        CacheSet<String> set = ignite.cache(CACHE_NAME).dataStructures().set(setName, false, true);\n\n        // Initialize set items.\n        for (int i = 0; i < 10; i++)\n            set.add(Integer.toString(i));\n\n        System.out.println(\"Set size after initializing: \" + set.size());\n\n        return set;\n    }\n"
  },
  {
    "id": "androidannotations_androidannotations-10-Param-0",
    "old_comment_raw": "@param t1 the first type",
    "new_code_raw": "\tpublic boolean isSubtype(TypeMirror potentialSubtype, TypeMirror potentialSupertype) {\n\n\t\tif (processingEnv.getTypeUtils().isSubtype(potentialSubtype, potentialSupertype)) {\n\t\t\treturn true;\n\t\t} else {\n\n\t\t\tif (potentialSubtype instanceof DeclaredType) {\n\n\t\t\t\tDeclaredType potentialDeclaredSubtype = (DeclaredType) potentialSubtype;\n\n\t\t\t\tElement potentialSubElement = potentialDeclaredSubtype.asElement();\n\t\t\t\tif (potentialSubElement instanceof TypeElement) {\n\t\t\t\t\tTypeElement potentialSubDeclaredElement = (TypeElement) potentialSubElement;\n\n\t\t\t\t\tTypeMirror superclassTypeMirror = potentialSubDeclaredElement.getSuperclass();\n\n\t\t\t\t\tif (isRootObjectClass(superclassTypeMirror)) {\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (superclassTypeMirror instanceof ErrorType) {\n\n\t\t\t\t\t\t\tErrorType errorType = (ErrorType) superclassTypeMirror;\n\n\t\t\t\t\t\t\tElement errorElement = errorType.asElement();\n\n\t\t\t\t\t\t\tString errorElementSimpleName = errorElement.getSimpleName().toString();\n\t\t\t\t\t\t\tif (errorElementSimpleName.endsWith(GENERATION_SUFFIX)) {\n\t\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tprocessingEnv.getMessager().printMessage(Kind.NOTE, String.format(\"The supertype %s of the potential subElement %s of potential supertype %s is an ErrorType that doesn't end with %s\", errorElement, potentialSubElement, potentialSupertype, GENERATION_SUFFIX));\n\t\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\treturn isSubtype(superclassTypeMirror, potentialSupertype);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tprocessingEnv.getMessager().printMessage(Kind.NOTE, String.format(\"The potential subElement %s of potential supertype %s is not a TypeElement but a %s\", potentialSubElement, potentialSupertype, potentialSubElement.getClass()));\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\n\t\t\t} else {\n\t\t\t\tprocessingEnv.getMessager().printMessage(Kind.NOTE, String.format(\"The potential subtype %s of potential supertype %s is not a DeclaredType but a %s\", potentialSubtype, potentialSupertype, potentialSubtype.getClass()));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n"
  },
  {
    "id": "apache_ignite-13277-Param-2",
    "old_comment_raw": "@param sample Sample size.",
    "new_code_raw": "    public static VisorCache from(Ignite ignite, GridCache c, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<GridCacheEntryEx> set = ca.map().entries0();\n\n        long memSz = 0;\n\n        Iterator<GridCacheEntryEx> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-12066-Param-0",
    "old_comment_raw": "@param ignite Grid.",
    "new_code_raw": "    public static VisorCache from(Ignite g, GridCache c, int sample) throws IgniteCheckedException {\n        assert g != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)g).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = g.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<CacheEntry> set = ca.entrySet();\n\n        long memSz = 0;\n\n        Iterator<CacheEntry> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-8031-Param-0",
    "old_comment_raw": "@param gridName Grid name.",
    "new_code_raw": "    protected Ignite startGrid(String gridName, IgniteConfiguration cfg, GridSpringResourceContext ctx)\n        throws Exception {\n        if (!isRemoteJvm(gridName)) {\n            startingGrid.set(gridName);\n\n            try {\n                Ignite node = IgnitionEx.start(cfg, ctx);\n\n                IgniteConfiguration nodeCfg = node.configuration();\n\n                log.info(\"Node started with the following configuration [id=\" + node.cluster().localNode().id()\n                    + \", marshaller=\" + nodeCfg.getMarshaller()\n                    + \", binaryCfg=\" + nodeCfg.getBinaryConfiguration() + \"]\");\n\n                return node;\n            }\n            finally {\n                startingGrid.set(null);\n            }\n        }\n        else\n            return startRemoteGrid(gridName, null, ctx);\n    }\n"
  },
  {
    "id": "xetorthio_jedis-803-Param-1",
    "old_comment_raw": "@param integer",
    "new_code_raw": "  public Long incrBy(final String key, final long increment) {\n    checkIsInMultiOrPipeline();\n    client.incrBy(key, increment);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "gephi_gephi-177-Param-0",
    "old_comment_raw": "@param sourceGraph the directed graph",
    "new_code_raw": "    public GraphImpl createPreviewGraph(PreviewModel model, HierarchicalDirectedGraph sourceGraph) {\n        // creates graph\n        GraphImpl previewGraph = new GraphImpl(model);\n\n        // creates nodes\n        for (org.gephi.graph.api.Node sourceNode : sourceGraph.getNodes()) {\n            createPreviewNode(previewGraph, sourceNode);\n        }\n\n        // creates edges\n        for (org.gephi.graph.api.Edge sourceEdge : sourceGraph.getEdgesAndMetaEdges()) {\n\n            if (sourceEdge.getWeight() <= 0) {\n                continue;\n            }\n\n            if (sourceEdge.isSelfLoop()) {\n                createPreviewSelfLoop(previewGraph, sourceEdge);\n                continue;\n            }\n\n            if (isBidirectional(sourceGraph, sourceEdge)) {\n                createPreviewBidirectionalEdge(previewGraph, sourceEdge);\n            } else {\n                createPreviewUnidirectionalEdge(previewGraph, sourceEdge);\n            }\n        }\n\n        // clears the node map\n        nodeMap.clear();\n\n        return previewGraph;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-784-Param-1",
    "old_comment_raw": "@param string",
    "new_code_raw": "    public Long lpush(final String key, final String... strings) {\n        checkIsInMulti();\n        client.lpush(key, strings);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-368-Param-1",
    "old_comment_raw": "@param aesKey The AES key to use for decryption",
    "new_code_raw": "    public byte[] decrypt(EncryptedData dataToDecrypt, KeyParameter aesKey) throws KeyCrypterException {\n        checkNotNull(dataToDecrypt);\n        checkNotNull(aesKey);\n\n        try {\n            ParametersWithIV keyWithIv = new ParametersWithIV(new KeyParameter(aesKey.getKey()), dataToDecrypt.initialisationVector);\n\n            // Decrypt the message.\n            BufferedBlockCipher cipher = new PaddedBufferedBlockCipher(new CBCBlockCipher(new AESFastEngine()));\n            cipher.init(false, keyWithIv);\n\n            byte[] cipherBytes = dataToDecrypt.encryptedBytes;\n            byte[] decryptedBytes = new byte[cipher.getOutputSize(cipherBytes.length)];\n            final int length1 = cipher.processBytes(cipherBytes, 0, cipherBytes.length, decryptedBytes, 0);\n            final int length2 = cipher.doFinal(decryptedBytes, length1);\n\n            return Arrays.copyOf(decryptedBytes, length1 + length2);\n        } catch (Exception e) {\n            throw new KeyCrypterException(\"Could not decrypt bytes\", e);\n        }\n    }\n"
  },
  {
    "id": "google_protobuf-dt-0-Associations-Param0",
    "old_comment_raw": "@param fileUri the URI of a resource.",
    "new_code_raw": "  public IProject project(Resource resource) {\n    return file(resource.getURI()).getProject();\n  }\n\n"
  },
  {
    "id": "apache_ignite-4949-Param-11",
    "old_comment_raw": "@param subjId Subject ID.",
    "new_code_raw": "    @Override protected void clearIndex(CacheObject val) {\n        // No-op.\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-376-Param-0",
    "old_comment_raw": "@param bits",
    "new_code_raw": "  public static PSetupGuess guessSetup(byte [] bytes){\n    // find the last eof\n    int i = bytes.length-1;\n    while(i > 0 && bytes[i] != '\\n')--i;\n    assert i >= 0;\n    InputStream is = new ByteArrayInputStream(Arrays.copyOf(bytes,i));\n    SVMLightParser p = new SVMLightParser(new ParserSetup(ParserType.SVMLight, CsvParser.AUTO_SEP, false));\n    InspectDataOut dout = new InspectDataOut();\n    try{p.streamParse(is, dout);}catch(Exception e){throw new RuntimeException(e);}\n    return new PSetupGuess(new ParserSetup(ParserType.SVMLight, CsvParser.AUTO_SEP, dout._ncols,false,null,false),dout._nlines,dout._invalidLines,dout.data(),dout._ncols > 0 && dout._nlines > 0 && dout._nlines > dout._invalidLines,dout.errors());\n  }\n"
  },
  {
    "id": "apache_ignite-8288-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    public boolean update(CacheObject key, CacheObject val, long expirationTime, boolean rmv)\n        throws IgniteCheckedException {\n        assert desc != null;\n\n        GridH2Row row = desc.createRow(key, val, expirationTime);\n\n        return doUpdate(row, rmv);\n    }\n"
  },
  {
    "id": "apache_ignite-11533-Param-0",
    "old_comment_raw": "@param obj Object.",
    "new_code_raw": "    public static boolean overridesEqualsAndHashCode(Class<?> cls) {\n        try {\n            return !Object.class.equals(cls.getMethod(\"equals\", Object.class).getDeclaringClass()) &&\n                !Object.class.equals(cls.getMethod(\"hashCode\").getDeclaringClass());\n        }\n        catch (NoSuchMethodException | SecurityException ignore) {\n            return true; // Ignore.\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-1826-Param-0",
    "old_comment_raw": "@param rec A raw data record.",
    "new_code_raw": "    @Override public void loadCache(IgniteBiInClosure<K, V> c, @Nullable Object... args)\n        throws GridException {\n        ExecutorService exec = new ThreadPoolExecutor(\n            threadsCnt,\n            threadsCnt,\n            0L,\n            MILLISECONDS,\n            new ArrayBlockingQueue<Runnable>(batchQueueSize),\n            new BlockingRejectedExecutionHandler());\n\n        Iterator<I> iter = inputIterator(args);\n\n        Collection<I> buf = new ArrayList<>(batchSize);\n\n        try {\n            while (iter.hasNext()) {\n                if (Thread.currentThread().isInterrupted()) {\n                    U.warn(log, \"Working thread was interrupted while loading data.\");\n\n                    break;\n                }\n\n                buf.add(iter.next());\n\n                if (buf.size() == batchSize) {\n                    exec.submit(new Worker(c, buf, args));\n\n                    buf = new ArrayList<>(batchSize);\n                }\n            }\n\n            if (!buf.isEmpty())\n                exec.submit(new Worker(c, buf, args));\n        }\n        catch (RejectedExecutionException ignored) {\n            // Because of custom RejectedExecutionHandler.\n            assert false : \"RejectedExecutionException was thrown while it shouldn't.\";\n        }\n        finally {\n            exec.shutdown();\n\n            try {\n                exec.awaitTermination(Long.MAX_VALUE, MILLISECONDS);\n            }\n            catch (InterruptedException ignored) {\n                U.warn(log, \"Working thread was interrupted while waiting for put operations to complete.\");\n\n                Thread.currentThread().interrupt();\n            }\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-808-Param-2",
    "old_comment_raw": "@param end",
    "new_code_raw": "  public Long zremrangeByScore(final String key, final double min, final double max) {\n    checkIsInMultiOrPipeline();\n    client.zremrangeByScore(key, min, max);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "haifengl_smile-300-Param-0",
    "old_comment_raw": "@param b the right hand side of linear equations.",
    "new_code_raw": "    public static double solve(Matrix A, double[] b, double[] x, double tol, int itol) {\n        return solve(A, diagonalPreconditioner(A), b, x, tol, itol);\n    }\n"
  },
  {
    "id": "apache_ignite-11577-Param-0",
    "old_comment_raw": "@param name Field name.",
    "new_code_raw": "    private int fieldOffset(int id) {\n        if (fieldsOffs == null) {\n            fieldsOffs = new HashMap<>();\n\n            int off = start + HDR_LEN;\n\n            while (true) {\n                if (off >= arr.length)\n                    break;\n\n                int id0 = PRIM.readInt(arr, off);\n\n                off += 4;\n\n                int len = PRIM.readInt(arr, off);\n\n                off += 4;\n\n                fieldsOffs.put(id0, off);\n\n                off += len;\n            }\n        }\n\n        Integer fieldOff = fieldsOffs.get(id);\n\n        return fieldOff != null ? fieldOff : -1;\n    }\n"
  },
  {
    "id": "zxing_zxing-694-Param-2",
    "old_comment_raw": "@param maxIndividualVariance The most any counter can differ before we give up",
    "new_code_raw": "  private static float patternMatchVariance(int[] counters, int[] pattern, float maxIndividualVariance) {\n    int numCounters = counters.length;\n    int total = 0;\n    int patternLength = 0;\n    for (int i = 0; i < numCounters; i++) {\n      total += counters[i];\n      patternLength += pattern[i];\n    }\n    if (total < patternLength) {\n      // If we don't even have one pixel per unit of bar width, assume this\n      // is too small to reliably match, so fail:\n      return Float.POSITIVE_INFINITY;\n    }\n    // We're going to fake floating-point math in integers. We just need to use more bits.\n    // Scale up patternLength so that intermediate values below like scaledCounter will have\n    // more \"significant digits\".\n    float unitBarWidth = (float) total / patternLength;\n    maxIndividualVariance *= unitBarWidth;\n\n    float totalVariance = 0.0f;\n    for (int x = 0; x < numCounters; x++) {\n      int counter = counters[x];\n      float scaledPattern = pattern[x] * unitBarWidth;\n      float variance = counter > scaledPattern ? counter - scaledPattern : scaledPattern - counter;\n      if (variance > maxIndividualVariance) {\n        return Float.POSITIVE_INFINITY;\n      }\n      totalVariance += variance;\n    }\n    return totalVariance / total;\n  }\n"
  },
  {
    "id": "codehaus_aspectwerkz-146-Associations-Param0",
    "old_comment_raw": "@param s string to escape",
    "new_code_raw": "    public static String removeFormattingCharacters(final String toBeEscaped) {\n        StringBuffer escapedBuffer = new StringBuffer();\n        for (int i = 0; i < toBeEscaped.length(); i++) {\n            if ((toBeEscaped.charAt(i) != '\\n') && (toBeEscaped.charAt(i) != '\\r') && (toBeEscaped.charAt(i) != '\\t')) {\n                escapedBuffer.append(toBeEscaped.charAt(i));\n            }\n        }\n        return escapedBuffer.toString();\n    }\n\n"
  },
  {
    "id": "apache_ignite-4996-Param-0",
    "old_comment_raw": "@param nodeId Node ID to get primary partitions for.",
    "new_code_raw": "    public Set<Integer> primaryPartitions(UUID nodeId, AffinityTopologyVersion topVer) {\n        return cachedAffinity(topVer).primaryPartitions(nodeId);\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1321-Param-1",
    "old_comment_raw": "@param publicKey",
    "new_code_raw": "    public boolean validate(Document signedDocument, KeyLocator keyLocator) throws ProcessingException {\n        try {\n            configureIdAttribute(signedDocument);\n            return XMLSignatureUtil.validate(signedDocument, keyLocator);\n        } catch (MarshalException | XMLSignatureException me) {\n            throw new ProcessingException(logger.signatureError(me));\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-8951-Param-1",
    "old_comment_raw": "@param newKey key to insert",
    "new_code_raw": "    static PreparedStatement createUpsertStatement(Connection conn, int newKey, int newVal) throws SQLException {\n        PreparedStatement stmt;\n        switch (conn.getMetaData().getDatabaseProductName()) {\n            case \"H2\":\n                stmt = conn.prepareStatement(\"merge into SAMPLE(id, val) values(?, ?)\");\n\n                break;\n\n            case \"MySQL\":\n                stmt = conn.prepareStatement(\"insert into SAMPLE(id, val) values(?, ?) on duplicate key update val = ?\");\n\n                stmt.setInt(3, newVal);\n\n                break;\n\n            case \"PostgreSQL\":\n                stmt = conn.prepareStatement(\"insert into SAMPLE(id, val) values(?, ?) on conflict(id) do \" +\n                    \"update set val = ?\");\n\n                stmt.setInt(3, newVal);\n\n                break;\n\n            default:\n                throw new IgniteException(\"Unexpected database type [databaseProductName=\" +\n                    conn.getMetaData().getDatabaseProductName() + ']');\n        }\n\n        stmt.setInt(1, newKey);\n        stmt.setInt(2, newVal);\n\n        return stmt;\n    }\n"
  },
  {
    "id": "eclipse_rt.equinox.framework-53-Associations-Param1",
    "old_comment_raw": "@param add indicate whether the target should be added to the manager if it is not managed.",
    "new_code_raw": "\tpublic File lookup(String managedFile, boolean add) throws IOException {\n\t\tif (!open)\n\t\t\tthrow new IOException(EclipseAdaptorMsg.fileManager_notOpen);\n\t\tEntry entry = (Entry) table.get(managedFile);\n\t\tif (entry == null) {\n\t\t\tif (add) {\n\t\t\t\tadd(managedFile);\n\t\t\t\tentry = (Entry) table.get(managedFile);\n\t\t\t} else {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\treturn new File(getAbsolutePath(managedFile + '.' + entry.getReadId()));\n\t}\n\n"
  },
  {
    "id": "apache_ignite-8162-Param-1",
    "old_comment_raw": "@param fileName File name in the parent's listing.",
    "new_code_raw": "    private IgniteUuid putIfAbsentNonTx(IgniteUuid parentId, String fileName, IgfsEntryInfo newFileInfo)\n        throws IgniteCheckedException {\n        if (log.isDebugEnabled())\n            log.debug(\"Locking parent id [parentId=\" + parentId + \", fileName=\" + fileName + \", newFileInfo=\" +\n                newFileInfo + ']');\n\n        validTxState(true);\n\n        // Lock only parent file ID.\n        IgfsEntryInfo parentInfo = info(parentId);\n\n        if (parentInfo == null)\n            throw fsException(new IgfsPathNotFoundException(\"Failed to lock parent directory (not found): \" +\n                parentId));\n\n        if (!parentInfo.isDirectory())\n            throw fsException(new IgfsPathIsNotDirectoryException(\"Parent file is not a directory: \" + parentInfo));\n\n        IgfsListingEntry childEntry = parentInfo.listing().get(fileName);\n\n        if (childEntry != null)\n            return childEntry.fileId();\n\n        createNewEntry(newFileInfo, parentId, fileName);\n\n        return null;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-965-Param-1",
    "old_comment_raw": "@param abbreviatedResponse",
    "new_code_raw": "\tprivate State createState(Item item, String transformedResponse) {\n\t\t\n\t\tif (item != null) {\n\t\t\treturn TypeParser.parseState(item.getAcceptedDataTypes(), transformedResponse);\n\t\t}\n\t\telse {\n\t\t\treturn StringType.valueOf(transformedResponse);\n\t\t}\n\t}\n"
  },
  {
    "id": "apache_ignite-5903-Param-1",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteInternalTx tx, K key, V val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key instanceof GridCacheInternal)\n                return true;\n\n            if (convertPortable) {\n                key = (K)cctx.unwrapPortableIfNeeded(key, false);\n                val = (V)cctx.unwrapPortableIfNeeded(val, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            boolean ses = initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(key, locStore ? F.t(val, ver) : val));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                if (ses)\n                    sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-11593-Param-0",
    "old_comment_raw": "@param cls Input split class.",
    "new_code_raw": "    public static GridHadoopFileBlock readFileBlock(String clsName, DataInput in, @Nullable String[] hosts)\n        throws GridException {\n        if (!FileSplit.class.getName().equals(clsName))\n            return null;\n\n        FileSplit split = new FileSplit();\n\n        try {\n            split.readFields(in);\n        }\n        catch (IOException e) {\n            throw new GridException(e);\n        }\n\n        if (hosts == null)\n            hosts = EMPTY_HOSTS;\n\n        return new GridHadoopFileBlock(hosts, split.getPath().toUri(), split.getStart(), split.getLength());\n    }\n"
  },
  {
    "id": "apache_ignite-1300-Param-0",
    "old_comment_raw": "@param cand Cache lock candidate to add.",
    "new_code_raw": "    public boolean addNext(GridCacheContext<K, V> cacheCtx, GridCacheMvccCandidate<K> cand) {\n        assert cand != null;\n        assert !cand.reentry() : \"Lock reentries should not be linked: \" + cand;\n\n        // Don't order near candidates by thread as they will be ordered on\n        // DHT node. Also, if candidate is implicit, no point to order him.\n        if (cacheCtx.isNear() || cand.singleImplicit())\n            return true;\n\n        Queue<GridCacheMvccCandidate<K>> queue = pending.get();\n\n        boolean add = true;\n\n        GridCacheMvccCandidate<K> prev = null;\n\n        for (Iterator<GridCacheMvccCandidate<K>> it = queue.iterator(); it.hasNext(); ) {\n            GridCacheMvccCandidate<K> c = it.next();\n\n            if (c.equals(cand))\n                add = false;\n\n            if (c.used()) {\n                it.remove();\n\n                unlink(c);\n\n                continue;\n            }\n\n            prev = c;\n        }\n\n        if (add) {\n            queue.add(cand);\n\n            if (prev != null) {\n                prev.next(cand);\n\n                cand.previous(prev);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Linked new candidate: \" + cand);\n        }\n\n        return add;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-387-Param-2",
    "old_comment_raw": "@param model_size Size of the model in #weights and #biases",
    "new_code_raw": "  private static long computeTrainSamplesPerIteration(final DeepLearning mp, final long numRows, DeepLearningModel model) {\n    long tspi = mp.train_samples_per_iteration;\n    assert(tspi == 0 || tspi == -1 || tspi == -2 || tspi >= 1);\n    if (tspi == 0 || (!mp.replicate_training_data && tspi == -1) ) {\n      tspi = numRows;\n      if (!mp.quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to one epoch: #rows (\" + tspi + \").\");\n    }\n    else if (tspi == -1) {\n      tspi = (mp.single_node_mode ? 1 : H2O.CLOUD.size()) * numRows;\n      if (!mp.quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to #nodes x #rows (\" + tspi + \").\");\n    } else if (tspi == -2) {\n      // automatic tuning based on CPU speed, network speed and model size\n\n      // measure cpu speed\n      double total_gflops = 0;\n      for (H2ONode h2o : H2O.CLOUD._memary) {\n        HeartBeat hb = h2o._heartbeat;\n        total_gflops += hb._gflops;\n      }\n      if (mp.single_node_mode) total_gflops /= H2O.CLOUD.size();\n      if (total_gflops == 0) {\n        total_gflops = Linpack.run(H2O.SELF._heartbeat._cpus_allowed) * (mp.single_node_mode ? 1 : H2O.CLOUD.size());\n      }\n\n      final long model_size = model.model_info().size();\n      int[] msg_sizes = new int[]{ (int)(model_size*4) == (model_size*4) ? (int)(model_size*4) : Integer.MAX_VALUE };\n      double[] microseconds_collective = new double[msg_sizes.length];\n      NetworkTest.NetworkTester nt = new NetworkTest.NetworkTester(msg_sizes,null,microseconds_collective,model_size>1e6 ? 1 : 5 /*repeats*/,false,true /*only collectives*/);\n      nt.compute2();\n\n      //length of the network traffic queue based on log-tree rollup (2 log(nodes))\n      int network_queue_length = mp.single_node_mode || H2O.CLOUD.size() == 1? 1 : 2*(int)Math.floor(Math.log(H2O.CLOUD.size())/Math.log(2));\n\n      // heuristics\n      double flops_overhead_per_row = 30;\n      if (mp.activation == Activation.Maxout || mp.activation == Activation.MaxoutWithDropout) {\n        flops_overhead_per_row *= 8;\n      } else if (mp.activation == Activation.Tanh || mp.activation == Activation.TanhWithDropout) {\n        flops_overhead_per_row *= 5;\n      }\n\n      // target fraction of comm vs cpu time: 5%\n      double fraction = mp.single_node_mode || H2O.CLOUD.size() == 1 ? 1e-3 : 0.05; //one single node mode, there's no model averaging effect, so less need to shorten the M/R iteration\n\n      // estimate the time for communication (network) and training (compute)\n      model.time_for_communication_us = (H2O.CLOUD.size() == 1 ? 1e4 /* add 10ms for single-node */ : 0) + network_queue_length * microseconds_collective[0];\n      double time_per_row_us  = flops_overhead_per_row * model_size / (total_gflops * 1e9) / H2O.SELF._heartbeat._cpus_allowed * 1e6;\n\n      // compute the optimal number of training rows per iteration\n      // fraction := time_comm_us / (time_comm_us + tspi * time_per_row_us)  ==>  tspi = (time_comm_us/fraction - time_comm_us)/time_per_row_us\n      tspi = (long)((model.time_for_communication_us / fraction - model.time_for_communication_us)/ time_per_row_us);\n\n      tspi = Math.min(tspi, (mp.single_node_mode ? 1 : H2O.CLOUD.size()) * numRows * 10); //not more than 10x of what train_samples_per_iteration=-1 would do\n\n      // If the number is close to a multiple of epochs, use that -> prettier scoring\n      if (tspi > numRows && Math.abs(tspi % numRows)/(double)numRows < 0.2)  tspi = tspi - tspi % numRows;\n      tspi = Math.min(tspi, (long)(mp.epochs * numRows / 10)); //limit to number of epochs desired, but at least 10 iterations total\n      tspi = Math.max(1, tspi); //at least 1 point\n\n      if (!mp.quiet_mode) {\n        Log.info(\"Auto-tuning parameter 'train_samples_per_iteration':\");\n        Log.info(\"Estimated compute power : \" + (int)total_gflops + \" GFlops\");\n        Log.info(\"Estimated time for comm : \" + PrettyPrint.usecs((long)model.time_for_communication_us));\n        Log.info(\"Estimated time per row  : \" + ((long)time_per_row_us > 0 ? PrettyPrint.usecs((long)time_per_row_us) : time_per_row_us + \" usecs\"));\n        Log.info(\"Estimated training speed: \" + (int)(1e6/time_per_row_us) + \" rows/sec\");\n        Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to auto-tuned value: \" + tspi);\n      }\n\n    } else {\n      // limit user-given value to number of epochs desired\n      tspi = Math.min(tspi, (long)(mp.epochs * numRows));\n    }\n    assert(tspi != 0 && tspi != -1 && tspi != -2 && tspi >= 1);\n    return tspi;\n  }\n"
  },
  {
    "id": "Bearded_Hen_Android_Bootstrap-22-Param-0",
    "old_comment_raw": "@param context the current context",
    "new_code_raw": "    public static Typeface getTypeface(Context context, IconSet iconSet) {\n        String path = iconSet.fontPath().toString();\n\n        if (TYPEFACE_MAP.get(path) == null) {\n            final Typeface font = Typeface.createFromAsset(context.getAssets(), path);\n            TYPEFACE_MAP.put(path, font);\n        }\n        return TYPEFACE_MAP.get(path);\n    }\n"
  },
  {
    "id": "nytimes_Store-31-Param-0",
    "old_comment_raw": "@param barCode",
    "new_code_raw": "    public Observable<Parsed> disk(@Nonnull final Key key) {\n        if (shouldReturnNetworkBeforeStale(persister, stalePolicy, key)) {\n            return Observable.empty();\n        }\n\n        return readDisk(key);\n    }\n"
  },
  {
    "id": "azkaban_azkaban-10-Param-0",
    "old_comment_raw": "@param exDir",
    "new_code_raw": "\tpublic static boolean updateFlowStatusFromFile(File exDir, ExecutableFlow flow, boolean cleanOldUpdates) throws ExecutorManagerException {\n\t\tFile file = getLatestExecutableFlowDir(exDir, cleanOldUpdates);\n\t\tint number =  getFlowUpdateNumber(file);\n\t\tif (flow.getUpdateNumber() >= number) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\tSystem.out.println(\"Loading from: \" + file);\n\t\tObject exFlowObj = getFlowObjectFromFile(file);\n\t\tflow.updateExecutableFlowFromObject(exFlowObj);\n\t\tflow.setUpdateNumber(number);\n\t\t\n\t\treturn true;\n\t}\n"
  },
  {
    "id": "json_path_JsonPath-185-Param-1",
    "old_comment_raw": "@param jsonProvider the json provider that is used to create the result list",
    "new_code_raw": "    public Object doFilter(Iterable<T> filterItems, Configuration configuration) {\n        JsonProvider provider = configuration.getProvider();\n        Object result = provider.createArray();\n        for (T filterItem : filterItems) {\n            if (accept(filterItem, configuration)) {\n                provider.setProperty(result, provider.length(result), filterItem);\n            }\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-3718-Param-0",
    "old_comment_raw": "@param tx Started transaction.",
    "new_code_raw": "    public boolean onStarted(IgniteInternalTx<K, V> tx) {\n        assert tx.state() == ACTIVE || tx.isRollbackOnly() : \"Invalid transaction state [locId=\" + cctx.localNodeId() +\n            \", tx=\" + tx + ']';\n\n        if (isCompleted(tx)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Attempt to start a completed transaction (will ignore): \" + tx);\n\n            return false;\n        }\n\n        onTxStateChange(null, ACTIVE, tx);\n\n        if (log.isDebugEnabled())\n            log.debug(\"Transaction started: \" + tx);\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-12081-Param-0",
    "old_comment_raw": "@param ggfs GGFS instance to resolve logs dir for.",
    "new_code_raw": "    public static Path resolveGgfsProfilerLogsDir(IgniteFs igfs) throws IgniteCheckedException {\n        String logsDir;\n\n        if (igfs instanceof IgfsEx)\n            logsDir = ((IgfsEx)igfs).clientLogDirectory();\n        else if (igfs == null)\n            throw new IgniteCheckedException(\"Failed to get profiler log folder (GGFS instance not found)\");\n        else\n            throw new IgniteCheckedException(\"Failed to get profiler log folder (unexpected GGFS instance type)\");\n\n        URL logsDirUrl = U.resolveIgniteUrl(logsDir != null ? logsDir : DFLT_GGFS_LOG_DIR);\n\n        return logsDirUrl != null ? new File(logsDirUrl.getPath()).toPath() : null;\n    }\n"
  },
  {
    "id": "apache_ignite-2255-Param-1",
    "old_comment_raw": "@param jdkMarshaller JDK marshaller.",
    "new_code_raw": "    private byte[] encodeMemcache(GridMemcachedMessage msg, IgniteMarshaller jdkMarshaller) throws GridException {\n        GridByteArrayList res = new GridByteArrayList(HDR_LEN - 1);\n\n        int keyLen = 0;\n\n        int keyFlags = 0;\n\n        if (msg.key() != null) {\n            ByteArrayOutputStream rawKey = new ByteArrayOutputStream();\n\n            keyFlags = encodeObj(msg.key(), rawKey, jdkMarshaller);\n\n            msg.key(rawKey.toByteArray());\n\n            keyLen = rawKey.size();\n        }\n\n        int dataLen = 0;\n\n        int valFlags = 0;\n\n        if (msg.value() != null) {\n            ByteArrayOutputStream rawVal = new ByteArrayOutputStream();\n\n            valFlags = encodeObj(msg.value(), rawVal, jdkMarshaller);\n\n            msg.value(rawVal.toByteArray());\n\n            dataLen = rawVal.size();\n        }\n\n        int flagsLen = 0;\n\n        if (msg.addFlags())\n            flagsLen = FLAGS_LENGTH;\n\n        res.add(msg.operationCode());\n\n        // Cast is required due to packet layout.\n        res.add((short)keyLen);\n\n        // Cast is required due to packet layout.\n        res.add((byte)flagsLen);\n\n        // Data type is always 0x00.\n        res.add((byte)0x00);\n\n        res.add((short)msg.status());\n\n        res.add(keyLen + flagsLen + dataLen);\n\n        res.add(msg.opaque(), 0, msg.opaque().length);\n\n        // CAS, unused.\n        res.add(0L);\n\n        assert res.size() == HDR_LEN - 1;\n\n        if (flagsLen > 0) {\n            res.add((short) keyFlags);\n            res.add((short) valFlags);\n        }\n\n        assert msg.key() == null || msg.key() instanceof byte[];\n        assert msg.value() == null || msg.value() instanceof byte[];\n\n        if (keyLen > 0)\n            res.add((byte[])msg.key(), 0, ((byte[])msg.key()).length);\n\n        if (dataLen > 0)\n            res.add((byte[])msg.value(), 0, ((byte[])msg.value()).length);\n\n        return res.entireArray();\n    }\n"
  },
  {
    "id": "apache_ignite-13175-Param-0",
    "old_comment_raw": "@param meta Job metadata.",
    "new_code_raw": "    private JobLocalState initState(GridHadoopJobId jobId) {\n        return F.addIfAbsent(activeJobs, jobId, new JobLocalState());\n    }\n"
  },
  {
    "id": "jprante_elasticsearch_jdbc-70-Param-1",
    "old_comment_raw": "@param listener the listener",
    "new_code_raw": "    public boolean nextRow(ResultSet results, KeyValueStreamListener listener)\n            throws SQLException, IOException, ParseException {\n        if (results.next()) {\n            processRow(results, listener);\n            return true;\n        }\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-12034-Param-0",
    "old_comment_raw": "@param ignite Ignite.",
    "new_code_raw": "    private static IgniteQueue<String> initializeQueue(Ignite g, String queueName) throws IgniteCheckedException {\n        IgniteCollectionConfiguration colCfg = new IgniteCollectionConfiguration();\n\n        // Initialize new FIFO queue.\n        IgniteQueue<String> queue = g.queue(queueName, colCfg, 0, true);\n\n        // Initialize queue items.\n        // We will be use blocking operation and queue size must be appropriated.\n        for (int i = 0; i < g.cluster().nodes().size() * RETRIES * 2; i++)\n            queue.put(Integer.toString(i));\n\n        System.out.println(\"Queue size after initializing: \" + queue.size());\n\n        return queue;\n    }\n"
  },
  {
    "id": "todoroo_astrid-799-Param-0",
    "old_comment_raw": "@param idTask",
    "new_code_raw": "    public JSONArray tasksSetTitle(long idTask, String title) throws ApiServiceException, IOException {\n        return getResponse(invokeGet(\"tasks/set_title.json\",\n                \"token\", token,\n                \"id_task\", idTask,\n                \"title\", title), \"tasks\");\n    }\n"
  },
  {
    "id": "apache_ignite-13170-Param-0",
    "old_comment_raw": "@param lines Lines to sum.",
    "new_code_raw": "    public static VisorGgfsProfilerEntry aggregateGgfsProfilerEntries(List<VisorGgfsProfilerEntry> entries) {\n        assert !F.isEmpty(entries);\n\n        if (entries.size() == 1) {\n            return entries.get(0); // No need to aggregate.\n        }\n        else {\n            String path = entries.get(0).path();\n\n            long timestamp = 0;\n            long size = 0;\n            long bytesRead = 0;\n            long readTime = 0;\n            long userReadTime = 0;\n            long bytesWritten = 0;\n            long writeTime = 0;\n            long userWriteTime = 0;\n            GridGgfsMode mode = null;\n            VisorGgfsProfilerUniformityCounters counters = new VisorGgfsProfilerUniformityCounters();\n\n            Collections.sort(entries, VisorGgfsProfilerEntry.ENTRY_TIMESTAMP_COMPARATOR);\n\n            for (VisorGgfsProfilerEntry entry : entries) {\n                // Take last timestamp.\n                timestamp = entry.timestamp();\n\n                // Take last size.\n                size = entry.size();\n\n                // Take last size.\n                mode = entry.mode();\n\n                // Aggregate metrics.\n                bytesRead += entry.bytesRead();\n                readTime += entry.readTime();\n                userReadTime += entry.userReadTime();\n                bytesWritten += entry.bytesWritten();\n                writeTime += entry.writeTime();\n                userWriteTime += entry.userWriteTime();\n\n                counters.aggregate(entry.counters());\n            }\n\n            return new VisorGgfsProfilerEntry(path, timestamp, mode, size, bytesRead, readTime, userReadTime,\n                bytesWritten, writeTime, userWriteTime, counters);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-2063-Param-1",
    "old_comment_raw": "@param excl Excludes.",
    "new_code_raw": "            @Override public void apply(IgniteFuture<?> f) {\n                try {\n                    f.get();\n                }\n                catch (GridException e) {\n                    if (!F.isEmpty(excl))\n                        for (Class cls : excl)\n                            if (e.hasCause(cls))\n                                return;\n\n                    U.error(log, \"Future execution resulted in error: \" + f, e);\n                }\n            }\n"
  },
  {
    "id": "lisawray_groupie-9-Param-0",
    "old_comment_raw": "@param position",
    "new_code_raw": "    public Group getGroup(Item contentItem) {\n        for (Group group : groups) {\n            if (group.getPosition(contentItem) >= 0) {\n                return group;\n            }\n        }\n        throw new IndexOutOfBoundsException(\"Item is not present in adapter or in any group\");\n    }\n"
  },
  {
    "id": "apache_ignite-5543-Param-2",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, AffinityTopologyVersion topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!cctx.discovery().cacheNearNode(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture<K, V> txFut = null;\n\n        Collection<GridCacheMvccCandidate<K>> cands = null;\n\n        ReaderId<K, V> reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId<>(nodeId, msgId);\n\n                ReaderId<K, V>[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate<K> c : cands) {\n                    IgniteInternalTx<K, V> tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId<K, V> reader0 = reader;\n\n                txFut.listenAsync(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        synchronized (this) {\n                            // Release memory.\n                            reader0.resetTxFuture();\n                        }\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "apache_ignite-11519-Param-0",
    "old_comment_raw": "@param zooKeeper Zookeeper address .",
    "new_code_raw": "    private ConsumerConfig createDefaultConsumerConfig(String zooKeeper, String grpId) {\n        A.notNull(zooKeeper, \"zookeeper\");\n        A.notNull(grpId, \"groupId\");\n\n        Properties props = new Properties();\n\n        props.put(\"zookeeper.connect\", zooKeeper);\n        props.put(\"group.id\", grpId);\n        props.put(\"zookeeper.session.timeout.ms\", \"400\");\n        props.put(\"zookeeper.sync.time.ms\", \"200\");\n        props.put(\"auto.commit.interval.ms\", \"1000\");\n        props.put(\"auto.offset.reset\", \"smallest\");\n\n        return new ConsumerConfig(props);\n    }\n"
  },
  {
    "id": "zxing_zxing-318-Param-1",
    "old_comment_raw": "@param startpos the start position within the message",
    "new_code_raw": "  private static int determineConsecutiveTextCount(CharSequence msg, int startpos) {\n    int len = msg.length();\n    int idx = startpos;\n    while (idx < len) {\n      char ch = msg.charAt(idx);\n      int numericCount = 0;\n      while (numericCount < 13 && isDigit(ch) && idx < len) {\n        numericCount++;\n        idx++;\n        if (idx < len) {\n          ch = msg.charAt(idx);\n        }\n      }\n      if (numericCount >= 13) {\n        return idx - startpos - numericCount;\n      }\n      if (numericCount > 0) {\n        //Heuristic: All text-encodable chars or digits are binary encodable\n        continue;\n      }\n      ch = msg.charAt(idx);\n\n      //Check if character is encodable\n      if (!isText(ch)) {\n        break;\n      }\n      idx++;\n    }\n    return idx - startpos;\n  }\n"
  },
  {
    "id": "apache_ignite-12022-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static CacheSet<String> initializeSet(Ignite ignite, String setName) throws IgniteCheckedException {\n        // Initialize new set.\n        CacheSet<String> set = ignite.cache(CACHE_NAME).dataStructures().set(setName, false, true);\n\n        // Initialize set items.\n        for (int i = 0; i < 10; i++)\n            set.add(Integer.toString(i));\n\n        System.out.println(\"Set size after initializing: \" + set.size());\n\n        return set;\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-66-Param-1",
    "old_comment_raw": "@param moduleIds",
    "new_code_raw": "    public List<SysRoleModule> getEntitys(Integer[] roleIds, String[] moduleIds) {\n        return dao.getEntitys(roleIds, moduleIds);\n    }\n"
  },
  {
    "id": "apache_ignite-13179-Param-0",
    "old_comment_raw": "@param info Task info.",
    "new_code_raw": "    private GridHadoopTaskOutput createOutput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case REDUCE:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case MAP:\n                if (locCombiner) {\n                    assert local == null;\n\n                    local = get(job.info(), SHUFFLE_COMBINER_NO_SORTING, false) ?\n                        new GridHadoopHashMultimap(job, mem, get(job.info(), COMBINER_HASHMAP_SIZE, 8 * 1024)):\n                        new GridHadoopSkipList(job, mem, job.sortComparator()); // TODO replace with red-black tree\n\n                    return local.startAdding();\n                }\n\n            default:\n                return createOutput(ctx);\n        }\n    }\n"
  },
  {
    "id": "zxing_zxing-503-Param-1",
    "old_comment_raw": "@param centerJ center of the section that appears to cross a finder pattern",
    "new_code_raw": "  private float crossCheckVertical(int startI, int centerJ, int maxCount, int originalStateCountTotal) {\n    MonochromeBitmapSource image = this.image;\n\n    int maxI = image.getHeight();\n    int[] stateCount = new int[5];\n\n    // Start counting up from center\n    int i = startI;\n    while (i >= 0 && image.isBlack(centerJ, i)) {\n      stateCount[2]++;\n      i--;\n    }\n    if (i < 0) {\n      return Float.NaN;\n    }\n    while (i >= 0 && !image.isBlack(centerJ, i) && stateCount[1] <= maxCount) {\n      stateCount[1]++;\n      i--;\n    }\n    // If already too many modules in this state or ran off the edge:\n    if (i < 0 || stateCount[1] > maxCount) {\n      return Float.NaN;\n    }\n    while (i >= 0 && image.isBlack(centerJ, i) && stateCount[0] <= maxCount) {\n      stateCount[0]++;\n      i--;\n    }\n    if (stateCount[0] > maxCount) {\n      return Float.NaN;\n    }\n\n    // Now also count down from center\n    i = startI + 1;\n    while (i < maxI && image.isBlack(centerJ, i)) {\n      stateCount[2]++;\n      i++;\n    }\n    if (i == maxI) {\n      return Float.NaN;\n    }\n    while (i < maxI && !image.isBlack(centerJ, i) && stateCount[3] < maxCount) {\n      stateCount[3]++;\n      i++;\n    }\n    if (i == maxI || stateCount[3] >= maxCount) {\n      return Float.NaN;\n    }\n    while (i < maxI && image.isBlack(centerJ, i) && stateCount[4] < maxCount) {\n      stateCount[4]++;\n      i++;\n    }\n    if (stateCount[4] >= maxCount) {\n      return Float.NaN;\n    }\n\n    // If we found a finder-pattern-like section, but its size is more than 20% different than\n    // the original, assume it's a false positive\n    int stateCountTotal = stateCount[0] + stateCount[1] + stateCount[2] + stateCount[3] + stateCount[4];\n    if (5 * Math.abs(stateCountTotal - originalStateCountTotal) >= originalStateCountTotal) {\n      return Float.NaN;\n    }\n\n    return foundPatternCross(stateCount) ? centerFromEnd(stateCount, i) : Float.NaN;\n  }\n"
  },
  {
    "id": "apache_ignite-13181-Param-0",
    "old_comment_raw": "@param info Task info.",
    "new_code_raw": "    private GridHadoopTaskInput createInput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case MAP:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case COMBINE:\n                if (locCombiner) {\n                    assert local != null;\n\n                    return local.input(ctx, (Comparator<Object>) ctx.combineGroupComparator());\n                }\n\n            default:\n                return createInput(ctx);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-2303-Param-0",
    "old_comment_raw": "@param path Path.",
    "new_code_raw": "    private List<IgniteUuid> fileIds(IgniteFsPath path, boolean skipTx) throws GridException {\n        assert path != null;\n\n        // Path components.\n        Collection<String> components = path.components();\n\n        // Collection of file IDs for components of specified path.\n        List<IgniteUuid> ids = new ArrayList<>(components.size() + 1);\n\n        ids.add(ROOT_ID); // Always add root ID.\n\n        IgniteUuid fileId = ROOT_ID;\n\n        for (String s : components) {\n            assert !s.isEmpty();\n\n            if (fileId != null)\n                fileId = fileId(fileId, s, skipTx);\n\n            ids.add(fileId);\n        }\n\n        return ids;\n    }\n"
  },
  {
    "id": "apache_ignite-12274-Param-1",
    "old_comment_raw": "@param spaces Space names.",
    "new_code_raw": "    private static GridSqlQuery collectAllSpaces(GridSqlQuery qry, Set<String> schemas) {\n        if (qry instanceof GridSqlUnion) {\n            GridSqlUnion union = (GridSqlUnion)qry;\n\n            collectAllSpaces(union.left(), schemas);\n            collectAllSpaces(union.right(), schemas);\n        }\n        else {\n            GridSqlSelect select = (GridSqlSelect)qry;\n\n            collectAllSpacesInFrom(select.from(), schemas);\n\n            for (GridSqlElement el : select.columns(false))\n                collectAllSpacesInSubqueries(el, schemas);\n\n            collectAllSpacesInSubqueries(select.where(), schemas);\n        }\n\n        return qry;\n    }\n"
  },
  {
    "id": "apache_ignite-12143-Param-0",
    "old_comment_raw": "@param cacheId Cache ID.",
    "new_code_raw": "    public GridDhtPartitionTopology clientTopology(int cacheId, GridDhtPartitionsExchangeFuture exchFut) {\n        GridClientPartitionTopology top = clientTops.get(cacheId);\n\n        if (top != null)\n            return top;\n\n        GridClientPartitionTopology old = clientTops.putIfAbsent(cacheId,\n            top = new GridClientPartitionTopology(cctx, cacheId, exchFut));\n\n        return old != null ? old : top;\n    }\n"
  },
  {
    "id": "apache_ignite-13312-Param-2",
    "old_comment_raw": "@param expFwdId Expected forward page ID.",
    "new_code_raw": "    private boolean putDown(final Put p, final long pageId, final long fwdId, final int lvl)\n        throws IgniteCheckedException {\n        assert lvl >= 0 : lvl;\n\n        for (;;) {\n            final Page page = page(pageId);\n\n            if (page == null)\n                return true; // Page was removed, retry.\n\n            try {\n                // Init args.\n                p.pageId = pageId;\n                p.fwdId = fwdId;\n\n                int res = readPage(page, search, p, lvl);\n\n                switch (res) {\n                    case Put.RETRY:\n                        return true; // Our page was splitted or merged, retry.\n\n                    case Put.GO_DOWN:\n                        assert lvl > 0 : lvl;\n                        assert p.pageId != pageId;\n                        assert p.fwdId != fwdId || fwdId == 0;\n\n                        if (p.foundInner) { // Need to replace ref in inner page.\n                            p.foundInner = false;\n\n                            int res0 = writePage(page, replace, p, lvl);\n\n                            switch (res0) {\n                                case Put.NOT_FOUND:\n                                    return true; // Our page was splitted or merged, retry.\n\n                                case Put.FOUND:\n                                    break; // Successfully replaced in inner page.\n\n                                default:\n                                    assert false : res0;\n                            }\n                        }\n\n                        // Go down recursively.\n                        if (putDown(p, p.pageId, p.fwdId, lvl - 1)) {\n                            checkInterrupted();\n\n                            continue; // The child page got splitted, need to reread our page.\n                        }\n\n                        if (p.isFinished()) {\n                            assert p.tailLock == null;\n\n                            return false; // Successfully inserted or replaced down the stack.\n                        }\n\n                        assert p.btmLvl == lvl : \"it must be a split: \" + p.btmLvl + \" == \" + lvl;\n\n                        checkInterrupted();\n\n                        continue; // We have to insert split row to the upper level.\n\n                    case Put.FOUND: // Do replace.\n                        assert lvl == 0 : \"This replace can happen only at the bottom level.\";\n\n                        // Init args.\n                        p.pageId = pageId;\n                        p.fwdId = fwdId;\n\n                        res = writePage(page, replace, p, lvl);\n\n                        switch (res) {\n                            case Put.NOT_FOUND:\n                                return true; // Retry.\n\n                            case Put.FOUND:\n                                assert p.isFinished();\n\n                                return false;\n\n                            default:\n                                assert false : res;\n                        }\n\n                        break;\n\n                    case Put.NOT_FOUND: // Do insert.\n                        assert lvl == p.btmLvl : \"must insert at the bottom level\";\n\n                        // Init args.\n                        p.pageId = pageId;\n                        p.fwdId = fwdId;\n\n                        res = writePage(page, insert, p, lvl);\n\n                        switch (res) {\n                            case Put.RETRY:\n                                return true; // Our page was splitted or merged, retry.\n\n                            case Put.FOUND:\n                                if (p.isFinished())\n                                    return false;\n\n                                assert p.btmLvl > lvl;\n\n                                return true; // Go insert to the upper level.\n\n                            default:\n                                assert false: res;\n                        }\n\n                        break;\n\n                    default:\n                        assert false : res;\n                }\n            }\n            finally{\n                if (p.tailLock != page)\n                    page.close();\n            }\n\n            checkInterrupted();\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-13275-Param-0",
    "old_comment_raw": "@param ignite Grid.",
    "new_code_raw": "    public static VisorCache from(Ignite ignite, GridCache c, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<GridCacheEntryEx> set = ca.map().entries0();\n\n        long memSz = 0;\n\n        Iterator<GridCacheEntryEx> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name = cacheName;\n        cache.mode = mode;\n        cache.memorySize = memSz;\n        cache.size = size;\n        cache.nearSize = near;\n        cache.dhtSize = size - near;\n        cache.primarySize = ca.primarySize();\n        cache.offHeapAllocatedSize = ca.offHeapAllocatedSize();\n        cache.offHeapEntriesCnt = ca.offHeapEntriesCount();\n        cache.swapSize = swapSize;\n        cache.swapKeys = swapKeys;\n        cache.partitions = ca.affinity().partitions();\n        cache.primaryPartitions = pps;\n        cache.backupPartitions = bps;\n        cache.metrics = VisorCacheMetrics.from(ca);\n        cache.partitionsMap = partsMap;\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-13204-Param-0",
    "old_comment_raw": "@param grid Node;",
    "new_code_raw": "    private GridGgfsImpl ggfs(Ignite ignite) throws Exception {\n        return (GridGgfsImpl) ignite.ggfs(GGFS_NAME);\n    }\n"
  },
  {
    "id": "apache_ignite-13313-Param-3",
    "old_comment_raw": "@param lvl Level.",
    "new_code_raw": "    private boolean findDown(final Get g, final long pageId, final long fwdId, final int lvl)\n        throws IgniteCheckedException {\n        Page page = page(pageId);\n\n        if (page == null)\n            return true; // Page was removed, retry.\n\n        try {\n            for (;;) {\n                // Init args.\n                g.pageId = pageId;\n                g.fwdId = fwdId;\n\n                int res = readPage(page, search, g, lvl, Get.RETRY);\n\n                switch (res) {\n                    case Get.RETRY:\n                        return true;\n\n                    case Get.GO_DOWN:\n                        assert g.pageId != pageId;\n                        assert g.fwdId != fwdId || fwdId == 0;\n\n                        // Go down recursively.\n                        if (findDown(g, g.pageId, g.fwdId, lvl - 1)) {\n                            checkInterrupted();\n\n                            continue; // The child page got splitted, need to reread our page.\n                        }\n\n                        return false;\n\n                    case Get.FOUND:\n                        return false; // We are done.\n\n                    case Get.NOT_FOUND:\n                        g.row = null; // Mark not found result.\n\n                        return false;\n\n                    default:\n                        assert false: res;\n                }\n            }\n        }\n        finally {\n            if (g.canRelease(page, lvl))\n                page.close();\n        }\n    }\n"
  },
  {
    "id": "todoroo_astrid-987-Param-0",
    "old_comment_raw": "@param tag",
    "new_code_raw": "        public static QueryTemplate queryTemplate(Criterion criterion, TagData tagData) {\n            return new QueryTemplate().join(Join.inner(Metadata.TABLE,\n                    Task.ID.eq(Metadata.TASK))).where(tagEqIgnoreCase(tagData.getValue(TagData.NAME), criterion));\n        }\n"
  },
  {
    "id": "apache_ignite-10255-Param-0",
    "old_comment_raw": "@param e Event",
    "new_code_raw": "        private boolean filterByTaskSessionId(Event e, IgniteUuid taskSesId) {\n            if (e.getClass().equals(TaskEvent.class)) {\n                TaskEvent te = (TaskEvent)e;\n\n                return te.taskSessionId().equals(taskSesId);\n            }\n\n            if (e.getClass().equals(JobEvent.class)) {\n                JobEvent je = (JobEvent)e;\n\n                return je.taskSessionId().equals(taskSesId);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "apache_ignite-12143-Param-1",
    "old_comment_raw": "@param exchId Exchange ID.",
    "new_code_raw": "    public GridDhtPartitionTopology clientTopology(int cacheId, GridDhtPartitionsExchangeFuture exchFut) {\n        GridClientPartitionTopology top = clientTops.get(cacheId);\n\n        if (top != null)\n            return top;\n\n        GridClientPartitionTopology old = clientTops.putIfAbsent(cacheId,\n            top = new GridClientPartitionTopology(cctx, cacheId, exchFut));\n\n        return old != null ? old : top;\n    }\n"
  },
  {
    "id": "apache_ignite-8800-Param-0",
    "old_comment_raw": "@param partId Partition ID.",
    "new_code_raw": "    public static long pageId(int partId, byte flag, long pageIdx) {\n        long fileId = 0;\n\n        fileId = (fileId << FLAG_SIZE) | (flag & FLAG_MASK);\n        fileId = (fileId << PART_ID_SIZE) | (partId & PART_ID_MASK);\n\n        return pageId((int)fileId, pageIdx);\n    }\n"
  },
  {
    "id": "apache_ignite-12025-Param-0",
    "old_comment_raw": "@param ignite Ignite.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite g, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = g.streamer(\"popular-numbers\");\n\n                try {\n                    // Send reduce query to all 'popular-numbers' streamers\n                    // running on local and remote nodes.\n                    Collection<StreamerIndexEntry<Integer, Integer, Long>> col = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext,\n                                                                            Collection<StreamerIndexEntry<Integer, Integer, Long>>>() {\n                            @Override public Collection<StreamerIndexEntry<Integer, Integer, Long>> apply(\n                                StreamerContext ctx) {\n                                StreamerIndex<Integer, Integer, Long> view = ctx.<Integer>window().index();\n\n                                return view.entries(-1 * POPULAR_NUMBERS_CNT);\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new PopularNumbersReducer());\n\n                    for (StreamerIndexEntry<Integer, Integer, Long> cntr : col)\n                        System.out.printf(\"%3d=%d\\n\", cntr.key(), cntr.value());\n\n                    System.out.println(\"----------------\");\n                }\n                catch (IgniteCheckedException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 3000, 3000);\n\n        return task;\n    }\n"
  },
  {
    "id": "azkaban_azkaban-20-Param-1",
    "old_comment_raw": "@param delimiter",
    "new_code_raw": "\tpublic static String join(Collection<String> list, String delimiter) {\n\t\tStringBuffer buffer = new StringBuffer();\n\t\tfor (String str: list) {\n\t\t\tbuffer.append(str);\n\t\t\tbuffer.append(delimiter);\n\t\t}\n\t\t\n\t\treturn buffer.toString();\n\t}\n"
  },
  {
    "id": "apache_ignite-13264-Param-0",
    "old_comment_raw": "@param cacheVal Value.",
    "new_code_raw": "    public V applyEntryProcessors(V val) {\n        for (T2<EntryProcessor<K, V, ?>, Object[]> t : entryProcessors()) {\n            try {\n                CacheInvokeEntry<K, V> invokeEntry = new CacheInvokeEntry<>(ctx, key, val);\n\n                EntryProcessor processor = t.get1();\n\n                processor.process(invokeEntry, t.get2());\n\n                val = invokeEntry.getValue();\n            }\n            catch (Exception ignore) {\n                // No-op.\n            }\n        }\n\n        if (ctx.portableEnabled())\n            val = (V)ctx.marshalToPortable(val);\n\n        return val;\n    }\n"
  },
  {
    "id": "apache_ignite-2359-Param-0",
    "old_comment_raw": "@param fs Secondary file system.",
    "new_code_raw": "    public boolean renameDual(final IgniteFsFileSystem fs, final IgniteFsPath src, final IgniteFsPath dest) throws\n        GridException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert src != null;\n                assert dest != null;\n\n                if (src.parent() == null)\n                    return false; // Root directory cannot be renamed.\n\n                // Events to fire (can be done outside of a transaction).\n                final Collection<IgniteFsEvent> pendingEvts = new LinkedList<>();\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<IgniteFsPath, GridGgfsFileInfo> infos) throws Exception {\n                        GridGgfsFileInfo srcInfo = infos.get(src);\n                        GridGgfsFileInfo srcParentInfo = infos.get(src.parent());\n                        GridGgfsFileInfo destInfo = infos.get(dest);\n                        GridGgfsFileInfo destParentInfo = dest.parent() != null ? infos.get(dest.parent()) : null;\n\n                        // Source path and destination (or destination parent) must exist.\n                        if (srcInfo == null)\n                            throw new IgniteFsFileNotFoundException(\"Failed to rename (source path not found): \" + src);\n\n                        if (destInfo == null && destParentInfo == null)\n                            throw new IgniteFsFileNotFoundException(\"Failed to rename (destination path not found): \" +\n                                dest);\n\n                        // Delegate to the secondary file system.\n                        fs.rename(src, dest);\n\n                        // Rename was successful, perform compensation in the local file system.\n                        if (destInfo == null) {\n                            // Move and rename.\n                            assert destParentInfo != null;\n\n                            moveNonTx(srcInfo.id(), src.name(), srcParentInfo.id(), dest.name(), destParentInfo.id());\n                        }\n                        else {\n                            // Move.\n                            if (destInfo.isFile())\n                                throw new IgniteFsException(\"Failed to rename the path in the local file system \" +\n                                    \"because destination path already exists and it is a file: \" + dest);\n                            else\n                                moveNonTx(srcInfo.id(), src.name(), srcParentInfo.id(), src.name(), destInfo.id());\n                        }\n\n                        // Record event if needed.\n                        if (srcInfo.isFile()) {\n                            if (evts.isRecordable(EVT_GGFS_FILE_RENAMED))\n                                pendingEvts.add(new IgniteFsEvent(\n                                    src,\n                                    destInfo == null ? dest : new IgniteFsPath(dest, src.name()),\n                                    locNode,\n                                    EVT_GGFS_FILE_RENAMED));\n                        }\n                        else if (evts.isRecordable(EVT_GGFS_DIR_RENAMED))\n                            pendingEvts.add(new IgniteFsEvent(src, dest, locNode, EVT_GGFS_DIR_RENAMED));\n\n                        return true;\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws GridException {\n                        U.error(log, \"Path rename in DUAL mode failed [source=\" + src + \", destination=\" + dest + ']',\n                            err);\n\n                        if (err instanceof IgniteFsException)\n                            throw (GridException)err;\n                        else\n                            throw new GridException(\"Failed to rename the path due to secondary file system \" +\n                                \"exception: \" + src, err);\n                    }\n                };\n\n                try {\n                    return synchronizeAndExecute(task, fs, false, src, dest);\n                }\n                finally {\n                    for (IgniteFsEvent evt : pendingEvts)\n                        evts.record(evt);\n                }\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to rename in DUAL mode because Grid is stopping [src=\" + src +\n                \", dest=\" + dest + ']');\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-951-Param-0",
    "old_comment_raw": "@param deviceNumber The bulb number the bridge has filed the bulb under.",
    "new_code_raw": "\tpublic int getBrightness(String deviceId) {\n\t\tif (settingsData == null) {\n\t\t\tlogger.error(\"Hue bridge settings not initialized correctly.\");\n\t\t\treturn 0;\n\t\t}\n\t\treturn (Integer) settingsData.node(\"lights\")\n\t\t\t\t.node(deviceId).node(\"state\")\n\t\t\t\t.value(\"bri\");\n\t}\n"
  },
  {
    "id": "bitcoinj_bitcoinj-52-Param-2",
    "old_comment_raw": "@param label A label",
    "new_code_raw": "    public static String convertToBitcoinURI(String address, BigInteger amount, String label, String message) {\n        Preconditions.checkNotNull(address);\n        if (amount != null && amount.compareTo(BigInteger.ZERO) < 0) {\n            throw new IllegalArgumentException(\"Amount must be positive\");\n        }\n        \n        StringBuilder builder = new StringBuilder();\n        builder.append(BITCOIN_SCHEME).append(COLON_SEPARATOR).append(address);\n        \n        boolean questionMarkHasBeenOutput = false;\n        \n        if (amount != null) {\n            builder.append(QUESTION_MARK_SEPARATOR).append(FIELD_AMOUNT).append(\"=\");\n            builder.append(Utils.bitcoinValueToPlainString(amount));\n            questionMarkHasBeenOutput = true;\n        }\n        \n        if (label != null && !\"\".equals(label)) {\n            if (questionMarkHasBeenOutput) {\n                builder.append(AMPERSAND_SEPARATOR);\n            } else {\n                builder.append(QUESTION_MARK_SEPARATOR);                \n                questionMarkHasBeenOutput = true;\n            }\n            builder.append(FIELD_LABEL).append(\"=\").append(encodeURLString(label));\n        }\n        \n        if (message != null && !\"\".equals(message)) {\n            if (questionMarkHasBeenOutput) {\n                builder.append(AMPERSAND_SEPARATOR);\n            } else {\n                builder.append(QUESTION_MARK_SEPARATOR);                \n                questionMarkHasBeenOutput = true;\n            }\n            builder.append(FIELD_MESSAGE).append(\"=\").append(encodeURLString(message));\n        }\n        \n        return builder.toString();\n    }\n"
  },
  {
    "id": "bauerca_drag_sort_listview-17-Param-0",
    "old_comment_raw": "@param remove Remove the dragged item from the list. Calls a registered DropListener, if one exists.",
    "new_code_raw": "    public boolean stopDrag(boolean remove) {\n        if (mFloatView != null) {\n            mDragScroller.stopScrolling(true);\n            \n            if (remove) {\n                removeItem(mSrcPos - getHeaderViewsCount());\n            } else {\n                if (mDropAnimator != null) {\n                    mDropAnimator.start();\n                } else {\n                    dropFloatView();\n                }\n            }\n\n            if (mTrackDragSort) {\n                mDragSortTracker.stopTracking();\n            }\n\n            return true;\n        } else {\n            // stop failed\n            return false;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-3612-Param-0",
    "old_comment_raw": "@param tx Cache transaction.",
    "new_code_raw": "    public boolean putAllToStore(@Nullable IgniteTxEx tx, Map<K, IgniteBiTuple<V, GridCacheVersion>> map)\n        throws IgniteCheckedException {\n        if (F.isEmpty(map))\n            return true;\n\n        if (map.size() == 1) {\n            Map.Entry<K, IgniteBiTuple<V, GridCacheVersion>> e = map.entrySet().iterator().next();\n\n            return putToStore(tx, e.getKey(), e.getValue().get1(), e.getValue().get2());\n        }\n        else {\n            if (store != null) {\n                EntriesView entries = new EntriesView(map);\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Storing values in cache store [entries=\" + entries + ']');\n\n                initSession(tx);\n\n                try {\n                    store.writeAll(entries);\n                }\n                catch (ClassCastException e) {\n                    handleClassCastException(e);\n                }\n                catch (Exception e) {\n                    if (!entries.isEmpty()) {\n                        List<Object> keys = new ArrayList<>(entries.size());\n\n                        for (Cache.Entry<?, ?> entry : entries)\n                            keys.add(entry.getKey());\n\n                        throw new CacheStorePartialUpdateException(keys, e);\n                    }\n\n                    if (!(e instanceof CacheWriterException))\n                        e = new CacheWriterException(e);\n\n                    throw new IgniteCheckedException(e);\n                }\n                finally {\n                    sesHolder.set(null);\n                }\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Stored value in cache store [entries=\" + entries + ']');\n\n                return true;\n            }\n\n            return false;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-12032-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite ignite, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = ignite.streamer(\"popular-numbers\");\n\n                try {\n                    // Send reduce query to all 'popular-numbers' streamers\n                    // running on local and remote nodes.\n                    Collection<StreamerIndexEntry<Integer, Integer, Long>> col = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext,\n                                                                            Collection<StreamerIndexEntry<Integer, Integer, Long>>>() {\n                            @Override public Collection<StreamerIndexEntry<Integer, Integer, Long>> apply(\n                                StreamerContext ctx) {\n                                StreamerIndex<Integer, Integer, Long> view = ctx.<Integer>window().index();\n\n                                return view.entries(-1 * POPULAR_NUMBERS_CNT);\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new PopularNumbersReducer());\n\n                    for (StreamerIndexEntry<Integer, Integer, Long> cntr : col)\n                        System.out.printf(\"%3d=%d\\n\", cntr.key(), cntr.value());\n\n                    System.out.println(\"----------------\");\n                }\n                catch (IgniteException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 3000, 3000);\n\n        return task;\n    }\n"
  },
  {
    "id": "apache_ignite-1555-Param-1",
    "old_comment_raw": "@param tier Tier number to assign.",
    "new_code_raw": "        boolean assign(int part, int tier, ClusterNode node, boolean force, Map<Integer, Queue<Integer>> pendingParts) {\n            UUID nodeId = node.id();\n\n            if (!fullMap.get(nodeId).contains(part)) {\n                tierMaps[tier].get(nodeId).add(part);\n\n                fullMap.get(nodeId).add(part);\n\n                List<ClusterNode> assignment = assignments.get(part);\n\n                if (assignment.size() <= tier)\n                    assignment.add(node);\n                else {\n                    ClusterNode oldNode = assignment.set(tier, node);\n\n                    if (oldNode != null) {\n                        UUID oldNodeId = oldNode.id();\n\n                        tierMaps[tier].get(oldNodeId).remove(part);\n                        fullMap.get(oldNodeId).remove(part);\n                    }\n                }\n\n                return true;\n            }\n            else if (force) {\n                assert !tierMaps[tier].get(nodeId).contains(part);\n\n                // Check previous tiers first.\n                for (int t = 0; t < tier; t++) {\n                    if (tierMaps[t].get(nodeId).contains(part))\n                        return false;\n                }\n\n                // Partition is on some lower tier, switch it.\n                for (int t = tier + 1; t < tierMaps.length; t++) {\n                    if (tierMaps[t].get(nodeId).contains(part)) {\n                        ClusterNode oldNode = assignments.get(part).get(tier);\n\n                        // Move partition from level t to tier.\n                        assignments.get(part).set(tier, node);\n                        assignments.get(part).set(t, null);\n\n                        if (oldNode != null) {\n                            tierMaps[tier].get(oldNode.id()).remove(part);\n                            fullMap.get(oldNode.id()).remove(part);\n                        }\n\n                        tierMaps[tier].get(nodeId).add(part);\n                        tierMaps[t].get(nodeId).remove(part);\n\n                        Queue<Integer> pending = pendingParts.get(t);\n\n                        if (pending == null) {\n                            pending = new LinkedList<>();\n\n                            pendingParts.put(t, pending);\n                        }\n\n                        pending.add(part);\n\n                        return true;\n                    }\n                }\n\n                throw new IllegalStateException(\"Unable to assign partition to node while force is true.\");\n            }\n\n            // !force.\n            return false;\n        }\n"
  },
  {
    "id": "spring_projects_spring_kafka-128-Param-0",
    "old_comment_raw": "@param kafkaPorts the ports.",
    "new_code_raw": "\tpublic EmbeddedKafkaBroker kafkaPorts(int... ports) {\n\t\tAssert.isTrue(ports.length == this.count, \"A port must be provided for each instance [\"\n\t\t\t\t+ this.count + \"], provided: \" + Arrays.toString(ports) + \", use 0 for a random port\");\n\t\tthis.kafkaPorts = ports;\n\t\treturn this;\n\t}\n"
  },
  {
    "id": "apache_ignite-3696-Param-0",
    "old_comment_raw": "@param tx Transaction to commit.",
    "new_code_raw": "    public IgniteInternalFuture<IgniteInternalTx> commitTxAsync(IgniteInternalTx<K, V> tx) {\n        Collection<Integer> cacheIds = tx.activeCacheIds();\n\n        if (cacheIds.isEmpty())\n            return tx.commitAsync();\n        else if (cacheIds.size() == 1) {\n            int cacheId = F.first(cacheIds);\n\n            return cacheContext(cacheId).cache().commitTxAsync(tx);\n        }\n        else {\n            for (Integer cacheId : cacheIds)\n                cacheContext(cacheId).cache().awaitLastFut();\n\n            return tx.commitAsync();\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-799-Param-2",
    "old_comment_raw": "@param end",
    "new_code_raw": "  public String ltrim(final byte[] key, final long start, final long stop) {\n    checkIsInMultiOrPipeline();\n    client.ltrim(key, start, stop);\n    return client.getStatusCodeReply();\n  }\n"
  },
  {
    "id": "apache_ignite-5662-Param-0",
    "old_comment_raw": "@param keys Keys to lock.",
    "new_code_raw": "    private boolean mapAsPrimary(Collection<KeyCacheObject> keys, AffinityTopologyVersion topVer) throws IgniteCheckedException {\n        // Assign keys to primary nodes.\n        Collection<KeyCacheObject> distributedKeys = new ArrayList<>(keys.size());\n\n        for (KeyCacheObject key : keys) {\n            if (!cctx.affinity().primary(cctx.localNode(), key, topVer)) {\n                // Remove explicit locks added so far.\n                for (KeyCacheObject k : keys)\n                    cctx.mvcc().removeExplicitLock(threadId, k, lockVer);\n\n                return false;\n            }\n\n            addLocalKey(key, topVer, distributedKeys);\n\n            if (isDone())\n                return true;\n        }\n\n        trackable = false;\n\n        if (tx != null)\n            tx.colocatedLocallyMapped(true);\n\n        if (!distributedKeys.isEmpty()) {\n            if (tx != null) {\n                for (KeyCacheObject key : distributedKeys)\n                    tx.addKeyMapping(cctx.txKey(key), cctx.localNode());\n            }\n\n            lockLocally(distributedKeys, topVer, null);\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-12206-Param-0",
    "old_comment_raw": "@param srvNodesNum Server nodes number.",
    "new_code_raw": "    private String topologySnapshotMessage(int serverNodesNum, int clientNodesNum, int totalCpus, double heap) {\n        return PREFIX + \" [\" +\n            (discoOrdered ? \"ver=\" + topSnap.get().topVer.topologyVersion() + \", \" : \"\") +\n            \"servers=\" + serverNodesNum +\n            \", clients=\" + clientNodesNum +\n            \", CPUs=\" + totalCpus +\n            \", heap=\" + heap + \"GB]\";\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-317-Param-0",
    "old_comment_raw": "@param repository",
    "new_code_raw": "    public static Intent createIntent(Repo repository) {\n        return new Builder(\"repo.VIEW\").repo(repository).toIntent();\n    }\n"
  },
  {
    "id": "apache_ignite-11624-Param-0",
    "old_comment_raw": "@param grid Grid.",
    "new_code_raw": "    private Collection<Integer> nearKeys(Ignite ignite) {\n        final Collection<Integer> keys = new ArrayList<>(KEY_CNT);\n\n        GridKernal kernal = (GridKernal) ignite;\n\n        GridCacheAffinityManager<Object, Object> affMgr = kernal.internalCache().context().affinity();\n\n        for (int i = 0; i < KEY_CNT * GRID_CNT * 1.5; i++) {\n            if (!affMgr.localNode((Object)i, kernal.context().discovery().topologyVersion())) {\n                keys.add(i);\n\n                if (keys.size() == KEY_CNT)\n                    break;\n            }\n        }\n\n        return keys;\n    }\n"
  },
  {
    "id": "apache_ignite-1503-Param-0",
    "old_comment_raw": "@param g Grid instance.",
    "new_code_raw": "    public static boolean checkExplicitTaskMonitoring(Ignite g) {\n        int[] evts = g.configuration().getIncludeEventTypes();\n\n        if (F.isEmpty(evts))\n            return false;\n\n        for (int evt : VISOR_TASK_EVTS) {\n            if (!F.contains(evts, evt))\n                return false;\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-12112-Param-0",
    "old_comment_raw": "@param ignite Grid.",
    "new_code_raw": "    public static VisorBasicConfiguration from(IgniteEx g, IgniteConfiguration c) {\n        VisorBasicConfiguration cfg = new VisorBasicConfiguration();\n\n        cfg.gridName(c.getGridName());\n        cfg.ggHome(getProperty(IGNITE_HOME, c.getIgniteHome()));\n        cfg.localHost(getProperty(IGNITE_LOCAL_HOST, c.getLocalHost()));\n        cfg.nodeId(g.localNode().id());\n        cfg.marshaller(compactClass(c.getMarshaller()));\n        cfg.deploymentMode(compactObject(c.getDeploymentMode()));\n        cfg.daemon(boolValue(IGNITE_DAEMON, c.isDaemon()));\n        cfg.jmxRemote(g.isJmxRemoteEnabled());\n        cfg.restart(g.isRestartEnabled());\n        cfg.networkTimeout(c.getNetworkTimeout());\n        cfg.logger(compactClass(c.getGridLogger()));\n        cfg.discoStartupDelay(c.getDiscoveryStartupDelay());\n        cfg.mBeanServer(compactClass(c.getMBeanServer()));\n        cfg.noAscii(boolValue(IGNITE_NO_ASCII, false));\n        cfg.noDiscoOrder(boolValue(IGNITE_NO_DISCO_ORDER, false));\n        cfg.noShutdownHook(boolValue(IGNITE_NO_SHUTDOWN_HOOK, false));\n        cfg.programName(getProperty(IGNITE_PROG_NAME));\n        cfg.quiet(boolValue(IGNITE_QUIET, true));\n        cfg.successFile(getProperty(IGNITE_SUCCESS_FILE));\n        cfg.updateNotifier(boolValue(IGNITE_UPDATE_NOTIFIER, true));\n        cfg.securityCredentialsProvider(compactClass(c.getSecurityCredentialsProvider()));\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_ignite-12066-Param-1",
    "old_comment_raw": "@param c Actual cache.",
    "new_code_raw": "    public static VisorCache from(Ignite g, GridCache c, int sample) throws IgniteCheckedException {\n        assert g != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)g).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = g.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<CacheEntry> set = ca.entrySet();\n\n        long memSz = 0;\n\n        Iterator<CacheEntry> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_ignite-11534-Param-0",
    "old_comment_raw": "@param in Input character stream.",
    "new_code_raw": "    public static int copy(InputStream in, OutputStream out) throws IOException {\n        assert in != null;\n        assert out != null;\n\n        byte[] buf = new byte[BUF_SIZE];\n\n        int cnt = 0;\n\n        for (int n; (n = in.read(buf)) > 0;) {\n            out.write(buf, 0, n);\n\n            cnt += n;\n        }\n\n        return cnt;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-774-Param-0",
    "old_comment_raw": "@param content the set of commands to be executed by the  ExecuteCommandJob later on",
    "new_code_raw": "    protected JobDetail createJob(String content, Event event, boolean isStartEvent) {\n        String jobIdentity = event.getICalUID() + (isStartEvent ? \"_start\" : \"_end\");\n\n        if (StringUtils.isBlank(content)) {\n            logger.debug(\"content of job '{}' is empty -> no task will be created!\", jobIdentity);\n            return null;\n        }\n\n        JobDetail job = newJob(ExecuteCommandJob.class).usingJobData(ExecuteCommandJob.JOB_DATA_CONTENT_KEY, content)\n                .withIdentity(jobIdentity, GCAL_SCHEDULER_GROUP).build();\n\n        return job;\n    }\n"
  },
  {
    "id": "json_path_JsonPath-233-Param-0",
    "old_comment_raw": "@param criteria criteria",
    "new_code_raw": "    public static Filter filter(Collection<Predicate> predicates) {\n        return new AndFilter(predicates);\n    }\n"
  },
  {
    "id": "apache_ignite-12111-Param-1",
    "old_comment_raw": "@param addr Address to send message to.",
    "new_code_raw": "    @Nullable private Integer sendMessageDirectly(TcpDiscoveryAbstractMessage msg, InetSocketAddress addr, Socket sock)\n        throws IgniteSpiException {\n        assert msg != null;\n        assert addr != null;\n\n        Collection<Throwable> errs = null;\n\n        long ackTimeout0 = ackTimeout;\n\n        int connectAttempts = 1;\n\n        boolean joinReqSent = false;\n\n        UUID locNodeId = ignite.configuration().getNodeId();\n\n        for (int i = 0; i < reconCnt; i++) {\n            // Need to set to false on each new iteration,\n            // since remote node may leave in the middle of the first iteration.\n            joinReqSent = false;\n\n            boolean openSock = false;\n\n            try {\n                long tstamp = U.currentTimeMillis();\n\n                if (sock == null)\n                    sock = openSocket(addr);\n\n                openSock = true;\n\n                // Handshake.\n                writeToSocket(sock, new TcpDiscoveryHandshakeRequest(locNodeId));\n\n                TcpDiscoveryHandshakeResponse res = readMessage(sock, null, ackTimeout0);\n\n                if (locNodeId.equals(res.creatorNodeId())) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Handshake response from local node: \" + res);\n\n                    break;\n                }\n\n                stats.onClientSocketInitialized(U.currentTimeMillis() - tstamp);\n\n                // Send message.\n                tstamp = U.currentTimeMillis();\n\n                writeToSocket(sock, msg);\n\n                stats.onMessageSent(msg, U.currentTimeMillis() - tstamp);\n\n                if (debugMode)\n                    debugLog(\"Message has been sent directly to address [msg=\" + msg + \", addr=\" + addr +\n                        \", rmtNodeId=\" + res.creatorNodeId() + ']');\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Message has been sent directly to address [msg=\" + msg + \", addr=\" + addr +\n                        \", rmtNodeId=\" + res.creatorNodeId() + ']');\n\n                // Connection has been established, but\n                // join request may not be unmarshalled on remote host.\n                // E.g. due to class not found issue.\n                joinReqSent = msg instanceof TcpDiscoveryJoinRequestMessage;\n\n                return readReceipt(sock, ackTimeout0);\n            }\n            catch (ClassCastException e) {\n                // This issue is rarely reproducible on AmazonEC2, but never\n                // on dedicated machines.\n                if (log.isDebugEnabled())\n                    U.error(log, \"Class cast exception on direct send: \" + addr, e);\n\n                if (errs == null)\n                    errs = new ArrayList<>();\n\n                errs.add(e);\n            }\n            catch (IOException | IgniteCheckedException e) {\n                if (log.isDebugEnabled())\n                    log.error(\"Exception on direct send: \" + e.getMessage(), e);\n\n                if (errs == null)\n                    errs = new ArrayList<>();\n\n                errs.add(e);\n\n                if (!openSock) {\n                    // Reconnect for the second time, if connection is not established.\n                    if (connectAttempts < 2) {\n                        connectAttempts++;\n\n                        continue;\n                    }\n\n                    break; // Don't retry if we can not establish connection.\n                }\n\n                if (e instanceof SocketTimeoutException || X.hasCause(e, SocketTimeoutException.class)) {\n                    ackTimeout0 *= 2;\n\n                    if (!checkAckTimeout(ackTimeout0))\n                        break;\n                }\n            }\n            finally {\n                U.closeQuiet(sock);\n\n                sock = null;\n            }\n        }\n\n        if (joinReqSent) {\n            if (log.isDebugEnabled())\n                log.debug(\"Join request has been sent, but receipt has not been read (returning RES_WAIT).\");\n\n            // Topology will not include this node,\n            // however, warning on timed out join will be output.\n            return RES_OK;\n        }\n\n        throw new IgniteSpiException(\n            \"Failed to send message to address [addr=\" + addr + \", msg=\" + msg + ']',\n            U.exceptionWithSuppressed(\"Failed to send message to address \" +\n                \"[addr=\" + addr + \", msg=\" + msg + ']', errs));\n    }\n"
  },
  {
    "id": "powermock_powermock-43-Param-0",
    "old_comment_raw": "@param type The type of the class where the method is located.",
    "new_code_raw": "\tpublic static Method method(Class<?> declaringClass, String methodName, Class<?>... parameterTypes) {\n\t\tfinal Method method = WhiteboxImpl.findMethod(declaringClass, methodName, parameterTypes);\n\t\tWhiteboxImpl.throwExceptionIfMethodWasNotFound(declaringClass, methodName, method, (Object[]) parameterTypes);\n\t\treturn method;\n\t}\n"
  },
  {
    "id": "sanluan_PublicCMS-24-Param-0",
    "old_comment_raw": "@param ids",
    "new_code_raw": "    public String delete(Long[] ids, HttpServletRequest request, HttpSession session) {\n        if (notEmpty(ids)) {\n            SysSite site = getSite(request);\n            service.delete(site.getId(), ids);\n            logOperateService.save(new LogOperate(site.getId(), getAdminFromSession(session).getId(),\n                    LogLoginService.CHANNEL_WEB_MANAGER, \"delete.place\", getIpAddress(request), getDate(), join(ids, ',')));\n        }\n        return TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "azkaban_azkaban-224-Param-0",
    "old_comment_raw": "@param filesStr File path(s) delimited by delimiter",
    "new_code_raw": "  public static Collection<String> listFiles(String filesString, String delimiter) {\n    ValidationUtils.validateNotEmpty(filesString, \"fileStr\");\n\n    List<String> files = new ArrayList<String>();\n    for (String fileString : filesString.split(delimiter)) {\n      File file = new File(fileString);\n      if (!file.getName().contains(\"*\") && !file.getName().contains(\"?\")) {\n        files.add(file.getAbsolutePath());\n        continue;\n      }\n\n      FileFilter fileFilter = new AndFileFilter(new WildcardFileFilter(file.getName()),\n          FileFileFilter.FILE);\n      File parent = file.getParentFile() == null ? file : file.getParentFile();\n      File[] filteredFiles = parent.listFiles(fileFilter);\n      if (filteredFiles == null) {\n        continue;\n      }\n\n      for (File filteredFile : filteredFiles) {\n        files.add(filteredFile.getAbsolutePath());\n      }\n    }\n    return files;\n  }\n"
  },
  {
    "id": "chrisbanes_ActionBar_PullToRefresh-2-Param-0",
    "old_comment_raw": "@param fromTouch - Whether this is being invoked from a touch event",
    "new_code_raw": "    private boolean canRefresh(boolean fromTouch, OnRefreshListener listener) {\n        return !mIsRefreshing && (!fromTouch || listener != null);\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-512-Param-0",
    "old_comment_raw": "@param way: needed to retrieve OSM tags",
    "new_code_raw": "    protected double applyMaxSpeed( ReaderWay way, double speed )\n    {\n        double maxSpeed = getMaxSpeed(way);\n        if (maxSpeed >= 0)\n        {\n            // We strictly obay speed limits, see #600\n            if (maxSpeed < speed)\n            {\n                return maxSpeed;\n            }\n        }\n        return speed;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-316-Param-0",
    "old_comment_raw": "@param repository",
    "new_code_raw": "    public static Intent createIntent(Repo repository) {\n        return new Intents.Builder(\"repo.contributors.VIEW\").repo(repository).toIntent();\n    }\n"
  },
  {
    "id": "apache_ignite-13314-Param-1",
    "old_comment_raw": "@param delete Whether lock is taken for delete.",
    "new_code_raw": "    private IgfsEntryInfo invokeLock(IgniteUuid id, boolean del) throws IgniteCheckedException {\n        return invokeAndGet(id, new IgfsMetaFileLockProcessor(createFileLockId(del)));\n    }\n"
  },
  {
    "id": "apache_ignite-4858-Param-1",
    "old_comment_raw": "@param key Key to look up.",
    "new_code_raw": "    @Nullable public GridCacheMvccCandidate explicitLock(long threadId, KeyCacheObject key) {\n        if (threadId < 0)\n            return explicitLock(key, null);\n        else {\n            GridCacheExplicitLockSpan span = pendingExplicit.get(threadId);\n\n            return span == null ? null : span.candidate(key, null);\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-830-Param-1",
    "old_comment_raw": "@param start",
    "new_code_raw": "  public Long zremrangeByScore(final byte[] key, final double min, final double max) {\n    return zremrangeByScore(key, toByteArray(min), toByteArray(max));\n  }\n"
  },
  {
    "id": "mitreid_connect_OpenID_Connect_Java_Spring_Server-59-Param-0",
    "old_comment_raw": "@param c",
    "new_code_raw": "\tpublic static JsonObject serialize(RegisteredClient c) {\n\t\tJsonObject o = new JsonObject();\n\n\t\to.addProperty(\"client_id\", c.getClientId());\n\t\tif (c.getClientSecret() != null) {\n\t\t\to.addProperty(\"client_secret\", c.getClientSecret());\n\t\t\to.addProperty(\"expires_at\", 0); // TODO: do we want to let secrets expire?\n\t\t}\n\n\t\tif (c.getIssuedAt() != null) {\n\t\t\to.addProperty(\"issued_at\", c.getIssuedAt().getTime() / 1000L);\n\t\t} else if (c.getCreatedAt() != null) {\n\t\t\to.addProperty(\"issued_at\", c.getCreatedAt().getTime() / 1000L);\n\t\t}\n\t\tif (c.getRegistrationAccessToken() != null) {\n\t\t\to.addProperty(\"registration_access_token\", c.getRegistrationAccessToken());\n\t\t}\n\n\t\tif (c.getRegistrationClientUri() != null) {\n\t\t\to.addProperty(\"registration_client_uri\", c.getRegistrationClientUri());\n\t\t}\n\n\n\t\t// add in all other client properties\n\n\t\t// OAuth DynReg\n\t\to.add(\"redirect_uris\", getAsArray(c.getRedirectUris()));\n\t\to.addProperty(\"client_name\", c.getClientName());\n\t\to.addProperty(\"client_uri\", c.getClientUri());\n\t\to.addProperty(\"logo_uri\", c.getLogoUri());\n\t\to.add(\"contacts\", getAsArray(c.getContacts()));\n\t\to.addProperty(\"tos_uri\", c.getTosUri());\n\t\to.addProperty(\"token_endpoint_auth_method\", c.getTokenEndpointAuthMethod() != null ? c.getTokenEndpointAuthMethod().getValue() : null);\n\t\to.addProperty(\"scope\", c.getScope() != null ? Joiner.on(\" \").join(c.getScope()) : null);\n\t\to.add(\"grant_types\", getAsArray(c.getGrantTypes()));\n\t\to.addProperty(\"policy_uri\", c.getPolicyUri());\n\t\to.addProperty(\"jwks_uri\", c.getJwksUri());\n\n\t\t// OIDC Registration\n\t\to.addProperty(\"application_type\", c.getApplicationType() != null ? c.getApplicationType().getValue() : null);\n\t\to.addProperty(\"sector_identifier_uri\", c.getSectorIdentifierUri());\n\t\to.addProperty(\"subject_type\", c.getSubjectType() != null ? c.getSubjectType().getValue() : null);\n\t\to.addProperty(\"request_object_signing_alg\", c.getRequestObjectSigningAlg() != null ? c.getRequestObjectSigningAlg().getAlgorithmName() : null);\n\t\to.addProperty(\"userinfo_signed_response_alg\", c.getUserInfoSignedResponseAlg() != null ? c.getUserInfoSignedResponseAlg().getAlgorithmName() : null);\n\t\to.addProperty(\"userinfo_encrypted_response_alg\", c.getUserInfoEncryptedResponseAlg() != null ? c.getUserInfoEncryptedResponseAlg().getAlgorithmName() : null);\n\t\to.addProperty(\"userinfo_encrypted_response_enc\", c.getUserInfoEncryptedResponseEnc() != null ? c.getUserInfoEncryptedResponseEnc().getAlgorithmName() : null);\n\t\to.addProperty(\"id_token_signed_response_alg\", c.getIdTokenSignedResponseAlg() != null ? c.getIdTokenSignedResponseAlg().getAlgorithmName() : null);\n\t\to.addProperty(\"id_token_encrypted_response_alg\", c.getIdTokenEncryptedResponseAlg() != null ? c.getIdTokenEncryptedResponseAlg().getAlgorithmName() : null);\n\t\to.addProperty(\"id_token_encrypted_response_enc\", c.getIdTokenEncryptedResponseEnc() != null ? c.getIdTokenEncryptedResponseEnc().getAlgorithmName() : null);\n\t\to.addProperty(\"default_max_age\", c.getDefaultMaxAge());\n\t\to.addProperty(\"require_auth_time\", c.getRequireAuthTime());\n\t\to.add(\"default_acr_values\", getAsArray(c.getDefaultACRvalues()));\n\t\to.addProperty(\"initiate_login_uri\", c.getInitiateLoginUri());\n\t\to.addProperty(\"post_logout_redirect_uri\", c.getPostLogoutRedirectUri());\n\t\to.add(\"request_uris\", getAsArray(c.getRequestUris()));\n\t\treturn o;\n\t}\n"
  },
  {
    "id": "xetorthio_jedis-807-Param-1",
    "old_comment_raw": "@param score",
    "new_code_raw": "  public Double zincrby(final String key, final double increment, final String member) {\n    checkIsInMultiOrPipeline();\n    client.zincrby(key, increment, member);\n    String newscore = client.getBulkReply();\n    return Double.valueOf(newscore);\n  }\n"
  },
  {
    "id": "apache_ignite-1368-Param-0",
    "old_comment_raw": "@param commit Commit flag (rollback if  false).",
    "new_code_raw": "    public GridFuture<GridCacheTx> finishLocal(boolean commit, boolean explicitLock, GridNearTxLocal<K, V> tx) {\n        try {\n            if (commit) {\n                if (!tx.markFinalizing(USER_FINISH)) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Will not finish transaction (it is handled by another thread): \" + tx);\n\n                    return null;\n                }\n\n                return tx.commitAsyncLocal();\n            }\n            else\n                return tx.rollbackAsyncLocal();\n        }\n        catch (Throwable e) {\n            U.error(log, \"Failed completing transaction [commit=\" + commit + \", tx=\" + tx + ']', e);\n\n            if (tx != null)\n                return tx.rollbackAsync();\n\n            return new GridFinishedFuture<>(ctx.kernalContext(), e);\n        }\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1324-Param-0",
    "old_comment_raw": "@param loginSession for current request",
    "new_code_raw": "    protected Response handleBrowserAuthenticationRequest(AuthenticationSessionModel authSession, LoginProtocol protocol, boolean isPassive, boolean redirectToAuthentication) {\n        AuthenticationFlowModel flow = getAuthenticationFlow();\n        String flowId = flow.getId();\n        AuthenticationProcessor processor = createProcessor(authSession, flowId, LoginActionsService.AUTHENTICATE_PATH);\n        event.detail(Details.CODE_ID, authSession.getId());\n        if (isPassive) {\n            // OIDC prompt == NONE or SAML 2 IsPassive flag\n            // This means that client is just checking if the user is already completely logged in.\n            // We cancel login if any authentication action or required action is required\n            try {\n                if (processor.authenticateOnly() == null) {\n                    // processor.attachSession();\n                } else {\n                    Response response = protocol.sendError(authSession, Error.PASSIVE_LOGIN_REQUIRED);\n                    session.authenticationSessions().removeAuthenticationSession(realm, authSession);\n                    return response;\n                }\n\n                AuthenticationManager.setRolesAndMappersInSession(authSession);\n\n                if (processor.isActionRequired()) {\n                    Response response = protocol.sendError(authSession, Error.PASSIVE_INTERACTION_REQUIRED);\n                    session.authenticationSessions().removeAuthenticationSession(realm, authSession);\n                    return response;\n                }\n\n                // Attach session once no requiredActions or other things are required\n                processor.attachSession();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n            return processor.finishAuthentication(protocol);\n        } else {\n            try {\n                RestartLoginCookie.setRestartCookie(session, realm, clientConnection, uriInfo, authSession);\n                if (redirectToAuthentication) {\n                    return processor.redirectToFlow(null);\n                }\n                return processor.authenticate();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n        }\n    }\n"
  },
  {
    "id": "mockito_mockito-169-Param-0",
    "old_comment_raw": "@param matcher decides whether argument matches",
    "new_code_raw": "    public static int intThat(MockitoMatcher<Integer> matcher) {\n        return reportMatcher(matcher).returnZero();\n    }\n"
  },
  {
    "id": "gephi_gephi-406-Param-2",
    "old_comment_raw": "@param pGraph",
    "new_code_raw": "    public double finalQ(int[] struct, double[] degrees, HierarchicalUndirectedGraph graph, AttributeModel attributeModel) {\n        AttributeTable nodeTable = attributeModel.getNodeTable();\n        AttributeColumn modCol = nodeTable.getColumn(MODULARITY_CLASS);\n        if (modCol == null) {\n            modCol = nodeTable.addColumn(MODULARITY_CLASS, \"Modularity Class\", AttributeType.INT, AttributeOrigin.COMPUTED, new Integer(0));\n        }\n\n        double res = 0;\n        double[] internal = new double[degrees.length];\n        for (Node n : graph.getNodes()) {\n            int n_index = structure.map.get(n);\n            AttributeRow row = (AttributeRow) n.getNodeData().getAttributes();\n            row.setValue(modCol, struct[n_index]);\n            for (Node neighbor : graph.getNeighbors(n)) {\n                if (n == neighbor) {\n                    continue;\n                }\n                int neigh_index = structure.map.get(neighbor);\n                if (struct[neigh_index] == struct[n_index]) {\n                    internal[struct[neigh_index]]++;\n                }\n            }\n        }\n        for (int i = 0; i < degrees.length; i++) {\n            internal[i] /= 2.0;\n            res += (internal[i] / graph.getEdgeCount()) - Math.pow(degrees[i] / (2 * graph.getEdgeCount()), 2);\n        }\n        return res;\n    }\n"
  },
  {
    "id": "apache_ignite-5658-Param-2",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, AffinityTopologyVersion topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!cctx.discovery().cacheNearNode(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture txFut = null;\n\n        Collection<GridCacheMvccCandidate> cands = null;\n\n        ReaderId reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId(nodeId, msgId);\n\n                ReaderId[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate c : cands) {\n                    IgniteInternalTx tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId reader0 = reader;\n\n                txFut.listen(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        cctx.kernalContext().closure().runLocalSafe(new GridPlainRunnable() {\n                            @Override public void run() {\n                                synchronized (this) {\n                                    // Release memory.\n                                    reader0.resetTxFuture();\n                                }\n                            }\n                        });\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "json_path_JsonPath-187-Param-0",
    "old_comment_raw": "@param pathFragment The path fragment that is currently being processed which is believed to be the name of a function",
    "new_code_raw": "    public static Function newFunction(String name) throws InvalidPathException {\n        Function result = new PassthruFunction();\n\n        if (null != name && FUNCTIONS.containsKey(name) && Function.class.isAssignableFrom(FUNCTIONS.get(name))) {\n            try {\n                result = (Function)FUNCTIONS.get(name).newInstance();\n            } catch (InstantiationException e) {\n                throw new InvalidPathException(\"Function of name: \" + name + \" cannot be created\", e);\n            } catch (IllegalAccessException e) {\n                throw new InvalidPathException(\"Function of name: \" + name + \" cannot be created\", e);\n            }\n        }\n        return result;\n\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-954-Param-0",
    "old_comment_raw": "@param byteBuffer",
    "new_code_raw": "\tprivate Object getValue(ByteBuffer byteBuffer, TelegramValue telegramValue) {\n\n\t\tString type = telegramValue.getType().toLowerCase();\n\t\tint pos = telegramValue.getPos() != null ? telegramValue.getPos() : -1;\n\n\t\tObject value = null;\n\n\t\t// requested pos is greater as whole buffer\n\t\tif(pos > byteBuffer.position()) {\n\t\t\tlogger.warn(\"eBus buffer pos error! Can happen ...\");\n\t\t}\n\n\t\t// replace similar data types\n\t\tif(type.equals(\"uint\"))\n\t\t\ttype = \"word\";\n\t\tif(type.equals(\"byte\"))\n\t\t\ttype = \"uchar\";\n\n\t\tbyte[] bytes = null;\n\t\tif(type.equals(\"data2b\") || type.equals(\"data2c\") || type.equals(\"word\")) {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos), byteBuffer.get(pos-1)};\n\t\t} else {\n\t\t\tbytes = new byte[] {byteBuffer.get(pos-1)};\n\t\t}\n\n\t\tif(type.equals(\"bit\")) {\n\t\t\tint bit = telegramValue.getBit();\n\t\t\tvalue = bytes[0];\n\n\t\t\tboolean isSet = ((Byte)value >> bit& 0x1) == 1;\n\t\t\tvalue = isSet;\n\n\t\t} else {\n\t\t\tvalue = NumberUtils.toBigDecimal(EBusCodecUtils.decode(type, bytes, telegramValue.getReplaceValue()));\n\t\t}\n\n\t\t// if BigDecimal check for min, max and replace value\n\t\tif(value instanceof BigDecimal) {\n\t\t\tBigDecimal b = (BigDecimal)value;\n\n\t\t\t// multiply before check min and max\n\t\t\tif(b != null && telegramValue.getFactor() != null) {\n\t\t\t\tlogger.trace(\"Value multiplied ...\");\n\t\t\t\tvalue = b = b.multiply(telegramValue.getFactor());\n\t\t\t}\n\n\t\t\t// value is below min value, return null\n\t\t\tif(telegramValue.getMin() != null && b != null && b.compareTo(telegramValue.getMin()) == -1) {\n\t\t\t\tlogger.trace(\"Minimal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\n\t\t\t\t// value is above max value, return null\n\t\t\t} else if (telegramValue.getMax() != null && b != null && b.compareTo(telegramValue.getMax()) == 1) {\n\t\t\t\tlogger.trace(\"Maximal value reached, skip value ...\");\n\t\t\t\tvalue = b = null;\n\t\t\t}\n\n\t\t}\n\n\t\treturn value;\n\t}\n"
  },
  {
    "id": "apache_ignite-12037-Param-0",
    "old_comment_raw": "@param ignite Ignite.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite g, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = g.streamer(\"priceBars\");\n\n                try {\n                    Collection<Bar> bars = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext, Collection<Bar>>() {\n                            @Override public Collection<Bar> apply(StreamerContext ctx) {\n                                Collection<Bar> values = ctx.<String, Bar>localSpace().values();\n\n                                Collection<Bar> res = new ArrayList<>(values.size());\n\n                                for (Bar bar : values)\n                                    res.add(bar.copy());\n\n                                return res;\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new IgniteReducer<Collection<Bar>, Collection<Bar>>() {\n                            private final Collection<Bar> res = new ArrayList<>();\n\n                            @Override public boolean collect(@Nullable Collection<Bar> col) {\n                                res.addAll(col);\n\n                                return true;\n                            }\n\n                            @Override public Collection<Bar> reduce() {\n                                return res;\n                            }\n                        }\n                    );\n\n                    for (Bar bar : bars)\n                        System.out.println(bar.toString());\n\n                    System.out.println(\"-----------------\");\n                }\n                catch (IgniteException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 2000, 2000);\n\n        return task;\n    }\n"
  },
  {
    "id": "apache_ignite-5937-Param-0",
    "old_comment_raw": "@param gridName Grid name.",
    "new_code_raw": "    protected CacheConfiguration cacheConfiguration(String gridName) {\n        CacheConfiguration cacheCfg = defaultCacheConfiguration();\n\n        cacheCfg.setName(\"partitioned\");\n        cacheCfg.setCacheMode(PARTITIONED);\n        cacheCfg.setDistributionMode(cnt == 0 ? NEAR_ONLY : PARTITIONED_ONLY);\n        cacheCfg.setWriteSynchronizationMode(CacheWriteSynchronizationMode.FULL_SYNC);\n        cacheCfg.setAffinityMapper(new IgfsGroupDataBlocksKeyMapper(GRP_SIZE));\n        cacheCfg.setBackups(0);\n        cacheCfg.setQueryIndexEnabled(false);\n        cacheCfg.setAtomicityMode(TRANSACTIONAL);\n\n        return cacheCfg;\n    }\n"
  },
  {
    "id": "apache_ignite-12328-Param-0",
    "old_comment_raw": "@param m IGFS metrics.",
    "new_code_raw": "    public static VisorIgfsMetrics from(IgniteFileSystem igfs) {\n        assert igfs != null;\n\n        IgfsMetrics m = igfs.metrics();\n\n        VisorIgfsMetrics metrics = new VisorIgfsMetrics();\n\n        metrics.totalSpaceSz = igfs.configuration().getMaxSpaceSize();\n        metrics.usedSpaceSz = m.localSpaceSize();\n        metrics.foldersCnt = m.directoriesCount();\n        metrics.filesCnt = m.filesCount();\n        metrics.filesOpenedForRd = m.filesOpenedForRead();\n        metrics.filesOpenedForWrt = m.filesOpenedForWrite();\n        metrics.blocksRd = m.blocksReadTotal();\n        metrics.blocksRdRmt = m.blocksReadRemote();\n        metrics.blocksWrt = m.blocksWrittenTotal();\n        metrics.blocksWrtRmt = m.blocksWrittenRemote();\n        metrics.bytesRd = m.bytesRead();\n        metrics.bytesRdTm = m.bytesReadTime();\n        metrics.bytesWrt = m.bytesWritten();\n        metrics.bytesWrtTm = m.bytesWriteTime();\n\n        return metrics;\n    }\n"
  },
  {
    "id": "todoroo_astrid-92-Param-0",
    "old_comment_raw": "@param directory",
    "new_code_raw": "    private String setupFile(File directory, boolean isService) throws IOException {\n        File astridDir = directory;\n        if (astridDir != null) {\n            // Check for /sdcard/astrid directory. If it doesn't exist, make it.\n            if (astridDir.exists() || astridDir.mkdir()) {\n                String fileName;\n                if (isService) {\n                    fileName = BackupConstants.BACKUP_FILE_NAME;\n                } else {\n                    fileName = BackupConstants.EXPORT_FILE_NAME;\n                }\n                fileName = String.format(fileName, BackupDateUtilities.getDateForExport());\n                return astridDir.getAbsolutePath() + File.separator + fileName;\n            } else {\n                // Unable to make the /sdcard/astrid directory.\n                throw new IOException(context.getString(R.string.DLG_error_sdcard,\n                        astridDir.getAbsolutePath()));\n            }\n        } else {\n            // Unable to access the sdcard because it's not in the mounted state.\n            throw new IOException(context.getString(R.string.DLG_error_sdcard_general));\n        }\n    }\n"
  },
  {
    "id": "CalebFenton_simplify-20-Param-0",
    "old_comment_raw": "@param methodDescriptor",
    "new_code_raw": "    public boolean isNativeMethod(String methodSignature) {\n        BuilderMethod method = getMethod(methodSignature);\n\n        return Modifier.isNative(method.getAccessFlags());\n    }\n"
  },
  {
    "id": "apache_ignite-11435-Param-0",
    "old_comment_raw": "@param spi SPI.",
    "new_code_raw": "    private GridNioSession communicationSession(TcpCommunicationSpi spi, boolean in) throws Exception {\n        final GridNioServer srv = U.field(spi, \"nioSrvr\");\n\n        GridTestUtils.waitForCondition(new GridAbsPredicate() {\n            @Override public boolean apply() {\n                Collection<? extends GridNioSession> sessions = GridTestUtils.getFieldValue(srv, \"sessions\");\n\n                return !sessions.isEmpty();\n            }\n        }, awaitForSocketWriteTimeout());\n\n        Collection<? extends GridNioSession> sessions = GridTestUtils.getFieldValue(srv, \"sessions\");\n\n        for (GridNioSession ses : sessions) {\n            if (in == ses.accepted())\n                return ses;\n        }\n\n        fail(\"Failed to find session\");\n\n        return null;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-790-Param-1",
    "old_comment_raw": "@param strings",
    "new_code_raw": "    public Long rpush(final byte[] key, final byte[]... string) {\n        checkIsInMulti();\n        client.rpush(key, string);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-11255-Param-0",
    "old_comment_raw": "@param name Property name.",
    "new_code_raw": "    private static String getStringProperty(String name, Properties fileProps, String dfltVal) {\n        if (fileProps != null && fileProps.containsKey(name))\n            return fileProps.getProperty(name);\n\n        String prop = System.getProperty(name);\n\n        if (prop == null)\n            prop = System.getenv(name);\n\n        return prop == null ? dfltVal : prop;\n    }\n"
  },
  {
    "id": "aurelhubert_ahbottomnavigation-1-Param-1",
    "old_comment_raw": "@param drawableResource",
    "new_code_raw": "\tpublic static Drawable getTintDrawable(Context context, Drawable drawable, int color) {\n\t\tDrawable wrapDrawable = DrawableCompat.wrap(drawable);\n\t\tDrawableCompat.setTint(wrapDrawable, color);\n\t\treturn wrapDrawable;\n\t}\n"
  },
  {
    "id": "apache_ignite-2246-Param-0",
    "old_comment_raw": "@param in Input stream.",
    "new_code_raw": "    Object read(IgniteOptimizedObjectInputStream in) throws ClassNotFoundException, IOException {\n        switch (type) {\n            case TYPE_BYTE:\n                return in.readByte();\n\n            case TYPE_SHORT:\n                return in.readShort();\n\n            case TYPE_INT:\n                return in.readInt();\n\n            case TYPE_LONG:\n                return in.readLong();\n\n            case TYPE_FLOAT:\n                return in.readFloat();\n\n            case TYPE_DOUBLE:\n                return in.readDouble();\n\n            case TYPE_CHAR:\n                return in.readChar();\n\n            case TYPE_BOOLEAN:\n                return in.readBoolean();\n\n            case TYPE_BYTE_ARR:\n                return in.readByteArray();\n\n            case TYPE_SHORT_ARR:\n                return in.readShortArray();\n\n            case TYPE_INT_ARR:\n                return in.readIntArray();\n\n            case TYPE_LONG_ARR:\n                return in.readLongArray();\n\n            case TYPE_FLOAT_ARR:\n                return in.readFloatArray();\n\n            case TYPE_DOUBLE_ARR:\n                return in.readDoubleArray();\n\n            case TYPE_CHAR_ARR:\n                return in.readCharArray();\n\n            case TYPE_BOOLEAN_ARR:\n                return in.readBooleanArray();\n\n            case TYPE_OBJ_ARR:\n                return in.readArray(arrCompType);\n\n            case TYPE_STR:\n                return in.readString();\n\n            case TYPE_ENUM:\n                return enumVals[in.readInt()];\n\n            case TYPE_UUID:\n                return in.readUuid();\n\n            case TYPE_PROPS:\n                return in.readProperties();\n\n            case TYPE_ARRAY_LIST:\n                return in.readArrayList();\n\n            case TYPE_HASH_MAP:\n                return in.readHashMap(false);\n\n            case TYPE_HASH_SET:\n                return in.readHashSet(mapFieldOff);\n\n            case TYPE_LINKED_LIST:\n                return in.readLinkedList();\n\n            case TYPE_LINKED_HASH_MAP:\n                return in.readLinkedHashMap(false);\n\n            case TYPE_LINKED_HASH_SET:\n                return in.readLinkedHashSet(mapFieldOff);\n\n            case TYPE_DATE:\n                return in.readDate();\n\n            case TYPE_CLS:\n                return IgniteOptimizedClassResolver.readClass(in, in.classLoader()).describedClass();\n\n            case TYPE_EXTERNALIZABLE:\n                return in.readExternalizable(constructor, readResolveMtd);\n\n            case TYPE_SERIALIZABLE:\n                return in.readSerializable(cls, readObjMtds, readResolveMtd, fields);\n\n            default:\n                throw new IllegalStateException(\"Invalid class type: \" + type);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-12033-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite ignite, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = ignite.streamer(\"priceBars\");\n\n                try {\n                    Collection<Bar> bars = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext, Collection<Bar>>() {\n                            @Override public Collection<Bar> apply(StreamerContext ctx) {\n                                Collection<Bar> values = ctx.<String, Bar>localSpace().values();\n\n                                Collection<Bar> res = new ArrayList<>(values.size());\n\n                                for (Bar bar : values)\n                                    res.add(bar.copy());\n\n                                return res;\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new IgniteReducer<Collection<Bar>, Collection<Bar>>() {\n                            private final Collection<Bar> res = new ArrayList<>();\n\n                            @Override public boolean collect(@Nullable Collection<Bar> col) {\n                                res.addAll(col);\n\n                                return true;\n                            }\n\n                            @Override public Collection<Bar> reduce() {\n                                return res;\n                            }\n                        }\n                    );\n\n                    for (Bar bar : bars)\n                        System.out.println(bar.toString());\n\n                    System.out.println(\"-----------------\");\n                }\n                catch (IgniteException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 2000, 2000);\n\n        return task;\n    }\n"
  },
  {
    "id": "apache_ignite-11102-Param-0",
    "old_comment_raw": "@param parentId Parent file ID.",
    "new_code_raw": "    private IgniteUuid putIfAbsentNonTx(IgniteUuid parentId, String fileName, IgfsFileInfo newFileInfo)\n        throws IgniteCheckedException {\n        if (log.isDebugEnabled())\n            log.debug(\"Locking parent id [parentId=\" + parentId + \", fileName=\" + fileName + \", newFileInfo=\" +\n                newFileInfo + ']');\n\n        assert validTxState(true);\n\n        // Lock only parent file ID.\n        IgfsFileInfo parentInfo = info(parentId);\n\n        if (parentInfo == null)\n            throw fsException(new IgfsPathNotFoundException(\"Failed to lock parent directory (not found): \" +\n                parentId));\n\n        if (!parentInfo.isDirectory())\n            throw fsException(new IgfsPathIsNotDirectoryException(\"Parent file is not a directory: \" + parentInfo));\n\n        Map<String, IgfsListingEntry> parentListing = parentInfo.listing();\n\n        assert parentListing != null;\n\n        IgfsListingEntry entry = parentListing.get(fileName);\n\n        if (entry != null)\n            return entry.fileId();\n\n        IgniteUuid fileId = newFileInfo.id();\n\n        if (!id2InfoPrj.putIfAbsent(fileId, newFileInfo))\n            throw fsException(\"Failed to add file details into cache: \" + newFileInfo);\n\n        assert metaCache.get(parentId) != null;\n\n        id2InfoPrj.invoke(parentId, new UpdateListing(fileName, new IgfsListingEntry(newFileInfo), false));\n\n        return null;\n    }\n"
  },
  {
    "id": "pubnub_java-65-Param-0",
    "old_comment_raw": "@param sUrl , input string",
    "new_code_raw": "    public static String pamEncode(String stringToEncode) {\n        /* !'()*~ */\n\n        String encoded = urlEncode(stringToEncode);\n        if (encoded != null) {\n            encoded = encoded\n                    .replace(\"*\", \"%2A\")\n                    .replace(\"!\", \"%21\")\n                    .replace(\"'\", \"%27\")\n                    .replace(\"(\", \"%28\")\n                    .replace(\")\", \"%29\")\n                    .replace(\"[\", \"%5B\")\n                    .replace(\"]\", \"%5D\")\n                    .replace(\"~\", \"%7E\");\n        }\n        return encoded;\n    }\n"
  },
  {
    "id": "react_native_community_react_native_svg-15-Param-2",
    "old_comment_raw": "@param offset offset for all units",
    "new_code_raw": "    static double fromRelative(SVGLength length, double relative, double offset, double scale, double fontSize) {\n        /*\n            TODO list\n\n            unit  relative to\n            em    font size of the element\n            ex    x-height of the element\u00e2\u0080\u0099s font\n            ch    width of the \"0\" (ZERO, U+0030) glyph in the element\u00e2\u0080\u0099s font\n            rem   font size of the root element\n            vw    1% of viewport\u00e2\u0080\u0099s width\n            vh    1% of viewport\u00e2\u0080\u0099s height\n            vmin  1% of viewport\u00e2\u0080\u0099s smaller dimension\n            vmax  1% of viewport\u00e2\u0080\u0099s larger dimension\n\n            relative-size [ larger | smaller ]\n            absolute-size: [ xx-small | x-small | small | medium | large | x-large | xx-large ]\n\n            https://www.w3.org/TR/css3-values/#relative-lengths\n            https://www.w3.org/TR/css3-values/#absolute-lengths\n            https://drafts.csswg.org/css-cascade-4/#computed-value\n            https://drafts.csswg.org/css-fonts-3/#propdef-font-size\n            https://drafts.csswg.org/css2/fonts.html#propdef-font-size\n        */\n        SVGLengthUnitType unitType = length.unit;\n        double value = length.value;\n        double unit = 1;\n        switch (unitType) {\n            case SVG_LENGTHTYPE_NUMBER:\n            case SVG_LENGTHTYPE_PX:\n                break;\n\n            case SVG_LENGTHTYPE_PERCENTAGE:\n                return value / 100 * relative + offset;\n\n            case SVG_LENGTHTYPE_EMS:\n                unit = fontSize;\n                break;\n            case SVG_LENGTHTYPE_EXS:\n                unit = fontSize / 2;\n                break;\n\n            case SVG_LENGTHTYPE_CM:\n                unit = 35.43307;\n                break;\n            case SVG_LENGTHTYPE_MM:\n                unit = 3.543307;\n                break;\n            case SVG_LENGTHTYPE_IN:\n                unit = 90;\n                break;\n            case SVG_LENGTHTYPE_PT:\n                unit = 1.25;\n                break;\n            case SVG_LENGTHTYPE_PC:\n                unit = 15;\n                break;\n\n            default:\n            case SVG_LENGTHTYPE_UNKNOWN:\n                return value * scale + offset;\n        }\n        return value * unit * scale + offset;\n    }\n"
  },
  {
    "id": "apache_shiro-710-Param-1",
    "old_comment_raw": "@param info the AuthenticationInfo of a newly authenticated subject/user.",
    "new_code_raw": "    protected SecurityContext createSecurityContext(AuthenticationToken token, Account account) {\n        SecurityContextFactory factory = getSecurityContextFactory();\n        if (factory == null) {\n            throw new IllegalStateException(\n                \"No SecurityContextFactory class attribute has been set, so authentication cannot \" +\n                    \"be completed.  Make sure the init() method is being called on this \" +\n                    \"Authenticator before it is used.\");\n        }\n\n        return factory.createSecurityContext(token, account);\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-316-Param-3",
    "old_comment_raw": "@param session",
    "new_code_raw": "    public String delete(Long[] ids, String _csrf, HttpServletRequest request, HttpSession session, ModelMap model) {\n        if (ControllerUtils.verifyNotEquals(\"_csrf\", ControllerUtils.getAdminToken(request), _csrf, model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        SysSite site = siteComponent.getSite(request.getServerName());\n        if (CommonUtils.notEmpty(ids)) {\n            service.delete(ids);\n            logOperateService.save(new LogOperate(site.getId(), ControllerUtils.getAdminFromSession(session).getId(),\n                    LogLoginService.CHANNEL_WEB_MANAGER, \"delete.cmsDictionary\", RequestUtils.getIpAddress(request),\n                    CommonUtils.getDate(), StringUtils.join(ids, CommonConstants.COMMA)));\n        }\n        return CommonConstants.TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-791-Param-1",
    "old_comment_raw": "@param strings",
    "new_code_raw": "    public Long lpush(final String key, final String... string) {\n        checkIsInMulti();\n        client.lpush(key, string);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "todoroo_astrid-716-Param-1",
    "old_comment_raw": "@param getParameters",
    "new_code_raw": "    private String createFetchUrl(String api, String method, Object... getParameters) throws UnsupportedEncodingException, NoSuchAlgorithmException {\n        ArrayList<Pair<String, Object>> params = new ArrayList<Pair<String, Object>>();\n        for(int i = 0; i < getParameters.length; i += 2) {\n            if(getParameters[i+1] instanceof ArrayList) {\n                ArrayList<?> list = (ArrayList<?>) getParameters[i+1];\n                for(int j = 0; j < list.size(); j++)\n                    params.add(new Pair<String, Object>(getParameters[i].toString() + \"[]\",\n                            list.get(j)));\n            } else\n                params.add(new Pair<String, Object>(getParameters[i].toString(), getParameters[i+1]));\n        }\n        params.add(new Pair<String, Object>(\"app_id\", APP_ID));\n        boolean syncMethod = \"synchronize\".equals(method);\n\n        if (!syncMethod)\n            params.add(new Pair<String, Object>(\"time\", System.currentTimeMillis() / 1000L));\n        if(token != null) {\n            boolean foundTokenKey = false;\n            for (Pair<String, Object> curr : params) {\n                if (curr.getLeft().equals(\"token\")) {\n                    foundTokenKey = true;\n                    break;\n                }\n            }\n            if (!foundTokenKey)\n                params.add(new Pair<String, Object>(\"token\", token));\n        }\n\n        Collections.sort(params, new Comparator<Pair<String, Object>>() {\n            @Override\n            public int compare(Pair<String, Object> object1,\n                    Pair<String, Object> object2) {\n                int result = object1.getLeft().compareTo(object2.getLeft());\n                if(result == 0)\n                    return object1.getRight().toString().compareTo(object2.getRight().toString());\n                return result;\n            }\n        });\n\n        String url = URL;\n        boolean customApi = false;\n        if (api != null) {\n            customApi = true;\n            url = url.replace(\"api\", api);\n        }\n        if (Preferences.getBoolean(R.string.actfm_https_key, false))\n            url = \"https:\" + url;\n        else\n            url = \"http:\" + url;\n\n        StringBuilder requestBuilder = new StringBuilder(url);\n        if (!customApi)\n            requestBuilder.append(API_VERSION).append(\"/\");\n        requestBuilder.append(method).append('?');\n        StringBuilder sigBuilder = new StringBuilder(method);\n        for(Pair<String, Object> entry : params) {\n            if(entry.getRight() == null)\n                continue;\n\n            String key = entry.getLeft();\n            String value = entry.getRight().toString();\n            String encoded = URLEncoder.encode(value, \"UTF-8\");\n\n            if (!syncMethod || \"app_id\".equals(key));\n                requestBuilder.append(key).append('=').append(encoded).append('&');\n\n            sigBuilder.append(key).append(value);\n        }\n\n        sigBuilder.append(APP_SECRET);\n        String signature = DigestUtils.md5Hex(sigBuilder.toString());\n        requestBuilder.append(\"sig\").append('=').append(signature);\n        return requestBuilder.toString();\n    }\n"
  },
  {
    "id": "niklasb_pse-broadcast-encryption-19-Associations-Param1",
    "old_comment_raw": "@param gr The value $g^r$.",
    "new_code_raw": "    public NaorPinkasShare getShare(BigInteger r, BigInteger gr) {\n        BigInteger x = schnorr.getFieldModP().pow(gr, pi);\n        return new NaorPinkasShare(t, r, i, x, schnorr);\n    }\n\n"
  },
  {
    "id": "apache_ignite-7869-Param-3",
    "old_comment_raw": "@param ver Version to use.",
    "new_code_raw": "    @Override protected void clearIndex(CacheObject val, GridCacheVersion ver) {\n        // No-op.\n    }\n"
  },
  {
    "id": "eclipse_elk-144-Associations-Param4",
    "old_comment_raw": "@param padding the padding to adjust.",
    "new_code_raw": "    public static Insets calculateRequiredNodeLabelSpace(final NodeAdapter<?> node,\n            final double labelSpacing, final Insets nodeLabelInsets,\n            final Map<LabelLocation, LabelGroup> labelGroupsBoundingBoxes, final Insets insets) {\n\n        // Check if there are any labels\n        if (!node.getLabels().iterator().hasNext()) {\n            return insets;\n        }\n        \n        // Retrieve the node's label placement policy\n        final Set<NodeLabelPlacement> nodeLabelPlacement = node.getProperty(CoreOptions.NODE_LABELS_PLACEMENT);\n        final LabelLocation nodeLabelLocation = LabelLocation.fromNodeLabelPlacement(nodeLabelPlacement);\n        \n        // Compute a bounding box for each location where labels should be placed.\n        // The size is calculated from the size of all labels stacked vertically at that location.\n        for (final LabelAdapter<?> label : node.getLabels()) {\n            LabelLocation labelPlacement =\n                    LabelLocation.fromNodeLabelPlacement(label.getProperty(CoreOptions.NODE_LABELS_PLACEMENT));\n            \n            // If no valid placement is set on the label, use the node's placement policy.\n            if (labelPlacement == LabelLocation.UNDEFINED) {\n                labelPlacement = nodeLabelLocation;\n            }\n            \n            // Save the location of this label in its id field for later use.\n            label.setVolatileId(labelPlacement.ordinal());\n            \n            // Create or retrieve the label group for the current label.\n            final Rectangle boundingBox = retrieveLabelGroupsBoundingBox(labelGroupsBoundingBoxes, labelPlacement);\n            boundingBox.width = Math.max(boundingBox.width, label.getSize().x);\n            boundingBox.height += label.getSize().y + labelSpacing;\n        }\n        \n        // We need to count different label placement boxes towards different kinds of insets, depending on whether\n        // or not H_PRIORITY is set on the node itself (see H_PRIORITY documentation)\n        boolean hPrio = nodeLabelPlacement.contains(NodeLabelPlacement.H_PRIORITY);\n        \n        // Calculate the node label space required inside the node (only label groups on the inside\n        // are relevant here).\n        for (final Entry<LabelLocation, LabelGroup> entry : labelGroupsBoundingBoxes.entrySet()) {\n            final Rectangle boundingBox = entry.getValue();\n            \n            // From each existing label group, remove the last superfluous label spacing\n            // (the mere existence of a label group implies that it contains at least one label)\n            boundingBox.height -= labelSpacing;\n            switch (entry.getKey()) {\n            case IN_T_L:\n                if (hPrio) {\n                    insets.left = Math.max(\n                            insets.left,\n                            boundingBox.width + labelSpacing + nodeLabelInsets.left);\n                } else {\n                    insets.top = Math.max(\n                            insets.top,\n                            boundingBox.height + labelSpacing + nodeLabelInsets.top);\n                }\n                break;\n                \n            case IN_T_C:\n                insets.top = Math.max(\n                        insets.top,\n                        boundingBox.height + labelSpacing + nodeLabelInsets.top);\n                break;\n                \n            case IN_T_R:\n                if (hPrio) {\n                    insets.right = Math.max(\n                            insets.right,\n                            boundingBox.width + labelSpacing + nodeLabelInsets.right);\n                } else {\n                    insets.top = Math.max(\n                            insets.top,\n                            boundingBox.height + labelSpacing + nodeLabelInsets.top);\n                }\n                break;\n                \n            case IN_C_L:\n                insets.left = Math.max(\n                        insets.left,\n                        boundingBox.width + labelSpacing + nodeLabelInsets.left);\n                break;\n                \n            case IN_C_R:\n                insets.right = Math.max(\n                        insets.right,\n                        boundingBox.width + labelSpacing + nodeLabelInsets.right);\n                break;\n                \n            case IN_B_L:\n                if (hPrio) {\n                    insets.left = Math.max(\n                            insets.left,\n                            boundingBox.width + labelSpacing + nodeLabelInsets.left);\n                } else {\n                    insets.bottom = Math.max(\n                            insets.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelInsets.bottom);\n                }\n                break;\n                \n            case IN_B_C:\n                insets.bottom = Math.max(\n                        insets.bottom,\n                        boundingBox.height + labelSpacing + nodeLabelInsets.bottom);\n                break;\n                \n            case IN_B_R:\n                if (hPrio) {\n                    insets.right = Math.max(\n                            insets.right,\n                            boundingBox.width + labelSpacing + nodeLabelInsets.right);\n                } else {\n                    insets.bottom = Math.max(\n                            insets.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelInsets.bottom);\n                }\n                break;\n                \n            default:\n                // In all other cases, no specific action is required\n            }\n        }\n\n        // Add node label insets that aren't set yet\n        // This happens if e.g. a top inset is set but no top label is present\n        insets.top    = Math.max(insets.top, nodeLabelInsets.top);\n        insets.left   = Math.max(insets.left, nodeLabelInsets.left);\n        insets.right  = Math.max(insets.right, nodeLabelInsets.right);\n        insets.bottom = Math.max(insets.bottom, nodeLabelInsets.bottom);\n\n        return insets;\n    }\n\n"
  },
  {
    "id": "apache_ignite-4949-Param-6",
    "old_comment_raw": "@param expVer Optional version to match.",
    "new_code_raw": "    @Override protected void clearIndex(CacheObject val) {\n        // No-op.\n    }\n"
  },
  {
    "id": "apache_ignite-3650-Param-0",
    "old_comment_raw": "@param m Cache query metrics.",
    "new_code_raw": "    public static VisorCacheQueryMetrics from(QueryMetrics m) {\n        VisorCacheQueryMetrics qm = new VisorCacheQueryMetrics();\n\n        qm.minTime = m.minimumTime();\n        qm.maxTime = m.maximumTime();\n        qm.avgTime = m.averageTime();\n        qm.execs = m.executions();\n        qm.fails = m.fails();\n\n        return qm;\n    }\n"
  },
  {
    "id": "JSQLParser_JSqlParser-31-Param-0",
    "old_comment_raw": "@param select",
    "new_code_raw": "\tpublic List<String> getTableList(Update update) {\n\t\tinit();\n\t\ttables.add(update.getTable().getName());\n\t\tif (update.getExpressions() != null) {\n\t\t\tfor (Expression expression : update.getExpressions()) {\n\t\t\t\texpression.accept(this);\n\t\t\t}\n\t\t}\n\t\tif (update.getWhere() != null) {\n\t\t\tupdate.getWhere().accept(this);\n\t\t}\n\n\t\treturn tables;\n\t}\n"
  },
  {
    "id": "apache_ignite-5314-Param-1",
    "old_comment_raw": "@param path Path to update.",
    "new_code_raw": "    public IgfsFileInfo updateDual(final IgfsSecondaryFileSystem fs, final IgfsPath path, final Map<String, String> props)\n        throws IgniteCheckedException {\n        assert fs != null;\n        assert path != null;\n        assert props != null && !props.isEmpty();\n\n        if (busyLock.enterBusy()) {\n            try {\n                SynchronizationTask<IgfsFileInfo> task = new SynchronizationTask<IgfsFileInfo>() {\n                    @Override public IgfsFileInfo onSuccess(Map<IgfsPath, IgfsFileInfo> infos)\n                        throws Exception {\n                        if (infos.get(path) == null)\n                            return null;\n\n                        fs.update(path, props);\n\n                        assert path.parent() == null || infos.get(path.parent()) != null;\n\n                        return updatePropertiesNonTx(infos.get(path.parent()).id(), infos.get(path).id(), path.name(),\n                            props);\n                    }\n\n                    @Override public IgfsFileInfo onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Path update in DUAL mode failed [path=\" + path + \", properties=\" + props + ']',\n                            err);\n\n                        throw new IgniteCheckedException(\"Failed to update the path due to secondary file system exception: \" +\n                            path, err);\n                    }\n                };\n\n                return synchronizeAndExecute(task, fs, false, path);\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to update in DUAL mode because Grid is stopping: \" + path);\n    }\n"
  },
  {
    "id": "GoogleCloudPlatform_java_docs_samples-0-Param-0",
    "old_comment_raw": "@param subscriptionId the user-specified identifier for the pubsub subscription",
    "new_code_raw": "  public static int pubSub(String subId, int timeout, String projectId) throws Exception {\n    Subscriber subscriber = null;\n    MessageReceiverExample receiver = new MessageReceiverExample();\n\n    try {\n      // subscribe to the requested pubsub channel\n      ProjectSubscriptionName subName = ProjectSubscriptionName.of(projectId, subId);\n      subscriber = Subscriber.newBuilder(subName, receiver).build();\n      subscriber.startAsync().awaitRunning();\n      // listen to messages for 'timeout' seconds\n      for (int i = 0; i < timeout; i++) {\n        sleep(1000);\n      }\n    } finally {\n      // stop listening to the channel\n      if (subscriber != null) {\n        subscriber.stopAsync();\n      }\n    }\n    //print and return the number of pubsub messages received\n    System.out.println(receiver.messageCount);\n    return receiver.messageCount;\n  }\n"
  },
  {
    "id": "apache_ignite-12146-Param-2",
    "old_comment_raw": "@param sample Sample size.",
    "new_code_raw": "    public static VisorCache from(Ignite ignite, String cacheName, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n\n        GridCacheAdapter ca = ((IgniteKernal)ignite).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && ca.context().affinityNode();\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(AffinityTopologyVersion.NONE)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = ignite.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<GridCacheEntryEx> set = ca.map().entries0();\n\n        long memSz = 0;\n\n        Iterator<GridCacheEntryEx> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name = cacheName;\n        cache.mode = mode;\n        cache.memorySize = memSz;\n        cache.size = size;\n        cache.nearSize = near;\n        cache.dhtSize = size - near;\n        cache.primarySize = ca.primarySize();\n        cache.offHeapAllocatedSize = ca.offHeapAllocatedSize();\n        cache.offHeapEntriesCnt = ca.offHeapEntriesCount();\n        cache.swapSize = swapSize;\n        cache.swapKeys = swapKeys;\n        cache.partitions = ca.affinity().partitions();\n        cache.primaryPartitions = pps;\n        cache.backupPartitions = bps;\n        cache.metrics = VisorCacheMetrics.from(ca);\n        cache.partitionsMap = partsMap;\n\n        return cache;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-767-Param-0",
    "old_comment_raw": "@param accountManager",
    "new_code_raw": "    public static Account getAccount(final AccountManager manager, final Activity activity) {\n        final boolean loggable = Log.isLoggable(TAG, DEBUG);\n        if (loggable)\n            Log.d(TAG, \"Getting account\");\n\n        if (activity == null)\n            throw new RuntimeException(\"Can't create new GitHub account - no activity available\");\n\n        Account[] accounts;\n        try {\n            while ((accounts = getAccounts(manager)).length == 0) {\n                if (loggable)\n                    Log.d(TAG, \"No GitHub accounts for activity=\" + activity);\n\n                Bundle result = manager.addAccount(GITHUB_ACCOUNT_TYPE, null, null, null, activity, null, null)\n                        .getResult();\n\n                if (loggable)\n                    Log.d(TAG, \"Added account \" + result.getString(KEY_ACCOUNT_NAME));\n            }\n        } catch (AuthenticatorException e) {\n            Log.d(TAG, \"Excepting retrieving account\", e);\n            throw new RuntimeException(e);\n        } catch (IOException e) {\n            Log.d(TAG, \"Excepting retrieving account\", e);\n            throw new RuntimeException(e);\n        } catch (OperationCanceledException e) {\n            Log.d(TAG, \"Excepting retrieving account\", e);\n            throw new RuntimeException(e);\n        }\n\n        if (loggable)\n            Log.d(TAG, \"Returning account \" + accounts[0].name);\n\n        return accounts[0];\n    }\n"
  },
  {
    "id": "apache_ignite-2219-Param-0",
    "old_comment_raw": "@param log Grid logger.",
    "new_code_raw": "    private IgniteConfiguration getConfiguration(IgniteLogger log) {\n        // We can't use U.getGridGainHome() here because\n        // it will initialize cached value which is forbidden to override.\n        String ggHome = GridSystemProperties.getString(GG_HOME);\n\n        assert ggHome != null;\n\n        U.setGridGainHome(null);\n\n        String ggHome0 = U.getGridGainHome();\n\n        assert ggHome0 == null;\n\n        GridTcpDiscoverySpi disc = new GridTcpDiscoverySpi();\n\n        disc.setIpFinder(IP_FINDER);\n\n        IgniteConfiguration cfg = new IgniteConfiguration();\n\n        cfg.setGridLogger(log);\n        cfg.setDiscoverySpi(disc);\n\n        return cfg;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-993-Param-0",
    "old_comment_raw": "@param item the item associated with the thermostat(s) against which to perform the function.",
    "new_code_raw": "    private static boolean callEcobeeInternal(String selection, AbstractFunction function) {\n        try {\n            logger.debug(\"Attempting to call Ecobee function '{}' against selection '{}'\", function, selection);\n\n            EcobeeActionProvider actionProvider = getActionProvider(selection);\n\n            return actionProvider.callEcobee(selection, function);\n        } catch (Exception ex) {\n            logger.error(ex.getMessage(), ex);\n            return false;\n        }\n    }\n"
  },
  {
    "id": "bytedeco_javacpp-116-Param-0",
    "old_comment_raw": "@param sourceFilename the C++ source filename",
    "new_code_raw": "    int compile(String[] sourceFilenames, String outputFilename, ClassProperties properties, File workingDirectory)\n            throws IOException, InterruptedException {\n        ArrayList<String> command = new ArrayList<String>();\n\n        includeJavaPaths(properties, header);\n\n        String platform  = Loader.getPlatform();\n        String compilerPath = properties.getProperty(\"platform.compiler\");\n        command.add(compilerPath);\n\n        {\n            String p = properties.getProperty(\"platform.sysroot.prefix\", \"\");\n            for (String s : properties.get(\"platform.sysroot\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.includepath.prefix\", \"\");\n            for (String s : properties.get(\"platform.includepath\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                }\n            }\n            for (String s : properties.get(\"platform.includeresource\")) {\n                for (File f : Loader.cacheResources(s)) {\n                    if (f.isDirectory()) {\n                        if (p.endsWith(\" \")) {\n                            command.add(p.trim()); command.add(f.getCanonicalPath());\n                        } else {\n                            command.add(p + f.getCanonicalPath());\n                        }\n                    }\n                }\n            }\n        }\n\n        for (String sourceFilename : sourceFilenames) {\n            command.add(sourceFilename);\n        }\n\n        List<String> allOptions = properties.get(\"platform.compiler.*\");\n        if (!allOptions.contains(\"!default\") && !allOptions.contains(\"default\")) {\n            allOptions.add(0, \"default\");\n        }\n        for (String s : allOptions) {\n            if (s == null || s.length() == 0) {\n                continue;\n            }\n            String p = \"platform.compiler.\" + s;\n            String options = properties.getProperty(p);\n            if (options != null && options.length() > 0) {\n                command.addAll(Arrays.asList(options.split(\" \")));\n            } else if (!\"!default\".equals(s) && !\"default\".equals(s)) {\n                logger.warn(\"Could not get the property named \\\"\" + p + \"\\\"\");\n            }\n        }\n\n        command.addAll(compilerOptions);\n\n        String output = properties.getProperty(\"platform.compiler.output\");\n        for (int i = 1; i < 2 || output != null; i++,\n                output = properties.getProperty(\"platform.compiler.output\" + i)) {\n            if (output != null && output.length() > 0) {\n                command.addAll(Arrays.asList(output.split(\" \")));\n            }\n\n            if (output == null || output.length() == 0 || output.endsWith(\" \")) {\n                command.add(outputFilename);\n            } else {\n                command.add(command.remove(command.size() - 1) + outputFilename);\n            }\n        }\n\n        {\n            String p  = properties.getProperty(\"platform.linkpath.prefix\", \"\");\n            String p2 = properties.getProperty(\"platform.linkpath.prefix2\");\n            for (String s : properties.get(\"platform.linkpath\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                    if (p2 != null) {\n                        if (p2.endsWith(\" \")) {\n                            command.add(p2.trim()); command.add(s);\n                        } else {\n                            command.add(p2 + s);\n                        }\n                    }\n                }\n            }\n            for (String s : properties.get(\"platform.linkresource\")) {\n                for (File f : Loader.cacheResources(s)) {\n                    if (f.isDirectory()) {\n                        if (p.endsWith(\" \")) {\n                            command.add(p.trim()); command.add(f.getCanonicalPath());\n                        } else {\n                            command.add(p + f.getCanonicalPath());\n                        }\n                        if (p2 != null) {\n                            if (p2.endsWith(\" \")) {\n                                command.add(p2.trim()); command.add(f.getCanonicalPath());\n                            } else {\n                                command.add(p2 + f.getCanonicalPath());\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.link.prefix\", \"\");\n            String x = properties.getProperty(\"platform.link.suffix\", \"\");\n            int i = command.size(); // to inverse order and satisfy typical compilers\n            for (String s : properties.get(\"platform.link\")) {\n                String[] libnameversion = s.split(\"#\")[0].split(\"@\");\n                if (libnameversion.length == 3 && libnameversion[1].length() == 0) {\n                    // Only use the version number when the user gave us a double @\n                    s = libnameversion[0] + libnameversion[2];\n                } else {\n                    s = libnameversion[0];\n                }\n                if (p.endsWith(\" \") && x.startsWith(\" \")) {\n                    command.add(i, p.trim()); command.add(i + 1, s); command.add(i + 2, x.trim());\n                } else if (p.endsWith(\" \")) {\n                    command.add(i, p.trim()); command.add(i + 1, s + x);\n                } else if (x.startsWith(\" \")) {\n                    command.add(i, p + s); command.add(i + 1, x.trim());\n                } else {\n                    command.add(i, p + s + x);\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.frameworkpath.prefix\", \"\");\n            for (String s : properties.get(\"platform.frameworkpath\")) {\n                if (new File(s).isDirectory()) {\n                    if (p.endsWith(\" \")) {\n                        command.add(p.trim()); command.add(s);\n                    } else {\n                        command.add(p + s);\n                    }\n                }\n            }\n        }\n\n        {\n            String p = properties.getProperty(\"platform.framework.prefix\", \"\");\n            String x = properties.getProperty(\"platform.framework.suffix\", \"\");\n            for (String s : properties.get(\"platform.framework\")) {\n                if (p.endsWith(\" \") && x.startsWith(\" \")) {\n                    command.add(p.trim()); command.add(s); command.add(x.trim());\n                } else if (p.endsWith(\" \")) {\n                    command.add(p.trim()); command.add(s + x);\n                } else if (x.startsWith(\" \")) {\n                    command.add(p + s); command.add(x.trim());\n                } else {\n                    command.add(p + s + x);\n                }\n            }\n        }\n\n        String text = \"\";\n        boolean windows = platform.startsWith(\"windows\");\n        for (String s : command) {\n            boolean hasSpaces = s.indexOf(\" \") > 0;\n            if (hasSpaces) {\n                text += windows ? \"\\\"\" : \"'\";\n            }\n            text += s;\n            if (hasSpaces) {\n                text += windows ? \"\\\"\" : \"'\";\n            }\n            text += \" \";\n        }\n        logger.info(text);\n\n        ProcessBuilder pb = new ProcessBuilder(command);\n        // Use the library output path as the working directory so that all\n        // build files, including intermediate ones from MSVC, are dumped there\n        pb.directory(workingDirectory);\n        if (environmentVariables != null) {\n            pb.environment().putAll(environmentVariables);\n        }\n        return pb.inheritIO().start().waitFor();\n    }\n"
  },
  {
    "id": "apache_ignite-11575-Param-0",
    "old_comment_raw": "@param userVersion Version to create.",
    "new_code_raw": "    private String makeUserVersion(String userVer) {\n        return \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?> \" +\n            \"<beans xmlns=\\\"http://www.springframework.org/schema/beans\\\" \" +\n            \"xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\" \" +\n            \"xmlns:util=\\\"http://www.springframework.org/schema/util\\\" \" +\n            \"xsi:schemaLocation=\\\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd \" +\n            \"http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd\\\"> \" +\n            \"<bean id=\\\"userVersion\\\" class=\\\"java.lang.String\\\"><constructor-arg value=\\\"\" + userVer + \"\\\"/></bean> \" +\n            \"</beans>\";\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-194-Param-3",
    "old_comment_raw": "@param single_node_mode whether or not the single node mode is enabled",
    "new_code_raw": "  private static long computeTrainSamplesPerIteration(final long train_samples_per_iteration, final long numRows, final boolean replicate_training_data, final boolean single_node_mode, final boolean quiet_mode) {\n    long tspi = train_samples_per_iteration;\n    assert(tspi == 0 || tspi == -1 || tspi >= 1);\n    if (tspi == 0 || (!replicate_training_data && tspi == -1) ) {\n      tspi = numRows;\n      if (!quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + train_samples_per_iteration + \") to one epoch: #rows (\" + tspi + \").\");\n    }\n    else if (tspi == -1) {\n      tspi = H2O.CLOUD.size() * numRows;\n      if (!quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + train_samples_per_iteration + \") to #nodes x #rows (\" + tspi + \").\");\n    }\n    assert(tspi != 0 && tspi != -1 && tspi >= 1);\n    return tspi;\n  }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-355-Param-0",
    "old_comment_raw": "@param matchedHashes A list which will contain the matched txn (will be cleared)",
    "new_code_raw": "    public Sha256Hash getTxnHashAndMerkleRoot(List<Sha256Hash> matchedHashes) throws VerificationException {\n        matchedHashes.clear();\n        \n        // An empty set will not work\n        if (transactionCount == 0)\n            throw new VerificationException(\"Got a CPartialMerkleTree with 0 transactions\");\n        // check for excessively high numbers of transactions\n        if (transactionCount > Block.MAX_BLOCK_SIZE / 60) // 60 is the lower bound for the size of a serialized CTransaction\n            throw new VerificationException(\"Got a CPartialMerkleTree with more transactions than is possible\");\n        // there can never be more hashes provided than one for every txid\n        if (hashes.size() > transactionCount)\n            throw new VerificationException(\"Got a CPartialMerkleTree with more hashes than transactions\");\n        // there must be at least one bit per node in the partial tree, and at least one node per hash\n        if (matchedChildBits.length*8 < hashes.size())\n            throw new VerificationException(\"Got a CPartialMerkleTree with fewer matched bits than hashes\");\n        // calculate height of tree\n        int height = 0;\n        while (getTreeWidth(height) > 1)\n            height++;\n        // traverse the partial tree\n        ValuesUsed used = new ValuesUsed();\n        Sha256Hash merkleRoot = recursiveExtractHashes(height, 0, used, matchedHashes);\n        // verify that all bits were consumed (except for the padding caused by serializing it as a byte sequence)\n        if ((used.bitsUsed+7)/8 != matchedChildBits.length ||\n                // verify that all hashes were consumed\n                used.hashesUsed != hashes.size())\n            throw new VerificationException(\"Got a CPartialMerkleTree that didn't need all the data it provided\");\n        \n        return merkleRoot;\n    }\n"
  },
  {
    "id": "zxing_zxing-503-Param-2",
    "old_comment_raw": "@param maxCount maximum reasonable number of modules that should be observed in any reading state, based on the results of the horizontal scan",
    "new_code_raw": "  private float crossCheckVertical(int startI, int centerJ, int maxCount, int originalStateCountTotal) {\n    MonochromeBitmapSource image = this.image;\n\n    int maxI = image.getHeight();\n    int[] stateCount = new int[5];\n\n    // Start counting up from center\n    int i = startI;\n    while (i >= 0 && image.isBlack(centerJ, i)) {\n      stateCount[2]++;\n      i--;\n    }\n    if (i < 0) {\n      return Float.NaN;\n    }\n    while (i >= 0 && !image.isBlack(centerJ, i) && stateCount[1] <= maxCount) {\n      stateCount[1]++;\n      i--;\n    }\n    // If already too many modules in this state or ran off the edge:\n    if (i < 0 || stateCount[1] > maxCount) {\n      return Float.NaN;\n    }\n    while (i >= 0 && image.isBlack(centerJ, i) && stateCount[0] <= maxCount) {\n      stateCount[0]++;\n      i--;\n    }\n    if (stateCount[0] > maxCount) {\n      return Float.NaN;\n    }\n\n    // Now also count down from center\n    i = startI + 1;\n    while (i < maxI && image.isBlack(centerJ, i)) {\n      stateCount[2]++;\n      i++;\n    }\n    if (i == maxI) {\n      return Float.NaN;\n    }\n    while (i < maxI && !image.isBlack(centerJ, i) && stateCount[3] < maxCount) {\n      stateCount[3]++;\n      i++;\n    }\n    if (i == maxI || stateCount[3] >= maxCount) {\n      return Float.NaN;\n    }\n    while (i < maxI && image.isBlack(centerJ, i) && stateCount[4] < maxCount) {\n      stateCount[4]++;\n      i++;\n    }\n    if (stateCount[4] >= maxCount) {\n      return Float.NaN;\n    }\n\n    // If we found a finder-pattern-like section, but its size is more than 20% different than\n    // the original, assume it's a false positive\n    int stateCountTotal = stateCount[0] + stateCount[1] + stateCount[2] + stateCount[3] + stateCount[4];\n    if (5 * Math.abs(stateCountTotal - originalStateCountTotal) >= originalStateCountTotal) {\n      return Float.NaN;\n    }\n\n    return foundPatternCross(stateCount) ? centerFromEnd(stateCount, i) : Float.NaN;\n  }\n"
  },
  {
    "id": "apache_ignite-12362-Param-0",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public GridCacheEntryEx entryEx(KeyCacheObject key, boolean touch) {\n        GridCacheEntryEx e = entry0(key, ctx.affinity().affinityTopologyVersion(), true, touch);\n\n        assert e != null;\n\n        return e;\n    }\n"
  },
  {
    "id": "apache_ignite-1884-Param-1",
    "old_comment_raw": "@param p Filter for IDs.",
    "new_code_raw": "    public Collection<ClusterNode> nodes(@Nullable Collection<UUID> ids, IgnitePredicate<UUID>... p) {\n        return F.isEmpty(ids) ? Collections.<ClusterNode>emptyList() :\n            F.view(\n                F.viewReadOnly(ids, U.id2Node(ctx), p),\n                F.notNull());\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-988-Param-1",
    "old_comment_raw": "@param timeout the timeout to set in milliseconds",
    "new_code_raw": "\tprotected String sendQuery(String query)\n\t\t\tthrows IhcExecption {\n\t\t\n\t\tconn.setReadTimeout(timeout);\n\n\t\ttry {\n\t\t\tOutputStreamWriter writer = new OutputStreamWriter(\n\t\t\t\t\tconn.getOutputStream(), \"UTF-8\");\n\n\t\t\tlogger.trace(\"Send query: {}\", query);\n\t\t\twriter.write(query);\n\t\t\twriter.flush();\n\t\t\twriter.close();\n\t\n\t\t\tInputStreamReader reader = new InputStreamReader(conn.getInputStream(),\n\t\t\t\t\t\"UTF-8\");\n\t\t\tString response = readInputStreamAsString(reader);\n\t\t\tlogger.trace(\"Receive response: {}\", response);\n\t\t\treturn response;\n\t\t\n\t\t} catch (UnsupportedEncodingException e) {\n\t\t\tthrow new IhcExecption(e);\n\t\t} catch (IOException e) {\n\t\t\tthrow new IhcExecption(e);\n\t\t}\n\t}\n"
  },
  {
    "id": "gephi_gephi-275-Param-0",
    "old_comment_raw": "@param node",
    "new_code_raw": "    private double q(int node, Community community) {\n\n        Integer edgesToInt = structure.nodeConnections[node].get(community);\n        double edgesTo = 0;\n        if (edgesToInt != null) {\n            edgesTo = edgesToInt.doubleValue();\n        }\n        double weightSum = community.weightSum;\n        double nodeWeight = structure.weights[node];\n        //double penalty = (nodeWeight * weightSum) / (2.0 * mStructure.graphWeightSum);\n        double qValue = edgesTo - (nodeWeight * weightSum) / (2.0 * structure.graphWeightSum);\n        if ((structure.nodeCommunities[node] == community) && (structure.nodeCommunities[node].size() > 1)) {\n            qValue = edgesTo - (nodeWeight * (weightSum - nodeWeight)) / (2.0 * structure.graphWeightSum);\n        }\n        return qValue;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-361-Param-2",
    "old_comment_raw": "@param adaptedValidation a test frame or null",
    "new_code_raw": "    public Score doIt(Model model, Frame fr, Frame adaptedValidation, Vec adaptedValidationResponse, int[][] modelTransf, String[] cmDomain, boolean oob, boolean build_tree_per_node) {\n      assert !oob || adaptedValidation==null : \"Validation frame cannot be specified if oob validation is demanded!\"; // oob => validation==null\n      assert _nclass == 1 || cmDomain != null ;\n\n      System.err.println(\"CM domain: \" + Arrays.toString(cmDomain));\n\n      _cmlen = _nclass > 1 ? cmDomain.length : 1;\n      _oob = oob;\n      // No validation frame is specified, so perform computation on training data\n      if( adaptedValidation == null ) return doAll(fr, build_tree_per_node);\n      _validation = true;\n      _cavr       = false;\n      // Validation: need to score the set, getting a probability distribution for each class\n      // Frame has nclass vectors (nclass, or 1 for regression), for classification it\n      Frame res = model.score(adaptedValidation, false); // For classification: predicted values (~ values in res[0]) are in interval 0..domain().length-1, for regression just single column.\n      Frame adapValidation = new Frame(adaptedValidation); // adapted validation dataset\n      // All columns including response of validation frame are already adapted to model\n      if (_nclass>1) { // Only for Classification\n        for( int i=0; i<_nclass; i++ ) // Distribution of response classes\n          adapValidation.add(\"ClassDist\"+i,res.vecs()[i+1]);\n        if (modelTransf!=null) {\n          Vec ar = res.vecs()[0].makeTransf(modelTransf); // perform transformation of model results to be consistent with expected confusion matrix domain\n          adapValidation.add(\"Prediction\", ar); // add as a prediction\n          adapValidation.add(\"ActualValidationResponse\", adaptedValidationResponse);\n          _cavr = true; // signal that we have two predictions vectors in the frame.\n          res.add(\"__dummyx__\", ar); // add the vector to clean up list\n        } else\n          adapValidation.add(\"Prediction\",res.vecs()[0]); // Predicted values\n      } else { // Regression\n        adapValidation.add(\"Prediction\",res.vecs()[0]);\n      }\n      // Compute a CM & MSE\n      try {\n        doAll(adapValidation, build_tree_per_node);\n      } finally {\n        // Perform clean-up: remove temporary result\n        res.delete();\n      }\n      return this;\n    }\n"
  },
  {
    "id": "todoroo_astrid-802-Param-0",
    "old_comment_raw": "@param idTask",
    "new_code_raw": "    public JSONArray tasksLabels(long idTask) throws ApiServiceException, IOException {\n        return getResponse(invokeGet(\"tasks/labels.json\",\n                \"token\", token,\n                \"id_task\", idTask), \"labels\");\n    }\n"
  },
  {
    "id": "mitreid_connect_OpenID_Connect_Java_Spring_Server-232-Param-2",
    "old_comment_raw": "@param requestObj",
    "new_code_raw": "\tprivate JsonObject toJsonFromRequestObj(UserInfo ui, Set<String> scope, JsonObject authorizedClaims, JsonObject requestedClaims) {\n\n\t\t// get the base object\n\t\tJsonObject obj = toJson(ui, scope);\n\n\t\tJsonObject userinfoAuthorized = authorizedClaims.getAsJsonObject().get(\"userinfo\").getAsJsonObject();\n\t\tJsonObject userinfoRequested = requestedClaims.getAsJsonObject().get(\"userinfo\").getAsJsonObject();\n\t\t\n\t\tif (userinfoAuthorized == null || !userinfoAuthorized.isJsonObject()) {\n\t\t\treturn obj;\n\t\t}\n\n\t\t\n\t\t// Filter claims from the request object with the claims from the claims request parameter, if it exists\n\t\t\n\t\t// Doing the set intersection manually because the claim entries may be referring to\n\t\t// the same claim but have different 'individual claim values', causing the Entry<> to be unequal, \n\t\t// which doesn't allow the use of the more compact Sets.intersection() type method.\n\t\tSet<Entry<String, JsonElement>> requestClaimsSet = Sets.newHashSet();\n\t\tif (requestedClaims != null) {\n\t\t\t\n\t\t\tfor (Entry<String, JsonElement> entry : userinfoAuthorized.getAsJsonObject().entrySet()) {\n\t\t\t\tif (userinfoRequested.has(entry.getKey())) {\n\t\t\t\t\trequestClaimsSet.add(entry);\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\n\t\t// TODO: this method is likely to be fragile if the data model changes at all\n\n\t\t//For each claim found, add it if not already present\n\t\tfor (Entry<String, JsonElement> i : requestClaimsSet) {\n\t\t\tString claimName = i.getKey();\n\t\t\tif (!obj.has(claimName)) {\n\t\t\t\tString value = \"\";\n\n\n\t\t\t\t//Process claim names to go from \"claim_name\" to \"ClaimName\"\n\t\t\t\tString camelClaimName = CaseFormat.LOWER_UNDERSCORE.to(CaseFormat.UPPER_CAMEL, claimName);\n\t\t\t\t//Now we have \"getClaimName\"\n\t\t\t\tString methodName = \"get\" + camelClaimName;\n\t\t\t\tMethod getter = null;\n\t\t\t\ttry {\n\t\t\t\t\tgetter = ui.getClass().getMethod(methodName);\n\t\t\t\t\tvalue = (String) getter.invoke(ui);\n\t\t\t\t\tobj.addProperty(claimName, value);\n\t\t\t\t} catch (SecurityException e) {\n\t\t\t\t\tlogger.error(\"SecurityException in UserInfoView.java: \", e);\n\t\t\t\t} catch (NoSuchMethodException e) {\n\t\t\t\t\tlogger.error(\"NoSuchMethodException in UserInfoView.java: \", e);\n\t\t\t\t} catch (IllegalArgumentException e) {\n\t\t\t\t\tlogger.error(\"IllegalArgumentException in UserInfoView.java: \", e);\n\t\t\t\t} catch (IllegalAccessException e) {\n\t\t\t\t\tlogger.error(\"IllegalAccessException in UserInfoView.java: \", e);\n\t\t\t\t} catch (InvocationTargetException e) {\n\t\t\t\t\tlogger.error(\"InvocationTargetException in UserInfoView.java: \", e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\n\t\treturn obj;\n\n\t}\n"
  },
  {
    "id": "apache_ignite-10110-Param-0",
    "old_comment_raw": "@param entry Entry.",
    "new_code_raw": "    private int extrasSize(CacheEntry entry) throws Exception {\n        Method mthd = GridCacheMapEntry.class.getDeclaredMethod(\"extrasSize\");\n\n        mthd.setAccessible(true);\n\n        GridCacheContext ctx = U.field(entry, \"ctx\");\n\n        GridCacheEntryEx entry0 = ((GridCacheEntryImpl)entry).entryEx(false, ctx.discovery().topologyVersion());\n\n        return (Integer)mthd.invoke(entry0);\n    }\n"
  },
  {
    "id": "eclipse_elk-140-Associations-Param0",
    "old_comment_raw": "@param nt1 a node type",
    "new_code_raw": "    public float getHorizontalSpacing(final NodeType t1, final NodeType t2) {\n        return nodeTypeSpacings[t1.ordinal()][t2.ordinal()];\n    }\n\n"
  },
  {
    "id": "todoroo_astrid-44-Param-2",
    "old_comment_raw": "@param item item model",
    "new_code_raw": "    public boolean saveExisting(TYPE item) {\n        ContentValues values = item.getSetValues();\n        if(values.size() == 0) // nothing changed\n            return true;\n        return database.getDatabase().update(table.name, values,\n                AbstractModel.ID_PROPERTY.eq(item.getId()).toString(), null) > 0;\n    }\n"
  },
  {
    "id": "apache_shiro-337-Param-0",
    "old_comment_raw": "@param methodInvocation the method invocation that the remote invocation should be based on.",
    "new_code_raw": "    public RemoteInvocation createRemoteInvocation(MethodInvocation mi) {\n\n        Serializable sessionId = null;\n        InetAddress inet = null;\n        boolean sessionManagerMethodInvocation = false;\n\n        //If the calling MI is for a remoting SessionManager proxy, we need to acquire the session ID from the method\n        //argument and NOT interact with SecurityUtils/subject.getSession to avoid a stack overflow\n        if (SessionManager.class.equals(mi.getMethod().getDeclaringClass())) {\n            sessionManagerMethodInvocation = true;\n            //for SessionManager calls, all method calls require the session id as the first argument, with\n            //the exception of 'start' that takes in an InetAddress.  So, ignore that one case:\n            Object firstArg = mi.getArguments()[0];\n            if (!(firstArg instanceof InetAddress)) {\n                sessionId = (Serializable) firstArg;\n            }\n        }\n\n        //tried the proxy.  If sessionId is still null, only then try the Subject:\n        if (sessionId == null && !sessionManagerMethodInvocation) {\n            Subject subject = SecurityUtils.getSubject();\n            Session session = subject.getSession(false);\n            if (session != null) {\n                inet = session.getHostAddress();                \n                sessionId = session.getId();\n            }\n        }\n\n        //No call to the sessionManager, and the Subject doesn't have a session.  Try a system property\n        //as a last result:\n        if (sessionId == null) {\n            if (log.isTraceEnabled()) {\n                log.trace(\"No Session found for the currently executing subject via subject.getSession(false).  \" +\n                    \"Attempting to revert back to the 'ki.session.id' system property...\");\n            }\n            sessionId = System.getProperty(SESSION_ID_SYSTEM_PROPERTY_NAME);\n            if (sessionId == null && log.isTraceEnabled()) {\n                log.trace(\"No 'ki.session.id' system property found.  Heuristics have been exhausted; \" +\n                    \"RemoteInvocation will not contain a sessionId.\");\n            }\n        }\n\n        if ( inet == null ) {\n            //try thread context:\n            inet = ThreadContext.getInetAddress();\n        }\n\n        RemoteInvocation ri = new RemoteInvocation(mi);\n        if (sessionId != null) {\n            ri.addAttribute(SESSION_ID_KEY, sessionId);\n        }\n        if ( inet != null ) {\n            ri.addAttribute(INET_ADDRESS_KEY, inet);\n        }\n\n        return ri;\n    }\n"
  },
  {
    "id": "haifengl_smile-233-Param-2",
    "old_comment_raw": "@param measures the performance measures of classification.",
    "new_code_raw": "    public double[][] test(DataFrame x, int[] y, ClassificationMeasure[] measures) {\n        int T = trees.length;\n        int m = measures.length;\n        double[][] results = new double[T][m];\n\n        int n = x.size();\n        int[] label = new int[n];\n\n        if (k == 2) {\n            double[] prediction = new double[n];\n            for (int i = 0; i < T; i++) {\n                for (int j = 0; j < n; j++) {\n                    prediction[j] += alpha[i] * trees[i].predict(x.get(j));\n                    label[j] = prediction[j] > 0 ? 1 : 0;\n                }\n\n                for (int j = 0; j < m; j++) {\n                    results[i][j] = measures[j].measure(y, label);\n                }\n            }\n        } else {\n            double[][] prediction = new double[n][k];\n            for (int i = 0; i < T; i++) {\n                for (int j = 0; j < n; j++) {\n                    prediction[j][trees[i].predict(x.get(j))] += alpha[i];\n                    label[j] = MathEx.whichMax(prediction[j]);\n                }\n\n                for (int j = 0; j < m; j++) {\n                    results[i][j] = measures[j].measure(y, label);\n                }\n            }\n\n        }\n        \n        return results;\n    }\n"
  },
  {
    "id": "bitcoin_wallet_bitcoin_wallet-65-Param-0",
    "old_comment_raw": "@param plainText The text to encrypt",
    "new_code_raw": "\tpublic static String encrypt(@Nonnull final byte[] plainTextAsBytes, @Nonnull final char[] password) throws IOException\n\t{\n\t\tfinal byte[] encryptedBytes = encryptRaw(plainTextAsBytes, password);\n\n\t\t// OpenSSL prefixes the salt bytes + encryptedBytes with Salted___ and then base64 encodes it\n\t\tfinal byte[] encryptedBytesPlusSaltedText = concat(OPENSSL_SALTED_BYTES, encryptedBytes);\n\n\t\treturn BASE64.encode(encryptedBytesPlusSaltedText);\n\t}\n"
  },
  {
    "id": "apache_ignite-2873-Param-0",
    "old_comment_raw": "@param tx Cache transaction.",
    "new_code_raw": "    public boolean putAllToStore(@Nullable IgniteTx tx, Map<K, IgniteBiTuple<V, GridCacheVersion>> map)\n        throws IgniteCheckedException {\n        if (F.isEmpty(map))\n            return true;\n\n        if (map.size() == 1) {\n            Map.Entry<K, IgniteBiTuple<V, GridCacheVersion>> e = map.entrySet().iterator().next();\n\n            return putToStore(tx, e.getKey(), e.getValue().get1(), e.getValue().get2());\n        }\n        else {\n            if (store != null) {\n                Map<K, IgniteBiTuple<V, GridCacheVersion>> map0;\n\n                if (convertPortable) {\n                    map0 = U.newHashMap(map.size());\n\n                    for (Map.Entry<K, IgniteBiTuple<V, GridCacheVersion>> e : map.entrySet()) {\n                        IgniteBiTuple<V, GridCacheVersion> t = e.getValue();\n\n                        map0.put((K)cctx.unwrapPortableIfNeeded(e.getKey(), false),\n                            F.t((V)cctx.unwrapPortableIfNeeded(t.get1(), false), t.get2()));\n                    }\n                }\n                else\n                    map0 = map;\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Storing values in cache store [map=\" + map0 + ']');\n\n                try {\n                    store.putAll(tx, locStore ? map0 : F.viewReadOnly(map0,\n                        new C1<IgniteBiTuple<V, GridCacheVersion>, Object>() {\n                            @Override public Object apply(IgniteBiTuple<V, GridCacheVersion> t) {\n                                return t.get1();\n                            }\n                    }));\n                }\n                catch (ClassCastException e) {\n                    handleClassCastException(e);\n                }\n\n                if (log.isDebugEnabled())\n                    log.debug(\"Stored value in cache store [map=\" + map0 + ']');\n\n                return true;\n            }\n\n            return false;\n        }\n    }\n"
  },
  {
    "id": "apache_shiro-316-Param-0",
    "old_comment_raw": "@param principal the primary identifying principal of the Account that should be retrieved.",
    "new_code_raw": "    protected Account getAccount(PrincipalCollection principals) {\n\n        if (principals == null) {\n            return null;\n        }\n\n        Account account = null;\n\n        if (log.isTraceEnabled()) {\n            log.trace(\"Retrieving Account for principals [\" + principals + \"]\");\n        }\n\n        Cache accountCache = getAccountCache();\n        if (accountCache != null) {\n            if (log.isTraceEnabled()) {\n                log.trace(\"Attempting to retrieve the Account from cache.\");\n            }\n            account = (Account) accountCache.get(principals);\n            if (log.isTraceEnabled()) {\n                if (account == null) {\n                    log.trace(\"No Account found in cache for principals [\" + principals + \"]\");\n                } else {\n                    log.trace(\"Account found in cache for principals [\" + principals + \"]\");\n                }\n            }\n        }\n\n\n        if (account == null) {\n            // Call template method if tbe Account was not found in a cache\n            account = doGetAccount(principals);\n            // If the account is not null and the cache has been created, then cache the account.\n            if (account != null && accountCache != null) {\n                if (log.isTraceEnabled()) {\n                    log.trace(\"Caching Account [\" + principals + \"].\");\n                }\n                accountCache.put(principals, account);\n            }\n        }\n\n        return account;\n    }\n"
  },
  {
    "id": "apache_ignite-1760-Param-1",
    "old_comment_raw": "@param metrics Metrics.",
    "new_code_raw": "    private static byte[] serializeMetrics(UUID nodeId, ClusterNodeMetrics metrics) {\n        assert nodeId != null;\n        assert metrics != null;\n\n        byte[] buf = new byte[16 + GridDiscoveryMetricsHelper.METRICS_SIZE];\n\n        U.longToBytes(nodeId.getMostSignificantBits(), buf, 0);\n        U.longToBytes(nodeId.getLeastSignificantBits(), buf, 8);\n\n        serialize(buf, 16, metrics);\n\n        return buf;\n    }\n"
  },
  {
    "id": "apache_ignite-12023-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite ignite, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = ignite.streamer(\"popular-numbers\");\n\n                try {\n                    // Send reduce query to all 'popular-numbers' streamers\n                    // running on local and remote nodes.\n                    Collection<StreamerIndexEntry<Integer, Integer, Long>> col = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext,\n                                                                            Collection<StreamerIndexEntry<Integer, Integer, Long>>>() {\n                            @Override public Collection<StreamerIndexEntry<Integer, Integer, Long>> apply(\n                                StreamerContext ctx) {\n                                StreamerIndex<Integer, Integer, Long> view = ctx.<Integer>window().index();\n\n                                return view.entries(-1 * POPULAR_NUMBERS_CNT);\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new PopularNumbersReducer());\n\n                    for (StreamerIndexEntry<Integer, Integer, Long> cntr : col)\n                        System.out.printf(\"%3d=%d\\n\", cntr.key(), cntr.value());\n\n                    System.out.println(\"----------------\");\n                }\n                catch (IgniteCheckedException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 3000, 3000);\n\n        return task;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-30-Param-0",
    "old_comment_raw": "@param chol",
    "new_code_raw": "  public Cholesky cholesky(Cholesky chol, int parallelize) {\n    long start = System.currentTimeMillis();\n    if( chol == null ) {\n      double[][] xx = _xx.clone();\n      for( int i = 0; i < xx.length; ++i )\n        xx[i] = xx[i].clone();\n      chol = new Cholesky(xx, _diag.clone());\n    }\n    final Cholesky fchol = chol;\n    final int sparseN = _diag.length;\n    final int denseN = _fullN - sparseN;\n    boolean spd=true;\n    // compute the cholesky of the diagonal and diagonal*dense parts\n    if( _diag != null ) for( int i = 0; i < sparseN; ++i ) {\n      double d = 1.0 / (chol._diag[i] = Math.sqrt(_diag[i]));\n      for( int j = 0; j < denseN; ++j )\n        chol._xx[j][i] = d*_xx[j][i];\n    }\n    Futures fs = new Futures();\n    // compute the outer product of diagonal*dense\n    final int chk = Math.max(denseN/10, 1); \n    Log.info(\"SPARSEN = \" + sparseN + \"    DENSEN = \" + denseN);\n\n    for( int i = 0; i < denseN; ++i ) {\n      final int fi = i;\n      fs.add(new RecursiveAction() {\n          @Override protected void compute() {\n            for( int j = 0; j <= fi; ++j ) {\n              double s = 0;\n              for( int k = 0; k < sparseN; ++k )\n                s += fchol._xx[fi][k] * fchol._xx[j][k];\n                 fchol._xx[fi][j + sparseN] = _xx[fi][j + sparseN] - s;\n            }\n          }\n        }.fork());\n    }\n    fs.blockForPending();\n    // compute the cholesky of dense*dense-outer_product(diagonal*dense)\n    // TODO we still use Jama, which requires (among other things) copy and expansion of the matrix. Do it here without copy and faster.\n    double[][] arr = new double[denseN][];\n    for( int i = 0; i < arr.length; ++i )\n      arr[i] = Arrays.copyOfRange(fchol._xx[i], sparseN, sparseN + denseN);\n\n    Log.info (\"CHOLESKY PRECOMPUTE TIME \" + (System.currentTimeMillis()-start));\n    start = System.currentTimeMillis();\n    // parallelize cholesky\n    if (parallelize == 1) {\n      int p = Runtime.getRuntime().availableProcessors();\n      InPlaceCholesky d = InPlaceCholesky.decompose_2(arr, 10, p);\n      fchol.setSPD(d.isSPD());\n      arr = d.getL();\n      Log.info (\"H2O CHOLESKY DECOMPOSE ON DENSEN*DENSEN TAKES: \" + (System.currentTimeMillis()-start));\n    } else {\n      // make it symmetric\n      for( int i = 0; i < arr.length; ++i )\n        for( int j = 0; j < i; ++j )\n          arr[j][i] = arr[i][j];\n      CholeskyDecomposition c = new Matrix(arr).chol();\n      fchol.setSPD(c.isSPD());\n      arr = c.getL().getArray();\n      Log.info (\"JAMA CHOLESKY DECOMPOSE TAKES: \" + (System.currentTimeMillis()-start));\n    }\n    for( int i = 0; i < arr.length; ++i )\n      System.arraycopy(arr[i], 0, fchol._xx[i], sparseN, i + 1);\n    return chol;\n  }\n"
  },
  {
    "id": "Ramblurr_Anki-Android-27-Associations-Param0",
    "old_comment_raw": "@param utcOffset The UTC offset in seconds.",
    "new_code_raw": "    public static Date genToday(long utcOffset) {\n        // The result is not adjusted for timezone anymore, following libanki model\n        // Timezone adjustment happens explicitly in Deck.updateCutoff(), but not in Deck.checkDailyStats()\n\n        Date today = new Date(System.currentTimeMillis() - (long) utcOffset * 1000l);\n        return today;\n    }\n\n"
  },
  {
    "id": "keycloak_keycloak-1296-Param-2",
    "old_comment_raw": "@param intervalMillis",
    "new_code_raw": "    public static int execute(Runnable runnable, int attemptsCount, long intervalMillis) {\n        int executionIndex = 0;\n        while (true) {\n            try {\n                runnable.run();\n                return executionIndex;\n            } catch (RuntimeException | AssertionError e) {\n                attemptsCount--;\n                executionIndex++;\n                if (attemptsCount > 0) {\n                    try {\n                        Thread.sleep(intervalMillis);\n                    } catch (InterruptedException ie) {\n                        ie.addSuppressed(e);\n                        throw new RuntimeException(ie);\n                    }\n                } else {\n                    throw e;\n                }\n            }\n        }\n    }\n"
  },
  {
    "id": "CalebFenton_simplify-16-Param-0",
    "old_comment_raw": "@param methodDescriptor",
    "new_code_raw": "    public BuilderMethod getMethod(String methodSignature) {\n        dexifyClassIfNecessary(methodSignature);\n\n        return methodSignatureToMethod.get(methodSignature);\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-133-Param-0",
    "old_comment_raw": "@param resKey",
    "new_code_raw": "  public static Frame rebalanceDataset(final Key resKey, final Frame f, final int nchunks){\n    H2O.H2OCountedCompleter cmp = new H2O.H2OEmptyCompleter();\n    rebalanceDataset(cmp,resKey,f,nchunks);\n    cmp.join();\n    return UKV.get(resKey);\n  }\n"
  },
  {
    "id": "zxing_zxing-680-Param-0",
    "old_comment_raw": "@param string the input string",
    "new_code_raw": "  private static String convertToQuotedString(String s) {\n    if (s == null || s.isEmpty()) {\n      return null;\n    }\n    // If already quoted, return as-is\n    if (s.charAt(0) == '\"' && s.charAt(s.length() - 1) == '\"') {\n      return s;\n    }\n    return '\\\"' + s + '\\\"';\n  }\n"
  },
  {
    "id": "apache_shiro-350-Param-0",
    "old_comment_raw": "@param subjectContext the contextual data, usually provided by a  Subject.Builder implementation, that is being used to construct a  Subject instance.",
    "new_code_raw": "    public PrincipalCollection getRememberedPrincipals(SubjectContext subjectContext) {\n        PrincipalCollection principals = null;\n        try {\n            byte[] bytes = getRememberedSerializedIdentity(subjectContext);\n            //SHIRO-138 - only call convertBytesToPrincipals if bytes exist:\n            if (bytes != null && bytes.length > 0) {\n                principals = convertBytesToPrincipals(bytes, subjectContext);\n            }\n        } catch (RuntimeException re) {\n            principals = onRememberedPrincipalFailure(re, subjectContext);\n        }\n\n        return principals;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-748-Param-0",
    "old_comment_raw": "@param repository",
    "new_code_raw": "    public static Intent createIntent(IssueFilter filter) {\n        return new Builder(\"repo.issues.VIEW\").repo(filter.getRepository()).add(EXTRA_ISSUE_FILTER, filter).toIntent();\n    }\n"
  },
  {
    "id": "apache_ignite-2325-Param-0",
    "old_comment_raw": "@param status File status.",
    "new_code_raw": "    @Override public boolean exists(IgniteFsPath path) throws GridException {\n        try {\n            return fileSys.exists(convert(path));\n        }\n        catch (IOException e) {\n            throw handleSecondaryFsError(e, \"Failed to check file existence [path=\" + path + \"]\");\n        }\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-342-Param-0",
    "old_comment_raw": "@param repository",
    "new_code_raw": "        public Builder repo(Repository repository) {\n            return add(EXTRA_REPOSITORY, repository);\n        }\n"
  },
  {
    "id": "hibernate_hibernate-orm-200-Associations-Param0",
    "old_comment_raw": "@param idx",
    "new_code_raw": "\tpublic E get(int index) {\n\t\treturn executables.get( index );\n\t}\n\n"
  },
  {
    "id": "apache_ignite-10123-Param-2",
    "old_comment_raw": "@param timeout Timeout.",
    "new_code_raw": "    private boolean waitCacheSize(IgniteCache<Integer, String> cache, int expSize, long timeout)\n        throws InterruptedException {\n        assert cache != null;\n        assert expSize > 0;\n        assert timeout >= 0;\n\n        long end = System.currentTimeMillis() + timeout;\n\n        while (cache.localSize() < expSize) {\n            Thread.sleep(50);\n\n            if (end - System.currentTimeMillis() <= 0)\n                break;\n        }\n\n        return cache.localSize() >= expSize;\n    }\n"
  },
  {
    "id": "cglib_cglib-0-Associations-Param1",
    "old_comment_raw": "@param interceptor interceptor used to handle implemented methods",
    "new_code_raw": "    public static Factory enhance(Class cls, MethodInterceptor ih) {\n        return (Factory)enhanceHelper(cls.isInterface() ? null : cls,\n                                      cls.isInterface() ? new Class[]{ cls } : null,\n                                      ih, cls.getClassLoader(), null, null );\n    }\n\n"
  },
  {
    "id": "keycloak_keycloak-352-Param-0",
    "old_comment_raw": "@param local",
    "new_code_raw": "    public boolean isValid(RealmModel realm, UserModel local) {\n        return properties.containsKey(local.getUsername());\n    }\n"
  },
  {
    "id": "google_protobuf-dt-1-Associations-Param0",
    "old_comment_raw": "@param resource the given resource.",
    "new_code_raw": "  public IProject project(URI resourceUri) {\n    return file(resourceUri).getProject();\n  }\n\n"
  },
  {
    "id": "apache_shiro-711-Param-0",
    "old_comment_raw": "@param token the authentication token reprenting the subject (user)'s authentication attempt.",
    "new_code_raw": "    protected AuthenticationEvent createSuccessEvent( AuthenticationToken token, Account account ) {\n        AuthenticationEventFactory factory = getAuthenticationEventFactory();\n        return factory.createSuccessEvent( token, account );\n    }\n"
  },
  {
    "id": "apache_ignite-12063-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    public VisorGridConfiguration from(IgniteEx ignite) {\n        assert ignite != null;\n\n        IgniteConfiguration c = ignite.configuration();\n\n        basic(VisorBasicConfiguration.from(ignite, c));\n        metrics(VisorMetricsConfiguration.from(c));\n        spis(VisorSpisConfiguration.from(c));\n        p2p(VisorPeerToPeerConfiguration.from(c));\n        email(VisorEmailConfiguration.from(c));\n        lifecycle(VisorLifecycleConfiguration.from(c));\n        executeService(VisorExecutorServiceConfiguration.from(c));\n        segmentation(VisorSegmentationConfiguration.from(c));\n        includeProperties(compactArray(c.getIncludeProperties()));\n        includeEventTypes(c.getIncludeEventTypes());\n        rest(VisorRestConfiguration.from(c));\n        userAttributes(c.getUserAttributes());\n        caches(VisorCacheConfiguration.list(c.getCacheConfiguration()));\n        ggfss(VisorGgfsConfiguration.list(c.getGgfsConfiguration()));\n        streamers(VisorStreamerConfiguration.list(c.getStreamerConfiguration()));\n        env(new HashMap<>(getenv()));\n        systemProperties(getProperties());\n\n        return this;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-805-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "  public String ltrim(final String key, final long start, final long stop) {\n    checkIsInMultiOrPipeline();\n    client.ltrim(key, start, stop);\n    return client.getStatusCodeReply();\n  }\n"
  },
  {
    "id": "apache_shiro-767-Param-0",
    "old_comment_raw": "@param m",
    "new_code_raw": "    public static boolean isEmpty(PrincipalCollection principals) {\n        return principals == null || principals.isEmpty();\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-531-Param-1",
    "old_comment_raw": "@param pageIndex",
    "new_code_raw": "    public PageHandler getPage(String hql, Map<String, Object> parameters, Integer pageIndex, Integer pageSize) {\n        return dao.getPage(hql, parameters, pageIndex, pageSize);\n    }\n"
  },
  {
    "id": "google_openrtb-doubleclick-1-Associations-Param0",
    "old_comment_raw": "@param ciphertext binary ciphertext",
    "new_code_raw": "  public byte[] decrypt(byte[] cipherData) {\n    if (cipherData.length < OVERHEAD_SIZE) {\n      throw new DoubleClickCryptoException(\"Invalid cipherData, \" + cipherData.length + \" bytes\");\n    }\n\n    // workBytes := initVector || E(payload) || I(signature)\n    byte[] workBytes = cipherData.clone();\n    ByteBuffer workBuffer = ByteBuffer.wrap(workBytes);\n\n    try {\n      // workBytes := initVector || payload || I(signature)\n      xorPayloadToHmacPad(workBytes);\n      // workBytes := initVector || payload || I'(signature)\n      int confirmationSignature = hmacSignature(workBytes);\n      int integritySignature = workBuffer.getInt(workBytes.length - SIGNATURE_SIZE);\n      workBuffer.putInt(workBytes.length - SIGNATURE_SIZE, confirmationSignature);\n\n      if (confirmationSignature != integritySignature) {\n        throw new DoubleClickCryptoException(\"Signature mismatch: \"\n            + Integer.toHexString(confirmationSignature)\n            + \" vs \" + Integer.toHexString(integritySignature));\n      }\n\n      if (logger.isDebugEnabled()) {\n        logger.debug(dump(\"Decrypted\", cipherData, workBytes));\n      }\n\n      return workBytes;\n    } catch (InvalidKeyException | NoSuchAlgorithmException | ShortBufferException e) {\n      if (logger.isWarnEnabled()) {\n        logger.warn(dump(\"Decrypted (failed)\", cipherData, workBytes));\n      }\n      throw new DoubleClickCryptoException(e);\n    }\n  }\n\n"
  },
  {
    "id": "apache_ignite-2223-Param-0",
    "old_comment_raw": "@param log Logger.",
    "new_code_raw": "    public GridNodeCallable setLogger(IgniteLogger log) {\n        this.log = log;\n\n        return this;\n    }\n"
  },
  {
    "id": "mitreid_connect_OpenID_Connect_Java_Spring_Server-232-Param-3",
    "old_comment_raw": "@param claimsRequest the claims request parameter object.",
    "new_code_raw": "\tprivate JsonObject toJsonFromRequestObj(UserInfo ui, Set<String> scope, JsonObject authorizedClaims, JsonObject requestedClaims) {\n\n\t\t// get the base object\n\t\tJsonObject obj = toJson(ui, scope);\n\n\t\tJsonObject userinfoAuthorized = authorizedClaims.getAsJsonObject().get(\"userinfo\").getAsJsonObject();\n\t\tJsonObject userinfoRequested = requestedClaims.getAsJsonObject().get(\"userinfo\").getAsJsonObject();\n\t\t\n\t\tif (userinfoAuthorized == null || !userinfoAuthorized.isJsonObject()) {\n\t\t\treturn obj;\n\t\t}\n\n\t\t\n\t\t// Filter claims from the request object with the claims from the claims request parameter, if it exists\n\t\t\n\t\t// Doing the set intersection manually because the claim entries may be referring to\n\t\t// the same claim but have different 'individual claim values', causing the Entry<> to be unequal, \n\t\t// which doesn't allow the use of the more compact Sets.intersection() type method.\n\t\tSet<Entry<String, JsonElement>> requestClaimsSet = Sets.newHashSet();\n\t\tif (requestedClaims != null) {\n\t\t\t\n\t\t\tfor (Entry<String, JsonElement> entry : userinfoAuthorized.getAsJsonObject().entrySet()) {\n\t\t\t\tif (userinfoRequested.has(entry.getKey())) {\n\t\t\t\t\trequestClaimsSet.add(entry);\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\n\t\t// TODO: this method is likely to be fragile if the data model changes at all\n\n\t\t//For each claim found, add it if not already present\n\t\tfor (Entry<String, JsonElement> i : requestClaimsSet) {\n\t\t\tString claimName = i.getKey();\n\t\t\tif (!obj.has(claimName)) {\n\t\t\t\tString value = \"\";\n\n\n\t\t\t\t//Process claim names to go from \"claim_name\" to \"ClaimName\"\n\t\t\t\tString camelClaimName = CaseFormat.LOWER_UNDERSCORE.to(CaseFormat.UPPER_CAMEL, claimName);\n\t\t\t\t//Now we have \"getClaimName\"\n\t\t\t\tString methodName = \"get\" + camelClaimName;\n\t\t\t\tMethod getter = null;\n\t\t\t\ttry {\n\t\t\t\t\tgetter = ui.getClass().getMethod(methodName);\n\t\t\t\t\tvalue = (String) getter.invoke(ui);\n\t\t\t\t\tobj.addProperty(claimName, value);\n\t\t\t\t} catch (SecurityException e) {\n\t\t\t\t\tlogger.error(\"SecurityException in UserInfoView.java: \", e);\n\t\t\t\t} catch (NoSuchMethodException e) {\n\t\t\t\t\tlogger.error(\"NoSuchMethodException in UserInfoView.java: \", e);\n\t\t\t\t} catch (IllegalArgumentException e) {\n\t\t\t\t\tlogger.error(\"IllegalArgumentException in UserInfoView.java: \", e);\n\t\t\t\t} catch (IllegalAccessException e) {\n\t\t\t\t\tlogger.error(\"IllegalAccessException in UserInfoView.java: \", e);\n\t\t\t\t} catch (InvocationTargetException e) {\n\t\t\t\t\tlogger.error(\"InvocationTargetException in UserInfoView.java: \", e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\n\t\treturn obj;\n\n\t}\n"
  },
  {
    "id": "apache_ignite-2044-Param-0",
    "old_comment_raw": "@param ids Event ids.",
    "new_code_raw": "    public static IgnitePredicate<GridEvent> eventId(@Nullable final IgniteUuid... ids) {\n        return isEmpty(ids) ? F.<GridEvent>alwaysFalse() :\n            new IgnitePredicate<GridEvent>() {\n                // Don't set peer deploy aware as UUID is loaded by\n                // system class loader.\n\n                @Override public boolean apply(GridEvent e) {\n                    assert e != null;\n\n                    return F.isAll(e.id(), in(ids));\n                }\n            };\n    }\n"
  },
  {
    "id": "apache_ignite-13318-Param-0",
    "old_comment_raw": "@param ignoreMergeMore Ignore the attempt to merge more pages up.",
    "new_code_raw": "        boolean finishTail(boolean skipMergeMore) throws IgniteCheckedException {\n            assert !isFinished();\n            assert needMerge != FALSE || needReplaceInner != FALSE;\n            assert tail != null;\n\n            if (needReplaceInner == READY) {\n                assert getTail(0, false) != null: \"we must keep lock on the leaf page\";\n\n                // We increment remove ID in write lock on leaf page, thus it is guaranteed that\n                // any successor will get greater value than he had read at the beginning of the operation.\n                // Thus it will be guaranteed to do a retry from root.\n                globalRmvId.incrementAndGet();\n\n                // Need to replace inner key with new max key for the left subtree.\n                doReplaceInner();\n\n                needReplaceInner = DONE;\n            }\n            else if (needMerge == READY) {\n                assert tail.down != null || tail.fwd.down != null;\n\n                boolean needMergeMore = merge(tail.lvl - 1, true, true);\n\n                if (needMergeMore && !skipMergeMore) {\n                    needMerge = TRUE;\n\n                    return false;\n                }\n\n                needMerge = DONE;\n            }\n            else\n                return false;\n\n            releaseTail();\n            finish();\n\n            return true;\n        }\n"
  },
  {
    "id": "mitreid_connect_OpenID_Connect_Java_Spring_Server-136-Param-2",
    "old_comment_raw": "@param userInfo",
    "new_code_raw": "\tprotected Authentication createAuthenticationToken(PendingOIDCAuthenticationToken token, Collection<? extends GrantedAuthority> authorities, UserInfo userInfo) {\n\t\treturn new OIDCAuthenticationToken(token.getSub(),\n\t\t\t\ttoken.getIssuer(),\n\t\t\t\tuserInfo, authorities,\n\t\t\t\ttoken.getIdToken(), token.getAccessTokenValue(), token.getRefreshTokenValue());\n\t}\n"
  },
  {
    "id": "pockethub_PocketHub-785-Param-0",
    "old_comment_raw": "@param gists",
    "new_code_raw": "    public static Intent createIntent(List<Item> items, int position) {\n        String[] ids = new String[items.size()];\n        int index = 0;\n        for (Item item : items) {\n            Gist gist = ((GistItem) item).getData();\n            ids[index++] = gist.id();\n        }\n        return new Builder(\"gists.VIEW\")\n            .add(EXTRA_GIST_IDS, (Serializable) ids)\n            .add(EXTRA_POSITION, position).toIntent();\n    }\n"
  },
  {
    "id": "keyboardsurfer_Crouton-19-Param-0",
    "old_comment_raw": "@param activity The  Activity that the  Crouton should be attached to.",
    "new_code_raw": "\tpublic static Crouton makeText(Activity activity, int textResourceId, Style style) {\n\t\treturn makeText(activity, activity.getString(textResourceId), style);\n\t}\n"
  },
  {
    "id": "nickman_UnsafeAdapter-12-Associations-Param0",
    "old_comment_raw": "@param address the memory address of the AllocationPointerOperations",
    "new_code_raw": "\tpublic static final String dump(final long address[]) {\n\t\tif(address==null || address.length==0) throw new IllegalArgumentException(\"Address array was null or zero length\");\n\t\tfinal byte dim = getDimension(address[0]);\t\t\n\t\tStringBuilder b = new StringBuilder(print(address));\n//\t\tb.append(\"\\n\\tAddresses: [\");\n//\t\tfinal int size = getSize(address);\n//\t\tif(size>0) {\n//\t\t\tfor(int i = 0; i < size; i++) {\n//\t\t\t\tb.append(getAddress(address, i)).append(\", \");\n//\t\t\t}\t\t\t\n//\t\t\tb.deleteCharAt(b.length()-1);\n//\t\t\tb.deleteCharAt(b.length()-1);\n//\t\t}\n//\t\treturn b.append(\"]\").toString();\n\t\treturn b.toString();\n\t}\n\n"
  },
  {
    "id": "keycloak_keycloak-1194-Param-0",
    "old_comment_raw": "@param realm",
    "new_code_raw": "    public AuthenticationSessionModel getCurrentAuthenticationSession(RealmModel realm, ClientModel client, String tabId) {\n        String authSessionId = getAuthSessionCookieDecoded(realm);\n\n        if (authSessionId == null) {\n            return null;\n        }\n\n        return getAuthenticationSessionByIdAndClient(realm, authSessionId, client, tabId);\n    }\n"
  },
  {
    "id": "jprante_elasticsearch_jdbc-70-Param-0",
    "old_comment_raw": "@param result the result set",
    "new_code_raw": "    public boolean nextRow(ResultSet results, KeyValueStreamListener listener)\n            throws SQLException, IOException, ParseException {\n        if (results.next()) {\n            processRow(results, listener);\n            return true;\n        }\n        return false;\n    }\n"
  },
  {
    "id": "haifengl_smile-114-Param-5",
    "old_comment_raw": "@param maxIter the maximum number of allowed iterations.",
    "new_code_raw": "    public static double solve(Matrix A, Preconditioner Ap, double[] b, double[] x, double tol, int itol, int maxIter) {\n        if (tol <= 0.0) {\n            throw new IllegalArgumentException(\"Invalid tolerance: \" + tol);\n        }\n\n        if (maxIter <= 0) {\n            throw new IllegalArgumentException(\"Invalid maximum number of iterations: \" + maxIter);\n        }\n\n        if (itol < 1 || itol > 4) {\n            throw new IllegalArgumentException(String.format(\"Illegal itol: %d\", itol));\n        }\n\n        double err = 0.0;\n        double ak, akden, bk, bkden = 1.0, bknum, bnrm, dxnrm, xnrm, zm1nrm, znrm = 0.0;\n        int j, n = b.length;\n\n        double[] p = new double[n];\n        double[] pp = new double[n];\n        double[] r = new double[n];\n        double[] rr = new double[n];\n        double[] z = new double[n];\n        double[] zz = new double[n];\n\n        A.ax(x, r);\n        for (j = 0; j < n; j++) {\n            r[j] = b[j] - r[j];\n            rr[j] = r[j];\n        }\n\n        if (itol == 1) {\n            bnrm = snorm(b, itol);\n            Ap.asolve(r, z);\n        } else if (itol == 2) {\n            Ap.asolve(b, z);\n            bnrm = snorm(z, itol);\n            Ap.asolve(r, z);\n        } else if (itol == 3 || itol == 4) {\n            Ap.asolve(b, z);\n            bnrm = snorm(z, itol);\n            Ap.asolve(r, z);\n            znrm = snorm(z, itol);\n        } else {\n            throw new IllegalArgumentException(String.format(\"Illegal itol: %d\", itol));\n        }\n\n        for (int iter = 1; iter <= maxIter; iter++) {\n            Ap.asolve(rr, zz);\n            for (bknum = 0.0, j = 0; j < n; j++) {\n                bknum += z[j] * rr[j];\n            }\n            if (iter == 1) {\n                for (j = 0; j < n; j++) {\n                    p[j] = z[j];\n                    pp[j] = zz[j];\n                }\n            } else {\n                bk = bknum / bkden;\n                for (j = 0; j < n; j++) {\n                    p[j] = bk * p[j] + z[j];\n                    pp[j] = bk * pp[j] + zz[j];\n                }\n            }\n            bkden = bknum;\n            A.ax(p, z);\n            for (akden = 0.0, j = 0; j < n; j++) {\n                akden += z[j] * pp[j];\n            }\n            ak = bknum / akden;\n            A.atx(pp, zz);\n            for (j = 0; j < n; j++) {\n                x[j] += ak * p[j];\n                r[j] -= ak * z[j];\n                rr[j] -= ak * zz[j];\n            }\n            Ap.asolve(r, z);\n            if (itol == 1) {\n                err = snorm(r, itol) / bnrm;\n            } else if (itol == 2) {\n                err = snorm(z, itol) / bnrm;\n            } else if (itol == 3 || itol == 4) {\n                zm1nrm = znrm;\n                znrm = snorm(z, itol);\n                if (Math.abs(zm1nrm - znrm) > Math.EPSILON * znrm) {\n                    dxnrm = Math.abs(ak) * snorm(p, itol);\n                    err = znrm / Math.abs(zm1nrm - znrm) * dxnrm;\n                } else {\n                    err = znrm / bnrm;\n                    continue;\n                }\n                xnrm = snorm(x, itol);\n                if (err <= 0.5 * xnrm) {\n                    err /= xnrm;\n                } else {\n                    err = znrm / bnrm;\n                    continue;\n                }\n            }\n\n            if (iter % 10 == 0) {\n                logger.info(String.format(\"BCG: the error after %3d iterations: %.5g\", iter, err));\n            }\n\n            if (err <= tol) {\n                logger.info(String.format(\"BCG: the error after %3d iterations: %.5g\", iter, err));\n                break;\n            }\n        }\n\n        return err;\n    }\n"
  },
  {
    "id": "line_line_bot_sdk_java-4-Param-0",
    "old_comment_raw": "@param eventRequest event request object",
    "new_code_raw": "    BotApiResponse reply(List<String> to, List<Message> messages)\n            throws LineBotAPIException;\n\n    BotApiResponse push(List<String> to, List<Message> messages)\n            throws LineBotAPIException;\n\n    default BotApiResponse push(String to, Message messages)\n            throws LineBotAPIException {\n        return push(Collections.singletonList(to), Collections.singletonList(messages));\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-183-Param-4",
    "old_comment_raw": "@param model",
    "new_code_raw": "    public String delete(Long[] ids, String _csrf, HttpServletRequest request, HttpSession session, ModelMap model) {\n        if (ControllerUtils.verifyNotEquals(\"_csrf\", ControllerUtils.getAdminToken(request), _csrf, model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        SysSite site = getSite(request);\n        if (CommonUtils.notEmpty(ids)) {\n            service.delete(site.getId(), ids);\n            logOperateService.save(new LogOperate(site.getId(), ControllerUtils.getAdminFromSession(session).getId(),\n                    LogLoginService.CHANNEL_WEB_MANAGER, \"delete.cmsComment\", RequestUtils.getIpAddress(request),\n                    CommonUtils.getDate(), StringUtils.join(ids, ',')));\n        }\n        return CommonConstants.TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "sonatype_sonatype-aether-18-Associations-Param0",
    "old_comment_raw": "@param dir the directory to create.",
    "new_code_raw": "    public static boolean mkdirs( File directory )\n    {\n        if ( directory == null )\n        {\n            return false;\n        }\n\n        if ( directory.exists() )\n        {\n            return false;\n        }\n        if ( directory.mkdir() )\n        {\n            return true;\n        }\n\n        File canonDir = null;\n        try\n        {\n            canonDir = directory.getCanonicalFile();\n        }\n        catch ( IOException e )\n        {\n            return false;\n        }\n\n        File parentDir = canonDir.getParentFile();\n        return ( parentDir != null && ( mkdirs( parentDir ) || parentDir.exists() ) && canonDir.mkdir() );\n    }\n\n"
  },
  {
    "id": "apache_ignite-5700-Param-0",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public boolean initializeFromDht(long topVer) throws GridCacheEntryRemovedException {\n        while (true) {\n            GridDhtCacheEntry<K, V> entry = cctx.near().dht().peekExx(key);\n\n            if (entry != null) {\n                GridCacheEntryInfo<K, V> e = entry.info();\n\n                if (e != null) {\n                    GridCacheVersion enqueueVer = null;\n\n                    try {\n                        synchronized (this) {\n                            checkObsolete();\n\n                            if (isNew() || !valid(topVer)) {\n                                // Version does not change for load ops.\n                                update(e.value(), e.valueBytes(), e.expireTime(), e.ttl(), e.isNew() ? ver : e.version());\n\n                                if (cctx.deferredDelete()) {\n                                    boolean deleted = val == null && valBytes == null;\n\n                                    if (deleted != deletedUnlocked()) {\n                                        deletedUnlocked(deleted);\n\n                                        if (deleted)\n                                            enqueueVer = e.version();\n                                    }\n                                }\n\n                                recordNodeId(cctx.affinity().primary(key, topVer).id());\n\n                                dhtVer = e.isNew() || e.isDeleted() ? null : e.version();\n\n                                return true;\n                            }\n\n                            return false;\n                        }\n                    }\n                    finally {\n                        if (enqueueVer != null)\n                            cctx.onDeferredDelete(this, enqueueVer);\n                    }\n                }\n            }\n            else\n                return false;\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-792-Param-1",
    "old_comment_raw": "@param strings",
    "new_code_raw": "    public Long rpush(final String key, final String... string) {\n        checkIsInMulti();\n        client.rpush(key, string);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-4423-Param-1",
    "old_comment_raw": "@param mode Mode.",
    "new_code_raw": "    private IgfsFileInfo resolveFileInfo(IgfsPath path, IgfsMode mode) throws IgniteCheckedException {\n        assert path != null;\n        assert mode != null;\n\n        IgfsFileInfo info = null;\n\n        switch (mode) {\n            case PRIMARY:\n                info = meta.info(meta.fileId(path));\n\n                break;\n\n            case DUAL_SYNC:\n            case DUAL_ASYNC:\n                info = meta.info(meta.fileId(path));\n\n                if (info == null) {\n                    IgfsFile status = secondaryFs.info(path);\n\n                    if (status != null)\n                        info = status.isDirectory() ? new IgfsFileInfo(true, status.properties()) :\n                            new IgfsFileInfo(status.blockSize(), status.length(), null, null, false,\n                            status.properties());\n                }\n\n                break;\n\n            default:\n                assert false : \"Unknown mode: \" + mode;\n        }\n\n        return info;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1296-Param-1",
    "old_comment_raw": "@param retryCount",
    "new_code_raw": "    public static int execute(Runnable runnable, int attemptsCount, long intervalMillis) {\n        int executionIndex = 0;\n        while (true) {\n            try {\n                runnable.run();\n                return executionIndex;\n            } catch (RuntimeException | AssertionError e) {\n                attemptsCount--;\n                executionIndex++;\n                if (attemptsCount > 0) {\n                    try {\n                        Thread.sleep(intervalMillis);\n                    } catch (InterruptedException ie) {\n                        ie.addSuppressed(e);\n                        throw new RuntimeException(ie);\n                    }\n                } else {\n                    throw e;\n                }\n            }\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5776-Param-1",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public static Collection<ClusterNode> remoteNodes(final GridCacheSharedContext ctx, AffinityTopologyVersion topVer) {\n        return ctx.discovery().remoteCacheNodes(topVer);\n    }\n"
  },
  {
    "id": "SpigotMC_BungeeCord-117-Param-0",
    "old_comment_raw": "@param clickEvent",
    "new_code_raw": "    public ComponentBuilder event(HoverEvent hoverEvent)\n    {\n        current.setHoverEvent( hoverEvent );\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-3719-Param-0",
    "old_comment_raw": "@param tx Transaction to check.",
    "new_code_raw": "    private boolean isSafeToForget(IgniteInternalTx<K, V> tx) {\n        Map.Entry<GridCacheVersion, AtomicInt> e = startVerCnts.firstEntry();\n\n        if (e == null)\n            return true;\n\n        assert e.getValue().get() >= 0;\n\n        return tx.endVersion().compareTo(e.getKey()) <= 0;\n    }\n"
  },
  {
    "id": "mitreid_connect_OpenID_Connect_Java_Spring_Server-231-Param-0",
    "old_comment_raw": "@param oAuthRequest the incoming authorization request",
    "new_code_raw": "\tpublic AuthorizationRequest checkForPreApproval(AuthorizationRequest authorizationRequest, Authentication userAuthentication) {\n\t\t\n\t\t//First, check database to see if the user identified by the userAuthentication has stored an approval decision\n\t\t\n\t\t//getName may not be filled in? TODO: investigate\n\t\tString userId = userAuthentication.getName();\n\t\tString clientId = authorizationRequest.getClientId();\n\n\t\t//lookup ApprovedSites by userId and clientId\n\t\tboolean alreadyApproved = false;\n\t\tCollection<ApprovedSite> aps = approvedSiteService.getByClientIdAndUserId(clientId, userId);\n\t\tfor (ApprovedSite ap : aps) {\n\t\t\t\n\t\t\tif (!ap.isExpired()) {\n\t\t\t\n\t\t\t\t// if we find one that fits...\n\t\t\t\tif (scopesMatch(authorizationRequest.getScope(), ap.getAllowedScopes())) {\n\t\t\t\t\t\n\t\t\t\t\t//We have a match; update the access date on the AP entry and return true.\n\t\t\t\t\tap.setAccessDate(new Date());\n\t\t\t\t\tapprovedSiteService.save(ap);\n\t\n\t\t\t\t\tauthorizationRequest.getExtensionProperties().put(\"approved_site\", ap.getId());\n\t\t\t\t\tauthorizationRequest.setApproved(true);\t\t\t\t\t\n\t\t\t\t\talreadyApproved = true;\n\t\t\t\t}\n\t\t\t}\n        }\n\t\t\n\t\tif (!alreadyApproved) {\n\t\t\tWhitelistedSite ws = whitelistedSiteService.getByClientId(clientId);\n\t\t\tif (ws != null && scopesMatch(authorizationRequest.getScope(), ws.getAllowedScopes())) {\n\t\t\t\t\n\t\t\t\t//Create an approved site\n\t\t\t\tApprovedSite newSite = approvedSiteService.createApprovedSite(clientId, userId, null, ws.getAllowedScopes(), ws);\t\n\t\t\t\tauthorizationRequest.getExtensionProperties().put(\"approved_site\", newSite.getId());\n\t\t\t\tauthorizationRequest.setApproved(true);\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn authorizationRequest;\n\t\t\n\t}\n"
  },
  {
    "id": "haifengl_smile-108-Param-2",
    "old_comment_raw": "@param tol the desired convergence tolerance.",
    "new_code_raw": "    public static double eigen(Matrix A, double[] v, double tol, int maxIter) {\n        return eigen(A, v, 0.0, tol, maxIter);\n    }\n"
  },
  {
    "id": "apache_ignite-5314-Param-2",
    "old_comment_raw": "@param props Properties to be applied.",
    "new_code_raw": "    public IgfsFileInfo updateDual(final IgfsSecondaryFileSystem fs, final IgfsPath path, final Map<String, String> props)\n        throws IgniteCheckedException {\n        assert fs != null;\n        assert path != null;\n        assert props != null && !props.isEmpty();\n\n        if (busyLock.enterBusy()) {\n            try {\n                SynchronizationTask<IgfsFileInfo> task = new SynchronizationTask<IgfsFileInfo>() {\n                    @Override public IgfsFileInfo onSuccess(Map<IgfsPath, IgfsFileInfo> infos)\n                        throws Exception {\n                        if (infos.get(path) == null)\n                            return null;\n\n                        fs.update(path, props);\n\n                        assert path.parent() == null || infos.get(path.parent()) != null;\n\n                        return updatePropertiesNonTx(infos.get(path.parent()).id(), infos.get(path).id(), path.name(),\n                            props);\n                    }\n\n                    @Override public IgfsFileInfo onFailure(@Nullable Exception err) throws IgniteCheckedException {\n                        U.error(log, \"Path update in DUAL mode failed [path=\" + path + \", properties=\" + props + ']',\n                            err);\n\n                        throw new IgniteCheckedException(\"Failed to update the path due to secondary file system exception: \" +\n                            path, err);\n                    }\n                };\n\n                return synchronizeAndExecute(task, fs, false, path);\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to update in DUAL mode because Grid is stopping: \" + path);\n    }\n"
  },
  {
    "id": "apache_ignite-13201-Param-0",
    "old_comment_raw": "@param grid Grid instance.",
    "new_code_raw": "    private GridCheckpointManager checkpoints(Ignite ignite) {\n        assert ignite != null;\n\n        return ((GridKernal) ignite).context().checkpoint();\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-488-Param-0",
    "old_comment_raw": "@param weightingMap all parameters influencing the weighting. E.g. parameters coming via GHRequest.getHints or directly via \"&amp;api.xy=\" from the URL of the web UI",
    "new_code_raw": "    public Weighting createWeighting( WeightingMap weightingMap, FlagEncoder encoder )\n    {\n        String weighting = weightingMap.getWeighting().toLowerCase();\n\n        if (\"shortest\".equalsIgnoreCase(weighting))\n        {\n            return new ShortestWeighting(encoder);\n        } else if (\"fastest\".equalsIgnoreCase(weighting) || weighting.isEmpty())\n        {\n            if (encoder.supports(PriorityWeighting.class))\n                return new PriorityWeighting(encoder, weightingMap);\n            else\n                return new FastestWeighting(encoder, weightingMap);\n        } else if (\"curvature\".equalsIgnoreCase(weighting))\n        {\n            if (encoder.supports(CurvatureWeighting.class))\n                return new CurvatureWeighting(encoder, weightingMap, ghStorage);\n            else\n                return new FastestWeighting(encoder, weightingMap);\n        }\n\n        throw new UnsupportedOperationException(\"weighting \" + weighting + \" not supported\");\n    }\n"
  },
  {
    "id": "apache_shiro-718-Param-0",
    "old_comment_raw": "@param principal the principal of the Subject whose Account is being retrieved.",
    "new_code_raw": "    protected AuthorizingAccount queryForLdapAccount( PrincipalCollection principals, LdapContextFactory ldapContextFactory) throws NamingException {\n\n        String username = null;\n\n        if ( !(principals instanceof String ) ) {\n            String msg = \"This implementation expects the principal argument to be a String.\";\n            throw new IllegalArgumentException( msg );\n        }\n\n        username = (String)principal;\n\n        // Perform context search\n        LdapContext ldapContext = ldapContextFactory.getSystemLdapContext();\n\n        Set<String> roleNames;\n\n        try {\n            roleNames = getRoleNamesForUser(username, ldapContext);\n        } finally {\n            LdapUtils.closeContext( ldapContext );\n        }\n\n        SimplePrincipalCollection principals = new SimplePrincipalCollection(getName(),username);\n        return new SimpleAuthorizingAccount( principals, null, roleNames, null );\n    }\n"
  },
  {
    "id": "apache_ignite-1939-Param-0",
    "old_comment_raw": "@param idx Node index.",
    "new_code_raw": "    private GridFuture<Integer> callAsync(int idx, Callable<Integer> job, @Nullable IgnitePredicate<ClusterNode> p)\n        throws GridException {\n        assert idx >= 0 && idx < NODES_CNT;\n        assert job != null;\n\n        execCntr.set(0);\n\n        GridCompute comp = p != null ? compute(grid(idx).forPredicate(p)) : grid(idx).compute();\n\n        comp = comp.enableAsync();\n\n        comp.call(job);\n\n        return comp.future();\n    }\n"
  },
  {
    "id": "eclipse_elk-137-Associations-Param4",
    "old_comment_raw": "@param insets the insets to adjust.",
    "new_code_raw": "    public static ElkPadding calculateRequiredNodeLabelSpace(final NodeAdapter<?> node,\n            final double labelSpacing, final ElkPadding nodeLabelPadding,\n            final Map<LabelLocation, LabelGroup> labelGroupsBoundingBoxes, final ElkPadding padding) {\n\n        // Check if there are any labels\n        if (!node.getLabels().iterator().hasNext()) {\n            return padding;\n        }\n        \n        // Retrieve the node's label placement policy\n        final Set<NodeLabelPlacement> nodeLabelPlacement = node.getProperty(CoreOptions.NODE_LABELS_PLACEMENT);\n        final LabelLocation nodeLabelLocation = LabelLocation.fromNodeLabelPlacement(nodeLabelPlacement);\n        \n        // Compute a bounding box for each location where labels should be placed.\n        // The size is calculated from the size of all labels stacked vertically at that location.\n        for (final LabelAdapter<?> label : node.getLabels()) {\n            LabelLocation labelPlacement =\n                    LabelLocation.fromNodeLabelPlacement(label.getProperty(CoreOptions.NODE_LABELS_PLACEMENT));\n            \n            // If no valid placement is set on the label, use the node's placement policy.\n            if (labelPlacement == LabelLocation.UNDEFINED) {\n                labelPlacement = nodeLabelLocation;\n            }\n            \n            // Save the location of this label in its id field for later use.\n            label.setVolatileId(labelPlacement.ordinal());\n            \n            // Create or retrieve the label group for the current label.\n            final Rectangle boundingBox = retrieveLabelGroupsBoundingBox(labelGroupsBoundingBoxes, labelPlacement);\n            boundingBox.width = Math.max(boundingBox.width, label.getSize().x);\n            boundingBox.height += label.getSize().y + labelSpacing;\n        }\n        \n        // We need to count different label placement boxes towards different kinds of padding, depending on whether\n        // or not H_PRIORITY is set on the node itself (see H_PRIORITY documentation)\n        boolean hPrio = nodeLabelPlacement.contains(NodeLabelPlacement.H_PRIORITY);\n        \n        // Calculate the node label space required inside the node (only label groups on the inside\n        // are relevant here).\n        for (final Entry<LabelLocation, LabelGroup> entry : labelGroupsBoundingBoxes.entrySet()) {\n            final Rectangle boundingBox = entry.getValue();\n            \n            // From each existing label group, remove the last superfluous label spacing\n            // (the mere existence of a label group implies that it contains at least one label)\n            boundingBox.height -= labelSpacing;\n            switch (entry.getKey()) {\n            case IN_T_L:\n                if (hPrio) {\n                    padding.left = Math.max(\n                            padding.left,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                } else {\n                    padding.top = Math.max(\n                            padding.top,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                }\n                break;\n                \n            case IN_T_C:\n                padding.top = Math.max(\n                        padding.top,\n                        boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                break;\n                \n            case IN_T_R:\n                if (hPrio) {\n                    padding.right = Math.max(\n                            padding.right,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                } else {\n                    padding.top = Math.max(\n                            padding.top,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.top);\n                }\n                break;\n                \n            case IN_C_L:\n                padding.left = Math.max(\n                        padding.left,\n                        boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                break;\n                \n            case IN_C_R:\n                padding.right = Math.max(\n                        padding.right,\n                        boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                break;\n                \n            case IN_B_L:\n                if (hPrio) {\n                    padding.left = Math.max(\n                            padding.left,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.left);\n                } else {\n                    padding.bottom = Math.max(\n                            padding.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                }\n                break;\n                \n            case IN_B_C:\n                padding.bottom = Math.max(\n                        padding.bottom,\n                        boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                break;\n                \n            case IN_B_R:\n                if (hPrio) {\n                    padding.right = Math.max(\n                            padding.right,\n                            boundingBox.width + labelSpacing + nodeLabelPadding.right);\n                } else {\n                    padding.bottom = Math.max(\n                            padding.bottom,\n                            boundingBox.height + labelSpacing + nodeLabelPadding.bottom);\n                }\n                break;\n                \n            default:\n                // In all other cases, no specific action is required\n            }\n        }\n\n        // Add node label padding that aren't set yet\n        // This happens if e.g. a top inset is set but no top label is present\n        padding.top    = Math.max(padding.top, nodeLabelPadding.top);\n        padding.left   = Math.max(padding.left, nodeLabelPadding.left);\n        padding.right  = Math.max(padding.right, nodeLabelPadding.right);\n        padding.bottom = Math.max(padding.bottom, nodeLabelPadding.bottom);\n\n        return padding;\n    }\n\n"
  },
  {
    "id": "singwhatiwanna_dynamic_load_apk-0-Param-2",
    "old_comment_raw": "@param requestCode",
    "new_code_raw": "    public int startPluginActivityForResult(Context base, DLIntent dlIntent, int requestCode) {\n        String packageName = dlIntent.getPluginPackage();\n        if (packageName == null) throw new NullPointerException(\"package name is null\");\n        DLPluginPackage pluginPackage = packageHolder.get(packageName);\n        \n        if (pluginPackage == null) {\n            return START_RESULT_NO_PKG;\n        } else {\n            DexClassLoader loader = pluginPackage.loader;\n            String className = dlIntent.getPluginClass();\n            className = className == null ? pluginPackage.getDefaultActivity() : className;\n            if (className.startsWith(\".\")) {\n                className = packageName + className;\n            }\n            Class<?> clazz = null;\n            try {\n                clazz = loader.loadClass(className);\n            } catch (ClassNotFoundException e) {\n                e.printStackTrace();\n                return START_RESULT_NO_CLASS;\n            }\n            \n            Class<? extends Activity> activityClass = null;\n            if (DLBasePluginActivity.class.isAssignableFrom(clazz)) {\n                activityClass = DLProxyActivity.class;\n            } else if (DLBasePluginFragmentActivity.class.isAssignableFrom(clazz)) {\n                activityClass = DLProxyFragmentActivity.class;\n            } else {\n                return START_RESULT_TYPE_ERROR;\n            }\n            \n            dlIntent.putExtra(DLConstants.EXTRA_CLASS, className);\n            dlIntent.putExtra(DLConstants.EXTRA_PACKAGE, packageName);\n            dlIntent.setClass(mContext, activityClass);\n            \n            if (base instanceof Activity) {\n                ((Activity) base).startActivityForResult(dlIntent, requestCode);\n            } else {\n                base.startActivity(dlIntent);\n            }\n            return START_RESULT_SUCCESS;\n        }\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1300-Param-0",
    "old_comment_raw": "@param configStream",
    "new_code_raw": "    public Object parse(InputStream stream) throws ParsingException {\n        XMLEventReader xmlEventReader = createEventReader(stream);\n        return parse(xmlEventReader);\n    }\n"
  },
  {
    "id": "apache_ignite-4102-Param-0",
    "old_comment_raw": "@param entry Entry.",
    "new_code_raw": "    private int extrasSize(Cache.Entry entry) throws Exception {\n        assert false : \"ignite-96\";\n\n        return -1;\n\n//        Method mthd = GridCacheMapEntry.class.getDeclaredMethod(\"extrasSize\");\n//\n//        mthd.setAccessible(true);\n//\n//        GridCacheContext ctx = U.field(entry, \"ctx\");\n//\n//        GridCacheEntryEx entry0 = ((GridCacheEntryImpl)entry).entryEx(false, ctx.discovery().topologyVersion());\n//\n//        return (Integer)mthd.invoke(entry0);\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-779-Param-0",
    "old_comment_raw": "@param user",
    "new_code_raw": "    protected BitmapDrawable getImage(final String userId) {\n        File avatarFile = new File(avatarDir, userId);\n\n        if (!avatarFile.exists() || avatarFile.length() == 0)\n            return null;\n\n        Bitmap bitmap = decode(avatarFile);\n        if (bitmap != null)\n            return new BitmapDrawable(context.getResources(), bitmap);\n        else {\n            avatarFile.delete();\n            return null;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-10157-Param-0",
    "old_comment_raw": "@param entry Entry.",
    "new_code_raw": "    private int extrasSize(CacheEntry entry) throws Exception {\n        Method mthd = GridCacheMapEntry.class.getDeclaredMethod(\"extrasSize\");\n\n        mthd.setAccessible(true);\n\n        GridCacheContext ctx = U.field(entry, \"ctx\");\n\n        GridCacheEntryEx entry0 = ((GridCacheEntryImpl)entry).entryEx(false, ctx.discovery().topologyVersion());\n\n        return (Integer)mthd.invoke(entry0);\n    }\n"
  },
  {
    "id": "gyf_dev_ImmersionBar-10-Param-0",
    "old_comment_raw": "@param statusBarFlag the status bar flag",
    "new_code_raw": "    public ImmersionBar statusBarColorTransformEnable(boolean statusBarColorTransformEnable) {\n        mBarParams.statusBarColorEnabled = statusBarColorTransformEnable;\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-3692-Param-0",
    "old_comment_raw": "@param tx Transaction to commit.",
    "new_code_raw": "    public IgniteInternalFuture<IgniteInternalTx> commitTxAsync(final IgniteInternalTx tx) {\n        FutureHolder holder = lastFut.get();\n\n        holder.lock();\n\n        try {\n            IgniteInternalFuture fut = holder.future();\n\n            if (fut != null && !fut.isDone()) {\n                IgniteInternalFuture<IgniteInternalTx> f = new GridEmbeddedFuture<>(fut,\n                    new C2<Object, Exception, IgniteInternalFuture<IgniteInternalTx>>() {\n                        @Override public IgniteInternalFuture<IgniteInternalTx> apply(Object o, Exception e) {\n                            return tx.commitAsync();\n                        }\n                    }, ctx.kernalContext());\n\n                saveFuture(holder, f);\n\n                return f;\n            }\n\n            IgniteInternalFuture<IgniteInternalTx> f = tx.commitAsync();\n\n            saveFuture(holder, f);\n\n            ctx.tm().txContextReset();\n\n            return f;\n        }\n        finally {\n            holder.unlock();\n        }\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-155-Param-0",
    "old_comment_raw": "@param url",
    "new_code_raw": "    protected BitmapDrawable fetchAvatar(final String url, final String userId) {\n        File rawAvatar = new File(avatarDir, userId + \"-raw\");\n        HttpRequest request = HttpRequest.get(url);\n        if (request.ok())\n            request.receive(rawAvatar);\n\n        if (!rawAvatar.exists() || rawAvatar.length() == 0)\n            return null;\n\n        Bitmap bitmap = decode(rawAvatar);\n        if (bitmap == null) {\n            rawAvatar.delete();\n            return null;\n        }\n\n        bitmap = ImageUtils.roundCorners(bitmap, cornerRadius);\n        if (bitmap == null) {\n            rawAvatar.delete();\n            return null;\n        }\n\n        File roundedAvatar = new File(avatarDir, userId.toString());\n        FileOutputStream output = null;\n        try {\n            output = new FileOutputStream(roundedAvatar);\n            if (bitmap.compress(PNG, 100, output))\n                return new BitmapDrawable(context.getResources(), bitmap);\n            else\n                return null;\n        } catch (IOException e) {\n            Log.d(TAG, \"Exception writing rounded avatar\", e);\n            return null;\n        } finally {\n            if (output != null)\n                try {\n                    output.close();\n                } catch (IOException e) {\n                    // Ignored\n                }\n            rawAvatar.delete();\n        }\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-357-Param-0",
    "old_comment_raw": "@param peerGroup a PeerGroup to use for broadcast or null.",
    "new_code_raw": "    public SendResult sendCoins(TransactionBroadcaster broadcaster, SendRequest request) {\n        // Does not need to be synchronized as sendCoinsOffline is and the rest is all thread-local.\n\n        // Commit the TX to the wallet immediately so the spent coins won't be reused.\n        // TODO: We should probably allow the request to specify tx commit only after the network has accepted it.\n        Transaction tx = sendCoinsOffline(request);\n        if (tx == null)\n            return null;  // Not enough money.\n        SendResult result = new SendResult();\n        result.tx = tx;\n        // The tx has been committed to the pending pool by this point (via sendCoinsOffline -> commitTx), so it has\n        // a txConfidenceListener registered. Once the tx is broadcast the peers will update the memory pool with the\n        // count of seen peers, the memory pool will update the transaction confidence object, that will invoke the\n        // txConfidenceListener which will in turn invoke the wallets event listener onTransactionConfidenceChanged\n        // method.\n        result.broadcastComplete = broadcaster.broadcastTransaction(tx);\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-1916-Param-0",
    "old_comment_raw": "@param p Predicate to check.",
    "new_code_raw": "    public static boolean isAlwaysTrue(IgnitePredicate p) {\n        return p == ALWAYS_TRUE;\n    }\n"
  },
  {
    "id": "apache_ignite-11988-Param-2",
    "old_comment_raw": "@param type Type description.",
    "new_code_raw": "    protected int fillValueParameters(PreparedStatement stmt, int i, EntryMapping m, Object val)\n        throws CacheWriterException {\n        for (CacheQueryTypeDescriptor field : m.uniqValFields) {\n            Object fieldVal = extractField(m.valueType(), field.getJavaName(), val);\n\n            try {\n                if (fieldVal != null)\n                    stmt.setObject(i++, fieldVal);\n                else\n                    stmt.setNull(i++, field.getDbType());\n            }\n            catch (SQLException e) {\n                throw new CacheWriterException(\"Failed to set statement parameter name: \" + field.getDbName(), e);\n            }\n        }\n\n        return i;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-336-Param-1",
    "old_comment_raw": "@param file file to parse",
    "new_code_raw": "  public static Frame parseFrame(Key okey, File file) {\n    if( !file.exists() )\n      throw new RuntimeException(\"File not found \" + file);\n    if(okey == null)\n      okey = Key.make(file.getName());\n    Key fkey = NFSFileVec.make(file);\n    return ParseDataset2.parse(okey, new Key[] { fkey });\n  }\n"
  },
  {
    "id": "bytedeco_javacpp-217-Param-0",
    "old_comment_raw": "@param pointer data to access via a buffer or to copy to an array",
    "new_code_raw": "    public static UShortIndexer create(final ShortPointer pointer, long[] sizes, long[] strides, boolean direct) {\n        if (direct) {\n            return Raw.getInstance() != null ? new UShortRawIndexer(pointer, sizes, strides)\n                                             : new UShortBufferIndexer(pointer.asBuffer(), sizes, strides);\n        } else {\n            final long position = pointer.position();\n            short[] array = new short[(int)Math.min(pointer.limit() - position, Integer.MAX_VALUE)];\n            pointer.get(array);\n            return new UShortArrayIndexer(array, sizes, strides) {\n                @Override public void release() {\n                    pointer.position(position).put(array);\n                    super.release();\n                }\n            };\n        }\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1319-Param-0",
    "old_comment_raw": "@param model Authentication flow model",
    "new_code_raw": "    public Response createFlow(AuthenticationFlowRepresentation flow) {\n        this.auth.requireManage();\n\n        if (flow.getAlias() == null || flow.getAlias().isEmpty()) {\n            return ErrorResponse.exists(\"Failed to create flow with empty alias name\");\n        }\n\n        if (realm.getFlowByAlias(flow.getAlias()) != null) {\n            return ErrorResponse.exists(\"Flow \" + flow.getAlias() + \" already exists\");\n        }\n\n        realm.addAuthenticationFlow(RepresentationToModel.toModel(flow));\n        return Response.status(201).build();\n    }\n"
  },
  {
    "id": "essentials_Essentials-197-Param-0",
    "old_comment_raw": "@param userName",
    "new_code_raw": "\tpublic boolean isOverloaded(String userId) {\n\n\t\treturn overloadedUsers.containsKey(userId.toLowerCase());\n\t}\n"
  },
  {
    "id": "apache_ignite-13185-Param-0",
    "old_comment_raw": "@param group Counter group's name.",
    "new_code_raw": "    public GridHadoopCounter counter(String grp, String name) {\n        return counters.counter(grp, name, true);\n    }\n"
  },
  {
    "id": "apache_ignite-11129-Param-0",
    "old_comment_raw": "@param key Entry key.",
    "new_code_raw": "    public boolean onSwap(KeyCacheObject key, int partId) throws IgniteCheckedException {\n        return onSwapUnswap(key, partId, null);\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-754-Param-0",
    "old_comment_raw": "@param repositoryId",
    "new_code_raw": "    public boolean contains(long id) {\n        if (ids == null)\n            load();\n        return ids.contains(id);\n    }\n"
  },
  {
    "id": "apache_ignite-5061-Param-0",
    "old_comment_raw": "@param keys Keys to lock.",
    "new_code_raw": "    private boolean mapAsPrimary(Collection<KeyCacheObject> keys, long topVer) throws IgniteCheckedException {\n        // Assign keys to primary nodes.\n        Collection<KeyCacheObject> distributedKeys = new ArrayList<>(keys.size());\n\n        for (KeyCacheObject key : keys) {\n            if (!cctx.affinity().primary(cctx.localNode(), key, topVer)) {\n                // Remove explicit locks added so far.\n                for (KeyCacheObject k : keys)\n                    cctx.mvcc().removeExplicitLock(threadId, k, lockVer);\n\n                return false;\n            }\n\n            addLocalKey(key, topVer, distributedKeys);\n\n            if (isDone())\n                return true;\n        }\n\n        trackable = false;\n\n        if (tx != null)\n            tx.colocatedLocallyMapped(true);\n\n        if (!distributedKeys.isEmpty()) {\n            if (tx != null) {\n                for (KeyCacheObject key : distributedKeys)\n                    tx.addKeyMapping(cctx.txKey(key), cctx.localNode());\n            }\n\n            lockLocally(distributedKeys, topVer, null);\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "zxing_zxing-654-Param-0",
    "old_comment_raw": "@param startColor starting color - 0 for white, 1 for black",
    "new_code_raw": "  protected static int appendPattern(boolean[] target, int pos, int[] pattern, boolean startColor) {\n    boolean color = startColor;\n    int numAdded = 0;\n    for (int len : pattern) {\n      for (int j = 0; j < len; j++) {\n        target[pos++] = color;\n      }\n      numAdded += len;\n      color = !color; // flip color after each segment\n    }\n    return numAdded;\n  }\n"
  },
  {
    "id": "apache_ignite-12123-Param-0",
    "old_comment_raw": "@param ch A character to convert to an integer digit",
    "new_code_raw": "    public static int toDigit(char ch, int index) throws IgniteCheckedException {\n        int digit = Character.digit(ch, 16);\n\n        if (digit == -1)\n            throw new IgniteCheckedException(\"Illegal hexadecimal character \" + ch + \" at index \" + index);\n\n        return digit;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-800-Param-2",
    "old_comment_raw": "@param end",
    "new_code_raw": "  public List<byte[]> lrange(final byte[] key, final long start, final long stop) {\n    checkIsInMultiOrPipeline();\n    client.lrange(key, start, stop);\n    return client.getBinaryMultiBulkReply();\n  }\n"
  },
  {
    "id": "apache_ignite-5038-Param-1",
    "old_comment_raw": "@param entry Entry to add.",
    "new_code_raw": "    @Nullable private GridCacheMvccCandidate<K> addEntry(AffinityTopologyVersion topVer, GridNearCacheEntry<K, V> entry, UUID dhtNodeId)\n        throws GridCacheEntryRemovedException {\n        // Check if lock acquisition is timed out.\n        if (timedOut)\n            return null;\n\n        // Add local lock first, as it may throw GridCacheEntryRemovedException.\n        GridCacheMvccCandidate<K> c = entry.addNearLocal(\n            dhtNodeId,\n            threadId,\n            lockVer,\n            timeout,\n            !inTx(),\n            inTx(),\n            implicitSingleTx()\n        );\n\n        if (inTx()) {\n            IgniteTxEntry<K, V> txEntry = tx.entry(entry.txKey());\n\n            txEntry.cached(entry, txEntry.keyBytes());\n        }\n\n        if (c != null)\n            c.topologyVersion(topVer);\n\n        synchronized (mux) {\n            entries.add(entry);\n        }\n\n        if (c == null && timeout < 0) {\n            if (log.isDebugEnabled())\n                log.debug(\"Failed to acquire lock with negative timeout: \" + entry);\n\n            onFailed(false);\n\n            return null;\n        }\n\n        // Double check if lock acquisition has already timed out.\n        if (timedOut) {\n            entry.removeLock(lockVer);\n\n            return null;\n        }\n\n        return c;\n    }\n"
  },
  {
    "id": "apache_ignite-11597-Param-1",
    "old_comment_raw": "@param out Output stream to that file.",
    "new_code_raw": "    private GridGgfsFileWorkerBatch newBatch(final GridGgfsPath path, GridGgfsWriter writer) throws GridException {\n        assert path != null;\n        assert writer != null;\n\n        if (busyLock.enterBusy()) {\n            try {\n                GridGgfsFileWorkerBatch batch = new GridGgfsFileWorkerBatch(path, writer);\n\n                while (true) {\n                    GridGgfsFileWorker worker = workerMap.get(path);\n\n                    if (worker != null) {\n                        if (worker.addBatch(batch)) // Added batch to active worker.\n                            break;\n                        else\n                            workerMap.remove(path, worker); // Worker is stopping. Remove it from map.\n                    }\n                    else {\n                        worker = new GridGgfsFileWorker(\"ggfs-file-worker-\" + path) {\n                            @Override protected void onFinish() {\n                                workerMap.remove(path, this);\n                            }\n                        };\n\n                        boolean b = worker.addBatch(batch);\n\n                        assert b;\n\n                        if (workerMap.putIfAbsent(path, worker) == null) {\n                            worker.start();\n\n                            break;\n                        }\n                    }\n                }\n\n                return batch;\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new GridException(\"Cannot create new output stream to the secondary file system because GGFS is \" +\n                \"stopping: \" + path);\n    }\n"
  },
  {
    "id": "purplecabbage_phonegap_plugins-33-Param-1",
    "old_comment_raw": "@param data JSONArray of arguments to the plugin",
    "new_code_raw": "    public PluginResult execute(String action, JSONArray data, String callbackId) {\n        PluginResult result = null;\n        if (NOTIFY.equals(action)) {\n            try {\n                String tag = data.getString(0);\n                String title = data.getString(1);\n                String body = data.getString(2);\n                Log.d(\"NotificationPlugin\", \"Notification: \" + tag + \", \" + title + \", \" + body);\n                showNotification(tag, title, body);\n                result = new PluginResult(Status.OK);\n            } catch (JSONException jsonEx) {\n                Log.d(\"NotificationPlugin\", \"Got JSON Exception \"\n                        + jsonEx.getMessage());\n                result = new PluginResult(Status.JSON_EXCEPTION);\n            }\n        } else if (CLEAR.equals(action)){\n            try {\n                String tag = data.getString(0);\n                Log.d(\"NotificationPlugin\", \"Notification cancel: \" + tag);\n                clearNotification(tag);\n            } catch (JSONException jsonEx) {\n                Log.d(\"NotificationPlugin\", \"Got JSON Exception \" + jsonEx.getMessage());\n                result = new PluginResult(Status.JSON_EXCEPTION);\n            }\n        } else {\n            result = new PluginResult(Status.INVALID_ACTION);\n            Log.d(\"NotificationPlugin\", \"Invalid action : \"+action+\" passed\");\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_shiro-760-Param-1",
    "old_comment_raw": "@param account the Account of a newly authenticated user.",
    "new_code_raw": "    protected Subject createSubject(AuthenticationToken token, AuthenticationInfo info) {\n        assertPrincipals(info);\n\n        //get any existing session that may exist - we don't want to lose it:\n        Subject subject = getSubject();\n        Session session = null;\n        if (subject != null) {\n            session = subject.getSession(false);\n        }\n\n        InetAddress authcSourceIP = null;\n        if (token instanceof InetAuthenticationToken) {\n            authcSourceIP = ((InetAuthenticationToken) token).getInetAddress();\n        }\n        if (authcSourceIP == null) {\n            //try the thread local:\n            authcSourceIP = ThreadContext.getInetAddress();\n        }\n\n        return createSubject(info.getPrincipals(), session, true, authcSourceIP);\n    }\n"
  },
  {
    "id": "apache_ignite-1793-Param-0",
    "old_comment_raw": "@param c Grid configuration.",
    "new_code_raw": "    public static VisorExecutorServiceConfiguration from(IgniteConfiguration c) {\n        VisorExecutorServiceConfiguration cfg = new VisorExecutorServiceConfiguration();\n\n        cfg.executeService(compactClass(c.getExecutorService()));\n        cfg.executeServiceShutdown(c.getExecutorServiceShutdown());\n\n        cfg.systemExecutorService(compactClass(c.getSystemExecutorService()));\n        cfg.systemExecutorServiceShutdown(c.getSystemExecutorServiceShutdown());\n\n        cfg.p2pExecutorService(compactClass(c.getPeerClassLoadingExecutorService()));\n        cfg.p2pExecutorServiceShutdown(c.getSystemExecutorServiceShutdown());\n\n        GridClientConnectionConfiguration cc = c.getClientConnectionConfiguration();\n\n        if (cc != null) {\n            cfg.restExecutorService(compactClass(cc.getRestExecutorService()));\n            cfg.restExecutorServiceShutdown(cc.isRestExecutorServiceShutdown());\n        }\n\n        return cfg;\n    }\n"
  },
  {
    "id": "apache_ignite-12068-Param-0",
    "old_comment_raw": "@param ignite Grid.",
    "new_code_raw": "    public static VisorCache from(Ignite g, GridCache c, int sample) throws IgniteCheckedException {\n        assert g != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)g).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = g.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<CacheEntry> set = ca.entrySet();\n\n        long memSz = 0;\n\n        Iterator<CacheEntry> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "apache_shiro-911-Param-0",
    "old_comment_raw": "@param context the subject context data that may provide (directly or indirectly through one of its values) a  PrincipalCollection identity.",
    "new_code_raw": "    protected SubjectContext resolvePrincipals(SubjectContext context) {\n        PrincipalCollection principals = context.resolvePrincipals();\n        if (CollectionUtils.isEmpty(principals)) {\n            log.trace(\"No identity (PrincipalCollection) found in the context.  Looking for a remembered identity.\");\n            principals = getRememberedIdentity(context);\n            if (!CollectionUtils.isEmpty(principals)) {\n                log.debug(\"Found remembered PrincipalCollection.  Adding to the context to be used \" +\n                        \"for subject construction by the SubjectFactory.\");\n                context.setPrincipals(principals);\n            } else {\n                log.trace(\"No remembered identity found.  Returning original context.\");\n            }\n        }\n\n        return context;\n    }\n"
  },
  {
    "id": "williamfiset_Algorithms-0-Param-0",
    "old_comment_raw": "@param maxWeight - The maximum weight of the knapsack",
    "new_code_raw": "  public static int knapsack(int capacity, int [] W, int [] V) {\n    \n    if (W == null || V == null || W.length != V.length || capacity < 0) \n      throw new IllegalArgumentException(\"Invalid input\");\n    \n    final int N = W.length;\n    \n    // Initialize a table where individual rows represent items \n    // and columns represent the weight of the knapsack\n    int[][] DP = new int[N+1][capacity+1];\n    \n    for (int i = 1; i <= N; i++) {\n      \n      // Get the value and weight of the item\n      int w = W[i-1], v = V[i-1];\n      \n      for (int sz = 1; sz <= capacity; sz++) {\n        \n        // Consider not picking this element\n        DP[i][sz] = DP[i-1][sz];\n        \n        // Consider including the current element and\n        // see if this would be more profitable\n        if (sz >= w && DP[i-1][sz-w] + v > DP[i][sz])\n          DP[i][sz] = DP[i-1][sz-w] + v;\n        \n      }\n      \n    }\n    \n    int sz = capacity;\n    java.util.List <Integer> itemsSelected = new java.util.ArrayList<>();\n    \n    // Using the information inside the table we can backtrack and determine\n    // which items were selected during the dynamic programming phase. The idea\n    // is that if DP[i][sz] != DP[i-1][sz] then the item was selected\n    for (int i = N; i > 0; i--) {\n      if (DP[i][sz] != DP[i-1][sz]) {\n        int itemIndex = i-1;\n        itemsSelected.add(itemIndex);\n        sz -= W[itemIndex];\n      }\n    }\n    \n    // Return the items that were selected\n    // java.util.Collections.reverse(itemsSelected);\n    // return itemsSelected;\n    \n    // Return the maximum profit\n    return DP[N][capacity];\n    \n  }\n"
  },
  {
    "id": "apache_ignite-5540-Param-1",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public List<ClusterNode> nodes(K key, AffinityTopologyVersion topVer) {\n        return nodes(partition(key), topVer);\n    }\n"
  },
  {
    "id": "gephi_gephi-408-Param-1",
    "old_comment_raw": "@param end End of the interval (must be lesser or equal than maximum time)",
    "new_code_raw": "    public BufferedImage createTimeIntervalImage(double starts[], double ends[], int width, int height, Color fill, Color border, Color background) {\n        if (starts.length != ends.length) {\n            throw new IllegalArgumentException(\"start and ends length should be equal\");\n        }\n        if (fill == null) {\n            fill = DEFAULT_FILL;\n        }\n        if (border == null) {\n            border = DEFAULT_BORDER;\n        }\n\n        final BufferedImage image = new BufferedImage(width, height, BufferedImage.TYPE_INT_ARGB);\n\n        final Graphics2D g = image.createGraphics();\n        g.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);\n\n        //Draw brackground if any:\n        if (background != null) {\n            g.setBackground(background);\n            g.clearRect(0, 0, width, height);\n        }\n\n        g.translate(1, 0);//Start drawing at pixel 1\n\n        width -= 2;//Reduce fill area in 2 pixels for the borders\n        double xTickWidth = (double) width / range;\n\n        //Draw time interval filled parts:\n        if (range == 0) {//No range, Min=Max\n            //Fill all drawing area:\n            g.setColor(fill);\n            g.fillRect(0, 0, width, height);\n            g.setColor(border);\n            //Draw borders:\n            g.drawLine(-1, 0, -1, height);\n            g.drawLine(width, 0, width, height);\n        } else {\n            int startPixel, endPixel;\n            for (int i = 0; i < starts.length; i++) {\n                g.setColor(fill);\n                startPixel = (int) (xTickWidth * (normalizeToRange(starts[i]) - min));\n                endPixel = (int) (xTickWidth * (normalizeToRange(ends[i]) - min));\n\n                int rectWidth = endPixel - startPixel;\n                if (rectWidth == 0) {\n                    rectWidth = 1;//Draw at least 1 pixel if a range is small\n                }\n                g.fillRect(startPixel, 0, rectWidth, height);\n\n                //Draw borders:\n                g.setColor(border);\n                g.drawLine(startPixel, 0, startPixel, height);\n                g.drawLine(endPixel, 0, endPixel, height);\n            }\n        }\n\n        return image;\n    }\n"
  },
  {
    "id": "apache_ignite-4949-Param-4",
    "old_comment_raw": "@param ver Version to use.",
    "new_code_raw": "    @Override protected void clearIndex(CacheObject val) {\n        // No-op.\n    }\n"
  },
  {
    "id": "apache_ignite-7529-Param-1",
    "old_comment_raw": "@param writer Writer.",
    "new_code_raw": "    private boolean writeHeader(Object obj, BinaryWriterExImpl writer) {\n        if (writer.tryWriteAsHandle(obj))\n            return false;\n\n        if (registered) {\n            PortableUtils.writeHeader(\n                writer,\n                typeId,\n                obj instanceof CacheObjectImpl ? 0 : obj.hashCode(),\n                null\n            );\n        }\n        else {\n            PortableUtils.writeHeader(\n                writer,\n                GridPortableMarshaller.UNREGISTERED_TYPE_ID,\n                obj instanceof CacheObjectImpl ? 0 : obj.hashCode(),\n                cls.getName()\n            );\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-12313-Param-0",
    "old_comment_raw": "@param cfg path to config file.",
    "new_code_raw": "    public static ClusterProperties from(String config) {\n        try {\n            Properties props = null;\n\n            if (config != null) {\n                props = new Properties();\n\n                props.load(new FileInputStream(config));\n            }\n\n            ClusterProperties prop = new ClusterProperties();\n\n            prop.mesosUrl = getStringProperty(MESOS_MASTER_URL, props, DEFAULT_MESOS_MASTER_URL);\n\n            prop.httpServerHost = getStringProperty(IGNITE_HTTP_SERVER_HOST, props, getNonLoopbackAddress());\n\n            String port = System.getProperty(\"PORT0\");\n\n            if (port != null && !port.isEmpty())\n                prop.httpServerPort = Integer.valueOf(port);\n            else\n                prop.httpServerPort = Integer.valueOf(getStringProperty(IGNITE_HTTP_SERVER_PORT, props,\n                    DEFAULT_HTTP_SERVER_PORT));\n\n            prop.clusterName = getStringProperty(IGNITE_CLUSTER_NAME, props, DEFAULT_CLUSTER_NAME);\n\n            prop.userLibsUrl = getStringProperty(IGNITE_USERS_LIBS_URL, props, null);\n            prop.ignitePackageUrl = getStringProperty(IGNITE_PACKAGE_URL, props, null);\n            prop.licenceUrl = getStringProperty(LICENCE_URL, props, null);\n            prop.igniteCfgUrl = getStringProperty(IGNITE_CONFIG_XML_URL, props, null);\n\n            prop.cpu = getDoubleProperty(IGNITE_TOTAL_CPU, props, UNLIMITED);\n            prop.cpuPerNode = getDoubleProperty(IGNITE_RUN_CPU_PER_NODE, props, UNLIMITED);\n            prop.mem = getDoubleProperty(IGNITE_TOTAL_MEMORY, props, UNLIMITED);\n            prop.memPerNode = getDoubleProperty(IGNITE_MEMORY_PER_NODE, props, UNLIMITED);\n            prop.disk = getDoubleProperty(IGNITE_TOTAL_DISK_SPACE, props, UNLIMITED);\n            prop.diskPerNode = getDoubleProperty(IGNITE_DISK_SPACE_PER_NODE, props, 1024.0);\n            prop.nodeCnt = getDoubleProperty(IGNITE_NODE_COUNT, props, UNLIMITED);\n            prop.minCpu = getDoubleProperty(IGNITE_MIN_CPU_PER_NODE, props, DEFAULT_RESOURCE_MIN_CPU);\n            prop.minMemory = getDoubleProperty(IGNITE_MIN_MEMORY_PER_NODE, props, DEFAULT_RESOURCE_MIN_MEM);\n\n            prop.jvmOpts = getStringProperty(IGNITE_JVM_OPTS, props, \"\");\n\n            prop.igniteVer = getStringProperty(IGNITE_VERSION, props, DEFAULT_IGNITE_VERSION);\n            prop.igniteWorkDir = getStringProperty(IGNITE_WORK_DIR, props, DEFAULT_IGNITE_WORK_DIR);\n            prop.igniteCfg = getStringProperty(IGNITE_CONFIG_XML, props, null);\n            prop.userLibs = getStringProperty(IGNITE_USERS_LIBS, props, null);\n\n            String pattern = getStringProperty(IGNITE_HOSTNAME_CONSTRAINT, props, null);\n\n            if (pattern != null) {\n                try {\n                    prop.hostnameConstraint = Pattern.compile(pattern);\n                }\n                catch (PatternSyntaxException e) {\n                    log.log(Level.WARNING, \"IGNITE_HOSTNAME_CONSTRAINT has invalid pattern. It will be ignore.\", e);\n                }\n            }\n\n            return prop;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n"
  },
  {
    "id": "todoroo_astrid-784-Param-0",
    "old_comment_raw": "@param task task to consider",
    "new_code_raw": "    private boolean shouldTransmit(TaskContainer task, Property<?> property, TaskContainer remoteTask) {\n        if(!task.task.containsValue(property))\n            return false;\n\n        if(remoteTask == null)\n            return true;\n        if(!remoteTask.task.containsValue(property))\n            return true;\n        return !AndroidUtilities.equals(task.task.getValue(property),\n                remoteTask.task.getValue(property));\n    }\n"
  },
  {
    "id": "xetorthio_jedis-798-Param-1",
    "old_comment_raw": "@param integer the value to increment by",
    "new_code_raw": "  public Double incrByFloat(final byte[] key, final double increment) {\n    checkIsInMultiOrPipeline();\n    client.incrByFloat(key, increment);\n    String dval = client.getBulkReply();\n    return (dval != null ? new Double(dval) : null);\n  }\n"
  },
  {
    "id": "apache_ignite-4005-Param-0",
    "old_comment_raw": "@param entry Entry to touch.",
    "new_code_raw": "    private boolean touch(Entry<GridGgfsBlockKey, byte[]> entry) {\n        byte[] val = entry.peek();\n\n        int blockSize = val != null ? val.length : 0;\n\n        MetaEntry meta = entry.meta(META_NODE);\n\n        // Entry has not been enqueued yet.\n        if (meta == null) {\n            while (true) {\n                Node<Entry<GridGgfsBlockKey, byte[]>> node = queue.offerLastx(entry);\n\n                meta = new MetaEntry(node, blockSize);\n\n                if (entry.putMetaIfAbsent(META_NODE, meta) != null) {\n                    // Was concurrently added, need to clear it from queue.\n                    queue.unlinkx(node);\n\n                    // Queue has not been changed.\n                    return false;\n                }\n                else if (node.item() != null) {\n                    if (!entry.isCached()) {\n                        // Was concurrently evicted, need to clear it from queue.\n                        queue.unlinkx(node);\n\n                        return false;\n                    }\n\n                    // Increment current size.\n                    changeSize(blockSize);\n\n                    return true;\n                }\n                // If node was unlinked by concurrent shrink() call, we must repeat the whole cycle.\n                else if (!entry.removeMeta(META_NODE, node))\n                    return false;\n            }\n        }\n        else {\n            int oldBlockSize = meta.size();\n\n            Node<Entry<GridGgfsBlockKey, byte[]>> node = meta.node();\n\n            if (queue.unlinkx(node)) {\n                // Move node to tail.\n                Node<Entry<GridGgfsBlockKey, byte[]>> newNode = queue.offerLastx(entry);\n\n                int delta = blockSize - oldBlockSize;\n\n                if (!entry.replaceMeta(META_NODE, meta, new MetaEntry(newNode, blockSize))) {\n                    // Was concurrently added, need to clear it from queue.\n                    if (queue.unlinkx(newNode))\n                        delta -= blockSize;\n                }\n\n                if (delta != 0) {\n                    changeSize(delta);\n\n                   if (delta > 0)\n                       // Total size increased, so shrinking could be needed.\n                       return true;\n                }\n            }\n        }\n\n        // Entry is already in queue.\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-13157-Param-0",
    "old_comment_raw": "@param nodeId Node ID.",
    "new_code_raw": "    private GridProjection forOthers(Collection<UUID> excludeIds) {\n        assert excludeIds != null;\n\n        if (ids != null) {\n            guard();\n\n            try {\n                Set<UUID> nodeIds = new HashSet<>(ids.size());\n\n                for (UUID id : ids) {\n                    if (!excludeIds.contains(id))\n                        nodeIds.add(id);\n                }\n\n                return new GridProjectionAdapter(this, ctx, nodeIds);\n            }\n            finally {\n                unguard();\n            }\n        }\n        else\n            return forPredicate(new OthersFilter(excludeIds));\n    }\n"
  },
  {
    "id": "apache_ignite-5772-Param-1",
    "old_comment_raw": "@param topOrder Maximum allowed node order.",
    "new_code_raw": "    public static Collection<ClusterNode> allNodes(GridCacheSharedContext ctx, AffinityTopologyVersion topOrder) {\n        return ctx.discovery().cacheNodes(topOrder);\n    }\n"
  },
  {
    "id": "apache_ignite-12212-Param-0",
    "old_comment_raw": "@param recipient ID of the recipient.",
    "new_code_raw": "        public boolean addRecipient(Object rcpt) {\n            synchronized (recipients) {\n                if (isDone())\n                    return false;\n\n                assert !recipients.containsKey(rcpt) : rcpt + \" -> \" + recipients;\n\n                recipients.put(rcpt, new QueueIterator(rcpt));\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "apache_ignite-13368-Param-2",
    "old_comment_raw": "@param len Length.",
    "new_code_raw": "    private static String parseExpression(String text, int startPos, int len, OdbcEscapeType type, Pattern pattern) {\n        String val = parseExpression(text, startPos, len);\n\n        if (!pattern.matcher(val).matches())\n            throw new IgniteException(\"Invalid \" + type + \" escape sequence: \" + substring(text, startPos, len));\n\n        return val;\n    }\n"
  },
  {
    "id": "gephi_gephi-406-Param-1",
    "old_comment_raw": "@param pDegrees",
    "new_code_raw": "    public double finalQ(int[] struct, double[] degrees, HierarchicalUndirectedGraph graph, AttributeModel attributeModel) {\n        AttributeTable nodeTable = attributeModel.getNodeTable();\n        AttributeColumn modCol = nodeTable.getColumn(MODULARITY_CLASS);\n        if (modCol == null) {\n            modCol = nodeTable.addColumn(MODULARITY_CLASS, \"Modularity Class\", AttributeType.INT, AttributeOrigin.COMPUTED, new Integer(0));\n        }\n\n        double res = 0;\n        double[] internal = new double[degrees.length];\n        for (Node n : graph.getNodes()) {\n            int n_index = structure.map.get(n);\n            AttributeRow row = (AttributeRow) n.getNodeData().getAttributes();\n            row.setValue(modCol, struct[n_index]);\n            for (Node neighbor : graph.getNeighbors(n)) {\n                if (n == neighbor) {\n                    continue;\n                }\n                int neigh_index = structure.map.get(neighbor);\n                if (struct[neigh_index] == struct[n_index]) {\n                    internal[struct[neigh_index]]++;\n                }\n            }\n        }\n        for (int i = 0; i < degrees.length; i++) {\n            internal[i] /= 2.0;\n            res += (internal[i] / graph.getEdgeCount()) - Math.pow(degrees[i] / (2 * graph.getEdgeCount()), 2);\n        }\n        return res;\n    }\n"
  },
  {
    "id": "mockito_mockito-173-Param-0",
    "old_comment_raw": "@param matcher decides whether argument matches",
    "new_code_raw": "    public static char charThat(ArgumentMatcher<Character> matcher) {\n        return reportMatcher(matcher).returnChar();\n    }\n"
  },
  {
    "id": "apache_ignite-12179-Param-1",
    "old_comment_raw": "@param c Cache.",
    "new_code_raw": "    public static VisorCacheMetrics from(IgniteEx ignite, String cacheName) {\n        VisorCacheMetrics cm = new VisorCacheMetrics();\n\n        GridCacheProcessor cacheProcessor = ignite.context().cache();\n\n        IgniteCache<Object, Object> c = cacheProcessor.jcache(cacheName);\n\n        cm.name = cacheName;\n        cm.mode = cacheProcessor.cacheMode(cacheName);\n        cm.sys = cacheProcessor.systemCache(cacheName);\n\n        CacheMetrics m = c.metrics();\n\n        cm.size = m.getSize();\n        cm.keySize = m.getKeySize();\n\n        cm.reads = m.getCacheGets();\n        cm.writes = m.getCachePuts() + m.getCacheRemovals();\n        cm.hits = m.getCacheHits();\n        cm.misses = m.getCacheMisses();\n\n        cm.txCommits = m.getCacheTxCommits();\n        cm.txRollbacks = m.getCacheTxRollbacks();\n\n        cm.avgTxCommitTime = m.getAverageTxCommitTime();\n        cm.avgTxRollbackTime = m.getAverageTxRollbackTime();\n\n        cm.puts = m.getCachePuts();\n        cm.removals = m.getCacheRemovals();\n        cm.evictions = m.getCacheEvictions();\n\n        cm.avgReadTime = m.getAverageGetTime();\n        cm.avgPutTime = m.getAveragePutTime();\n        cm.avgRemovalTime = m.getAverageRemoveTime();\n\n        cm.readsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageGetTime());\n        cm.writesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAveragePutTime());\n        cm.hitsPerSec = -1;\n        cm.missesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageRemoveTime());\n        cm.commitsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxCommitTime());\n        cm.rollbacksPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxRollbackTime());\n\n        cm.qryMetrics = VisorCacheQueryMetrics.from(c.queryMetrics());\n\n        cm.dhtEvictQueueCurrSize = m.getDhtEvictQueueCurrentSize();\n        cm.txThreadMapSize = m.getTxThreadMapSize();\n        cm.txXidMapSize = m.getTxXidMapSize();\n        cm.txCommitQueueSize = m.getTxCommitQueueSize();\n        cm.txPrepareQueueSize = m.getTxPrepareQueueSize();\n        cm.txStartVerCountsSize = m.getTxStartVersionCountsSize();\n        cm.txCommittedVersionsSize = m.getTxCommittedVersionsSize();\n        cm.txRolledbackVersionsSize = m.getTxRolledbackVersionsSize();\n        cm.txDhtThreadMapSize = m.getTxDhtThreadMapSize();\n        cm.txDhtXidMapSize = m.getTxDhtXidMapSize();\n        cm.txDhtCommitQueueSize = m.getTxDhtCommitQueueSize();\n        cm.txDhtPrepareQueueSize = m.getTxDhtPrepareQueueSize();\n        cm.txDhtStartVerCountsSize = m.getTxDhtStartVersionCountsSize();\n        cm.txDhtCommittedVersionsSize = m.getTxDhtCommittedVersionsSize();\n        cm.txDhtRolledbackVersionsSize = m.getTxDhtRolledbackVersionsSize();\n\n        return cm;\n    }\n"
  },
  {
    "id": "shopizer_ecommerce_shopizer-25-Param-0",
    "old_comment_raw": "@param store",
    "new_code_raw": "  private Criteria createCriteria(HttpServletRequest request) {\n    Criteria criteria = ServiceRequestCriteriaBuilderUtils.buildRequest(MAPPING_FIELDS, request);\n\n    //Optional.ofNullable(start).ifPresent(criteria::setStartIndex);\n    //Optional.ofNullable(count).ifPresent(criteria::setMaxCount);\n\n    return criteria;\n  }\n"
  },
  {
    "id": "apache_ignite-13352-Param-1",
    "old_comment_raw": "@param c Actual cache.",
    "new_code_raw": "    public VisorCache from(IgniteEx ignite, String cacheName, int sample) throws IgniteCheckedException {\n        assert ignite != null;\n\n        GridCacheAdapter ca = ignite.context().cache().internalCache(cacheName);\n\n        // Cache was not started.\n        if (ca == null || !ca.context().started())\n            return null;\n\n        GridCacheContext cctx = ca.context();\n\n        name = cacheName;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cctx.affinityNode();\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0) {\n                    partitionsMap = top.localPartitionMap();\n                }\n            }\n        }\n\n        size = ca.size();\n        nearSize = ca.nearSize();\n        dynamicDeploymentId = cctx.dynamicDeploymentId();\n        dhtSize = size - nearSize;\n        primarySize = ca.primarySize();\n        offHeapAllocatedSize = ca.offHeapAllocatedSize();\n        offHeapEntriesCnt = ca.offHeapEntriesCount();\n        partitions = ca.affinity().partitions();\n        metrics = new VisorCacheMetrics().from(ignite, cacheName);\n        near = cctx.isNear();\n\n        estimateMemorySize(ignite, ca, sample);\n\n        return this;\n    }\n"
  },
  {
    "id": "apache_ignite-5031-Param-1",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    private boolean mapAsPrimary(Collection<? extends K> keys, AffinityTopologyVersion topVer) throws IgniteCheckedException {\n        // Assign keys to primary nodes.\n        Collection<K> distributedKeys = new ArrayList<>(keys.size());\n\n        for (K key : keys) {\n            if (!cctx.affinity().primary(cctx.localNode(), key, topVer)) {\n                // Remove explicit locks added so far.\n                for (K k : keys)\n                    cctx.mvcc().removeExplicitLock(threadId, k, lockVer);\n\n                return false;\n            }\n\n            addLocalKey(key, topVer, distributedKeys);\n\n            if (isDone())\n                return true;\n        }\n\n        trackable = false;\n\n        if (tx != null)\n            tx.colocatedLocallyMapped(true);\n\n        if (!distributedKeys.isEmpty()) {\n            if (tx != null) {\n                for (K key : distributedKeys)\n                    tx.addKeyMapping(cctx.txKey(key), cctx.localNode());\n            }\n\n            lockLocally(distributedKeys, topVer, null);\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-1891-Param-0",
    "old_comment_raw": "@param filter Filter.",
    "new_code_raw": "    public Collection<V> values(IgnitePredicate<GridCacheEntry<K, V>>... filter) {\n        checkWeakQueue();\n\n        return allValues(filter);\n    }\n"
  },
  {
    "id": "CalebFenton_simplify-18-Param-0",
    "old_comment_raw": "@param methodDescriptor",
    "new_code_raw": "    public boolean isLocalMethod(String methodSignature) {\n        String[] parts = methodSignature.split(\"->\");\n        String className = parts[0];\n        if (!isLocalClass(className)) {\n            return false;\n        }\n\n        return getMethod(methodSignature) != null;\n    }\n"
  },
  {
    "id": "apache_ignite-5775-Param-0",
    "old_comment_raw": "@param ctx Cache context.",
    "new_code_raw": "    public static Collection<ClusterNode> aliveRemoteNodes(final GridCacheContext ctx, AffinityTopologyVersion topOrder) {\n        return ctx.discovery().aliveRemoteCacheNodes(ctx.namex(), topOrder);\n    }\n"
  },
  {
    "id": "apache_ignite-11589-Param-0",
    "old_comment_raw": "@param taskInfo Task info.",
    "new_code_raw": "    public GridHadoopTaskInput input(GridHadoopTaskContext taskCtx) throws GridException {\n        switch (taskCtx.taskInfo().type()) {\n            case COMBINE:\n                return combinerMap.input((Comparator<Object>)job.combineGroupComparator());\n\n            case REDUCE:\n                int reducer = taskCtx.taskInfo().taskNumber();\n\n                GridHadoopMultimap m = maps.get(reducer);\n\n                if (m != null)\n                    return m.input((Comparator<Object>)job.reduceGroupComparator());\n\n                return new GridHadoopTaskInput() { // Empty input.\n                    @Override public boolean next() {\n                        return false;\n                    }\n\n                    @Override public Object key() {\n                        throw new IllegalStateException();\n                    }\n\n                    @Override public Iterator<?> values() {\n                        throw new IllegalStateException();\n                    }\n\n                    @Override public void close() {\n                        // No-op.\n                    }\n                };\n\n            default:\n                throw new IllegalStateException(\"Illegal type: \" + taskCtx.taskInfo().type());\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-6458-Param-0",
    "old_comment_raw": "@param cache Cache.",
    "new_code_raw": "    private Thread runCacheOperations(final IgniteInternalCache<Object,Object> cache, final int keys) {\n        Thread t = new Thread() {\n            @Override public void run() {\n                while (run) {\n                    TreeMap<Integer, String> vals = generateValues(keys);\n\n                    try {\n                        // Explicit lock.\n                        cache.lock(vals.firstKey(), 0);\n\n                        try {\n                            // Put or remove.\n                            if (ThreadLocalRandom.current().nextDouble(1) < 0.65)\n                                cache.putAll(vals);\n                            else\n                                cache.removeAll(vals.keySet());\n                        }\n                        catch (Exception e) {\n                            U.error(log(), \"Failed cache operation.\", e);\n                        }\n                        finally {\n                            cache.unlock(vals.firstKey());\n                        }\n\n                        U.sleep(100);\n                    }\n                    catch (Exception e){\n                        U.error(log(), \"Failed unlock.\", e);\n                    }\n                }\n            }\n        };\n\n        t.start();\n\n        return t;\n    }\n"
  },
  {
    "id": "apache_ignite-13302-Param-1",
    "old_comment_raw": "@param deserializePortable Deserialize portable flag.",
    "new_code_raw": "    @Nullable public V get(K key, boolean deserializeBinary)\n        throws IgniteCheckedException {\n        return getAsync(key, deserializeBinary).get();\n    }\n"
  },
  {
    "id": "apache_ignite-6131-Param-0",
    "old_comment_raw": "@param aff Cache affinity.",
    "new_code_raw": "    private Object keyForNode(Affinity<Object> aff, ClusterNode node) {\n        assertNotNull(node);\n\n        Object key = null;\n\n        for (int i = 0; i < 1000; i++) {\n            if (aff.isPrimary(node, i)) {\n                key = i;\n\n                break;\n            }\n        }\n\n        assertNotNull(key);\n\n        return key;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-949-Param-0",
    "old_comment_raw": "@param deviceNumber The bulb number the bridge has filed the bulb under.",
    "new_code_raw": "\tpublic int getColorTemperature(String deviceId) {\n\t\tif (settingsData == null) {\n\t\t\tlogger.error(\"Hue bridge settings not initialized correctly.\");\n\t\t\treturn 154;\n\t\t}\n\t\tObject ct = settingsData.node(\"lights\").node(deviceId).node(\"state\").value(\"ct\");\n\t\tif(ct instanceof Integer) {\n\t\t\treturn (Integer) ct;\n\t\t} else {\n\t\t\treturn 154;\n\t\t}\n\t}\n"
  },
  {
    "id": "apache_ignite-5701-Param-1",
    "old_comment_raw": "@param obsoleteVer Obsolete version.",
    "new_code_raw": "    protected boolean evictNearEntry(GridCacheEntryEx<K, V> e, GridCacheVersion obsoleteVer, long topVer) {\n        assert e != null;\n        assert obsoleteVer != null;\n\n        if (isNearLocallyMapped(e, topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Evicting dht-local entry from near cache [entry=\" + e + \", tx=\" + this + ']');\n\n            if (e.markObsolete(obsoleteVer))\n                return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-11546-Param-1",
    "old_comment_raw": "@param unique Unique index.",
    "new_code_raw": "        public IndexDescriptor addIndex(String idxName, GridIndexType type) throws GridException {\n            IndexDescriptor idx = new IndexDescriptor(type);\n\n            if (indexes.put(idxName, idx) != null)\n                throw new GridException(\"Index with name '\" + idxName + \"' already exists.\");\n\n            return idx;\n        }\n"
  },
  {
    "id": "apache_ignite-10502-Param-0",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "    public Collection<ClusterNode> remoteCacheNodes(AffinityTopologyVersion topVer) {\n        return resolveDiscoCache(null, topVer).remoteCacheNodes(topVer.topologyVersion());\n    }\n"
  },
  {
    "id": "xetorthio_jedis-779-Param-1",
    "old_comment_raw": "@param string",
    "new_code_raw": "    public Long lpush(final byte[] key, final byte[]... strings) {\n        checkIsInMulti();\n        client.lpush(key, strings);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-1309-Param-0",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    long entryExpireTime(GridCacheTxKey<K> key) {\n        assert key != null;\n\n        GridCacheTxEntry<K, V> e = entry(key);\n\n        if (e != null) {\n            long ttl = e.ttl();\n\n            assert ttl != -1;\n\n            if (ttl > 0) {\n                long expireTime = U.currentTimeMillis() + ttl;\n\n                if (expireTime > 0)\n                    return expireTime;\n            }\n        }\n\n        return 0;\n    }\n"
  },
  {
    "id": "apache_ignite-13245-Param-1",
    "old_comment_raw": "@param i Start index for parameters.",
    "new_code_raw": "    protected int fillValueParameters(PreparedStatement stmt, int idx, EntryMapping em, Object val)\n        throws CacheWriterException {\n        for (CacheTypeFieldMetadata field : em.uniqValFields) {\n            Object fieldVal = extractField(em.cacheName, em.valueType(), field.getJavaName(), val);\n\n            try {\n                if (fieldVal != null)\n                    stmt.setObject(idx++, fieldVal);\n                else\n                    stmt.setNull(idx++, field.getDatabaseType());\n            }\n            catch (SQLException e) {\n                throw new CacheWriterException(\"Failed to set statement parameter name: \" + field.getDatabaseName(), e);\n            }\n        }\n\n        return idx;\n    }\n"
  },
  {
    "id": "apache_ignite-2358-Param-2",
    "old_comment_raw": "@param props Properties to be applied.",
    "new_code_raw": "    public boolean mkdirsDual(final IgniteFsFileSystem fs, final IgniteFsPath path, final Map<String, String> props)\n        throws GridException {\n        if (busyLock.enterBusy()) {\n            try {\n                assert fs != null;\n                assert path != null;\n                assert props != null;\n\n                if (path.parent() == null)\n                    return true; // No additional handling for root directory is needed.\n\n                // Events to fire (can be done outside of a transaction).\n                final Deque<IgniteFsEvent> pendingEvts = new LinkedList<>();\n\n                SynchronizationTask<Boolean> task = new SynchronizationTask<Boolean>() {\n                    @Override public Boolean onSuccess(Map<IgniteFsPath, GridGgfsFileInfo> infos) throws Exception {\n                        fs.mkdirs(path, props);\n\n                        assert !infos.isEmpty();\n\n                        // Now perform synchronization again starting with the last created parent.\n                        IgniteFsPath parentPath = null;\n\n                        for (IgniteFsPath curPath : infos.keySet()) {\n                            if (parentPath == null || curPath.isSubDirectoryOf(parentPath))\n                                parentPath = curPath;\n                        }\n\n                        assert parentPath != null;\n\n                        GridGgfsFileInfo parentPathInfo = infos.get(parentPath);\n\n                        synchronize(fs, parentPath, parentPathInfo, path, true, null);\n\n                        if (evts.isRecordable(EVT_GGFS_DIR_CREATED)) {\n                            IgniteFsPath evtPath = path;\n\n                            while (!parentPath.equals(evtPath)) {\n                                pendingEvts.addFirst(new IgniteFsEvent(evtPath, locNode, EVT_GGFS_DIR_CREATED));\n\n                                evtPath = evtPath.parent();\n\n                                assert evtPath != null; // If this fails, then ROOT does not exist.\n                            }\n                        }\n\n                        return true;\n                    }\n\n                    @Override public Boolean onFailure(@Nullable Exception err) throws GridException {\n                        U.error(log, \"Directory creation in DUAL mode failed [path=\" + path + \", properties=\" + props +\n                            ']', err);\n\n                        throw new GridException(\"Failed to create the path due to secondary file system exception: \" +\n                            path, err);\n                    }\n                };\n\n                try {\n                    return synchronizeAndExecute(task, fs, false, path.parent());\n                }\n                finally {\n                    for (IgniteFsEvent evt : pendingEvts)\n                        evts.record(evt);\n                }\n            }\n            finally {\n                busyLock.leaveBusy();\n            }\n        }\n        else\n            throw new IllegalStateException(\"Failed to create directory in DUAL mode because Grid is stopping: \" +\n                path);\n    }\n"
  },
  {
    "id": "mockito_mockito-1202-Param-0",
    "old_comment_raw": "@param millis - duration in milliseconds",
    "new_code_raw": "    public static VerificationAfterDelay after(Duration delay) {\n        return new After(delay, VerificationModeFactory.times(1));\n    }\n"
  },
  {
    "id": "haifengl_smile-61-Param-1",
    "old_comment_raw": "@param k the number of cluster.",
    "new_code_raw": "    public static int[] seed(double[][] data, int k, ClusteringDistance distance) {\n        int n = data.length;\n        int[] y = new int[n];\n        double[] centroid = data[Math.randomInt(n)];\n\n        double[] d = new double[n];\n        for (int i = 0; i < n; i++) {\n            d[i] = Double.MAX_VALUE;\n        }\n\n        // pick the next center\n        for (int j = 1; j < k; j++) {\n            // Loop over the samples and compare them to the most recent center.  Store\n            // the distance from each sample to its closest center in scores.\n            for (int i = 0; i < n; i++) {\n                // compute the distance between this sample and the current center\n                double dist = 0.0;\n                switch (distance) {\n                    case EUCLIDEAN:\n                        dist = Math.squaredDistance(data[i], centroid);\n                        break;\n                    case EUCLIDEAN_MISSING_VALUES:\n                        dist = squaredDistance(data[i], centroid);\n                        break;\n                    case JENSEN_SHANNON_DIVERGENCE:\n                        dist = Math.JensenShannonDivergence(data[i], centroid);\n                        break;\n                }\n                \n                if (dist < d[i]) {\n                    d[i] = dist;\n                    y[i] = j - 1;\n                }\n            }\n\n            double cutoff = Math.random() * Math.sum(d);\n            double cost = 0.0;\n            int index = 0;\n            for (; index < n; index++) {\n                cost += d[index];\n                if (cost >= cutoff) {\n                    break;\n                }\n            }\n\n            centroid = data[index];\n        }\n\n        for (int i = 0; i < n; i++) {\n            // compute the distance between this sample and the current center\n            double dist = 0.0;\n            switch (distance) {\n                case EUCLIDEAN:\n                    dist = Math.squaredDistance(data[i], centroid);\n                    break;\n                case EUCLIDEAN_MISSING_VALUES:\n                    dist = squaredDistance(data[i], centroid);\n                    break;\n                case JENSEN_SHANNON_DIVERGENCE:\n                    dist = Math.JensenShannonDivergence(data[i], centroid);\n                    break;\n            }\n            \n            if (dist < d[i]) {\n                d[i] = dist;\n                y[i] = k - 1;\n            }\n        }\n\n        return y;\n    }\n"
  },
  {
    "id": "purplecabbage_phonegap_plugins-33-Param-2",
    "old_comment_raw": "@param callbackContext The callback context used when calling back into JavaScript.",
    "new_code_raw": "    public PluginResult execute(String action, JSONArray data, String callbackId) {\n        PluginResult result = null;\n        if (NOTIFY.equals(action)) {\n            try {\n                String tag = data.getString(0);\n                String title = data.getString(1);\n                String body = data.getString(2);\n                Log.d(\"NotificationPlugin\", \"Notification: \" + tag + \", \" + title + \", \" + body);\n                showNotification(tag, title, body);\n                result = new PluginResult(Status.OK);\n            } catch (JSONException jsonEx) {\n                Log.d(\"NotificationPlugin\", \"Got JSON Exception \"\n                        + jsonEx.getMessage());\n                result = new PluginResult(Status.JSON_EXCEPTION);\n            }\n        } else if (CLEAR.equals(action)){\n            try {\n                String tag = data.getString(0);\n                Log.d(\"NotificationPlugin\", \"Notification cancel: \" + tag);\n                clearNotification(tag);\n            } catch (JSONException jsonEx) {\n                Log.d(\"NotificationPlugin\", \"Got JSON Exception \" + jsonEx.getMessage());\n                result = new PluginResult(Status.JSON_EXCEPTION);\n            }\n        } else {\n            result = new PluginResult(Status.INVALID_ACTION);\n            Log.d(\"NotificationPlugin\", \"Invalid action : \"+action+\" passed\");\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-1884-Param-0",
    "old_comment_raw": "@param ids Ids to include.",
    "new_code_raw": "    public Collection<ClusterNode> nodes(@Nullable Collection<UUID> ids, IgnitePredicate<UUID>... p) {\n        return F.isEmpty(ids) ? Collections.<ClusterNode>emptyList() :\n            F.view(\n                F.viewReadOnly(ids, U.id2Node(ctx), p),\n                F.notNull());\n    }\n"
  },
  {
    "id": "essentials_Essentials-235-Param-0",
    "old_comment_raw": "@param userName the username you want",
    "new_code_raw": "\tpublic User createUser(String userId) {\n\n\t\tif (getUsers().containsKey(userId.toLowerCase())) {\n\t\t\treturn null;\n\t\t}\n\t\tUser newUser = new User(this, userId);\n\t\tnewUser.setGroup(groups.getDefaultGroup(), false);\n\t\taddUser(newUser);\n\t\tsetUsersChanged(true);\n\t\treturn newUser;\n\t}\n"
  },
  {
    "id": "h2oai_h2o_2-28-Param-0",
    "old_comment_raw": "@param chol",
    "new_code_raw": "  public Cholesky cholesky(Cholesky chol, int parallelize) {\n    long start = System.currentTimeMillis();\n    if( chol == null ) {\n      double[][] xx = _xx.clone();\n      for( int i = 0; i < xx.length; ++i )\n        xx[i] = xx[i].clone();\n      chol = new Cholesky(xx, _diag.clone());\n    }\n    final Cholesky fchol = chol;\n    final int sparseN = _diag.length;\n    final int denseN = _fullN - sparseN;\n    boolean spd=true;\n    // compute the cholesky of the diagonal and diagonal*dense parts\n    if( _diag != null ) for( int i = 0; i < sparseN; ++i ) {\n      double d = 1.0 / (chol._diag[i] = Math.sqrt(_diag[i]));\n      for( int j = 0; j < denseN; ++j )\n        chol._xx[j][i] = d*_xx[j][i];\n    }\n    Futures fs = new Futures();\n    // compute the outer product of diagonal*dense\n    for( int i = 0; i < denseN; ++i ) {\n      final int fi = i;\n      fs.add(new RecursiveAction() {\n        @Override protected void compute() {\n          for( int j = 0; j <= fi; ++j ) {\n            double s = 0;\n            for( int k = 0; k < sparseN; ++k )\n              s += fchol._xx[fi][k] * fchol._xx[j][k];\n            fchol._xx[fi][j + sparseN] = _xx[fi][j + sparseN] - s;\n          }\n        }\n      }.fork());\n    }\n    fs.blockForPending();\n        \n    // compute the cholesky of dense*dense-outer_product(diagonal*dense)\n    // TODO we still use Jama, which requires (among other things) copy and expansion of the matrix. Do it here without copy and faster.\n    double[][] arr = new double[denseN][];\n    for( int i = 0; i < arr.length; ++i )\n      arr[i] = Arrays.copyOfRange(fchol._xx[i], sparseN, sparseN + denseN);\n\n    Log.info (\"CHOLESKY PRECOMPUTE TIME \" + (System.currentTimeMillis()-start));\n    start = System.currentTimeMillis();\n    // parallelize cholesky\n    if (parallelize == 1) {\n      int p = Runtime.getRuntime().availableProcessors();\n      InPlaceCholesky d = InPlaceCholesky.decompose_2(arr, 10, p);\n      fchol.setSPD(d.isSPD());\n      arr = d.getL();\n      Log.info (\"H2O CHOLESKY DECOMPOSE TAKES: \" + (System.currentTimeMillis()-start));\n    } else {\n      // make it symmetric\n      for( int i = 0; i < arr.length; ++i )\n        for( int j = 0; j < i; ++j )\n          arr[j][i] = arr[i][j];\n      CholeskyDecomposition c = new Matrix(arr).chol();\n      fchol.setSPD(c.isSPD());\n      arr = c.getL().getArray();\n      Log.info (\"JAMA CHOLESKY DECOMPOSE TAKES: \" + (System.currentTimeMillis()-start));\n    }\n    for( int i = 0; i < arr.length; ++i )\n      System.arraycopy(arr[i], 0, fchol._xx[i], sparseN, i + 1);\n    return chol;\n  }\n"
  },
  {
    "id": "guoguibing_librec-222-Param-0",
    "old_comment_raw": "@param col column id",
    "new_code_raw": "\tpublic double columnMean(int column) {\n\t\tdouble sum = 0.0;\n\n\t\tfor (int i = 0; i < numRows; i++)\n\t\t\tsum += data[i][column];\n\n\t\treturn sum / numRows;\n\t}\n"
  },
  {
    "id": "apache_ignite-5200-Param-3",
    "old_comment_raw": "@param topVer Topology version.",
    "new_code_raw": "        private boolean preloadEntry(ClusterNode pick, int p, GridCacheEntryInfo<K, V> entry, AffinityTopologyVersion topVer)\n            throws IgniteCheckedException {\n            try {\n                GridCacheEntryEx<K, V> cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isIgfsDataCache() &&\n                        cctx.dht().igfsDataSpaceUsed() > cctx.dht().igfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload IGFS data cache (IGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            entry.valueBytes(),\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isDrEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (IgniteUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false, null, null, null);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (IgniteInterruptedCheckedException e) {\n                throw e;\n            }\n            catch (IgniteCheckedException e) {\n                throw new IgniteCheckedException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "linkedin_rest.li-8-Associations-Param0",
    "old_comment_raw": "@param ancestorSchema a root resource schema",
    "new_code_raw": "  public List<ResourceSchema> getSubResources(ResourceSchema parentSchema)\n  {\n    return _subResources.get(parentSchema);\n  }\n\n"
  },
  {
    "id": "pockethub_PocketHub-682-Param-0",
    "old_comment_raw": "@param commit",
    "new_code_raw": "    public static Date getCommitterDate(final Commit commit) {\n        GitCommit rawCommit = commit.commit;\n        if (rawCommit == null)\n            return null;\n\n        User commitCommitter = rawCommit.committer;\n        return commitCommitter != null && commitCommitter.date != null? TimeUtils.stringToDate(commitCommitter.date): null;\n    }\n"
  },
  {
    "id": "google_tink-277-Param-1",
    "old_comment_raw": "@param additionalData additional data",
    "new_code_raw": "  public byte[] decrypt(final byte[] ciphertext, final byte[] associatedData)\n      throws GeneralSecurityException {\n    return decrypt(ByteBuffer.wrap(ciphertext), associatedData);\n  }\n"
  },
  {
    "id": "haifengl_smile-257-Param-3",
    "old_comment_raw": "@param measure classification measure as the chromosome fitness measure.",
    "new_code_raw": "    public BitString[] learn(int size, int generation, double[][] x, double[] y, double[][] testx, double[] testy, RegressionMeasure measure, BiFunction<double[][], double[], Regression<double[]>> trainer) {\n        if (size <= 0) {\n            throw new IllegalArgumentException(\"Invalid population size: \" + size);\n        }\n        \n        if (generation <= 0) {\n            throw new IllegalArgumentException(\"Invalid number of generations to go: \" + generation);\n        }\n        \n        if (x.length != y.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of X and Y don't match: %d != %d\", x.length, y.length));\n        }\n\n        if (testx.length != testy.length) {\n            throw new IllegalArgumentException(String.format(\"The sizes of test X and Y don't match: %d != %d\", testx.length, testy.length));\n        }\n\n        int p = x[0].length;\n        RegressionFitness fitness = new RegressionFitness(trainer, measure, x, y, testx, testy);\n        \n        BitString[] seeds = new BitString[size];\n        for (int i = 0; i < size; i++) {\n            seeds[i] = new BitString(p, fitness, crossover, crossoverRate, mutationRate);\n        }\n\n        GeneticAlgorithm<BitString> ga = new GeneticAlgorithm<>(seeds, selection);\n        ga.evolve(generation);       \n        \n        return seeds;        \n    }\n"
  },
  {
    "id": "apache_ignite-13173-Param-0",
    "old_comment_raw": "@param taskName Task name.",
    "new_code_raw": "    private boolean visorTask(String taskCls) {\n        return taskCls.startsWith(VISOR_TASK_PREFIX);\n    }\n"
  },
  {
    "id": "google_tink-65-Param-1",
    "old_comment_raw": "@param format the format for the encoding",
    "new_code_raw": "  public static byte[] ecPointEncode(EllipticCurve curve, EcPointFormat format, ECPoint point)\n      throws GeneralSecurityException {\n    EcUtil.checkPointOnCurve(point, curve);\n    int coordinateSize = EcUtil.fieldSizeInBytes(curve);\n    switch (format) {\n      case UNCOMPRESSED:\n        {\n          byte[] encoded = new byte[2 * coordinateSize + 1];\n          byte[] x = point.getAffineX().toByteArray();\n          byte[] y = point.getAffineY().toByteArray();\n          // Order of System.arraycopy is important because x,y can have leading 0's.\n          System.arraycopy(y, 0, encoded, 1 + 2 * coordinateSize - y.length, y.length);\n          System.arraycopy(x, 0, encoded, 1 + coordinateSize - x.length, x.length);\n          encoded[0] = 4;\n          return encoded;\n        }\n      case COMPRESSED:\n        {\n          byte[] encoded = new byte[coordinateSize + 1];\n          byte[] x = point.getAffineX().toByteArray();\n          System.arraycopy(x, 0, encoded, 1 + coordinateSize - x.length, x.length);\n          encoded[0] = (byte) (point.getAffineY().testBit(0) ? 3 : 2);\n          return encoded;\n        }\n      default:\n        throw new GeneralSecurityException(\"Invalid format:\" + format);\n    }\n  }\n"
  },
  {
    "id": "apache_ignite-12203-Param-0",
    "old_comment_raw": "@param serverNodesNum Server nodes number.",
    "new_code_raw": "    private String topologySnapshotMessage(int srvNodesNum, int clientNodesNum, int totalCpus, double heap) {\n        return PREFIX + \" [\" +\n            (discoOrdered ? \"ver=\" + topSnap.get().topVer.topologyVersion() + \", \" : \"\") +\n            \"server nodes=\" + srvNodesNum +\n            \", client nodes=\" + clientNodesNum +\n            \", CPUs=\" + totalCpus +\n            \", heap=\" + heap + \"GB\" +\n            ']';\n    }\n"
  },
  {
    "id": "apache_ignite-5989-Param-0",
    "old_comment_raw": "@param igfs IGFS configuration.",
    "new_code_raw": "    public static VisorIgfsConfiguration from(IgfsConfiguration igfs) {\n        VisorIgfsConfiguration cfg = new VisorIgfsConfiguration();\n\n        cfg.name(igfs.getName());\n        cfg.metaCacheName(igfs.getMetaCacheName());\n        cfg.dataCacheName(igfs.getDataCacheName());\n        cfg.blockSize(igfs.getBlockSize());\n        cfg.prefetchBlocks(igfs.getPrefetchBlocks());\n        cfg.streamBufferSize(igfs.getStreamBufferSize());\n        cfg.perNodeBatchSize(igfs.getPerNodeBatchSize());\n        cfg.perNodeParallelBatchCount(igfs.getPerNodeParallelBatchCount());\n\n        Igfs secFs = igfs.getSecondaryFileSystem();\n\n        if (secFs != null) {\n            Map<String, String> props = secFs.properties();\n\n            cfg.secondaryHadoopFileSystemUri(props.get(SECONDARY_FS_URI));\n            cfg.secondaryHadoopFileSystemConfigPath(props.get(SECONDARY_FS_CONFIG_PATH));\n        }\n\n        cfg.defaultMode(igfs.getDefaultMode());\n        cfg.pathModes(igfs.getPathModes());\n        cfg.dualModePutExecutorService(compactClass(igfs.getDualModePutExecutorService()));\n        cfg.dualModePutExecutorServiceShutdown(igfs.getDualModePutExecutorServiceShutdown());\n        cfg.dualModeMaxPendingPutsSize(igfs.getDualModeMaxPendingPutsSize());\n        cfg.maxTaskRangeLength(igfs.getMaximumTaskRangeLength());\n        cfg.fragmentizerConcurrentFiles(igfs.getFragmentizerConcurrentFiles());\n        cfg.fragmentizerLocalWritesRatio(igfs.getFragmentizerLocalWritesRatio());\n        cfg.fragmentizerEnabled(igfs.isFragmentizerEnabled());\n        cfg.fragmentizerThrottlingBlockLength(igfs.getFragmentizerThrottlingBlockLength());\n        cfg.fragmentizerThrottlingDelay(igfs.getFragmentizerThrottlingDelay());\n\n        Map<String, String> endpointCfg = igfs.getIpcEndpointConfiguration();\n        cfg.ipcEndpointConfiguration(endpointCfg != null ? endpointCfg.toString() : null);\n\n        cfg.ipcEndpointEnabled(igfs.isIpcEndpointEnabled());\n        cfg.maxSpace(igfs.getMaxSpaceSize());\n        cfg.managementPort(igfs.getManagementPort());\n        cfg.sequenceReadsBeforePrefetch(igfs.getSequentialReadsBeforePrefetch());\n        cfg.trashPurgeTimeout(igfs.getTrashPurgeTimeout());\n\n        return cfg;\n    }\n"
  },
  {
    "id": "react_native_community_react_native_svg-14-Param-2",
    "old_comment_raw": "@param offset offset number",
    "new_code_raw": "    static float fromRelativeToFloat(String length, float relative, float offset, float scale, float fontSize) {\n        /*\n            TODO list\n\n            unit\trelative to\n            em\t    font size of the element\n            ex\t    x-height of the element\u00e2\u0080\u0099s font\n            ch\t    width of the \"0\" (ZERO, U+0030) glyph in the element\u00e2\u0080\u0099s font\n            rem\t    font size of the root element\n            vw\t    1% of viewport\u00e2\u0080\u0099s width\n            vh\t    1% of viewport\u00e2\u0080\u0099s height\n            vmin\t1% of viewport\u00e2\u0080\u0099s smaller dimension\n            vmax\t1% of viewport\u00e2\u0080\u0099s larger dimension\n\n            relative-size [ larger | smaller ]\n            absolute-size: [ xx-small | x-small | small | medium | large | x-large | xx-large ]\n\n            https://www.w3.org/TR/css3-values/#relative-lengths\n            https://www.w3.org/TR/css3-values/#absolute-lengths\n            https://drafts.csswg.org/css-cascade-4/#computed-value\n            https://drafts.csswg.org/css-fonts-3/#propdef-font-size\n            https://drafts.csswg.org/css2/fonts.html#propdef-font-size\n        */\n        length = length.trim();\n        int stringLength = length.length();\n        int percentIndex = stringLength - 1;\n        if (stringLength == 0) {\n            return offset;\n        } else if (length.codePointAt(percentIndex) == '%') {\n            return Float.valueOf(length.substring(0, percentIndex)) / 100 * relative + offset;\n        } else {\n            int twoLetterUnitIndex = stringLength - 2;\n            if (twoLetterUnitIndex > 0) {\n                String lastTwo = length.substring(twoLetterUnitIndex);\n                int end = twoLetterUnitIndex;\n                float unit = 1;\n\n                switch (lastTwo) {\n                    case \"px\":\n                        break;\n\n                    case \"em\":\n                        unit = fontSize;\n                        break;\n\n                    /*\n                     \"1pt\" equals \"1.25px\" (and therefore 1.25 user units)\n                     \"1pc\" equals \"15px\" (and therefore 15 user units)\n                     \"1mm\" would be \"3.543307px\" (3.543307 user units)\n                     \"1cm\" equals \"35.43307px\" (and therefore 35.43307 user units)\n                     \"1in\" equals \"90px\" (and therefore 90 user units)\n                     */\n\n                    case \"pt\":\n                        unit = 1.25f;\n                        break;\n\n                    case \"pc\":\n                        unit = 15;\n                        break;\n\n                    case \"mm\":\n                        unit = 3.543307f;\n                        break;\n\n                    case \"cm\":\n                        unit = 35.43307f;\n                        break;\n\n                    case \"in\":\n                        unit = 90;\n                        break;\n\n                    default:\n                        end = stringLength;\n                }\n\n                return Float.valueOf(length.substring(0, end)) * unit * scale + offset;\n            } else {\n                return Float.valueOf(length) * scale + offset;\n            }\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-2229-Param-2",
    "old_comment_raw": "@param allSigned If  true then all files must be signed.",
    "new_code_raw": "    static boolean verify(String jarName, PublicKey pubKey, boolean allSigned, IgniteLogger log)\n        throws IOException {\n        assert jarName != null;\n        assert pubKey != null;\n\n        return verify0(jarName, pubKey, allSigned, log);\n    }\n"
  },
  {
    "id": "apache_shiro-725-Param-0",
    "old_comment_raw": "@param account the Account stored in the data store to be compared against the submitted authentication token's credentials.",
    "new_code_raw": "    protected Object getCredentials(AuthenticationInfo info) {\n        return info.getCredentials();\n    }\n"
  },
  {
    "id": "apache_ignite-4010-Param-1",
    "old_comment_raw": "@param cache Cache.",
    "new_code_raw": "                private boolean undeploy(Entry<K, V> e, GridCacheAdapter<K, V> cache) {\n                    K k = e.getKey();\n\n                    GridCacheEntryEx<K, V> entry = cache.peekEx(e.getKey());\n\n                    if (entry == null)\n                        return false;\n\n                    V v;\n\n                    try {\n                        v = entry.peek(GridCachePeekMode.GLOBAL, CU.<K, V>empty());\n                    }\n                    catch (GridCacheEntryRemovedException ignore) {\n                        return false;\n                    }\n                    catch (IgniteException ignore) {\n                        // Peek can throw runtime exception if unmarshalling failed.\n                        return true;\n                    }\n\n                    assert k != null : \"Key cannot be null for cache entry: \" + e;\n\n                    ClassLoader keyLdr = U.detectObjectClassLoader(k);\n                    ClassLoader valLdr = U.detectObjectClassLoader(v);\n\n                    boolean res = F.eq(ldr, keyLdr) || F.eq(ldr, valLdr);\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Finished examining entry [entryCls=\" + e.getClass() +\n                            \", key=\" + k + \", keyCls=\" + k.getClass() +\n                            \", valCls=\" + (v != null ? v.getClass() : \"null\") +\n                            \", keyLdr=\" + keyLdr + \", valLdr=\" + valLdr + \", res=\" + res + ']');\n\n                    return res;\n                }\n"
  },
  {
    "id": "aurelhubert_ahbottomnavigation-0-Param-0",
    "old_comment_raw": "@param view",
    "new_code_raw": "\tpublic static boolean isTranslucentStatusBar(Context context) {\n\t\tWindow w = unwrap(context).getWindow();\n\t\tWindowManager.LayoutParams lp = w.getAttributes();\n\t\tint flags = lp.flags;\n\t\tif ((flags & WindowManager.LayoutParams.FLAG_TRANSLUCENT_NAVIGATION) == WindowManager.LayoutParams.FLAG_TRANSLUCENT_NAVIGATION) {\n\t\t\treturn true;\n\t\t}\n\n\t\treturn false;\n\t}\n"
  },
  {
    "id": "apache_ignite-2872-Param-2",
    "old_comment_raw": "@param val Value.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteTx tx, K key, V val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key instanceof GridCacheInternal)\n                return true;\n\n            if (convertPortable) {\n                key = (K)cctx.unwrapPortableIfNeeded(key, false);\n                val = (V)cctx.unwrapPortableIfNeeded(val, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            try {\n                store.put(tx, key, locStore ? F.t(val, ver) : val);\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-13178-Param-1",
    "old_comment_raw": "@param localCombiner If we have mapper with combiner.",
    "new_code_raw": "    private GridHadoopTaskInput createInput(GridHadoopTaskContext ctx, boolean locCombiner) throws GridException {\n        switch (ctx.taskInfo().type()) {\n            case SETUP:\n            case MAP:\n            case COMMIT:\n            case ABORT:\n                return null;\n\n            case COMBINE:\n                if (locCombiner) {\n                    assert local != null;\n\n                    return local.input((Comparator<Object>)job.combineGroupComparator());\n                }\n\n            default:\n                return createInput(ctx);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-4894-Param-0",
    "old_comment_raw": "@param skipped Skipped set (possibly  null).",
    "new_code_raw": "    private Set<KeyCacheObject> skip(Set<KeyCacheObject> skipped, KeyCacheObject key) {\n        if (skipped == null)\n            skipped = new GridLeanSet<>();\n\n        skipped.add(key);\n\n        if (log.isDebugEnabled())\n            log.debug(\"Added key to skipped set: \" + key);\n\n        return skipped;\n    }\n"
  },
  {
    "id": "spring_projects_spring_kafka-135-Param-0",
    "old_comment_raw": "@param categories the categories to use for logging level adjusting",
    "new_code_raw": "\tpublic Log4j2LevelAdjuster categories(String... categoriesToAdjust) {\n\t\treturn categories(false, categoriesToAdjust);\n\t}\n"
  },
  {
    "id": "natario1_CameraView-73-Param-1",
    "old_comment_raw": "@param time timestamp",
    "new_code_raw": "    public Frame getFrame(@NonNull T data, long time, int rotation) {\n        if (!isSetUp()) {\n            throw new IllegalStateException(\"Can't call getFrame() after releasing \" +\n                    \"or before setUp.\");\n        }\n\n        Frame frame = mFrameQueue.poll();\n        if (frame != null) {\n            LOG.v(\"getFrame for time:\", time, \"RECYCLING.\");\n        } else {\n            LOG.v(\"getFrame for time:\", time, \"CREATING.\");\n            frame = new Frame(this);\n        }\n        frame.setContent(data, time, rotation, mFrameSize, mFrameFormat);\n        return frame;\n    }\n"
  },
  {
    "id": "apache_ignite-13216-Param-0",
    "old_comment_raw": "@param c Transform closure to be applied for queue header.",
    "new_code_raw": "    @Nullable private Long transformHeader(EntryProcessor<GridCacheQueueHeaderKey, GridCacheQueueHeader, Long> c)\n        throws IgniteCheckedException {\n        int cnt = 0;\n\n        while (true) {\n            try {\n                return (Long)cache.invoke(queueKey, c);\n            }\n            catch (CachePartialUpdateException e) {\n                if (cnt++ == MAX_UPDATE_RETRIES)\n                    throw e;\n                else {\n                    U.warn(log, \"Failed to update queue header, will retry [err=\" + e + ']');\n\n                    U.sleep(RETRY_DELAY);\n                }\n            }\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-2229-Param-0",
    "old_comment_raw": "@param jarName JAR file name.",
    "new_code_raw": "    static boolean verify(String jarName, PublicKey pubKey, boolean allSigned, IgniteLogger log)\n        throws IOException {\n        assert jarName != null;\n        assert pubKey != null;\n\n        return verify0(jarName, pubKey, allSigned, log);\n    }\n"
  },
  {
    "id": "apache_ignite-11578-Param-0",
    "old_comment_raw": "@param job Job to get reducers for.",
    "new_code_raw": "    private Collection<Integer> allReducers(GridHadoopMapReducePlan plan) {\n        Collection<Integer> res = new HashSet<>();\n\n        for (int i = 0; i < plan.reducers(); i++)\n            res.add(i);\n\n        return res;\n    }\n"
  },
  {
    "id": "keycloak_keycloak-1324-Param-2",
    "old_comment_raw": "@param isPassive set to true if login should be passive (without login screen shown)",
    "new_code_raw": "    protected Response handleBrowserAuthenticationRequest(AuthenticationSessionModel authSession, LoginProtocol protocol, boolean isPassive, boolean redirectToAuthentication) {\n        AuthenticationFlowModel flow = getAuthenticationFlow();\n        String flowId = flow.getId();\n        AuthenticationProcessor processor = createProcessor(authSession, flowId, LoginActionsService.AUTHENTICATE_PATH);\n        event.detail(Details.CODE_ID, authSession.getId());\n        if (isPassive) {\n            // OIDC prompt == NONE or SAML 2 IsPassive flag\n            // This means that client is just checking if the user is already completely logged in.\n            // We cancel login if any authentication action or required action is required\n            try {\n                if (processor.authenticateOnly() == null) {\n                    // processor.attachSession();\n                } else {\n                    Response response = protocol.sendError(authSession, Error.PASSIVE_LOGIN_REQUIRED);\n                    session.authenticationSessions().removeAuthenticationSession(realm, authSession);\n                    return response;\n                }\n\n                AuthenticationManager.setRolesAndMappersInSession(authSession);\n\n                if (processor.isActionRequired()) {\n                    Response response = protocol.sendError(authSession, Error.PASSIVE_INTERACTION_REQUIRED);\n                    session.authenticationSessions().removeAuthenticationSession(realm, authSession);\n                    return response;\n                }\n\n                // Attach session once no requiredActions or other things are required\n                processor.attachSession();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n            return processor.finishAuthentication(protocol);\n        } else {\n            try {\n                RestartLoginCookie.setRestartCookie(session, realm, clientConnection, uriInfo, authSession);\n                if (redirectToAuthentication) {\n                    return processor.redirectToFlow(null);\n                }\n                return processor.authenticate();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-12140-Param-0",
    "old_comment_raw": "@param topSnapshot Topology snapshot for which candidate is added.",
    "new_code_raw": "    public boolean addCandidate(AffinityTopologyVersion topVer, GridCacheMvccCandidate cand) {\n        lock();\n\n        try {\n            if (cands.isEmpty())\n                return false;\n\n            assert this.topVer.equals(this.topVer);\n\n            Deque<GridCacheMvccCandidate> deque = ensureDeque(cand.key());\n\n            GridCacheMvccCandidate old = F.first(deque);\n\n            deque.add(cand);\n\n            if (old != null && old.owner())\n                cand.setOwner();\n\n            return true;\n        }\n        finally {\n            unlock();\n        }\n    }\n"
  },
  {
    "id": "xetorthio_jedis-720-Param-2",
    "old_comment_raw": "@param value",
    "new_code_raw": "    public boolean setbit(String key, long offset, boolean value) {\n        client.setbit(key, offset, value);\n        return client.getIntegerReply() == 1;\n    }\n"
  },
  {
    "id": "apache_ignite-12195-Param-0",
    "old_comment_raw": "@param serverNodesNum Server nodes number.",
    "new_code_raw": "    private String topologySnapshotMessage(int srvNodesNum, int clientNodesNum, int totalCpus, double heap) {\n        return PREFIX + \" [\" +\n            (discoOrdered ? \"ver=\" + topSnap.get().topVer.topologyVersion() + \", \" : \"\") +\n            \"server nodes=\" + srvNodesNum +\n            \", client nodes=\" + clientNodesNum +\n            \", CPUs=\" + totalCpus +\n            \", heap=\" + heap + \"GB\" +\n            ']';\n    }\n"
  },
  {
    "id": "apache_ignite-13368-Param-1",
    "old_comment_raw": "@param startPos Start position.",
    "new_code_raw": "    private static String parseExpression(String text, int startPos, int len, OdbcEscapeType type, Pattern pattern) {\n        String val = parseExpression(text, startPos, len);\n\n        if (!pattern.matcher(val).matches())\n            throw new IgniteException(\"Invalid \" + type + \" escape sequence: \" + substring(text, startPos, len));\n\n        return val;\n    }\n"
  },
  {
    "id": "apache_ignite-12319-Param-0",
    "old_comment_raw": "@param fileInfo File info of file opened to write.",
    "new_code_raw": "    public IgniteInternalFuture<Boolean> writeStart(IgniteUuid fileId) {\n        WriteCompletionFuture fut = new WriteCompletionFuture(fileId);\n\n        WriteCompletionFuture oldFut = pendingWrites.putIfAbsent(fileId, fut);\n\n        assert oldFut == null : \"Opened write that is being concurrently written: \" + fileId;\n\n        if (log.isDebugEnabled())\n            log.debug(\"Registered write completion future for file output stream [fileId=\" + fileId +\n                \", fut=\" + fut + ']');\n\n        return fut;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-376-Param-0",
    "old_comment_raw": "@param hintsMap all parameters influencing the weighting. E.g. parameters coming via GHRequest.getHints or directly via \"&amp;api.xy=\" from the URL of the web UI",
    "new_code_raw": "    public Weighting createWeighting(HintsMap hintsMap, FlagEncoder encoder, Graph graph, TurnCostProvider turnCostProvider) {\n        String weightingStr = toLowerCase(hintsMap.getWeighting());\n        Weighting weighting = null;\n\n        if (\"shortest\".equalsIgnoreCase(weightingStr)) {\n            weighting = new ShortestWeighting(encoder, turnCostProvider);\n        } else if (\"fastest\".equalsIgnoreCase(weightingStr) || weightingStr.isEmpty()) {\n            if (encoder.supports(PriorityWeighting.class))\n                weighting = new PriorityWeighting(encoder, hintsMap, turnCostProvider);\n            else\n                weighting = new FastestWeighting(encoder, hintsMap, turnCostProvider);\n        } else if (\"curvature\".equalsIgnoreCase(weightingStr)) {\n            if (encoder.supports(CurvatureWeighting.class))\n                weighting = new CurvatureWeighting(encoder, hintsMap, turnCostProvider);\n\n        } else if (\"short_fastest\".equalsIgnoreCase(weightingStr)) {\n            weighting = new ShortFastestWeighting(encoder, hintsMap, turnCostProvider);\n        }\n\n        if (weighting == null)\n            throw new IllegalArgumentException(\"weighting \" + weightingStr + \" not supported\");\n\n        if (hintsMap.has(Routing.BLOCK_AREA)) {\n            String blockAreaStr = hintsMap.get(Parameters.Routing.BLOCK_AREA, \"\");\n            GraphEdgeIdFinder.BlockArea blockArea = new GraphEdgeIdFinder(graph, locationIndex).\n                    parseBlockArea(blockAreaStr, DefaultEdgeFilter.allEdges(encoder), hintsMap.getDouble(\"block_area.edge_id_max_area\", 1000 * 1000));\n            return new BlockAreaWeighting(weighting, blockArea);\n        }\n\n        return weighting;\n    }\n"
  },
  {
    "id": "apache_ignite-13349-Param-0",
    "old_comment_raw": "@param nearNodeId Near node ID that initiated transaction.",
    "new_code_raw": "            @Override public GridNearTxPrepareResponse apply(IgniteInternalFuture<GridNearTxPrepareResponse> f) {\n                try {\n                    return f.get();\n                }\n                catch (Exception e) {\n                    locTx.setRollbackOnly(); // Just in case.\n\n                    if (!X.hasCause(e, IgniteTxOptimisticCheckedException.class) &&\n                        !X.hasCause(e, IgniteFutureCancelledException.class))\n                        U.error(log, \"Failed to prepare DHT transaction: \" + locTx, e);\n\n                    return new GridNearTxPrepareResponse(\n                        req.version(),\n                        req.futureId(),\n                        req.miniId(),\n                        req.version(),\n                        req.version(),\n                        null,\n                        e,\n                        null,\n                        req.deployInfo() != null);\n                }\n            }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-1-Param-0",
    "old_comment_raw": "@param address destination IP and port.",
    "new_code_raw": "    public Peer connectTo(InetSocketAddress address) {\n        return connectTo(address, true);\n    }\n"
  },
  {
    "id": "linkedin_rest.li-68-Associations-Param0",
    "old_comment_raw": "@param type to check.",
    "new_code_raw": "  public boolean contains(String memberKey)\n  {\n    return _memberKeyToIndexMap.containsKey(memberKey);\n  }\n\n"
  },
  {
    "id": "apache_ignite-13368-Param-0",
    "old_comment_raw": "@param text Text.",
    "new_code_raw": "    private static String parseExpression(String text, int startPos, int len, OdbcEscapeType type, Pattern pattern) {\n        String val = parseExpression(text, startPos, len);\n\n        if (!pattern.matcher(val).matches())\n            throw new IgniteException(\"Invalid \" + type + \" escape sequence: \" + substring(text, startPos, len));\n\n        return val;\n    }\n"
  },
  {
    "id": "graphhopper_graphhopper-484-Param-0",
    "old_comment_raw": "@param weightingStr specify e.g. fastest or shortest (or empty for default)",
    "new_code_raw": "    public Weighting createWeighting( String weighting, FlagEncoder encoder )\n    {\n        // ignore case\n        weighting = weighting.toLowerCase();\n        if (\"fastest\".equals(weighting))\n        {\n            if (encoder instanceof BikeCommonFlagEncoder)\n                return new PriorityWeighting((BikeCommonFlagEncoder) encoder);\n            else\n                return new FastestWeighting(encoder);\n        }\n        return new ShortestWeighting();\n    }\n"
  },
  {
    "id": "apache_ignite-2369-Param-0",
    "old_comment_raw": "@param file GGFS file information.",
    "new_code_raw": "    private FileStatus convert(IgniteFsFile file) {\n        return new FileStatus(file.length(), file.isDirectory(), getDefaultReplication(),\n            file.groupBlockSize(), file.modificationTime(), file.accessTime(), permission(file),\n            file.property(PROP_USER_NAME, DFLT_USER_NAME), file.property(PROP_GROUP_NAME, \"users\"),\n            convert(file.path())) {\n            @Override public String toString() {\n                return \"FileStatus [path=\" + getPath() + \", isDir=\" + isDir() + \", len=\" + getLen() +\n                    \", mtime=\" + getModificationTime() + \", atime=\" + getAccessTime() + ']';\n            }\n        };\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-362-Param-1",
    "old_comment_raw": "@param nanocoins How much currency to send, in nanocoins.",
    "new_code_raw": "    public Transaction createSend(Address address, Coin value) throws InsufficientMoneyException {\n        SendRequest req = SendRequest.to(address, value);\n        if (params == UnitTestParams.get())\n            req.shuffleOutputs = false;\n        completeTx(req);\n        return req.tx;\n    }\n"
  },
  {
    "id": "apache_ignite-3339-Param-0",
    "old_comment_raw": "@param data Byte array.",
    "new_code_raw": "    public static int serialize(byte[] data, int off, ClusterMetrics metrics) {\n        int start = off;\n\n        off = U.intToBytes(metrics.getMaximumActiveJobs(), data, off);\n        off = U.intToBytes(metrics.getCurrentActiveJobs(), data, off);\n        off = U.floatToBytes(metrics.getAverageActiveJobs(), data, off);\n        off = U.intToBytes(metrics.getMaximumWaitingJobs(), data, off);\n        off = U.intToBytes(metrics.getCurrentWaitingJobs(), data, off);\n        off = U.floatToBytes(metrics.getAverageWaitingJobs(), data, off);\n        off = U.intToBytes(metrics.getMaximumRejectedJobs(), data, off);\n        off = U.intToBytes(metrics.getCurrentRejectedJobs(), data, off);\n        off = U.floatToBytes(metrics.getAverageRejectedJobs(), data, off);\n        off = U.intToBytes(metrics.getMaximumCancelledJobs(), data, off);\n        off = U.intToBytes(metrics.getCurrentCancelledJobs(), data, off);\n        off = U.floatToBytes(metrics.getAverageCancelledJobs(), data, off);\n        off = U.intToBytes(metrics.getTotalRejectedJobs(), data , off);\n        off = U.intToBytes(metrics.getTotalCancelledJobs(), data , off);\n        off = U.intToBytes(metrics.getTotalExecutedJobs(), data , off);\n        off = U.longToBytes(metrics.getMaximumJobWaitTime(), data, off);\n        off = U.longToBytes(metrics.getCurrentJobWaitTime(), data, off);\n        off = U.doubleToBytes(metrics.getAverageJobWaitTime(), data, off);\n        off = U.longToBytes(metrics.getMaximumJobExecuteTime(), data, off);\n        off = U.longToBytes(metrics.getCurrentJobExecuteTime(), data, off);\n        off = U.doubleToBytes(metrics.getAverageJobExecuteTime(), data, off);\n        off = U.intToBytes(metrics.getTotalExecutedTasks(), data, off);\n        off = U.longToBytes(metrics.getCurrentIdleTime(), data, off);\n        off = U.longToBytes(metrics.getTotalIdleTime(), data , off);\n        off = U.intToBytes(metrics.getTotalCpus(), data, off);\n        off = U.doubleToBytes(metrics.getCurrentCpuLoad(), data, off);\n        off = U.doubleToBytes(metrics.getAverageCpuLoad(), data, off);\n        off = U.doubleToBytes(metrics.getCurrentGcCpuLoad(), data, off);\n        off = U.longToBytes(metrics.getHeapMemoryInitialized(), data, off);\n        off = U.longToBytes(metrics.getHeapMemoryUsed(), data, off);\n        off = U.longToBytes(metrics.getHeapMemoryCommitted(), data, off);\n        off = U.longToBytes(metrics.getHeapMemoryMaximum(), data, off);\n        off = U.longToBytes(metrics.getNonHeapMemoryInitialized(), data, off);\n        off = U.longToBytes(metrics.getNonHeapMemoryUsed(), data, off);\n        off = U.longToBytes(metrics.getNonHeapMemoryCommitted(), data, off);\n        off = U.longToBytes(metrics.getNonHeapMemoryMaximum(), data, off);\n        off = U.longToBytes(metrics.getStartTime(), data, off);\n        off = U.longToBytes(metrics.getNodeStartTime(), data, off);\n        off = U.longToBytes(metrics.getUpTime(), data, off);\n        off = U.intToBytes(metrics.getCurrentThreadCount(), data, off);\n        off = U.intToBytes(metrics.getMaximumThreadCount(), data, off);\n        off = U.longToBytes(metrics.getTotalStartedThreadCount(), data, off);\n        off = U.intToBytes(metrics.getCurrentDaemonThreadCount(), data, off);\n        off = U.longToBytes(metrics.getLastDataVersion(), data, off);\n        off = U.intToBytes(metrics.getSentMessagesCount(), data, off);\n        off = U.longToBytes(metrics.getSentBytesCount(), data, off);\n        off = U.intToBytes(metrics.getReceivedMessagesCount(), data, off);\n        off = U.longToBytes(metrics.getReceivedBytesCount(), data, off);\n        off = U.intToBytes(metrics.getOutboundMessagesQueueSize(), data, off);\n\n        assert off - start == METRICS_SIZE : \"Invalid metrics size [expected=\" + METRICS_SIZE + \", actual=\" +\n            (off - start) + ']';\n\n        return off;\n    }\n"
  },
  {
    "id": "Raizlabs_DBFlow-151-Associations-Param0",
    "old_comment_raw": "@param conditionQueryBuilder The builder of a specific set of conditions used in this query",
    "new_code_raw": "    public Where<ModelClass> where(SQLCondition... conditions) {\n        return where().andThese(conditions);\n    }\n\n"
  },
  {
    "id": "bitcoinj_bitcoinj-377-Param-0",
    "old_comment_raw": "@param params network parameters",
    "new_code_raw": "    public static Wallet fromSeed(NetworkParameters params, DeterministicSeed seed, List<ChildNumber> accountPath) {\n        return fromSeed(params, seed, Script.ScriptType.P2PKH, accountPath);\n    }\n"
  },
  {
    "id": "react_native_community_react_native_svg-14-Param-1",
    "old_comment_raw": "@param relative relative number",
    "new_code_raw": "    static float fromRelativeToFloat(String length, float relative, float offset, float scale, float fontSize) {\n        /*\n            TODO list\n\n            unit\trelative to\n            em\t    font size of the element\n            ex\t    x-height of the element\u00e2\u0080\u0099s font\n            ch\t    width of the \"0\" (ZERO, U+0030) glyph in the element\u00e2\u0080\u0099s font\n            rem\t    font size of the root element\n            vw\t    1% of viewport\u00e2\u0080\u0099s width\n            vh\t    1% of viewport\u00e2\u0080\u0099s height\n            vmin\t1% of viewport\u00e2\u0080\u0099s smaller dimension\n            vmax\t1% of viewport\u00e2\u0080\u0099s larger dimension\n\n            relative-size [ larger | smaller ]\n            absolute-size: [ xx-small | x-small | small | medium | large | x-large | xx-large ]\n\n            https://www.w3.org/TR/css3-values/#relative-lengths\n            https://www.w3.org/TR/css3-values/#absolute-lengths\n            https://drafts.csswg.org/css-cascade-4/#computed-value\n            https://drafts.csswg.org/css-fonts-3/#propdef-font-size\n            https://drafts.csswg.org/css2/fonts.html#propdef-font-size\n        */\n        length = length.trim();\n        int stringLength = length.length();\n        int percentIndex = stringLength - 1;\n        if (stringLength == 0) {\n            return offset;\n        } else if (length.codePointAt(percentIndex) == '%') {\n            return Float.valueOf(length.substring(0, percentIndex)) / 100 * relative + offset;\n        } else {\n            int twoLetterUnitIndex = stringLength - 2;\n            if (twoLetterUnitIndex > 0) {\n                String lastTwo = length.substring(twoLetterUnitIndex);\n                int end = twoLetterUnitIndex;\n                float unit = 1;\n\n                switch (lastTwo) {\n                    case \"px\":\n                        break;\n\n                    case \"em\":\n                        unit = fontSize;\n                        break;\n\n                    /*\n                     \"1pt\" equals \"1.25px\" (and therefore 1.25 user units)\n                     \"1pc\" equals \"15px\" (and therefore 15 user units)\n                     \"1mm\" would be \"3.543307px\" (3.543307 user units)\n                     \"1cm\" equals \"35.43307px\" (and therefore 35.43307 user units)\n                     \"1in\" equals \"90px\" (and therefore 90 user units)\n                     */\n\n                    case \"pt\":\n                        unit = 1.25f;\n                        break;\n\n                    case \"pc\":\n                        unit = 15;\n                        break;\n\n                    case \"mm\":\n                        unit = 3.543307f;\n                        break;\n\n                    case \"cm\":\n                        unit = 35.43307f;\n                        break;\n\n                    case \"in\":\n                        unit = 90;\n                        break;\n\n                    default:\n                        end = stringLength;\n                }\n\n                return Float.valueOf(length.substring(0, end)) * unit * scale + offset;\n            } else {\n                return Float.valueOf(length) * scale + offset;\n            }\n        }\n    }\n"
  },
  {
    "id": "todoroo_astrid-724-Param-1",
    "old_comment_raw": "@param activeStatus criterion for specifying completed or uncompleted",
    "new_code_raw": "    public Tag[] getGroupedTags(Order order, Criterion activeStatus) {\n        Criterion criterion = Criterion.and(activeStatus, MetadataCriteria.withKey(TaskToTagMetadata.KEY));\n        Query query = Query.select(TaskToTagMetadata.TAG_NAME, TaskToTagMetadata.TAG_UUID, COUNT).\n            join(Join.inner(Task.TABLE, Metadata.TASK.eq(Task.ID))).\n            where(criterion).\n            orderBy(order).groupBy(TaskToTagMetadata.TAG_NAME);\n        TodorooCursor<Metadata> cursor = metadataDao.query(query);\n        try {\n            ArrayList<Tag> array = new ArrayList<Tag>();\n            for (int i = 0; i < cursor.getCount(); i++) {\n                cursor.moveToNext();\n                Tag tag = Tag.tagFromUUID(cursor.get(TaskToTagMetadata.TAG_UUID));\n                if (tag != null)\n                    array.add(tag);\n            }\n            return array.toArray(new Tag[array.size()]);\n        } finally {\n            cursor.close();\n        }\n    }\n"
  },
  {
    "id": "apache_shiro-754-Param-0",
    "old_comment_raw": "@param info account info after a successful authentication attempt.",
    "new_code_raw": "    protected String displayName( Account account) {\n        Object  p = account.getPrincipal();\n        if ( p != null ) {\n            return p.toString();\n        } else {\n            return account.toString();\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-3569-Param-1",
    "old_comment_raw": "@param c Grid configuration.",
    "new_code_raw": "    public static VisorBasicConfiguration from(GridEx g, IgniteConfiguration c) {\n        VisorBasicConfiguration cfg = new VisorBasicConfiguration();\n\n        cfg.gridName(c.getGridName());\n        cfg.ggHome(getProperty(GG_HOME, c.getGridGainHome()));\n        cfg.localHost(getProperty(GG_LOCAL_HOST, c.getLocalHost()));\n        cfg.nodeId(g.localNode().id());\n        cfg.marshaller(compactClass(c.getMarshaller()));\n        cfg.deploymentMode(compactObject(c.getDeploymentMode()));\n        cfg.daemon(boolValue(GG_DAEMON, c.isDaemon()));\n        cfg.jmxRemote(g.isJmxRemoteEnabled());\n        cfg.restart(g.isRestartEnabled());\n        cfg.networkTimeout(c.getNetworkTimeout());\n        cfg.licenseUrl(c.getLicenseUrl());\n        cfg.logger(compactClass(c.getGridLogger()));\n        cfg.discoStartupDelay(c.getDiscoveryStartupDelay());\n        cfg.mBeanServer(compactClass(c.getMBeanServer()));\n        cfg.noAscii(boolValue(GG_NO_ASCII, false));\n        cfg.noDiscoOrder(boolValue(GG_NO_DISCO_ORDER, false));\n        cfg.noShutdownHook(boolValue(GG_NO_SHUTDOWN_HOOK, false));\n        cfg.programName(getProperty(GG_PROG_NAME));\n        cfg.quiet(boolValue(GG_QUIET, true));\n        cfg.successFile(getProperty(GG_SUCCESS_FILE));\n        cfg.updateNotifier(boolValue(GG_UPDATE_NOTIFIER, true));\n        cfg.securityCredentialsProvider(compactClass(c.getSecurityCredentialsProvider()));\n\n        return cfg;\n    }\n"
  },
  {
    "id": "stephanenicolas_robospice-41-Param-0",
    "old_comment_raw": "@param cachedContentRequest the request know by the  SpiceManager.",
    "new_code_raw": "    private boolean match( CachedSpiceRequest< ? > cachedSpiceRequest, SpiceRequest< ? > spiceRequest ) {\n        if ( spiceRequest instanceof CachedSpiceRequest ) {\n            return spiceRequest == cachedSpiceRequest;\n        } else {\n            return cachedSpiceRequest.getSpiceRequest() == spiceRequest;\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-5514-Param-1",
    "old_comment_raw": "@param msgId Message ID.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, AffinityTopologyVersion topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!cctx.discovery().cacheNearNode(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture<K, V> txFut = null;\n\n        Collection<GridCacheMvccCandidate<K>> cands = null;\n\n        ReaderId<K, V> reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId<>(nodeId, msgId);\n\n                ReaderId<K, V>[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate<K> c : cands) {\n                    IgniteInternalTx<K, V> tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId<K, V> reader0 = reader;\n\n                txFut.listenAsync(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        synchronized (this) {\n                            // Release memory.\n                            reader0.resetTxFuture();\n                        }\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "apache_shiro-903-Param-0",
    "old_comment_raw": "@param account the Account from which to retrive the credentials which assumed to be in already-hashed form.",
    "new_code_raw": "    protected Object getCredentials(AuthenticationInfo info) {\n        Object credentials = info.getCredentials();\n\n        byte[] storedBytes = toBytes(credentials);\n\n        if (credentials instanceof String || credentials instanceof char[]) {\n            //account.credentials were a char[] or String, so\n            //we need to do text decoding first:\n            if (isStoredCredentialsHexEncoded()) {\n                storedBytes = Hex.decode(storedBytes);\n            } else {\n                storedBytes = Base64.decode(storedBytes);\n            }\n        }\n        AbstractHash hash = newHashInstance();\n        hash.setBytes(storedBytes);\n        return hash;\n    }\n"
  },
  {
    "id": "apache_ignite-7529-Param-0",
    "old_comment_raw": "@param obj Object.",
    "new_code_raw": "    private boolean writeHeader(Object obj, BinaryWriterExImpl writer) {\n        if (writer.tryWriteAsHandle(obj))\n            return false;\n\n        if (registered) {\n            PortableUtils.writeHeader(\n                writer,\n                typeId,\n                obj instanceof CacheObjectImpl ? 0 : obj.hashCode(),\n                null\n            );\n        }\n        else {\n            PortableUtils.writeHeader(\n                writer,\n                GridPortableMarshaller.UNREGISTERED_TYPE_ID,\n                obj instanceof CacheObjectImpl ? 0 : obj.hashCode(),\n                cls.getName()\n            );\n        }\n\n        return true;\n    }\n"
  },
  {
    "id": "apache_ignite-13611-Param-3",
    "old_comment_raw": "@param resType Expected result type.",
    "new_code_raw": "    private static ClassProperty buildClassProperty(Class<?> keyCls, Class<?> valCls, String pathStr, Class<?> resType)\n        throws IgniteCheckedException {\n        ClassProperty res = buildClassProperty(true, keyCls, pathStr, resType);\n\n        if (res == null) // We check key before value consistently with PortableProperty.\n            res = buildClassProperty(false, valCls, pathStr, resType);\n\n        if (res == null)\n            throw new IgniteCheckedException(\"Failed to initialize property '\" + pathStr + \"' for \" +\n                \"key class '\" + keyCls + \"' and value class '\" + valCls + \"'. \" +\n                \"Make sure that one of these classes contains respective getter method or field.\");\n\n        return res;\n    }\n"
  },
  {
    "id": "apache_ignite-5459-Param-1",
    "old_comment_raw": "@param key Key.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteInternalTx tx, Object key, Object val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key instanceof GridCacheInternal)\n                return true;\n\n            if (convertPortable) {\n                key = cctx.unwrapPortableIfNeeded(key, false);\n                val = cctx.unwrapPortableIfNeeded(val, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            boolean ses = initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(key, locStore ? F.t(val, ver) : val));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                if (ses)\n                    sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "apache_ignite-12044-Param-0",
    "old_comment_raw": "@param g Grid.",
    "new_code_raw": "    private static CacheQueue<String> initializeQueue(Ignite ignite, String queueName) throws IgniteCheckedException {\n        // Initialize new FIFO queue.\n        CacheQueue<String> queue = ignite.cache(CACHE_NAME).dataStructures().queue(queueName, 0, false, true);\n\n        // Initialize queue items.\n        // We will be use blocking operation and queue size must be appropriated.\n        for (int i = 0; i < ignite.cluster().nodes().size() * RETRIES * 2; i++)\n            queue.put(Integer.toString(i));\n\n        System.out.println(\"Queue size after initializing: \" + queue.size());\n\n        return queue;\n    }\n"
  },
  {
    "id": "apache_ignite-6447-Param-1",
    "old_comment_raw": "@param c Cache.",
    "new_code_raw": "    public static VisorCacheMetrics from(IgniteEx ignite, CacheProjection c) {\n        VisorCacheMetrics cm = new VisorCacheMetrics();\n\n        CacheMetrics m = c.metrics();\n\n        GridCacheProcessor cacheProcessor = ignite.context().cache();\n\n        cm.name = c.name();\n        cm.mode = cacheProcessor.cacheMode(c.name());\n        cm.sys = cacheProcessor.systemCache(c.name());\n\n        cm.size = m.getSize();\n        cm.keySize = m.getKeySize();\n\n        cm.reads = m.getCacheGets();\n        cm.writes = m.getCachePuts() + m.getCacheRemovals();\n        cm.hits = m.getCacheHits();\n        cm.misses = m.getCacheMisses();\n\n        cm.txCommits = m.getCacheTxCommits();\n        cm.txRollbacks = m.getCacheTxRollbacks();\n\n        cm.avgTxCommitTime = m.getAverageTxCommitTime();\n        cm.avgTxRollbackTime = m.getAverageTxRollbackTime();\n\n        cm.puts = m.getCachePuts();\n        cm.removals = m.getCacheRemovals();\n        cm.evictions = m.getCacheEvictions();\n\n        cm.avgReadTime = m.getAverageGetTime();\n        cm.avgPutTime = m.getAveragePutTime();\n        cm.avgRemovalTime = m.getAverageRemoveTime();\n\n        cm.readsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageGetTime());\n        cm.writesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAveragePutTime());\n        cm.hitsPerSec = -1;\n        cm.missesPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageRemoveTime());\n        cm.commitsPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxCommitTime());\n        cm.rollbacksPerSec = (int)(MICROSECONDS_IN_SECOND * 1.f / m.getAverageTxRollbackTime());\n\n        cm.qryMetrics = VisorCacheQueryMetrics.from(c.queries().metrics());\n\n        cm.dhtEvictQueueCurrSize = m.getDhtEvictQueueCurrentSize();\n        cm.txThreadMapSize = m.getTxThreadMapSize();\n        cm.txXidMapSize = m.getTxXidMapSize();\n        cm.txCommitQueueSize = m.getTxCommitQueueSize();\n        cm.txPrepareQueueSize = m.getTxPrepareQueueSize();\n        cm.txStartVerCountsSize = m.getTxStartVersionCountsSize();\n        cm.txCommittedVersionsSize = m.getTxCommittedVersionsSize();\n        cm.txRolledbackVersionsSize = m.getTxRolledbackVersionsSize();\n        cm.txDhtThreadMapSize = m.getTxDhtThreadMapSize();\n        cm.txDhtXidMapSize = m.getTxDhtXidMapSize();\n        cm.txDhtCommitQueueSize = m.getTxDhtCommitQueueSize();\n        cm.txDhtPrepareQueueSize = m.getTxDhtPrepareQueueSize();\n        cm.txDhtStartVerCountsSize = m.getTxDhtStartVersionCountsSize();\n        cm.txDhtCommittedVersionsSize = m.getTxDhtCommittedVersionsSize();\n        cm.txDhtRolledbackVersionsSize = m.getTxDhtRolledbackVersionsSize();\n\n        return cm;\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-604-Param-0",
    "old_comment_raw": "@param createDate",
    "new_code_raw": "    public int delete(Date now) {\n        if (null != now) {\n            QueryHandler queryHandler = getQueryHandler(\"delete from SysAppToken bean\");\n            queryHandler.condition(\"bean.expiryDate is not null\");\n            queryHandler.condition(\"bean.expiryDate <= :expiryDate\").setParameter(\"expiryDate\", now);\n            return delete(queryHandler);\n        }\n        return 0;\n    }\n"
  },
  {
    "id": "apache_ignite-4437-Param-0",
    "old_comment_raw": "@param mapper GGFS blocks mapper.",
    "new_code_raw": "    private int partition(IgfsGroupDataBlocksKeyMapper mapper, IgniteUuid fileId, long blockId, int partCnt) {\n        return U.safeAbs((Integer) mapper.affinityKey(new IgfsBlockKey(fileId, null, false, blockId)) % partCnt);\n    }\n"
  },
  {
    "id": "apache_shiro-726-Param-1",
    "old_comment_raw": "@param account the account data constructed due to the successful attempt.",
    "new_code_raw": "    public AuthenticationEvent createSuccessEvent(AuthenticationToken token, AuthenticationInfo info) {\n        return new SuccessfulAuthenticationEvent(token, info);\n    }\n"
  },
  {
    "id": "apache_ignite-246-Param-2",
    "old_comment_raw": "@param entry Preloaded entry.",
    "new_code_raw": "        private boolean preloadEntry(GridNode pick, int p, GridCacheEntryInfo<K, V> entry, long topVer)\n            throws GridException, GridInterruptedException {\n            try {\n                GridCacheEntryEx<K, V> cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isGgfsDataCache() &&\n                        cctx.dht().ggfsDataSpaceUsed() > cctx.dht().ggfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload GGFS data cache (GGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            entry.valueBytes(),\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isReplicationEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (GridUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (GridInterruptedException e) {\n                throw e;\n            }\n            catch (GridException e) {\n                throw new GridException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "apache_ignite-13245-Param-2",
    "old_comment_raw": "@param m Type mapping description.",
    "new_code_raw": "    protected int fillValueParameters(PreparedStatement stmt, int idx, EntryMapping em, Object val)\n        throws CacheWriterException {\n        for (CacheTypeFieldMetadata field : em.uniqValFields) {\n            Object fieldVal = extractField(em.cacheName, em.valueType(), field.getJavaName(), val);\n\n            try {\n                if (fieldVal != null)\n                    stmt.setObject(idx++, fieldVal);\n                else\n                    stmt.setNull(idx++, field.getDatabaseType());\n            }\n            catch (SQLException e) {\n                throw new CacheWriterException(\"Failed to set statement parameter name: \" + field.getDatabaseName(), e);\n            }\n        }\n\n        return idx;\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-429-Param-2",
    "old_comment_raw": "@param request",
    "new_code_raw": "    public String delete(String path, Long[] ids, String _csrf, HttpServletRequest request, HttpSession session, ModelMap model) {\n        if (ControllerUtils.verifyNotEquals(\"_csrf\", ControllerUtils.getAdminToken(request), _csrf, model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        SysUser user = ControllerUtils.getAdminFromSession(session);\n        SysDept dept = sysDeptService.getEntity(user.getDeptId());\n        if (ControllerUtils.verifyNotEmpty(\"deptId\", user.getDeptId(), model)\n                || ControllerUtils.verifyNotEmpty(\"deptId\", dept, model)\n                || ControllerUtils.verifyCustom(\"noright\",\n                        !(dept.isOwnsAllPage() || null != sysDeptPageService.getEntity(new SysDeptPageId(user.getDeptId(),\n                                CommonConstants.SEPARATOR + TemplateComponent.INCLUDE_DIRECTORY + path))),\n                        model)) {\n            return CommonConstants.TEMPLATE_ERROR;\n        }\n        if (CommonUtils.notEmpty(ids)) {\n            SysSite site = getSite(request);\n            service.delete(site.getId(), ids, path);\n            logOperateService.save(new LogOperate(site.getId(), ControllerUtils.getAdminFromSession(session).getId(),\n                    LogLoginService.CHANNEL_WEB_MANAGER, \"delete.place\", RequestUtils.getIpAddress(request),\n                    CommonUtils.getDate(), StringUtils.join(ids, ',')));\n        }\n        return CommonConstants.TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "apache_ignite-4796-Param-0",
    "old_comment_raw": "@param tx Cache transaction.",
    "new_code_raw": "    public boolean putToStore(@Nullable IgniteInternalTx tx, KeyCacheObject key, CacheObject val, GridCacheVersion ver)\n        throws IgniteCheckedException {\n        if (store != null) {\n            // Never persist internal keys.\n            if (key.internal())\n                return true;\n\n            Object storeKey = key.value(cctx);\n            Object storeVal = val.value(cctx);\n\n            if (convertPortable) {\n                storeKey = cctx.unwrapPortableIfNeeded(storeKey, false);\n                storeVal = cctx.unwrapPortableIfNeeded(storeVal, false);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Storing value in cache store [key=\" + key + \", val=\" + val + ']');\n\n            boolean ses = initSession(tx);\n\n            try {\n                store.write(new CacheEntryImpl<>(storeKey, locStore ? F.t(storeVal, ver) : storeVal));\n            }\n            catch (ClassCastException e) {\n                handleClassCastException(e);\n            }\n            catch (CacheWriterException e) {\n                throw new IgniteCheckedException(e);\n            }\n            catch (Exception e) {\n                throw new IgniteCheckedException(new CacheWriterException(e));\n            }\n            finally {\n                if (ses)\n                    sesHolder.set(null);\n            }\n\n            if (log.isDebugEnabled())\n                log.debug(\"Stored value in cache store [key=\" + storeKey + \", val=\" + storeVal + ']');\n\n            return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-365-Param-0",
    "old_comment_raw": "@param matchedHashes A list which will contain the matched txn (will be cleared) Required to be a LinkedHashSet in order to retain order or transactions in the block",
    "new_code_raw": "    public Sha256Hash getTxnHashAndMerkleRoot(List<Sha256Hash> matchedHashesOut) throws VerificationException {\n        matchedHashesOut.clear();\n        \n        // An empty set will not work\n        if (transactionCount == 0)\n            throw new VerificationException(\"Got a CPartialMerkleTree with 0 transactions\");\n        // check for excessively high numbers of transactions\n        if (transactionCount > Block.MAX_BLOCK_SIZE / 60) // 60 is the lower bound for the size of a serialized CTransaction\n            throw new VerificationException(\"Got a CPartialMerkleTree with more transactions than is possible\");\n        // there can never be more hashes provided than one for every txid\n        if (hashes.size() > transactionCount)\n            throw new VerificationException(\"Got a CPartialMerkleTree with more hashes than transactions\");\n        // there must be at least one bit per node in the partial tree, and at least one node per hash\n        if (matchedChildBits.length*8 < hashes.size())\n            throw new VerificationException(\"Got a CPartialMerkleTree with fewer matched bits than hashes\");\n        // calculate height of tree\n        int height = 0;\n        while (getTreeWidth(transactionCount, height) > 1)\n            height++;\n        // traverse the partial tree\n        ValuesUsed used = new ValuesUsed();\n        Sha256Hash merkleRoot = recursiveExtractHashes(height, 0, used, matchedHashesOut);\n        // verify that all bits were consumed (except for the padding caused by serializing it as a byte sequence)\n        if ((used.bitsUsed+7)/8 != matchedChildBits.length ||\n                // verify that all hashes were consumed\n                used.hashesUsed != hashes.size())\n            throw new VerificationException(\"Got a CPartialMerkleTree that didn't need all the data it provided\");\n        \n        return merkleRoot;\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-59-Param-1",
    "old_comment_raw": "@param view",
    "new_code_raw": "    protected AvatarHelper setImage(final BitmapDrawable image, final ImageView view, final User user) {\n        if (!Integer.valueOf(user.getId()).equals(view.getTag(id.iv_gravatar)))\n            return this;\n\n        view.setTag(id.iv_gravatar, null);\n\n        if (image != null) {\n            loaded.put(user.getId(), image);\n            view.setImageDrawable(image);\n            view.setVisibility(VISIBLE);\n        }\n\n        return this;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-785-Param-1",
    "old_comment_raw": "@param string",
    "new_code_raw": "    public Long rpush(final String key, final String... strings) {\n        checkIsInMulti();\n        client.rpush(key, strings);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-2114-Param-0",
    "old_comment_raw": "@param streamer Source streamer.",
    "new_code_raw": "    public static VisorStreamerMetrics from(IgniteStreamer streamer) {\n        assert streamer != null;\n\n        GridStreamerMetrics m = streamer.metrics();\n\n        int windowSz = 0;\n\n        for (GridStreamerWindowMetrics wm : m.windowMetrics())\n            windowSz += wm.size();\n\n        VisorStreamerMetrics metrics = new VisorStreamerMetrics();\n\n        metrics.active(m.stageActiveExecutionCount());\n        metrics.waiting(m.stageWaitingExecutionCount());\n        metrics.capacity(m.executorServiceCapacity());\n\n        metrics.pipelineMinExecutionTime(m.pipelineMinimumExecutionTime());\n        metrics.pipelineAvgExecutionTime(m.pipelineAverageExecutionTime());\n        metrics.pipelineMaxExecutionTime(m.pipelineMaximumExecutionTime());\n\n        metrics.pipelineMinExecutionNodes(m.pipelineMinimumExecutionNodes());\n        metrics.pipelineAvgExecutionNodes(m.pipelineAverageExecutionNodes());\n        metrics.pipelineMaxExecutionNodes(m.pipelineMaximumExecutionNodes());\n\n        metrics.queryMinExecutionTime(m.queryMinimumExecutionTime());\n        metrics.queryAvgExecutionTime(m.queryAverageExecutionTime());\n        metrics.queryMaxExecutionTime(m.queryMaximumExecutionTime());\n\n        metrics.queryMinExecutionNodes(m.queryMinimumExecutionNodes());\n        metrics.queryAvgExecutionNodes(m.queryAverageExecutionNodes());\n        metrics.queryMaxExecutionNodes(m.queryMaximumExecutionNodes());\n\n        metrics.windowSize(windowSz);\n\n        return metrics;\n    }\n"
  },
  {
    "id": "apache_ignite-13164-Param-0",
    "old_comment_raw": "@param cacheFlagsStr String representation of cache flags bit set.",
    "new_code_raw": "    public static GridCacheFlag[] parseCacheFlags(int cacheFlagsBits) {\n        if (cacheFlagsBits == 0)\n            return EMPTY_FLAGS;\n\n        EnumSet<GridCacheFlag> flagSet = EnumSet.noneOf(GridCacheFlag.class);\n\n        if ((cacheFlagsBits & 1) != 0)\n            flagSet.add(GridCacheFlag.SKIP_STORE);\n\n        if ((cacheFlagsBits & (1 << 1)) != 0)\n            flagSet.add(GridCacheFlag.SKIP_SWAP);\n\n        if ((cacheFlagsBits & (1 << 2)) != 0)\n            flagSet.add(GridCacheFlag.SYNC_COMMIT);\n\n        if ((cacheFlagsBits & (1 << 4)) != 0)\n            flagSet.add(GridCacheFlag.INVALIDATE);\n\n        return flagSet.toArray(new GridCacheFlag[flagSet.size()]);\n    }\n"
  },
  {
    "id": "keycloak_keycloak-673-Param-1",
    "old_comment_raw": "@param execution",
    "new_code_raw": "    protected Response resetCredentials(String code, String execution, String clientId) {\n        SessionCodeChecks checks = checksForCode(code, execution, clientId, RESET_CREDENTIALS_PATH);\n        if (!checks.verifyActiveAndValidAction(ClientSessionModel.Action.AUTHENTICATE.name(), ClientSessionCode.ActionType.USER)) {\n            return checks.getResponse();\n        }\n        final AuthenticationSessionModel authSession = checks.getAuthenticationSession();\n\n        if (!realm.isResetPasswordAllowed()) {\n            event.error(Errors.NOT_ALLOWED);\n            return ErrorPage.error(session, Messages.RESET_CREDENTIAL_NOT_ALLOWED);\n\n        }\n\n        return processResetCredentials(checks.isActionRequest(), execution, authSession);\n    }\n"
  },
  {
    "id": "apache_ignite-13600-Param-0",
    "old_comment_raw": "@param partition partition",
    "new_code_raw": "    private boolean isMetadataPropagated(String topic, int part) {\n        scala.Option<PartitionStateInfo> partStateOption =\n            kafkaSrv.apis().metadataCache().getPartitionInfo(topic, part);\n\n        if (!partStateOption.isDefined())\n            return false;\n\n        PartitionStateInfo partState = partStateOption.get();\n\n        LeaderAndIsr LeaderAndIsr = partState.leaderIsrAndControllerEpoch().leaderAndIsr();\n\n        return ZkUtils.getLeaderForPartition(getZkClient(), topic, part) != null &&\n            Request.isValidBrokerId(LeaderAndIsr.leader()) && LeaderAndIsr.isr().size() >= 1;\n    }\n"
  },
  {
    "id": "todoroo_astrid-772-Param-0",
    "old_comment_raw": "@param database",
    "new_code_raw": "    public int deleteWhere(AbstractDatabase database, Criterion where) {\n        return database.getDatabase().delete(Metadata.TABLE.getName(),\n                where.toString(), null);\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-756-Param-1",
    "old_comment_raw": "@param color",
    "new_code_raw": "    public StyledText foreground(final CharSequence text, final ColorStateList states) {\n        return append(text, new StateForegroundSpan(states));\n    }\n"
  },
  {
    "id": "apache_ignite-5543-Param-1",
    "old_comment_raw": "@param msgId Message ID.",
    "new_code_raw": "    @Nullable public IgniteInternalFuture<Boolean> addReader(UUID nodeId, long msgId, AffinityTopologyVersion topVer)\n        throws GridCacheEntryRemovedException {\n        // Don't add local node as reader.\n        if (cctx.nodeId().equals(nodeId))\n            return null;\n\n        ClusterNode node = cctx.discovery().node(nodeId);\n\n        if (node == null) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because node left the grid: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node has no near cache, don't add it.\n        if (!cctx.discovery().cacheNearNode(node, cacheName())) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because near cache is disabled: \" + nodeId);\n\n            return null;\n        }\n\n        // If remote node is (primary?) or back up, don't add it as a reader.\n        if (cctx.affinity().belongs(node, partition(), topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Ignoring near reader because remote node is affinity node [locNodeId=\" + cctx.localNodeId()\n                    + \", rmtNodeId=\" + nodeId + \", key=\" + key + ']');\n\n            return null;\n        }\n\n        boolean ret = false;\n\n        GridCacheMultiTxFuture<K, V> txFut = null;\n\n        Collection<GridCacheMvccCandidate<K>> cands = null;\n\n        ReaderId<K, V> reader;\n\n        synchronized (this) {\n            checkObsolete();\n\n            reader = readerId(nodeId);\n\n            if (reader == null) {\n                reader = new ReaderId<>(nodeId, msgId);\n\n                ReaderId<K, V>[] rdrs = Arrays.copyOf(this.rdrs, this.rdrs.length + 1);\n\n                rdrs[rdrs.length - 1] = reader;\n\n                // Seal.\n                this.rdrs = rdrs;\n\n                // No transactions in ATOMIC cache.\n                if (!cctx.atomic()) {\n                    txFut = reader.getOrCreateTxFuture(cctx);\n\n                    cands = localCandidates();\n\n                    ret = true;\n                }\n            }\n            else {\n                txFut = reader.txFuture();\n\n                long id = reader.messageId();\n\n                if (id < msgId)\n                    reader.messageId(msgId);\n            }\n        }\n\n        if (ret) {\n            assert txFut != null;\n\n            if (!F.isEmpty(cands)) {\n                for (GridCacheMvccCandidate<K> c : cands) {\n                    IgniteInternalTx<K, V> tx = cctx.tm().tx(c.version());\n\n                    if (tx != null) {\n                        assert tx.local();\n\n                        txFut.addTx(tx);\n                    }\n                }\n            }\n\n            txFut.init();\n\n            if (!txFut.isDone()) {\n                final ReaderId<K, V> reader0 = reader;\n\n                txFut.listenAsync(new CI1<IgniteInternalFuture<?>>() {\n                    @Override public void apply(IgniteInternalFuture<?> f) {\n                        synchronized (this) {\n                            // Release memory.\n                            reader0.resetTxFuture();\n                        }\n                    }\n                });\n            }\n            else {\n                synchronized (this) {\n                    // Release memory.\n                    reader.resetTxFuture();\n                }\n\n                txFut = null;\n            }\n        }\n\n        return txFut;\n    }\n"
  },
  {
    "id": "pubnub_java-67-Param-0",
    "old_comment_raw": "@param sUrl , input string",
    "new_code_raw": "    public static String urlEncode(String stringToEncode) {\n        try {\n            return URLEncoder.encode(stringToEncode, \"UTF-8\").replace(\"+\", \"%20\");\n        } catch (UnsupportedEncodingException e) {\n            return null;\n        }\n    }\n"
  },
  {
    "id": "sanluan_PublicCMS-23-Param-0",
    "old_comment_raw": "@param ids",
    "new_code_raw": "    public String check(Long[] ids, HttpServletRequest request, HttpSession session, ModelMap model) {\n        if (notEmpty(ids)) {\n            SysSite site = getSite(request);\n            service.check(site.getId(), ids);\n            logOperateService.save(new LogOperate(site.getId(), getAdminFromSession(session).getId(),\n                    LogLoginService.CHANNEL_WEB_MANAGER, \"check.place\", getIpAddress(request), getDate(), join(ids, ',')));\n        }\n        return TEMPLATE_DONE;\n    }\n"
  },
  {
    "id": "codehaus_aspectwerkz-22-Associations-Param1",
    "old_comment_raw": "@param methodMetaData the method to filter",
    "new_code_raw": "    private String methodFilter(final ClassGen cg,\r\n                                final Method method) {\r\n        MethodMetaData methodMetaData =\r\n                TransformationUtil.createMethodMetaData(method);\r\n\r\n        String uuid = null;\r\n        if (methodMetaData.getName().equals(\"<init>\") ||\r\n                methodMetaData.getName().equals(\"<clinit>\") ||\r\n                methodMetaData.getName().startsWith(TransformationUtil.ORIGINAL_METHOD_PREFIX) ||\r\n                methodMetaData.getName().equals(TransformationUtil.GET_META_DATA_METHOD) ||\r\n                methodMetaData.getName().equals(TransformationUtil.SET_META_DATA_METHOD) ||\r\n                methodMetaData.getName().equals(TransformationUtil.GET_UUID_METHOD)) {\r\n            uuid = null;\r\n        }\r\n        else {\r\n            if (m_weaveModel.hasMethodPointcut(\r\n                    cg.getClassName(), methodMetaData)) {\r\n                uuid = m_weaveModel.getUuid();\r\n            }\r\n            if (m_weaveModel.hasThrowsPointcut(\r\n                    cg.getClassName(), methodMetaData)) {\r\n                uuid = m_weaveModel.getUuid();\r\n            }\r\n        }\r\n        return uuid;\r\n    }\r\n\n"
  },
  {
    "id": "openhab_openhab1_addons-38-Param-0",
    "old_comment_raw": "@param buffer the buffer to be parsed.",
    "new_code_raw": "\tprotected BigDecimal extractValue(byte[] buffer, int offset) {\n\t\tint size = buffer[offset] & SIZE_MASK;\n\t\tint precision = (buffer[offset] & PRECISION_MASK) >> PRECISION_SHIFT;\n\n\t\tint value = 0;\n\t\tint i;\n\t\tfor (i = 0; i < size; ++i) {\n\t\t\tvalue <<= 8;\n\t\t\tvalue |= buffer[offset + i + 1] & 0xFF;\n\t\t}\n\t\t\n\t\t// Deal with sign extension. All values are signed\n\t\tBigDecimal result;\n\t\tif ((buffer[offset + 1] & 0x80) == 0x80) {\n\n\t\t\t// MSB is signed\n\t\t\tif (size == 1) {\n\t\t\t\tvalue |= 0xffffff00;\n\t\t\t} else if (size == 2) {\n\t\t\t\tvalue |= 0xffff0000;\n\t\t\t}\n\t\t}\n\n\t\tresult = BigDecimal.valueOf(value);\n\n\t\tBigDecimal divisor = BigDecimal.valueOf(Math.pow(10, precision));\n\t\treturn result.divide(divisor);\n\t}\n"
  },
  {
    "id": "rmtheis_android_ocr-0-Param-0",
    "old_comment_raw": "@param file a Gzipped file",
    "new_code_raw": "  private int getGzipSizeUncompressed(File zipFile) throws IOException {\n    RandomAccessFile raf = new RandomAccessFile(zipFile, \"r\");\n    raf.seek(raf.length() - 4);\n    int b4 = raf.read();\n    int b3 = raf.read();\n    int b2 = raf.read();\n    int b1 = raf.read();\n    raf.close();\n    return (b1 << 24) | (b2 << 16) + (b3 << 8) + b4;\n  }\n"
  },
  {
    "id": "xetorthio_jedis-499-Param-0",
    "old_comment_raw": "@param key",
    "new_code_raw": "    public String lset(final byte[] key, final long index, final byte[] value) {\n\tcheckIsInMulti();\n\tclient.lset(key, index, value);\n\treturn client.getStatusCodeReply();\n    }\n"
  },
  {
    "id": "apache_ignite-11623-Param-0",
    "old_comment_raw": "@param grid Grid.",
    "new_code_raw": "    private Integer key(Ignite ignite, int mode) {\n        GridCache<Integer, Integer> cache = ignite.cache(null);\n\n        GridCacheAffinity<Integer> aff = cache.affinity();\n\n        Integer key = null;\n\n        for (int i = lastKey + 1; i < 1_000_000; i++) {\n            boolean pass = false;\n\n            switch(mode) {\n                case PRIMARY: pass = aff.isPrimary(ignite.cluster().localNode(), i); break;\n\n                case BACKUP: pass = aff.isBackup(ignite.cluster().localNode(), i); break;\n\n                case NOT_PRIMARY_AND_BACKUP: pass = !aff.isPrimaryOrBackup(ignite.cluster().localNode(), i); break;\n\n                default: fail();\n            }\n\n            lastKey = i;\n\n            if (pass) {\n                key = i;\n\n                break;\n            }\n        }\n\n        assertNotNull(key);\n\n        return key;\n    }\n"
  },
  {
    "id": "apache_ignite-2209-Param-1",
    "old_comment_raw": "@param m Grid marshaller.",
    "new_code_raw": "    static GridSharedFsCheckpointData read(File file, GridMarshaller m, IgniteLogger log)\n        throws IOException, GridException {\n        assert file != null;\n        assert m != null;\n        assert log != null;\n\n        InputStream in = new FileInputStream(file);\n\n        try {\n            return (GridSharedFsCheckpointData)m.unmarshal(in, U.gridClassLoader());\n        }\n        finally {\n            U.close(in, log);\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-11621-Param-0",
    "old_comment_raw": "@param grid Grid.",
    "new_code_raw": "    private String txGet(Ignite ignite, String key) throws Exception {\n        try (GridCacheTx tx = ignite.cache(null).txStart(PESSIMISTIC, REPEATABLE_READ)) {\n            GridCacheEntryEx<String, Integer> dhtEntry = dht(ignite).peekEx(key);\n\n            if (DEBUG)\n                info(\"DHT entry [hash=\" + System.identityHashCode(dhtEntry) + \", xid=\" + tx.xid() +\n                    \", entry=\" + dhtEntry + ']');\n\n            String val = ignite.<String, String>cache(null).get(key);\n\n            assertNotNull(val);\n            assertEquals(\"val\", val);\n\n            tx.commit();\n\n            return val;\n        }\n    }\n"
  },
  {
    "id": "bitcoinj_bitcoinj-356-Param-3",
    "old_comment_raw": "@param privateDerivation whether to use private or public derivation",
    "new_code_raw": "    public ExtendedHierarchicKey deriveNextChild(ImmutableList<ChildNumber> parentPath, boolean relative, boolean createParent, boolean privateDerivation) {\n        ExtendedHierarchicKey parent = get(parentPath, relative, createParent);\n        int nAttempts = 0;\n        while (nAttempts++ < MAX_CHILD_DERIVATION_ATTEMPTS) {\n            try {\n                ChildNumber createChildNumber = getNextChildNumberToDerive(parent.getChildNumberPath(), privateDerivation);\n                return deriveChild(parent, createChildNumber);\n            } catch (HDDerivationException ignore) { }\n        }\n        throw new HDDerivationException(\"Maximum number of child derivation attempts reached, this is probably an indication of a bug.\");\n    }\n"
  },
  {
    "id": "apache_ignite-12101-Param-0",
    "old_comment_raw": "@param ggfs GGFS flag.",
    "new_code_raw": "    private static GridHadoopFileBlock split(boolean igfs, String file, long start, long len, String... hosts) {\n        URI uri = URI.create((igfs ? \"igfs://igfs@\" : \"hdfs://\") + file);\n\n        return new GridHadoopFileBlock(hosts, uri, start, len);\n    }\n"
  },
  {
    "id": "pockethub_PocketHub-290-Param-0",
    "old_comment_raw": "@param repository",
    "new_code_raw": "    public Issue getIssue(Repo repository, int number) {\n        ItemReferences<Issue> repoIssues = repos.get(InfoUtils.createRepoId(repository));\n        return repoIssues != null ? repoIssues.get(number) : null;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-782-Param-1",
    "old_comment_raw": "@param member",
    "new_code_raw": "    public Long zrem(final byte[] key, final byte[]... members) {\n        checkIsInMulti();\n        client.zrem(key, members);\n        return client.getIntegerReply();\n    }\n"
  },
  {
    "id": "apache_ignite-1568-Param-0",
    "old_comment_raw": "@param node Node.",
    "new_code_raw": "    public boolean alive(ClusterNode node) {\n        assert node != null;\n\n        return alive(node.id());\n    }\n"
  },
  {
    "id": "apache_ignite-11576-Param-0",
    "old_comment_raw": "@param userVersion Version to create.",
    "new_code_raw": "    private String makeUserVersion(String userVer) {\n        return \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?> \" +\n            \"<beans xmlns=\\\"http://www.springframework.org/schema/beans\\\" \" +\n            \"xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\" \" +\n            \"xmlns:util=\\\"http://www.springframework.org/schema/util\\\" \" +\n            \"xsi:schemaLocation=\\\"http://www.springframework.org/schema/beans \" +\n            \"http://www.springframework.org/schema/beans/spring-beans.xsd \" +\n            \"http://www.springframework.org/schema/util \" +\n            \"http://www.springframework.org/schema/util/spring-util.xsd\\\"> \" +\n            \"<bean id=\\\"userVersion\\\" class=\\\"java.lang.String\\\"><constructor-arg value=\\\"\" + userVer + \"\\\"/></bean> \" +\n            \"</beans>\";\n    }\n"
  },
  {
    "id": "apache_ignite-402-Param-0",
    "old_comment_raw": "@param meta Job metadata.",
    "new_code_raw": "    private JobLocalState initState(GridHadoopJobMetadata meta) {\n        GridHadoopJobId jobId = meta.jobId();\n\n        GridHadoopJob job = ctx.jobFactory().createJob(jobId, meta.jobInfo());\n\n        JobLocalState state = new JobLocalState(job, meta);\n\n        return F.addIfAbsent(activeJobs, jobId, state);\n    }\n"
  },
  {
    "id": "zxing_zxing-679-Param-0",
    "old_comment_raw": "@param bullEyeCornerPoints the array of bull's eye corners",
    "new_code_raw": "  private ResultPoint[] getMatrixCornerPoints(ResultPoint[] bullsEyeCorners) throws NotFoundException {\n    return expandSquare(bullsEyeCorners, 2 * nbCenterLayers, getDimension());\n  }\n"
  },
  {
    "id": "apache_ignite-4205-Param-0",
    "old_comment_raw": "@param cache Cache.",
    "new_code_raw": "    private Iterable<Integer> primaryKeysForCache(GridCache<Integer,String> cache, int cnt) {\n        Collection<Integer> found = new ArrayList<>(cnt);\n\n        for (int i = 0; i < 10000; i++) {\n            if (cache.affinity().isPrimary(grid(caches.indexOf(cache)).localNode(), i)) {\n                found.add(i);\n\n                if (found.size() == cnt)\n                    return found;\n            }\n        }\n\n        throw new IllegalStateException(\"Unable to find \" + cnt + \" keys as primary for cache.\");\n    }\n"
  },
  {
    "id": "spring_projects_spring_session-100-Param-0",
    "old_comment_raw": "@param repository - a bean that implements  ReactorSessionRepository.",
    "new_code_raw": "\tpublic WebSessionManager webSessionManager(ReactiveSessionRepository<? extends Session> repository) {\n\t\tSpringSessionWebSessionStore<? extends Session> sessionStore = new SpringSessionWebSessionStore<>(repository);\n\t\tDefaultWebSessionManager manager = new DefaultWebSessionManager();\n\t\tmanager.setSessionStore(sessionStore);\n\n\t\tif (this.webSessionIdResolver != null) {\n\t\t\tmanager.setSessionIdResolver(this.webSessionIdResolver);\n\t\t}\n\n\t\treturn manager;\n\t}\n"
  },
  {
    "id": "keycloak_keycloak-1294-Param-3",
    "old_comment_raw": "@param redirectToAuthentication if true redirect to flow url. If initial call to protocol is a POST, you probably want to do this. This is so we can disable the back button on browser",
    "new_code_raw": "    protected Response handleBrowserAuthenticationRequest(ClientSessionModel clientSession, LoginProtocol protocol, boolean isPassive, boolean redirectToAuthentication) {\n        AuthenticationFlowModel flow = getAuthenticationFlow();\n        String flowId = flow.getId();\n        AuthenticationProcessor processor = createProcessor(clientSession, flowId, LoginActionsService.AUTHENTICATE_PATH);\n        event.detail(Details.CODE_ID, clientSession.getId());\n        if (isPassive) {\n            // OIDC prompt == NONE or SAML 2 IsPassive flag\n            // This means that client is just checking if the user is already completely logged in.\n            // We cancel login if any authentication action or required action is required\n            try {\n                if (processor.authenticateOnly() == null) {\n                    processor.attachSession();\n                } else {\n                    Response response = protocol.sendError(clientSession, Error.PASSIVE_LOGIN_REQUIRED);\n                    session.sessions().removeClientSession(realm, clientSession);\n                    return response;\n                }\n                if (processor.isActionRequired()) {\n                    Response response = protocol.sendError(clientSession, Error.PASSIVE_INTERACTION_REQUIRED);\n                    session.sessions().removeClientSession(realm, clientSession);\n                    return response;\n\n                }\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n            return processor.finishAuthentication(protocol);\n        } else {\n            try {\n                RestartLoginCookie.setRestartCookie(session, realm, clientConnection, uriInfo, clientSession);\n                if (redirectToAuthentication) {\n                    return processor.redirectToFlow();\n                }\n                return processor.authenticate();\n            } catch (Exception e) {\n                return processor.handleBrowserException(e);\n            }\n        }\n    }\n"
  },
  {
    "id": "spring_projects_spring_kafka-127-Param-0",
    "old_comment_raw": "@param brokerProperties the properties to use for configuring Kafka Broker(s).",
    "new_code_raw": "\tpublic EmbeddedKafkaBroker brokerProperties(Map<String, String> properties) {\n\t\tthis.brokerProperties.putAll(properties);\n\t\treturn this;\n\t}\n"
  },
  {
    "id": "apache_ignite-4895-Param-2",
    "old_comment_raw": "@param missedMap Missed keys.",
    "new_code_raw": "                @Override public void apply(KeyCacheObject key, Object val) {\n                    if (isRollbackOnly()) {\n                        if (log.isDebugEnabled())\n                            log.debug(\"Ignoring loaded value for read because transaction was rolled back: \" +\n                                IgniteTxLocalAdapter.this);\n\n                        return;\n                    }\n\n                    GridCacheVersion ver = missedMap.get(key);\n\n                    if (ver == null) {\n                        if (log.isDebugEnabled())\n                            log.debug(\"Value from storage was never asked for [key=\" + key + \", val=\" + val + ']');\n\n                        return;\n                    }\n\n                    CacheObject cacheVal = cacheCtx.toCacheObject(val);\n\n                    Object visibleVal = val;\n\n                    IgniteTxKey txKey = cacheCtx.txKey(key);\n\n                    IgniteTxEntry txEntry = entry(txKey);\n\n                    if (txEntry != null) {\n                        if (!readCommitted())\n                            txEntry.readValue(cacheVal);\n\n                        if (!F.isEmpty(txEntry.entryProcessors()))\n                            visibleVal = txEntry.applyEntryProcessors(visibleVal);\n                    }\n\n                    // In pessimistic mode we hold the lock, so filter validation\n                    // should always be valid.\n                    if (pessimistic())\n                        ver = null;\n\n                    // Initialize next version.\n                    if (nextVer == null)\n                        nextVer = cctx.versions().next(topologyVersion());\n\n                    while (true) {\n                        assert txEntry != null || readCommitted() || groupLock() || skipVals;\n\n                        GridCacheEntryEx e = txEntry == null ? entryEx(cacheCtx, txKey) : txEntry.cached();\n\n                        try {\n                            // Must initialize to true since even if filter didn't pass,\n                            // we still record the transaction value.\n                            boolean set;\n\n                            try {\n                                set = e.versionedValue(cacheVal, ver, nextVer);\n                            }\n                            catch (GridCacheEntryRemovedException ignore) {\n                                if (log.isDebugEnabled())\n                                    log.debug(\"Got removed entry in transaction getAll method \" +\n                                        \"(will try again): \" + e);\n\n                                if (pessimistic() && !readCommitted() && !isRollbackOnly() &&\n                                    (!groupLock() || F.eq(e.key(), groupLockKey()))) {\n                                    U.error(log, \"Inconsistent transaction state (entry got removed while \" +\n                                        \"holding lock) [entry=\" + e + \", tx=\" + IgniteTxLocalAdapter.this + \"]\");\n\n                                    setRollbackOnly();\n\n                                    return;\n                                }\n\n                                if (txEntry != null)\n                                    txEntry.cached(entryEx(cacheCtx, txKey), null);\n\n                                continue; // While loop.\n                            }\n\n                            // In pessimistic mode, we should always be able to set.\n                            assert set || !pessimistic();\n\n                            if (readCommitted() || groupLock() || skipVals) {\n                                cacheCtx.evicts().touch(e, topologyVersion());\n\n                                if (visibleVal != null)\n                                    map.put(key.<K>value(cacheCtx), (V)CU.skipValue(visibleVal, skipVals));\n                            }\n                            else {\n                                assert txEntry != null;\n\n                                txEntry.setAndMarkValid(cacheVal);\n\n                                if (visibleVal != null)\n                                    map.put(key.<K>value(cacheCtx), (V)visibleVal);\n                            }\n\n                            loaded.add(key);\n\n                            if (log.isDebugEnabled())\n                                log.debug(\"Set value loaded from store into entry from transaction [set=\" + set +\n                                    \", matchVer=\" + ver + \", newVer=\" + nextVer + \", entry=\" + e + ']');\n\n                            break; // While loop.\n                        }\n                        catch (IgniteCheckedException ex) {\n                            throw new IgniteException(\"Failed to put value for cache entry: \" + e, ex);\n                        }\n                    }\n                }\n"
  },
  {
    "id": "apache_ignite-12142-Param-0",
    "old_comment_raw": "@param topVer Topology snapshot for which candidate is added.",
    "new_code_raw": "    public boolean addCandidate(GridDiscoveryTopologySnapshot topSnapshot, GridCacheMvccCandidate cand) {\n        lock();\n\n        try {\n            if (cands.isEmpty())\n                return false;\n\n            assert this.topSnapshot.topologyVersion() == topSnapshot.topologyVersion();\n\n            Deque<GridCacheMvccCandidate> deque = ensureDeque(cand.key());\n\n            GridCacheMvccCandidate old = F.first(deque);\n\n            deque.add(cand);\n\n            if (old != null && old.owner())\n                cand.setOwner();\n\n            return true;\n        }\n        finally {\n            unlock();\n        }\n    }\n"
  },
  {
    "id": "json_path_JsonPath-185-Param-0",
    "old_comment_raw": "@param filterItems items to filter",
    "new_code_raw": "    public Object doFilter(Iterable<T> filterItems, Configuration configuration) {\n        JsonProvider provider = configuration.getProvider();\n        Object result = provider.createArray();\n        for (T filterItem : filterItems) {\n            if (accept(filterItem, configuration)) {\n                provider.setProperty(result, provider.length(result), filterItem);\n            }\n        }\n        return result;\n    }\n"
  },
  {
    "id": "apache_ignite-12201-Param-0",
    "old_comment_raw": "@param srvNodesNum Server nodes number.",
    "new_code_raw": "    private String topologySnapshotMessage(int serverNodesNum, int clientNodesNum, int totalCpus, double heap) {\n        return PREFIX + \" [\" +\n            (discoOrdered ? \"ver=\" + topSnap.get().topVer.topologyVersion() + \", \" : \"\") +\n            \"servers=\" + serverNodesNum +\n            \", clients=\" + clientNodesNum +\n            \", CPUs=\" + totalCpus +\n            \", heap=\" + heap + \"GB\" +\n            ']';\n    }\n"
  },
  {
    "id": "essentials_Essentials-164-Param-1",
    "old_comment_raw": "@param fullPermissionName",
    "new_code_raw": "\tpublic boolean comparePermissionString(String userAcessLevel, String fullPermissionName) {\n\t\tif (userAcessLevel == null || fullPermissionName == null) {\n\t\t\treturn false;\n\t\t}\n\t\tGroupManager.logger.finest(\"COMPARING \" + userAcessLevel + \" WITH \" + fullPermissionName);\n\n\t\tif (userAcessLevel.startsWith(\"+\")) {\n\t\t\tuserAcessLevel = userAcessLevel.substring(1);\n\t\t} else if (userAcessLevel.startsWith(\"-\")) {\n\t\t\tuserAcessLevel = userAcessLevel.substring(1);\n\t\t}\n\n\t\tif (fullPermissionName.startsWith(\"+\")) {\n\t\t\tfullPermissionName = fullPermissionName.substring(1);\n\t\t} else if (fullPermissionName.startsWith(\"-\")) {\n\t\t\tfullPermissionName = fullPermissionName.substring(1);\n\t\t}\n\n\t\tStringTokenizer levelATokenizer = new StringTokenizer(userAcessLevel, \".\");\n\t\tStringTokenizer levelBTokenizer = new StringTokenizer(fullPermissionName, \".\");\n\t\twhile (levelATokenizer.hasMoreTokens() && levelBTokenizer.hasMoreTokens()) {\n\t\t\tString levelA = levelATokenizer.nextToken();\n\t\t\tString levelB = levelBTokenizer.nextToken();\n\t\t\tGroupManager.logger.finest(\"ROUND \" + levelA + \" AGAINST \" + levelB);\n\t\t\tif (levelA.contains(\"*\")) {\n\t\t\t\tGroupManager.logger.finest(\"WIN\");\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tif (levelA.equalsIgnoreCase(levelB)) {\n\t\t\t\tif (!levelATokenizer.hasMoreTokens() && !levelBTokenizer.hasMoreTokens()) {\n\t\t\t\t\tGroupManager.logger.finest(\"WIN\");\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\tGroupManager.logger.finest(\"NEXT\");\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tGroupManager.logger.finest(\"FAIL\");\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t}\n\t\tGroupManager.logger.finest(\"FAIL\");\n\t\treturn false;\n\t}\n"
  },
  {
    "id": "codehaus_coconut-39-Associations-Param0",
    "old_comment_raw": "@param charSequence the CharSequence the predicate will check for",
    "new_code_raw": "    public static Predicate<String> contains(CharSequence contains) {\r\n        return new ContainsPredicate(contains);\r\n    }\r\n\n"
  },
  {
    "id": "apache_ignite-246-Param-1",
    "old_comment_raw": "@param p Partition.",
    "new_code_raw": "        private boolean preloadEntry(GridNode pick, int p, GridCacheEntryInfo<K, V> entry, long topVer)\n            throws GridException, GridInterruptedException {\n            try {\n                GridCacheEntryEx<K, V> cached = null;\n\n                try {\n                    cached = cctx.dht().entryEx(entry.key());\n\n                    if (log.isDebugEnabled())\n                        log.debug(\"Preloading key [key=\" + entry.key() + \", part=\" + p + \", node=\" + pick.id() + ']');\n\n                    if (cctx.dht().isGgfsDataCache() &&\n                        cctx.dht().ggfsDataSpaceUsed() > cctx.dht().ggfsDataSpaceMax()) {\n                        LT.error(log, null, \"Failed to preload GGFS data cache (GGFS space size exceeded maximum \" +\n                            \"value, will ignore preload entries): \" + name());\n\n                        if (cached.markObsoleteIfEmpty(null))\n                            cached.context().cache().removeIfObsolete(cached.key());\n\n                        return true;\n                    }\n\n                    if (preloadPred == null || preloadPred.apply(entry)) {\n                        if (cached.initialValue(\n                            entry.value(),\n                            entry.valueBytes(),\n                            entry.version(),\n                            entry.ttl(),\n                            entry.expireTime(),\n                            true,\n                            topVer,\n                            cctx.isReplicationEnabled() ? DR_PRELOAD : DR_NONE\n                        )) {\n                            cctx.evicts().touch(cached, topVer); // Start tracking.\n\n                            if (cctx.events().isRecordable(EVT_CACHE_PRELOAD_OBJECT_LOADED) && !cached.isInternal())\n                                cctx.events().addEvent(cached.partition(), cached.key(), cctx.localNodeId(),\n                                    (GridUuid)null, null, EVT_CACHE_PRELOAD_OBJECT_LOADED, entry.value(), true, null,\n                                    false);\n                        }\n                        else if (log.isDebugEnabled())\n                            log.debug(\"Preloading entry is already in cache (will ignore) [key=\" + cached.key() +\n                                \", part=\" + p + ']');\n                    }\n                    else if (log.isDebugEnabled())\n                        log.debug(\"Preload predicate evaluated to false for entry (will ignore): \" + entry);\n                }\n                catch (GridCacheEntryRemovedException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Entry has been concurrently removed while preloading (will ignore) [key=\" +\n                            cached.key() + \", part=\" + p + ']');\n                }\n                catch (GridDhtInvalidPartitionException ignored) {\n                    if (log.isDebugEnabled())\n                        log.debug(\"Partition became invalid during preloading (will ignore): \" + p);\n\n                    return false;\n                }\n            }\n            catch (GridInterruptedException e) {\n                throw e;\n            }\n            catch (GridException e) {\n                throw new GridException(\"Failed to cache preloaded entry (will stop preloading) [local=\" +\n                    cctx.nodeId() + \", node=\" + pick.id() + \", key=\" + entry.key() + \", part=\" + p + ']', e);\n            }\n\n            return true;\n        }\n"
  },
  {
    "id": "xetorthio_jedis-802-Param-1",
    "old_comment_raw": "@param integer",
    "new_code_raw": "  public Long decrBy(final String key, final long decrement) {\n    checkIsInMultiOrPipeline();\n    client.decrBy(key, decrement);\n    return client.getIntegerReply();\n  }\n"
  },
  {
    "id": "apache_ignite-2299-Param-0",
    "old_comment_raw": "@param desc File descriptor of file or directory to delete.",
    "new_code_raw": "    private boolean delete0(FileDescriptor desc, @Nullable IgniteFsPath parentPath, boolean recursive)\n        throws GridException {\n        IgniteFsPath curPath = parentPath == null ? new IgniteFsPath() : new IgniteFsPath(parentPath, desc.fileName);\n\n        if (desc.isFile) {\n            deleteFile(curPath, desc, true);\n\n            return true;\n        }\n        else {\n            if (recursive) {\n                meta.softDelete(desc.parentId, desc.fileName, desc.fileId);\n\n                return true;\n            }\n            else {\n                Map<String, GridGgfsListingEntry> infoMap = meta.directoryListing(desc.fileId);\n\n                if (F.isEmpty(infoMap)) {\n                    deleteFile(curPath, desc, true);\n\n                    return true;\n                }\n                else\n                    // Throw exception if not empty and not recursive.\n                    throw new GridGgfsDirectoryNotEmptyException(\"Failed to remove directory (directory is not empty \" +\n                        \"and recursive flag is not set)\");\n            }\n        }\n    }\n"
  },
  {
    "id": "haifengl_smile-371-Param-0",
    "old_comment_raw": "@param posteriori the input/output vector.",
    "new_code_raw": "    public static int softmax(double[] x, int k) {\n        int y = -1;\n        double max = Double.NEGATIVE_INFINITY;\n        for (int i = 0; i < k; i++) {\n            if (x[i] > max) {\n                max = x[i];\n                y = i;\n            }\n        }\n\n        double Z = 0.0;\n        for (int i = 0; i < k; i++) {\n            double out = Math.exp(x[i] - max);\n            x[i] = out;\n            Z += out;\n        }\n\n        for (int i = 0; i < k; i++) {\n            x[i] /= Z;\n        }\n\n        return y;\n    }\n"
  },
  {
    "id": "apache_ignite-5039-Param-1",
    "old_comment_raw": "@param obsoleteVer Obsolete version.",
    "new_code_raw": "    protected boolean evictNearEntry(GridCacheEntryEx<K, V> e, GridCacheVersion obsoleteVer, AffinityTopologyVersion topVer) {\n        assert e != null;\n        assert obsoleteVer != null;\n\n        if (isNearLocallyMapped(e, topVer)) {\n            if (log.isDebugEnabled())\n                log.debug(\"Evicting dht-local entry from near cache [entry=\" + e + \", tx=\" + this + ']');\n\n            if (e.markObsolete(obsoleteVer))\n                return true;\n        }\n\n        return false;\n    }\n"
  },
  {
    "id": "h2oai_h2o_2-386-Param-2",
    "old_comment_raw": "@param replicate_training_data whether or not the training data is replicated on each node",
    "new_code_raw": "  private static long computeTrainSamplesPerIteration(final DeepLearning mp, final long numRows, long model_size) {\n    long tspi = mp.train_samples_per_iteration;\n    assert(tspi == 0 || tspi == -1 || tspi == -2 || tspi >= 1);\n    if (tspi == 0 || (!mp.replicate_training_data && tspi == -1) ) {\n      tspi = numRows;\n      if (!mp.quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to one epoch: #rows (\" + tspi + \").\");\n    }\n    else if (tspi == -1) {\n      tspi = (mp.single_node_mode ? 1 : H2O.CLOUD.size()) * numRows;\n      if (!mp.quiet_mode) Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to #nodes x #rows (\" + tspi + \").\");\n    } else if (tspi == -2) {\n      // automatic tuning based on CPU speed, network speed and model size\n\n      // measure cpu speed\n      double total_gflops = 0;\n      for (H2ONode h2o : H2O.CLOUD._memary) {\n        HeartBeat hb = h2o._heartbeat;\n        total_gflops += hb._gflops;\n      }\n      if (mp.single_node_mode) total_gflops /= H2O.CLOUD.size();\n      if (total_gflops == 0) {\n        total_gflops = Linpack.run(H2O.SELF._heartbeat._cpus_allowed) * (mp.single_node_mode ? 1 : H2O.CLOUD.size());\n      }\n\n      int[] msg_sizes = new int[]{ (int)(model_size*4) == (model_size*4) ? (int)(model_size*4) : Integer.MAX_VALUE };\n      double[] microseconds_collective = new double[msg_sizes.length];\n      NetworkTest.NetworkTester nt = new NetworkTest.NetworkTester(msg_sizes,null,microseconds_collective,model_size>1e6 ? 1 : 5 /*repeats*/,false,true /*only collectives*/);\n      nt.compute2();\n\n      //length of the network traffic queue based on log-tree rollup (2 log(nodes))\n      int network_queue_length = mp.single_node_mode || H2O.CLOUD.size() == 1? 1 : 2*(int)Math.floor(Math.log(H2O.CLOUD.size())/Math.log(2));\n\n      // heuristics\n      double flops_overhead_per_row = 30;\n      if (mp.activation == Activation.Maxout || mp.activation == Activation.MaxoutWithDropout) {\n        flops_overhead_per_row *= 8;\n      } else if (mp.activation == Activation.Tanh || mp.activation == Activation.TanhWithDropout) {\n        flops_overhead_per_row *= 5;\n      }\n\n      // target fraction of comm vs cpu time: 5%\n      double fraction = mp.single_node_mode || H2O.CLOUD.size() == 1 ? 1e-3 : 0.05; //one single node mode, there's no model averaging effect, so less need to shorten the M/R iteration\n\n      // estimate the time for communication (network) and training (compute)\n      double time_comm_us = (H2O.CLOUD.size() == 1 ? 1e4 /* add 10ms for single-node */ : 0) + network_queue_length * microseconds_collective[0];\n      double time_per_row_us  = flops_overhead_per_row * model_size / (total_gflops * 1e9) / H2O.SELF._heartbeat._cpus_allowed * 1e6;\n\n      // compute the optimal number of training rows per iteration\n      // fraction := time_comm_us / (time_comm_us + tspi * time_per_row_us)  ==>  tspi = (time_comm_us/fraction - time_comm_us)/time_per_row_us\n      tspi = (long)((time_comm_us / fraction - time_comm_us)/ time_per_row_us);\n\n      tspi = Math.max(1, tspi); //at least 1 point\n      tspi = Math.min(tspi, (mp.single_node_mode ? 1 : H2O.CLOUD.size()) * numRows * 10); //not more than 10x of what train_samples_per_iteration=-1 would do\n\n      // If the number is close to a multiple of epochs, use that -> prettier scoring\n      if (tspi > numRows && Math.abs(tspi % numRows)/(double)numRows < 0.2)  tspi = tspi - tspi % numRows;\n      tspi = Math.min(tspi, (long)(mp.epochs * numRows)); //limit to number of epochs desired\n\n      if (!mp.quiet_mode) {\n        Log.info(\"Auto-tuning parameter 'train_samples_per_iteration':\");\n        Log.info(\"Estimated compute power : \" + (int)total_gflops + \" GFlops\");\n        Log.info(\"Estimated time for comm : \" + PrettyPrint.usecs((long)time_comm_us));\n        Log.info(\"Estimated time per row  : \" + ((long)time_per_row_us > 0 ? PrettyPrint.usecs((long)time_per_row_us) : time_per_row_us + \" usecs\"));\n        Log.info(\"Estimated training speed: \" + (int)(1e6/time_per_row_us) + \" rows/sec\");\n        Log.info(\"Setting train_samples_per_iteration (\" + mp.train_samples_per_iteration + \") to auto-tuned value: \" + tspi);\n      }\n\n    } else {\n      // limit user-given value to number of epochs desired\n      tspi = Math.min(tspi, (long)(mp.epochs * numRows));\n    }\n    assert(tspi != 0 && tspi != -1 && tspi != -2 && tspi >= 1);\n    return tspi;\n  }\n"
  },
  {
    "id": "azkaban_azkaban-114-Param-0",
    "old_comment_raw": "@param runner runner.",
    "new_code_raw": "  public static Event create(final Object runner, final EventType type, final EventData eventData)\n      throws NullPointerException {\n    Preconditions.checkNotNull(eventData, \"EventData was null\");\n    return new Event(runner, type, eventData);\n  }\n"
  },
  {
    "id": "apache_ignite-12036-Param-0",
    "old_comment_raw": "@param ignite Ignite.",
    "new_code_raw": "    private static TimerTask scheduleQuery(final Ignite g, Timer timer) {\n        TimerTask task = new TimerTask() {\n            @Override public void run() {\n                final IgniteStreamer streamer = g.streamer(\"popular-numbers\");\n\n                try {\n                    // Send reduce query to all 'popular-numbers' streamers\n                    // running on local and remote nodes.\n                    Collection<StreamerIndexEntry<Integer, Integer, Long>> col = streamer.context().reduce(\n                        // This closure will execute on remote nodes.\n                        new IgniteClosure<StreamerContext,\n                                                                            Collection<StreamerIndexEntry<Integer, Integer, Long>>>() {\n                            @Override public Collection<StreamerIndexEntry<Integer, Integer, Long>> apply(\n                                StreamerContext ctx) {\n                                StreamerIndex<Integer, Integer, Long> view = ctx.<Integer>window().index();\n\n                                return view.entries(-1 * POPULAR_NUMBERS_CNT);\n                            }\n                        },\n                        // The reducer will always execute locally, on the same node\n                        // that submitted the query.\n                        new PopularNumbersReducer());\n\n                    for (StreamerIndexEntry<Integer, Integer, Long> cntr : col)\n                        System.out.printf(\"%3d=%d\\n\", cntr.key(), cntr.value());\n\n                    System.out.println(\"----------------\");\n                }\n                catch (IgniteException e) {\n                    e.printStackTrace();\n                }\n            }\n        };\n\n        timer.schedule(task, 3000, 3000);\n\n        return task;\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-955-Param-0",
    "old_comment_raw": "@param itemName unused",
    "new_code_raw": "    private static EcobeeActionProvider getActionProvider(String selection) throws Exception {\n        EcobeeActionService service = EcobeeActionService.getEcobeeActionService();\n        if (service == null) {\n            throw new Exception(String.format(\"Ecobee Service is not configured, Action for selection %1$s not queued.\",\n                    selection));\n        }\n\n        EcobeeActionProvider actionProvider = service.getEcobeeActionProvider();\n        if (actionProvider == null) {\n            throw new Exception(String.format(\n                    \"Ecobee Action Provider is not configured, Action for selection %1$s not queued.\", selection));\n        }\n\n        return actionProvider;\n    }\n"
  },
  {
    "id": "alexa_alexa_skills_kit_sdk_for_java-68-Param-0",
    "old_comment_raw": "@param requestEnvelope request envelope",
    "new_code_raw": "    protected ResponseEnvelope invoke(UnmarshalledRequest<RequestEnvelope> unmarshalledRequest, Object context) {\n        RequestEnvelope requestEnvelope = unmarshalledRequest.getUnmarshalledRequest();\n        JsonNode requestEnvelopeJson = unmarshalledRequest.getRequestJson();\n\n        if (skillId != null && !requestEnvelope.getContext().getSystem().getApplication().getApplicationId().equals(skillId)) {\n            throw new AskSdkException(\"AlexaSkill ID verification failed.\");\n        }\n\n        ServiceClientFactory factory = apiClient != null ? ServiceClientFactory.builder()\n                .withDefaultApiConfiguration(getApiConfiguration(requestEnvelope))\n                .build() : null;\n\n        HandlerInput handlerInput = HandlerInput.builder()\n                .withRequestEnvelope(requestEnvelope)\n                .withPersistenceAdapter(persistenceAdapter)\n                .withContext(context)\n                .withServiceClientFactory(factory)\n                .withRequestEnvelopeJson(requestEnvelopeJson)\n                .build();\n\n        Optional<Response> response = requestDispatcher.dispatch(handlerInput);\n        return ResponseEnvelope.builder()\n                .withResponse(response != null ? response.orElse(null) : null)\n                .withSessionAttributes\n                        (requestEnvelope.getSession() != null ? handlerInput.getAttributesManager().getSessionAttributes() : null)\n                .withVersion(SdkConstants.FORMAT_VERSION)\n                .withUserAgent(UserAgentUtils.getUserAgent(customUserAgent))\n                .build();\n    }\n"
  },
  {
    "id": "openhab_openhab1_addons-1024-Param-0",
    "old_comment_raw": "@param deviceId The bulb id the bridge has filed the bulb under.",
    "new_code_raw": "\tpublic int getBrightness(int deviceNumber) {\n\t\tif (settingsData == null) {\n\t\t\tlogger.error(\"Hue bridge settings not initialized correctly.\");\n\t\t\treturn 0;\n\t\t}\n\t\treturn (Integer) settingsData.node(\"lights\")\n\t\t\t\t.node(Integer.toString(deviceNumber)).node(\"state\")\n\t\t\t\t.value(\"bri\");\n\t}\n"
  },
  {
    "id": "killme2008_Metamorphosis-0-Param-1",
    "old_comment_raw": "@param tmps",
    "new_code_raw": "                private Object decodeBoolean(final IoBuffer buff, final String[] sa) {\n                    this.assertCommand(sa[0], \"result\");\n                    final int valueLen = Integer.parseInt(sa[2]);\n                    if (valueLen == 0) {\n                        return new BooleanCommand(Integer.parseInt(sa[1]), null, Integer.parseInt(sa[3]));\n                    }\n                    else {\n                        if (buff.remaining() < valueLen) {\n                            buff.reset();\n                            return null;\n                        }\n                        else {\n                            final byte[] data = new byte[valueLen];\n                            buff.get(data);\n                            return new BooleanCommand(Integer.parseInt(sa[1]), ByteUtils.getString(data),\n                                Integer.parseInt(sa[3]));\n                        }\n                    }\n                }\n"
  },
  {
    "id": "apache_ignite-12067-Param-0",
    "old_comment_raw": "@param ignite Grid.",
    "new_code_raw": "    public static VisorCache from(Ignite g, GridCache c, int sample) throws IgniteCheckedException {\n        assert g != null;\n        assert c != null;\n\n        String cacheName = c.name();\n\n        GridCacheAdapter ca = ((IgniteKernal)g).internalCache(cacheName);\n\n        long swapSize;\n        long swapKeys;\n\n        try {\n            swapSize = ca.swapSize();\n            swapKeys = ca.swapKeys();\n        }\n        catch (IgniteCheckedException ignored) {\n            swapSize = -1;\n            swapKeys = -1;\n        }\n\n        Collection<IgnitePair<Integer>> pps = Collections.emptyList();\n        Collection<IgnitePair<Integer>> bps = Collections.emptyList();\n        GridDhtPartitionMap partsMap = null;\n\n        CacheConfiguration cfg = ca.configuration();\n\n        CacheMode mode = cfg.getCacheMode();\n\n        boolean partitioned = (mode == CacheMode.PARTITIONED || mode == CacheMode.REPLICATED)\n            && cfg.getDistributionMode() != CacheDistributionMode.CLIENT_ONLY;\n\n        if (partitioned) {\n            GridDhtCacheAdapter dca = null;\n\n            if (ca instanceof GridNearCacheAdapter)\n                dca = ((GridNearCacheAdapter)ca).dht();\n            else if (ca instanceof GridDhtCacheAdapter)\n                dca = (GridDhtCacheAdapter)ca;\n\n            if (dca != null) {\n                GridDhtPartitionTopology top = dca.topology();\n\n                if (cfg.getCacheMode() != CacheMode.LOCAL && cfg.getBackups() > 0)\n                    partsMap = top.localPartitionMap();\n\n                List<GridDhtLocalPartition> parts = top.localPartitions();\n\n                pps = new ArrayList<>(parts.size());\n                bps = new ArrayList<>(parts.size());\n\n                for (GridDhtLocalPartition part : parts) {\n                    int p = part.id();\n\n                    int sz = part.size();\n\n                    if (part.primary(-1)) // Pass -1 as topology version in order not to wait for topology version.\n                        pps.add(new IgnitePair<>(p, sz));\n                    else\n                        bps.add(new IgnitePair<>(p, sz));\n                }\n            }\n            else {\n                // Old way of collecting partitions info.\n                ClusterNode node = g.cluster().localNode();\n\n                int[] pp = ca.affinity().primaryPartitions(node);\n\n                pps = new ArrayList<>(pp.length);\n\n                for (int p : pp) {\n                    Set set = ca.entrySet(p);\n\n                    pps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n\n                int[] bp = ca.affinity().backupPartitions(node);\n\n                bps = new ArrayList<>(bp.length);\n\n                for (int p : bp) {\n                    Set set = ca.entrySet(p);\n\n                    bps.add(new IgnitePair<>(p, set != null ? set.size() : 0));\n                }\n            }\n        }\n\n        int size = ca.size();\n        int near = ca.nearSize();\n\n        Set<CacheEntry> set = ca.entrySet();\n\n        long memSz = 0;\n\n        Iterator<CacheEntry> it = set.iterator();\n\n        int sz = sample > 0 ? sample : DFLT_CACHE_SIZE_SAMPLING;\n\n        int cnt = 0;\n\n        while (it.hasNext() && cnt < sz) {\n            memSz += it.next().memorySize();\n\n            cnt++;\n        }\n\n        if (cnt > 0)\n            memSz = (long)((double)memSz / cnt * size);\n\n        VisorCache cache = new VisorCache();\n\n        cache.name(cacheName);\n        cache.mode(mode);\n        cache.memorySize(memSz);\n        cache.size(size);\n        cache.nearSize(near);\n        cache.dhtSize(size - near);\n        cache.primarySize(ca.primarySize());\n        cache.offHeapAllocatedSize(ca.offHeapAllocatedSize());\n        cache.offHeapEntriesCount(ca.offHeapEntriesCount());\n        cache.swapSize(swapSize);\n        cache.swapKeys(swapKeys);\n        cache.partitions(ca.affinity().partitions());\n        cache.primaryPartitions(pps);\n        cache.backupPartitions(bps);\n        cache.metrics(VisorCacheMetrics.from(ca));\n        cache.partitionMap(partsMap);\n\n        return cache;\n    }\n"
  },
  {
    "id": "natario1_CameraView-169-Param-0",
    "old_comment_raw": "@param sessionType the sessionType to be checked",
    "new_code_raw": "    protected boolean checkPermissions(Mode mode, Audio audio) {\n        checkPermissionsManifestOrThrow(mode, audio);\n        // Manifest is OK at this point. Let's check runtime permissions.\n        if (Build.VERSION.SDK_INT < Build.VERSION_CODES.M) return true;\n\n        Context c = getContext();\n        boolean needsCamera = true;\n        boolean needsAudio = mode == Mode.VIDEO && audio == Audio.ON;\n\n        needsCamera = needsCamera && c.checkSelfPermission(Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED;\n        needsAudio = needsAudio && c.checkSelfPermission(Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED;\n\n        if (needsCamera || needsAudio) {\n            requestPermissions(needsCamera, needsAudio);\n            return false;\n        }\n        return true;\n    }\n"
  },
  {
    "id": "powermock_powermock-139-Param-0",
    "old_comment_raw": "@param type The type of the class where the method is located.",
    "new_code_raw": "\tpublic static Method method(Class<?> declaringClass, Class<?>... parameterTypes) {\n\t\treturn Whitebox.getMethod(declaringClass, parameterTypes);\n\t}\n"
  },
  {
    "id": "apache_ignite-12193-Param-0",
    "old_comment_raw": "@param local Enforce local.",
    "new_code_raw": "    private ClusterGroup projection(boolean loc) {\n        if (loc || ctx.isLocal() || isReplicatedDataNode())\n            return ctx.kernalContext().grid().cluster().forLocal();\n\n        if (ctx.isReplicated())\n            return ctx.kernalContext().grid().cluster().forDataNodes(ctx.name()).forRandom();\n\n        return null;\n    }\n"
  },
  {
    "id": "apache_ignite-11605-Param-1",
    "old_comment_raw": "@param command environment variable name.",
    "new_code_raw": "    private String exec(Session ses, String cmd) throws JSchException, IOException {\n        ChannelExec ch = null;\n\n        try {\n            ch = (ChannelExec)ses.openChannel(\"exec\");\n\n            ch.setCommand(cmd);\n\n            ch.connect();\n\n            try (BufferedReader reader = new BufferedReader(new InputStreamReader(ch.getInputStream()))) {\n                return reader.readLine();\n            }\n        }\n        finally {\n            if (ch != null && ch.isConnected())\n                ch.disconnect();\n        }\n    }\n"
  },
  {
    "id": "apache_ignite-13248-Param-0",
    "old_comment_raw": "@param policy Eviction policy.",
    "new_code_raw": "    public static Integer evictionPolicyMaxSize(CacheEvictionPolicy plc) {\n        if (plc instanceof CacheLruEvictionPolicyMBean)\n            return ((CacheLruEvictionPolicyMBean)plc).getMaxSize();\n\n        if (plc instanceof CacheRandomEvictionPolicyMBean)\n            return ((CacheRandomEvictionPolicyMBean)plc).getMaxSize();\n\n        if (plc instanceof CacheFifoEvictionPolicyMBean)\n            return ((CacheFifoEvictionPolicyMBean)plc).getMaxSize();\n\n        return null;\n    }\n"
  },
  {
    "id": "xetorthio_jedis-781-Param-1",
    "old_comment_raw": "@param member",
    "new_code_raw": "    public Long sadd(final byte[] key, final byte[]... members) {\n        checkIsInMulti();\n        client.sadd(key, members);\n        return client.getIntegerReply();\n    }\n"
  }
]